111
[Music]

foreign

[Music]

hi everyone and welcome back and yes

this time we are doing CompTIA Security

Plus for free just like before and I'm

really excited for this this training

specifically because I've put in just so

much effort into developing it and it's

an awesome learning opportunity as well

I mean there's just so much content to

cover here so many interesting things

that we're going to be talking about so

many related fields with security with

cyber security that you might not even

think about right now is going to be an

awesome journey I I can promise you this

from the very beginning

now Security Plus is also one of the

most requested security trainings out

there so that's another reason why we're

doing this and it's also one of the most

requested ones because it's the exam or

the certification or the learning path

that is perfect for anyone who wants to

become a better security professional or

actually for anyone who wants to become

a security professional because even

though it's it's introductory it's it

and it doesn't take you from Zero to

Hero it still covers so much content

that it doesn't really matter if you're

a developer if you if you work as a sys

admin if you work in networking and

security if you work with Cloud

environments or with mobile devices it

doesn't matter you're going to find

something useful and some security

Concepts that apply to your very job

role right in this training so again I'm

really confident that this content is

going to be useful to you especially

nowadays because security is everywhere

and as I used to say in pretty much

every trading security is going to be

there and there's going to be a need for

security right up until the end of the

world perhaps right especially if it's a

cyber war or something but I I just

cannot imagine a future without

information without information security

without computers without the need to

protect data so if you're just starting

in security and this wonderful domain

you're not going to be left without the

job in your lifetime or even your

grandchildren's lifetimes

so I'm not going to bore you with any

introductory details let's get straight

to the point first things first compared

to our previous video series my previous

video series I I'm still a one man show

here at certified breakfast but compared

to our previous training on scissor plus

a couple of things will change and a

couple of things will stay the same

first of all start with the good news

and the things that will stay the same

the most important one probably it's

still going to be free free as in free

beer right not as in free speech as in

free beer Google the difference if you

need to but there's not going to be any

hidden costs no pay World content uh

nothing actually that requires you to

pay something to access this content of

course if you if you feel that you have

gained something useful if it helps you

move forward in your career in your

studies if it helps you get

certification but if you want to

contribute as little as a coffee perhaps

there are some links in each video

description just to motivate me to keep

doing this and perhaps even I don't know

pay for coffee why not and I know I've

said this before but I'm doing this for

free because I've been through so many

certification exams I've studied ever

since I can remember and I've gathered a

lot of knowledge I have a lot of things

I can tell you a lot of stories and I

can tell you and I I think that the best

thing I can do with all this knowledge

is not just use it you know to pay the

bills and or or buy a house perhaps but

it would be awesome for my own let's say

human satisfaction to know that I was

able to to help out people just like you

right to move forward in their careers

to help them get a better life and

perhaps you know even a more interesting

life because working in cyber security

is never going to be boring

secondly another thing that stays the

same is the completeness of the training

it's not going to be easy uh it's not

going to be short but that's why I'm

doing it because other trainings out

there are painfully living out vital

content especially for the certification

or just skimming over important details

and they don't exactly you know invest

the necessary time and effort and

provide you with enough examples to

understand what's going on in there you

know Neuroscience says that you remember

best when you explain something to

somebody else or when you teach someone

and also thought about wrapping this

around this idea around as in if you're

able to explain something is especially

a complex idea to somebody else who

doesn't know it then that's proof that

you understand it correctly

and I honestly I I don't feel confident

to be able to explain a lot of the ideas

that other video trainings out there try

to explain to me so that's why this is

kind of different right this this type

of training here is a bit more thorough

but I I can bet that it's not gonna feel

like a waste of time to you and thirdly

another thing that's gonna stay the same

and I know that you've told me this in

the comments section a number of times

is the demos we're not going to be just

talking about the tools and the

techniques we're going to demonstrate

them live or at least I'm going to show

you some some examples or some live

websites that demonstrate what we what

we just talked about right because you

know everything works in PowerPoint all

right or on a drawing board but real

life happens outside of PowerPoint so

why not learn how things work in real

life as well

and some things will change first of all

the speed of the content delivery will

be a bit higher and the overall

structure of the videos will be more

condensed more content in fewer minutes

because time is the most precious

resource that both you and I have so why

waste it on useless content now it

doesn't mean that it's going to be a

short training but I just won't be

insisting so much on basic ideas another

thing that's going to change for the

better is one of the things that you've

suggested over and over in the comments

section and that is we're going to map

the topics that we're covering onto the

actual exam objectives you're going to

find this information in each video

description some of the videos will

fully cover a specific exam objective

some of the videos will just uh

partially or just mention some related

exam objectives but they're both going

to be mentioned right there in each

video description so you can put a check

mark If you really wanna put check marks

in it too next to all the exam topics

while you're preparing for the exam I

hope it's going to help you a lot and

finally the last thing that I want to

tell you about in this introduction is

just a couple of things that I like and

a couple of things that I don't like

about the exam and you might say here

well Andrew you know I respect you I

like you as a teacher but why do I care

what you like or what you don't like you

are entitled not to care of course but

the reason why you might care is that

I've been through around 30

certification exams so far uh past 95 of

them all right at least on the first

attempt but having been through so many

certification exams allows me to compare

some things that work with some some

examples that don't really work in uh in

in that exam day right especially when

it comes to expectations what you're

learning versus what's actually being uh

asked of you when you're actually taking

the exam so the first thing that I like

about this exam is that it's vendor

agnostic it's not focused on a specific

vendor out there because there are a lot

of vendors that do security and pretty

much all the it devices nowadays have

some sort of security embedded into them

and CompTIA is vendor agnostic by itself

so it doesn't require you to know how to

configure Cisco switches or how to uh

configure checkpoint firewalls right

examples of course will have to be

vendor specific because we have to work

with a specific product but you get to

develop some skills that you can later

on apply to any vendor out there

another thing that I really like is I

know it sounds like a cliche but it's

the journey it's not a destination but

it's the journey that this exam allows

you to take towards the certification

that is The Learning Journey that is how

many things you'll get to learn and play

with and find out about how they work

how they should be secured things you

should watch out for in your day-to-day

life not not just on your job I mean

we're going to be talking about mobile

phones web apps mobile applications uh

even cars and drones it's not just the

Enterprise realm that benefits from

security it's your each and every phone

and wearable device and everything that

you have at your disposal that has an

electronic chip in it it does have the

potential of having secured implications

so the journey is an awesome one because

this exam takes you through so much

stuff that you'll be learning about

that you're actually going to build some

confidence

when it comes to talking about cyber

security and just to mention a couple of

things that I don't like about the exam

uh first of all is the quality of the

exam questions themselves now of course

this might change the future it's

probably changing constantly so your

mileage may vary I took the exam around

a year and a half ago I've been through

three CompTIA exams so far different

ones mind you and the the quality of the

questions kind of drops the lower you

get in the exam complexity as in network

plus was the worst Security Plus was a

bit of better size plus was the best out

of these three when I say the quality of

the exam questions where I'm actually

talking about is how they are designed

or how good do they manage to explain

the context that requires you to provide

an answer and sometimes you get the

feeling that the question has been

written by somebody who knows less about

C security than you do you know there's

a there's an idea here that the more you

know

the more unsure you become the more

questions you start to ask and that's

exactly what happens with cyber security

as well because there are specific

questions that it's obvious that they

tried to simplify the context simplify

the the actual question so much that it

actually doesn't have enough information

and you're gonna have to assume make

some assumptions about what the question

author had in mind when he or she wrote

that question which is not okay for a

technical exam I mean we're working with

computers we're asking something that

should have one specific single answer

and also not to mention the fact that

many CompTIA questions uh start with the

what is the best way of doing something

and they don't tell you if that best way

is supposed to be the best financially

optimized method or the best technical

method or the best method that is not

going to frustrate the users no just

best it's up to you to guess which best

is it going to be also on the topic of

exam questions second complaint that I

have is that sometimes they're written

in Bad English or like they coming from

a bad translation like a machine

translation perhaps like Google

Translate

I know I'm not a native English speaker

and it's still painfully scratches my my

brain and my eyes when I see a question

in an international exam that is badly

written right and if it's just the way

the question is written it's probably

not going to be a problem because you're

still understand what the question is

trying to tell you but there are

situations where you have some tough

time realizing what is the question

referring to so it's just a bit

frustrating but again if I as a

non-native English speaker can detect

those mistakes that's bad I mean

somebody should review those questions

so be prepared for this now all these

negative traits here all these negative

Parts might sound just like nitpicking

to you which is okay I mean you don't

need a perfect scored pass you can screw

up a couple of questions and you're

still gonna be fine so let's say that

maybe you're not 100 prepared for the

exam but neither is come to you okay

okay so we're going to be following the

exam blueprint even though we're not

going to be following the topics in the

exact same order that they're presented

in in the blueprint simply because I

personally don't agree with this order I

mean I find that there are much better

ways to introduce these Concepts or to

reorder them so that they're going to

make a lot more sense if you disagree

with me feel free to disagree but we're

still going to be covering everything

that needs to be covered so no worries

on that account so we're going to start

talking about threats attacks and

vulnerabilities which is one way of

basically referring to the entire

content of the training right

um malware uh physical attacks password

attacks uh we'll talk about types of

attacks like privilege escalation race

conditions

um buffer overflows are actually

traversal a lot of the things that

you've probably heard about maybe you

don't know exactly how they work I want

to see how they work Network attacks a

lot of attacks in there as well more

categories in here including attacker

categories in which is basically going

to be about in understanding the

motivations behind an attacker behind

hacker

the security concerns associated with

vulnerabilities

especially problems that stem from Bad

configuration on misconfiguration which

is going to be extremely useful on your

on your job if it's in any way related

to security

we're going to talk about security

assessments are not going to be teaching

or learning how to perform a security

assessment we're going to be learning

about a lot of stuff that that's

involved during a security assessment

actually we are going to be learning a

bit about how to perform a security

assessment just not so thoroughly as

other certifications are are trying to

to teach you also penetration testing is

one of the topics that will be covered

just briefly architecture and design or

how to design your networks or buildings

or your applications for security and

how to design infrastructure and when we

talk about infrastructure we're talking

about the physical infrastructure from a

Data Center and also about the cloud

infrastructure which is also a data

center it's just that somebody else's

data center right

application security very important here

we're going to talk about coding

techniques techniques to secure your

application code that's going to be

really interesting here

um cyber security resilience uh talk

about redundancy load balancing how to

make sure that your systems are

resilient and they can handle uh an

interruption in service or a disaster

specialized systems told you we're going

to be talking about things like drones

and and printers and embedded devices

and 5G and whatnot security controls

physical security is also an important

topic if an effort basically talking

about information security in the

virtual world well don't forget about

physical world as well

cryptography not the most exciting topic

but also it's not going to be really

thorough so don't be scared uh pretty

much zero to very little math involved

in here so it's going to be more than

fine to to go through this uh the

scriptography topic here

I implemented Security in network

protocols again a very wide topic here

because a lot of vulnerabilities come

from the way the security protocols were

designed many of them tens of years ago

uh host security that is the security of

your you know workstation desktop laptop

even your mobile devices Network design

again coming back to securing networks

as I said it's not the most intuitive

order of of ideas of Topics in here but

we're gonna try to make it more

intuitive wireless security I don't need

to tell you why wireless security is

important right Mobile Solutions mobile

devices tablets wearables smartphones a

lot of things go into securing those as

well and finally cyber Security

Solutions applied to the cloud because

the cloud kind of works a bit different

than your own data center or your own

applications

identity and accounts in an Enterprise

organization very important thing to

manage and to keep your eyes on

authentication and authorization

Solutions how you verify the identity of

your users it it might be inside of a

company it might be inside of a web app

that you're using or inside of a mobile

app that you're developing a lot of

Concepts apply all over the board public

infrastructure we're going to talk about

here about certificates and let's see

what else we have the incident response

section and methods for organizing in

advance before an incident a security

incident happens during a security

incident and of course what to do if it

already happens and you know you need to

recover from some um from The Fallout

policies processes again not the most

Stellar topics in here but we have to

talk about those as well

um investigation after an incident learn

what happened make sure it doesn't

happen again mitigating controls what

you can fix to make sure that the

incident doesn't happen and we're going

to talk briefly about digital forensics

right CSI stuff in here

and finally governance risk and

compliance some procedures in here uh

some regulations some ways to design

security policies inside of a company so

that you can be sure that you're

minimizing as much of the risk as

possible talk about methods of

categorizing risks and calculating those

risks

and finally I think this is the last

topic actually yeah the last topic is

going to be it's gonna be about privacy

and sensitivity of data right so that's

pretty much what we're going to be

covering in this training as well again

not exactly in this order but we're

going to be talking about all of these

all right with all that being said I

really hope to see you on the next video

and actually if I come to think of it

I would really like to see you on the

last video of this series and I really

like to to see a comment from you

telling me if it if it was useful for

you if it helped you move forward in

your career in your studies in your

whatever you want to do and the security

domain all right so

good luck and let's get started

[Music]

222

[Music]

foreign

[Music]

's name is Security Plus

it's not something security or securing

something

it's just security that's it

and one pertinent question here would be

what exactly are we securing because we

know we're talking about I.T so it

stands for information technology

and security applied to it means that

everything that we're basically securing

is information or data

and that's exactly the answer to all ID

security in the world everywhere

we Implement Security in it what we're

actually doing is securing data or

information

you may think here well Andrew I know

that for example I'm using a VPN to

connect to my work environment and I

know the VPN is a secure connection and

I'm just using it to to gain access to

the to my company's Network and how is

that data security

or another example I'm using a credit

card or Apple pay or Google pay or

whatever to pay for something at a

grocery store and I know that the

transaction is supposed to be secured

but again where is the data how how

exactly are we securing data in there is

there really everything related to data

security or not and I will tell you that

in both those examples there's still

data being involved I mean the VPN

you're using it to connect to your

company network but you're not

connecting it just for the sake of the

connection to your company's Network

just to feel close to the office but

you're connecting because you need

access to some data that is only

accessible from within the company

Network

maybe applications internal applications

maybe databases maybe even your own

email mailbox that's only accessible

from within the company

so at the end of the day you're still

protecting data you're still securing

data now on the credit card example

what's happening in there when that

transaction goes through is that you're

using some protocols and some security

techniques to protect the data the

information that is being sent back and

forth between you the merchant and your

bank right we're protecting your your

credit card information so that it's not

going to be spoofed or stolen by

somebody who's who might be a performing

throttle in transactions and we're also

protecting the contents of that

transaction itself because it pertains

to your buyer profile maybe your your

bank account or everything that's

involved that identifies you as a person

in there so everywhere you look it's

gonna be about securing data it's going

to be about securing information and

since we're talking about security

information

well let's think about this for a second

what's the first thing that comes into

mind if somebody comes to your friend

comes to you gives you a piece of paper

and tells you well that this right here

is some very important and sensitive

information make sure you secure it

what's the first thing that comes into

your mind

well probably it's going to be to hide

it somewhere right so that it's not

going to be visible for anybody who

doesn't have any business knowing that

information hiding that information or I

don't know maybe memorizing it and

destroying the paper but that's just a

quarter case perhaps the first thing

that comes into mind for most people

when we're talking about information

security is about keeping that

information secret and that's exactly

the first pillar so to say of ID

security as well that's confidentiality

making sure that only you have access to

that information or only authorized

people have access to that information

and nobody else now this in real life

can be implemented in a number of ways

just to mention two of them we have

encryption right we are relying on the

fact that we encrypt some information

with some specific key and if we're the

only ones who know that key then that

information is safe because whoever

doesn't have the key has no way of

accessing that information another way

of ensuring confidentiality is by using

some sort of an axis control system that

is a just a simple web page perhaps that

asks you for your username and a

password if you're accessing your email

account you're gonna have to provide a

username and a password and perhaps a to

a second Factor authentication token in

there but again this ensures

confidentiality this is a barrier that

stops other people from accessing data

in your email that you should consider

private right it should be kept

confidential

next pillar of security is integrity and

this one is is not let's say the most

obvious one again it's not the first

thing that people think about when it

comes to securing information because it

addresses the fact that we need that

information even though it might be

secure it might be confidential we need

it to be reliable we need to be able to

consider that information true not

tempered with in order to trust it I

mean uh

let's let's just take an example here

that has nothing to do with

confidentiality you know let's say you

have an online Store with uh you're

sending some products in there and each

product has a specific price now is that

information the pricing information is

that confidential no of course not

everybody can see the prices in there

but you probably need to trust that the

database that stores those product

prices hasn't been tampered with or a

normal user or a hacker doesn't get the

opportunity to change the prices they

have the products that they're they're

actually willing to buy so those are

going to be some some methods in there

which ensure that we have integrity

before that specific piece of data now

luckily this is an example where

Integrity has nothing to do with

confidentiality but luckily

confidentiality by itself also kind of

ensures Integrity as well because well

if we think about encryption for example

if you if you're the only one who knows

the encryption or decrease key of the

specific piece of data then it's it's

also a way of ensuring Integrity because

a potential attacker has no way of

altering or tampering with that data

unless they're actually known the key

right so ensuring confidentiality

sometimes just sometimes ensures

Integrity as well and the third one is

actually the least obvious one is the

the last one everybody thinks about when

it comes to security and that's

availability availability means that the

systems that store data the systems that

ensure encryption and decryption that

ensure authenticated access to that data

they're all working it might be obvious

but

if you have a server that stores a bunch

of information and it's encrypted it's

authenticated it's checked for integrity

it's uh protected behind 10 firewalls

and you lose internet connection to that

server and then that data is useless all

right so availability again it's a very

important aspect even when it comes to

security because that data has to be

available for you to be able to access

it all right another example here would

be let's say that you have that piece of

paper that we talked about in the very

beginning and uh you you lock the piece

of paper in a safe and you bury that

safe

10 feet in the ground and you pour some

concrete over it is it secure yes is the

comfort is the information in there

confidential now yes it is

does it have integrity well yes because

nobody can access it and nobody can

change that information in there do you

have availability no because not even

you can access that information anymore

all right so as you can see there's

there's actually a Triad here there's a

triangle and you're going to see this

depicted in many trainings with the c

the I and a the CIA Triad here because

there's usually when designing security

there's usually the need to develop a

sweet spot a perfect balance between

Integrity confidentiality and

availability because you're you cannot

have all of them

at the max at the same time right and

we're going to talk about this uh also

later on because in many situations the

more security you have

the more difficult becomes to access

that information and the more frustrated

the users are going to be the users

actually need that information

and finally that's the fourth pillar

here and again this is not so obvious

but it's non-repudiation our repudiation

means uh the inability of someone to

deny having performed an action

does this make any sense

well it's a bit harder to understand

here without going into some actual

technical details and examples of real

life implementations of this but suffice

to say that whenever people need to be

held accountable

for example people have sent an email

people have encrypted some piece of

information has have sent some pieces of

information there are methods

mathematical methods actually embedded

in all the security technologies that

allow us to confidently state to the

fact that only that specific person only

Andrew was able to send that data or was

able to generate that data and Andrew

has no way of denying it because Andrew

probably is the only

um is the only person who possesses the

necessary keys or the necessary

permissions to perform those actions and

that is non-repudiation

and when talking about the stages at

which we can Implement security uh we

have uh some starting points from Nest

the National Institute for standards and

technology which defines security as

five distinct functions uh starting with

identification identification of an

incident where you just evaluate what

threats you might be facing you're

developing some security policies you're

thinking about what should be done in

order to avoid a potential incident in

the future followed by the actual

protect phase where you're developing

Security Solutions you're buying

firewalls you're configuring ips's in

your network making sure that the

network is secure the detection phase

where this is more like an uh a constant

monitoring operation where you're making

sure that whatever happens in your

network with your users uh internet or

traffic is monitored validated and

potentially scanned for malicious and

tent then follows the respond phase

where you're actually facing an incident

so this is where you decide how will you

act when a security incident actually

happens when a Cyber attack happens and

we end with the recovery function which

is a way of bringing back into

compliance all the systems affected by a

secret incident as you can see these

phases basically describe the State of

Affairs before during and after a

security incident all right so how does

exactly a security professional's job

look like what does what do they do so

this is of course is not an exhaustive

list these are not all the potential

tasks that a security analyst or an ID

security specialist would do on a daily

basis but we could at least pinpoint a

couple of them first of all configure

devices configure security devices

develop security policies Implement

those security policies of course uh

then follows the a bit boring parts of

the day where there's simply monitoring

events it doesn't have to be boring it

can actually automate this on a lot of

platforms where you actually have to

decide what type of events or what

exactly are you looking for not just you

know digging through all that

information through all those logs

generating by generate by your your uh

your devices

instant response of course this is the

unhappy or unfortunate days where an

actual security incident happens of

course the security professional has to

be the person the Hands-On person

involved in a security incident response

um before reaching an incident of course

this person should be responsible for

planning as well uh that is developing

or at least advising when the security

policies are being developed and as a

let's say sub category of those security

policies we also have these access

control and internal access policies uh

those are the things that most I.T

departments handle whenever people come

into the company or leave the company or

go from one Department to the next

making sure that their permissions are

adequate they have access to the right

applications and to the right networks

and they can actually do their daily

jobs and finally of course the security

professional is going to be involved in

Risk assessments because a risk

assessment even though we have an entire

chapter to talk about this a risk

assessment is very useful because it

tells you where you are and where you

should be

ideally it would also tell you what are

necessary steps that you should take in

order to get from where you are to that

ideal security posture that everybody is

dreaming about so it's about evaluating

how much risk are we currently facing

what can we do and what is a realistic

expectation of minimizing that risk in

the future and realistic doesn't

necessarily mean that it can be done it

has to be financially feasible as well

and while since it all comes down to

people for developing and implementing

those security policies we have some

very specific job roles involved in

security functions so we're starting

with the c ISO that's the Chief

Information Security Officer the lead

person responsible for security in an

organization now it might be that the

department that the ciso belongs to is a

separate Department in itself concerned

with security or it might be as an added

appendix to the IET department now

there's also a lot of discussion here as

to which one is better should security

be its own department or should it be

merged with it because it basically well

refers to information right and it

people are those who actually make sure

that the information is accessible

available and usable by all the

employees in a company and this is

actually the main problem here because

many people agree that the IT department

in a company is focused so much more on

availability on making things work

so that people don't complain

that security is very often an

afterthought it's implemented later on

or not at all or just patched on some

existing solution it's not designed from

the ground up so this is why some people

think that it's better to have a

separate Department concerned with

security rather than merging it with the

IT department and well of course to get

things actually done we need some

technical staff in there we need people

to install devices to monitor them to

configure them and to ideally keep up to

date with current threats and recurring

Technologies so that they know what to

do and uh when they need to be proactive

and we're facing a larger company where

there's a lot of effort put into

securing actual data or information or

intellectual property we might have a

separate Department

led by an information system security

officer or an isso which is only

responsible for securing data that is is

in situations where the rest of the

technical staff is more concerned with

securing let's say network devices

servers virtual machines Cloud

environments and so on well the

information security officer is

concerned with actual data and it might

not even be

solely about Digital Data it can also be

about printed information as well and

don't forget that we also have

non-technical staff involved in Security

First of all because well the

non-technical staff actually uses the

systems that we're trying to to protect

those are the other all the other

employees in our company of course they

they might not be technical staff and

also we have non-technical staff in HR

because there are involved in developing

employee policies and security policies

that apply to employees as well and also

we have non-technical staff on the legal

department because cyber crime might

have legal implications and we need

someone on the legal department to

understand what's going on in there and

just wrap this up we also have some

dedicated departments that might or

might not exist depending on the profile

of the company or how big the company is

or how security concerned the company is

and we're gonna find some let's say

traditional business units or

departments and a couple of companies

here starting with the uh the department

that deals with incident response and

this one has a number of names it could

be a computer instant Response Team it

could be a computer security is a

response team those are the people which

might not even be solely assigned to

that single job responsibility but those

are the people that are involved that

are gonna get a call when a security

incident is detected when a security

incident happens when an attack happens

and we could also have a security

Operation Center or an SOC which is a

let's say a department that handles

pretty much everything related to

security but in most cases in most

companies and by the way you're gonna

find this only in large companies or

state-owned companies uh this is going

to be a department that deals with

monitoring keeping an eye on potential

threats on external attacks on uh on

updates on zero days or exploits that

have uh that have appeared from one day

to day

it's a lot of effort involving here it's

a constant uh work that never ends so so

it's a really big cost factor in

maintaining an SOC as we said before

don't forget we also have the or we had

traditionally had the I.T Department to

handle everything related to it

including some security functions right

sometimes we don't even have a dedicated

security department and IIT is going to

handle everything uh don't forget that

it nowadays and infrastructure that is

managed by that I.T Department might be

on premises as well as in public clouds

and finally we have a department that is

uh it's a bit atypical not so

traditional as the other ones which

stems from the devops movement you know

the movement that tries to befriend both

developers and sysadmins or operations

people this one happened

or gained traction lately because uh

along with the development of automation

tools because we can treat

infrastructure now as code we can

configure virtual devices using Code we

can do a lot of things in an automated

manner we can even configure security

completely automated from a single

centralized point for an entire

environment for an entire infrastructure

and all these all these developments

have been merged into all these all

these Technologies all these tools have

emerged Under the devops Umbrella so

it's Automation and software development

and Automation in infrastructure

management so devsecops is a natural

Evolution that tries to implement

Security on all stages of this

automation pipeline starting from the

very beginning when the software is

developed from from with the developers

ending with the uh the deployment phase

where the soft software or the code or

the application actually runs on a

dedicated infrastructure it might be

virtualized it might be containers it

might be somewhere in the cloud it might

be on premises or no in a client's data

center it doesn't matter but nowadays we

have the tools to automate this entire

process from development to deliver your

deployment so we'd better make sure that

we don't forget about security somewhere

in between

so devsecops is basically security

embedded at every stage in the

development Pipeline and also in the

deployment phases that ensure that the

end product reaches the hands of its

users is this a separate Department

probably no but it involves people from

both development and it operations and

it requires both of them to be aware of

each other and also to be aware of these

security implications that they they

might be facing

all right that's it about information

security and roles I told you that we're

not going to be wasting any more time so

that's it for now see you on the next

video If you like this share a comment

in the comment section like And

subscribe and see you next time

[Music]


333

[Music]

foreign

[Music]

security controls is a term that you'll

find very often in a lot of security

trainings and it basically means a

control is something that helps you

become more secure it could be as simple

as a guideline or a policy it could be a

rule in the configuration of a firewall

it could be the firewall itself the Box

itself it's something a it could be

technical it could be administrative it

could be anything that helps you improve

your security posture so as a security

professional of course you need to

understand what the potential controls

are and also when we talk later about

security Frameworks you need to

understand how those Frameworks help you

choose the right security controls for

your company for your environment for

your needs so what do we mean exactly

when we say that the security control is

supposed to give you more security well

it's actually one of three right

remember we talked about CIA Triad the

confidentiality integrity and

availability well we have controls

dedicated to increasing the amount of

confidentiality Integrity or

availability that they provide to your

applications to your networks to even to

your your end users so security controls

address one or more of these three

pillars of security so let's see what

are the categories of security controls

from the perspective of how we're

choosing them in order to implement them

and this simplest type of control is the

technical control it could be Hardware

it could be software so it could be a

device a physical box that you're

installing in a network it could be a

softer a softer solution a security

solution that you're installing on a

server or a virtual machine or it could

just be

some piece of configuration that you did

not have before that you chose to

implement right now because you've

determined that it would improve your

security posture also if you think about

the hosts the endpoints the computers

that the employees are working on uh

technical controls on those computers

could be anything ranging from the

firewalls or the antivirus that is

installed on those those devices and

maybe even the fact that you're

demanding that every single mobile

device in the company has to have some

sort of a fingerprint or face ID

recognition enables in order to be

accepted in a company that type of

authentication is also a type of

technical control and you're going to

find technical controls uh called

logical controls as well regardless if

they're implemented as Hardware or as

software the next category are

operational controls these involve the

human factor so this so we have a

control that relies on humans in order

to be implemented it could be a training

program for your employees it could be

even be the fact that you're educating

the front desk staff on how to check or

validate the IDS of the people coming

into the building and finally we have

managerial type of controls these refer

to high-level policies and strictly when

talking about security controls a

manager control is the way that we

decide from top level management on how

to choose the rest of the technical and

the operational types of controls how do

we decide when to buy a firewall how do

we decide which firewall will buy and

how do we decide if we need a firewall

or not that's some type of managerial

control we also have another way of

categorizing these controls and this is

by the way that they are designed to

help us improve our security posture so

what how exactly do they act and how

exactly do they help us improve our

security posture let me give you a first

example preventative controls these are

controls that prevent a security

incident from happening it could be

anything from a firewall for example

that doesn't let any traffic initiated

from the outside to reach our internal

Network which means it's not going to

let any attacker attempting to exploit

perhaps somebody uh or a computer inside

of our Network coming from the outside

it could also be an access list blocking

per specific protocols or ports or

applications from reaching another

segment of the network anti-virus

Solutions are preventative as well they

don't allow the execution of a program

if they detect malware code in it so it

prevents a security incident from

happening next category detective

controls now these controls might not

stop the incident but they're going to

detect it they're going to log it

they're going to record as much

information as possible because that's

going to help you later on understand

what you did wrong what happened in

there who was affected how did the

attack come to happen and and learn some

lessons for the future so that in the

future you get a chance to avoid such

incidents a detective control could also

be a system that simply alerts when

something abnormal happens it might not

need to block the incident from

happening at all but it might be useful

to generate an alert so that somebody

else perhaps a human

could intervene and decide whether it's

actually a reason for concern or not

another category are corrective controls

these attempt to correct to recover

after an incident so they're going to

help you bring your system back to a

functional state or backed compliance

after an unfortunate incident has

happened what's the first thing that

comes into mind here think about backups

you lost some data you lost the database

you got a database corrupted destroyed

you lost perhaps something not just

because of a Cyber attack but because I

don't know the power source failed on a

server maybe maybe there was a flood in

the data center all right if you have a

backup in place that's going to be a

type of corrective control that's going

to help you come back to a functional

state from before that incident even

happened another one is deterrent type

controls now the deterring controls

might not again might not actually

prevent the instant from happening but

might discourage potential attackers or

potential Intruders from actually you

know performing something malicious it

could be something as as simple as a

sign that says this is private property

it doesn't have to say that trespassers

will be shot but it's private property

so you will be prosecuted if you are

found within this perimeter without

proper authorization it could be a

banner on some devices it could be just

lighting over the parking lot over the

building entrance it could be CCTV or

cameras installed in there it could even

be cameras that don't even work because

people see that there's a camera in

there and they might be discouraged from

performing some malicious actions though

that's a deterrent type of control uh

funny one is decompensating controls

it's the at least we have this type of

control it's actually a type of control

that we were implementing in a situation

where we're not able to implement the

the control that we should

so let's say that we are not uh we

should invest in a new firewall we don't

have the money for it right now we can

only buy that firewall six months from

now what we do in between what we do

until uh we're able to to purchase that

firewall where we might think about

maybe installing some uh some other type

of device in there maybe a router with

some firewall functionality maybe

disabling some some services that are

not critical just to lower our exposure

that's some type of compensating control

if we cannot do what we should be doing

uh at least we're doing this and finally

we have physical controls don't forget

about physical security as well we're

going to have a separate chapter and

discussion about those but physical

security means actually uh those systems

those uh those controls that deny or

check or permit access into secure areas

of a building a simple door with a lock

can be considered a a security control a

a physical security control again uh

monitoring CCTV uh guards even guard

dogs closed doors authentication using

uh Biometrics or or RFID cards those are

all physical security controls

now we briefly talked about Frameworks a

couple of minutes ago and the reason why

Frameworks exist is because there's just

so much complexity when it comes to

securing a company when securing the

network the servers the cloud

environments the applications the uh the

computer endpoints the mobile devices

the building access systems the physical

security everything else is so much

complexity in there and so much variety

between the offerings of multiple

vendors that you're gonna run into some

analysis paralysis when trying to decide

where exactly you should be investing

and what exactly you should be

purchasing in order to secure to secure

a company so a framework is some sort of

a guideline that is going to help us

step by step not only to identify the

necessary uh security

items or the the security controls that

we should be investing in but also

deciding where exactly we are at the

current moment how secure are we e what

type of business we have or what level

of security we should be aiming for and

we have a number of of such Frameworks

some of them are regulatory that is uh

there are some guidelines specific

guidelines that tell you how should you

be processing credit card transactions

for example and it's not just the

guideline it is it's it's more than that

it's it's basically a checklist that if

you don't comply with it you're not

allowed to do credit card business

now on the other hand we also have

non-regulatory Frameworks as well which

basically tell you well if you are a

small to medium company that deals in

this area with these types of services

and applications and you have a network

that looks like this that you should

probably invest in something like this

so that's just a guideline in which you

decide you get to decide how much you're

you're willing to invest what type of

Security Solutions you're willing to to

bring into your environment but it's

it's not mandatory it's up to you and

just to mention a couple of these

because you might find them in the exam

as well from nist again the National

Institute of Standards and Technology we

can find the cyber security framework

the CSF this one is solely focused on

IIT security and it's a bit more focused

on the on the US the United States way

of doing things in cyber security some

of these some of these Frameworks are

more focused on a specific region in the

world some of them are more

International also from honest we have

RMF that's the risk management framework

which again is focused more on the US

but more on the federal government

and we have fips that's the federal

information processing standards which

is pretty self-explanatory right also

developed by Nest you don't really have

to dig so deep within these Frameworks

uh you just have to recognize these

names for the exam that should be more

than enough

then we have the Frameworks from ISO and

you're probably recognizing the

27001 standard because that's one of the

standards that a lot of companies

nowadays are trying to achieve and they

pay good money for uh for Auditors and

for uh for a helping hand in in gaining

this type of certification now from left

to right you don't really need to know

about all of these but we should at

least mention them once just in case you

you'll encounter them in in the exam so

we have

27001 which is a generic security

standard when it comes to information

information technology and information

security uh then we have uh zero zero

two which which is about the

classification of security controls we

have 017 and 0 18 which focus on cloud

environments and securing Cloud

applications and Cloud infrastructure

and finally the 27

701 the last one here on the list this

is about privacy and uh ways in which

you should or should not be processing

personal data another one worth

mentioning here is the iso 31k so uh

well 27k focuses on information security

the 31k focuses on risk management and

since we're in the age of the cloud we

also have the cloud security Alliance or

the CSA which develops a number of

Frameworks in an attempt to land a

helping hand to cloud service providers

that are those are might be public Cloud

providers such as you know Google Amazon

Oracle and Microsoft and so on or

smaller Cloud providers so CSA publishes

some some architectural guides best

practice guides these are going to be

called security guidance we also have

the Enterprise reference architecture

which refers to specific tools that are

supposed to be used by these cloud

service providers and finally the cloud

control Matrix is a publication that

tries to list the recommended Security

Solutions the security products involved

in providing cloud services and finally

and I promise you this is the last one

because I know this is boring we have

the

ssae Frameworks which stands for

statements on standards for attestation

engagements which is something that you

will never remember

which are just audit specifications for

companies that aim to provide some type

of hosted Services hosting data centers

hosting networking equipment servers or

applications or data it's basically a

checklist to to prove to the to the

customers ultimately that the the

provider itself has reached a a certain

level of Professional Standards when

delivering those services or providing

those those hosting services and we have

here SOC two and three SOC stands for

service organization control which is a

way to evaluate the the controls

implemented by the the hosting provider

itself so what do they use to protect

data or to protect access to the

infrastructure that is hosted by them

and we have a number of reports in here

we have the soc2 type 1 report which uh

it's a way to demonstrate that the

design of the system complies with

specific standards while the type 2

report actually focuses on real data

monitored data that shows how those

systems have behaved in the last let's

say three or six months

so the first one is a more theoretical

description the second one is actually

proving that you are complying with

those standards now of course these two

types of reports the soc type 1 and type

2 us are most likely uh private because

they provide a lot of information about

the internal infrastructure of that

service provider which should not be

public knowledge because it's going to

help potential attackers in developing

customized tools to attack that

infrastructure so this is why we also

have an SOC 3 type of report which can

be freely published and it's less

detailed but IT addresses the common

security concerns of the customers in

order for them to sleep soundly at night

knowing that their infrastructure their

data is secured according to best

practices and up-to-date security

policies now a specific type of

Frameworks are benchmarks now benchmarks

go a little deeper in detail as to how

exactly you should be implementing those

Security Solutions described in a high

level overview inside of those

Frameworks so the framework tells you

how things should look like well the

benchmark

actually tells you what you should do or

where you're lacking the necessary

security controls now one of the most

well-known organizations worldwide is

the CIS the center for Internet Security

they generate benchmarks for security

oriented benchmarks for a lot of

products we have benchmarks focused on

validating compliance with specific ID

Frameworks we also have benchmarks

focused on validating specific

configurations on on desktop PCS or in

servers on Windows and Linux or Mac OS

there's also a CIS Benchmark for example

for for Docker just uh just give an

example here for the docker installation

if you don't know exactly how you should

be securing Docker because let's say

it's a it's a bit of a newer technology

you've just implemented it in a company

you don't know how to secure it you run

a CIS Benchmark in here and it's going

to scan your entire Docker installation

it's going to look for all the

configuration items that it can find

it's going to give you a report and and

a grade is important report telling you

this is where you're awesome this is

where some configuration items need

attention and this is where you

absolutely suck in the way you've

implemented security you're lacking for

example encrypted traffic between the

docker client and the docker server

that's just an example of a report line

included in such acis Benchmark so it's

it's going to provide you with a huge

amount of information but very

addressable immediately addressable

information because you know exactly

what you need to do

to increase your security posture people

tend to forget about this one but

vendors the actual manufacturers of

router switches servers and databases

and storage devices and whatnot they

actually develop their own internal

security documents and guidelines and

and design guides to help you secure

their own Solutions and they know their

Solutions best right they know what to

advise you how to advise you in order to

learn how you should Implement those

devices those products in a secret

manner so don't forget about vendor

documentation they all do it all the

major vendors do it you just have to

search for it

and since the vendor documentation is of

course vendor specific we also have some

type of documentation that is not so

vendor specific just to give you two

examples here we have the Department of

Defense Cyber Exchange this one provides

some technical guidelines to help you

choose the necessary software and

Hardware configurations in order to

better secure your systems but not

focused on a specific vendor and finally

the national checklist program this one

again is a benchmark created this time

by Nest we keep running into Nest on

every presentation apparently which

helps you define the current posture and

the necessary tasks that you should

address for all the major operating

systems out there in the market and I

know I'm repeating myself but don't

forget that every time you talk about

infrastructure you should address the

cloud infrastructure as well so it's not

enough just to physically secure or

logically secure your own data center if

some of your applications are actually

running in somebody else's data center

like in a public Cloud that's a

completely different way of managing

things in there it's a completely

different architecture different

infrastructure you don't have that much

control over the low level part of that

infrastructure so you need to address

security completely different when you

go from on-prem to the cloud just

remember this now the benchmarks and

Frameworks of course take this into

consideration you just have to don't

forget that there's also a cloud part of

your infrastructure and that needs some

TLC

and finally don't forget about

applications because we've talked about

securing environments infrastructure

devices and so on but at the end of the

day all that infrastructure is there to

serve code to serve applications right

so the way the applications are

developed and the way the applications

are secured more or less is going to

have a big impact on your overall

security posture that's why many

benchmarks and many Frameworks actually

address not the infrastructure on which

the application is running but the

application code itself and of course

since nowadays we have such a wide

variety of applications we have specific

benchmarks and tools and guidelines to

help us for determining the software

flaws and software issues that might

might arrive from a badly configured

application for web applications for

mobile applications and even for

microservices applications running in uh

in containers managed perhaps or scaled

by something like kubernetes

and since we mentioned that the

beginning of this episode that there are

Frameworks on the more mandatory side

well here they are they're called

standards and regulations you have to

abide by these regulations if you plan

on doing business in a specific

territory with a specific type of data

or interacting with a specific entity a

special governmental entities so just a

brief glance over the major ones here we

have gdpr General data protection

regulation widely known in in Europe and

European Union which is strongly focused

on privacy and protecting personally

identifiable information we also have

the glba the ground bleach Bailey act

for financial institutions

sarbanes-oxley or Sox makes sure that

all the companies major companies at

least properly Implement things such as

selecting security controls performing

risk assessments and so on next up we

have the computer Security Act which

requires uh Federal institutions to have

proper security policies for any system

that processes private or confidential

information

fisma the federal information security

management act again pretty

self-explanatory addressing Federal

governments HIPAA includes a number of

procedures and policies that dictate how

medical records should be processed

and how patient information is supposed

to be transferred store for how long how

it should be secured CCPA is the

California consumer Privacy Act pretty

similar to gdpr but it's one example of

a of a regulation that applies only to a

single state like California and finally

PCI DSS focused on credit card

transaction and any kind of institution

or a company that processes payments

using credit cards of course you do need

to have some sort of infrastructure uh

well secured infrastructure in place in

order to be part of an entire system

that processes credit cards so that's

why we have a specific regulation that

addresses this specific use case

it stands for the payment card industry

data security standard

all right that's it about Frameworks and

benchmarks if you like this leave a

comment like And subscribe and see you

on the next video bye

[Music]


444

[Music]

foreign

[Music]

so let's talk about attacks and attacker

categories but before we get a chance to

actually figure out what's going on

during an attack or how to mitigate it

there's a process that companies should

go through which is called a risk

assessment and the risk assessment aims

to clarify or to specify exactly what

type of risk and how much risk are we

currently facing right how risky it is

to continue doing business as we're

doing right now but in order to Define

what exactly we need for that risk

assessment we're going to have to focus

our attention on two major areas in

security the first one being the

vulnerabilities that we currently have

in our systems now a vulnerability is

any kind of weakness that makes it

easier for an attacker to perform an

attack on our system it could be a flaw

in Hardware it could be a software

vulnerability it could be a

misconfiguration it could be that you're

lacking some sort of a security control

that you simply forget to enable

encryption on a link for example it

could be the fact that we're not

validating we're not checking the input

that we're receiving from our users it

could be any number of things but if

vulnerability is a weakness that could

be exploited by an attacker second one

is the threat now the threat is the

actual potential of something or someone

or an attacker or an unfortunate event

of exploiting that vulnerability the

threat needs to be measured as well

because we could know that we actually

have vulnerability in there but we could

also let's say prove that the

vulnerability cannot be exploited

because it requires I don't know maybe

perhaps physical access to the system

and we we know for sure that nobody has

physical access to the system so we

could have a high vulnerability with a

low threat or vice versa that's why

we're combining these two not in exactly

in a mathematical operation but we're

combining them inside of a risk

assessment report so we say that the

risk represents the vulnerability and a

specific threat associated with that

vulnerability so to determine if we

actually have a type of risk that's

worth considering we need to know

exactly what's the vulnerability that we

have and how likely that vulnerability

is to be exploited now there used to be

a time when Security in it basically

meant scanning for viruses and we didn't

really have that many viruses out there

we had a some very well maintained

databases with static signatures in

there and that was about it well

nowadays attack techniques and attackers

have become so complex that we simply

cannot rely on static signatures anymore

so nowadays we don't just focus on the

vulnerability itself we also focus on

the attacker the attacker type their

motivation their intent perhaps in order

to understand what are the end goals of

that attack in order to understand how

an attack might behave even if we don't

have a static signature to detect it

right out of the box alright so I have

to focus on a couple of attacker

attributes which were developed over

time in order to better characterize the

persons or the groups behind the cyber

attacks nowadays and one of the first

things that we should focus on is

whether the attackers are internal or

external now an external attacker is

probably the idea that you have in your

mind about a let's say normal hacker out

there so it's somebody who doesn't have

access to a company or to a network and

tries to to break their way into

circumvent some security systems to

bypass some authentication methods and

to gain access to some confidential

information that's the external attacker

the one that doesn't have any kind of

privileges and has to find a way to

penetrate that that enclosed perimeter

which might be a logical perimeter if

it's if it's just a company Network now

on the other hand we also have internal

attackers and internal attackers also

known as Insider threats are actually

even more dangerous than external ones

because an internal attacker is

basically somebody who already has

access already has some level of

privileges inside your network and

decides one day to do some nasty stuff

enough it could be an employee it could

be your colleague it could be a a

business partner that has VPN access to

some of your applications if somebody on

the inside suddenly decides to perform

some malicious actions they're going to

be that more dangerous because they

already have

some level of privileges which the

external attacker doesn't have and so

they get a head start a dangerous Head

Start

we also have to look at intent what is

the actual reason behind that attacker's

attack do they want to destroy data do

we want to deface some websites do they

want to steal confidential information

do they want to hold Ransom some piece

of data for you to to pay in return for

that data this is also one of the things

that needs to be understood in order to

better mitigate attacks also related to

intent we find motivation motivation is

more on the psychological side of things

I mean if it's an internal threat an

Insider threat the motivation might be

that it's just a disgruntled employee

employee somebody who is not content

with the the current way the business is

being conducted

so they have some sort of grievance

against management or against the

company they could be somebody who

militates for specific rights or laws

that they don't agree with they could be

motivated by greed of course a lot of

the uh the financial threats out there

are motivated by greed an intent to

steal money and sometimes you even find

motivation behind curiosity because some

people are just curious to see well is

this is this system something that I can

buy best can I can I crack the system

can I gain access to this database just

to see if I can and they want to do this

just to see if they're able to do it

it's like a challenge to them and

finally we can look at capabilities this

is the amount of resources that the

attacker has at their disposal in order

to conduct their attacks now it might be

just somebody has decided one day to use

some freely available tools on the

internet so they don't really have any

resources available it's just that they

have the right tools to conduct the

attack but a more dangerous alternative

to this is an attacker or an attacker

group that actually invests time effort

money into developing custom tools that

Target specific companies or specific

people in order to conduct some attacks

that are so customized so new that

nobody can detect them perhaps not even

a while after the attack has completed

so when talking about ways to categorize

threats we also have to look at the

attacker types the first type that we're

going to be talking about is the hacker

you might think well aren't they all

hackers why why is there anything else

beside the hacker well the hacker is

just a generic term that that's true but

one one important thing here to remember

is that the term hacker even though

nowadays does have a bad name attached

to it now historically the hacker was

actually a person who was able to use a

system

in a different way than the system was

designed for

now if you think about it it's still

this definition still stands because

hackers actually manage to exploit

authentication systems make applications

execute foreign code or crash

applications or crash online services or

access confidential information and

those are all operations that the

hackers are performing which those

targets should not allow them to perform

so they're actually using them outside

the way that the database the website

the application was designed so that's a

hacker and you've probably heard about

black hat hackers white hat hackers no

black hats are the bad hackers right the

ones that are actually pursuing you know

financial interest uh they're trying to

destroy the face websites or steal

confidential information on the other

hand we have white hat hackers we also

call them penetration testers because we

use them to research vulnerabilities to

test for vulnerabilities and they

immediately report them in order for

them to be fixed and somewhere in

between we find also gray hat hackers

which might have you know mixed feelings

about whether they report the

vulnerabilities that they find or not or

we also sometimes consider gray hat

hackers to be those who find

vulnerabilities find weaknesses in

software or in in public publicly

available products in order to gain a

financial advantage by reporting them

and accessing something called a bug

Bounty because many companies out there

will actually pay security analysts and

security researchers that are able to

find flaws and defects in their products

and report them back to them right so

instead of going ahead and exploiting

the affordability for your own gain you

go to the company tell them I just found

this in your code and they give you a

reward for it right now of course they

then they move on to fixing that that

flaw in their code so we consider gray

hat hackers somewhere in this area as

well next we have the script kitties

they're not actually kitties but but

these are hackers who use hacking tools

without understanding how they work they

just download a piece of software that

says this this piece of software is

going to crack the password from a zip

archive or this piece of software is

going to launch a denial of service on a

web server you just have to enter the IP

address in there and click a button it's

not going to tell you what it does you

don't even know how it does don't might

even not know how a denial service

actually works but that software is

going to do its job

you just have to use it right hackers

who use tools like these without actual

having knowledge hacking knowledge about

them these are called Script kitties

activists are most likely hackers who

have some sort of a political agenda

behind them they are militating for or

against some governmental position some

sort of a party or any type of

legislation or things that are happening

in the public space where they're living

or around the world so basically the

term comes from the term of activist but

they're using hacking tools to reach

their objectives

next we have the apts or the advanced

persistent threats and this is this term

has sort of a double meaning now the the

first meaning of the term actually

refers to the attack itself so advanced

persistent threat means some sort of an

attack which has the ability of

maintaining access to a system not just

gaining access and doing something and

then leaving but also maintaining access

over time perhaps Gathering data over

time maybe uh covering its tracks there

are a lot of examples in the media of

apt's attacks that have been detected

even months after they have been

initially installed these are the types

of attacks where hackers manage to

install their own tools their own

software inside of a company and they

manage to keep it hidden in there for

months or years in row silently

monitoring Gathering data or sending or

altering information inside the systems

of that company the second meaning of

this term actually refers to the group

that is conducting such attacks as you

can probably guess conducting such an

attack is no easy business and usually

requires customized tools customized

attack methods perhaps even combined

with social engineering and other attack

vectors and the group that are

performing these attacks that are behind

those tools are called apt groups now of

course the APT groups are right now only

the ones that we know about so these are

the APT groups that have been identified

historically identified where we have

some limited certainty that they are

located in a certain country and they

are behind certain attacks because we

cannot be always sure 100 sure which apt

group is actually behind on attack even

if they claim to be so this website

right here provides you with a short

overview of the known apt groups out

there you can see that the naming

convention here is not awfully original

it's apt followed by a number 39 35 34

40 something I believe that right now

are we are around 40 or 50 or so uh

again it doesn't mean that these are all

the APT groups groups out there it's

just the ones that we've been able to

identify next we have criminal

syndicates which are which are somehow

related to apt groups because in most

cases apts are actually related to cyber

crime as well and organized groups

at the level and complexity of Apt

groups are more often than not sponsored

by dedicated countries and governments

out there so the goals here could be

just theft it could be Espionage it

could be uh Gathering military

intelligence and so on but criminal

syndicates not only that they can have

political motivation behind them but

they usually Target critical

infrastructure at the level of an entire

country like energy gas oil and so on

and one of the reasons why cyber crime

becomes so difficult to investigate is

the fact that there are no clear

boundaries who is located where who is

attacking who which resource is located

under whose jurisdiction and so on

everything is sort of a Blurred Lines

when it comes to cyber attacks so that

they're extremely difficult to detect

mitigate and unprosecute and finally

last type of attacker which is kind of

obvious right it could be a competitor

of your company the reasons here might

be to put you out of business to make

you lose some some part of your market

share to steal some intellectual

property from your company or sometimes

just to damage the reputation of a

specific vendor or a specific company

and as you can probably guess a lot of

the situations where competitors were

attacked led by competitors are

successful rely on Insider threats it

might be somebody that is currently

working in your company that has been

bribed or motivated in some other way or

threatened by a competitor or it could

be somebody that has left your company

and has started working for a competitor

alright so a special category of

attackers and a really dangerous one for

that matter is The Insider threat as we

said before The Insider could be your

colleague somebody who is part of the

company and the big problem here from a

security perspective is the fact that if

they decide one day to act in a

malicious manner they already have

access inside of the company they

already have some level of access even

if they're just a regular user regular

employee and not to mention the

situation when The Insider threat comes

from a person in the IT department they

probably already have admin rights over

the network devices over the hosts in

their Network so there's a huge risk

right here inside of your network inside

of your company if at some point an

employee decides to go Rogue then the

big problem here is that they're just so

difficult to detect because if you're

dealing with somebody who already has

access to the security devices to the

the logs that are being generated the

event logs that are being generated for

potential security incidents and they

have access to those storage devices of

course they can tamper with them so

sometimes detecting an Insider threat

might be the most difficult part of

Defending Your Network

and we have to also make a difference

here between intentional and

unintentional Insider threats and I

think everybody can guess what an

intentional Insider threat might look

like right it's just somebody who

decides one day to to act in a malicious

manner to steal some data to tamper with

the company's database and to

impersonate another user to commit fraud

perhaps by tampering with or generating

fake invoices or by stealing data so

that it could be provided to a

competitor but what about unintentional

threats well unintentional threats

usually stem from the fact that most

users are not so security aware not just

in I.T companies but in companies

everywhere so users that don't have

security training might expose their

accounts might expose their workstations

their mobile devices without knowing

right the poor password management

policy a poor screen locking policy or

any kind of security measures that they

they just ignore can expose their

devices and through their devices they

can expose your entire network and this

is unintentional but it is a lack of

Education lack of awareness on their

side another unintentional way of

exposing your network is by installing

unauthorized devices or enabling

unauthorized services in your network

for example hosting file sharing

services from the company Network or

installing Rogue devices such as

wireless access points or foreign

switches that are not part of the

company managed devices usually this

type of let's say additional

I.T infrastructure that kind of lies on

top of the uh the Enterprise

infrastructure is called Shadow I.T and

that's a term that usually suggests that

people are using services or using

devices that are not authorized or the

IIT Department doesn't even know about

them another example of Shadow ID would

be for example employees suddenly

deciding to use a public file sharing

service or file synchronization service

to store their company files their

company data which probably isn't secure

enough or isn't accepted by the

company's security policy so while

talking about exposure now would be a

good time to introduce the term of

attack surface now the attack surface is

just like the name says is the amount of

points of Entry that a potential

attacker could use to exploit your

network or your systems so it's

basically the answer to the question of

how exposed are you to potential threats

to potential attacks now of course

ideally the attack surface for an

outsider threat should be much smaller

than the attack surface for an Insider

threat which happens as we said before

because an Insider threat already has a

level of access that the outside

attacker still needs to gain before

moving forward with their attack

intentions the attack surface in itself

is a big Topic in any security

assessment because it needs to be

evaluated while thinking about the all

the potential points of entry in your

network I mean not just I don't know

open ports or a firewall or open ports

on your servers but think about mobile

devices when they leave your building

think about your actual employees that

might be subjected to social engineering

and they could be tricked into divulging

secret information or even think about

physical security how difficult is for

somebody from the outside to actually

enter your building and sit at a desk

and access confidential data from your

company that is also part of an attack

surface so we said that a an attack

surface represents the multitude of

points of Entry potential points of

Entry that could be exploited well one

such point of entry is actually called

an attack Vector which is the method or

the vector by which an attack can happen

right so let's put a couple of these

attack vectors here on the slide and see

what they're all about starting with

email the traditional point of entry of

malware and malicious intent in your

network so with email an attacker could

potentially craft a message that tricks

a user into clicking a link downloading

some malware or exploiting some kind of

vulnerability in their browser now

usually this type of approach combines

the email Vector with some sort of

social engineering attempt because it

does have to look legit in order to

convince that user that they should

actually click on that link or download

that attachment or execute data

attachment that came with the original

email next we have the removable media

Threat Vector that is the USB thumb

drives that everybody is using nowadays

and which are often involved in

transmitting malware it usually relies

on the fact that you manage to trick a

user into inserting a user USB stick

into their own company computer or

laptop and there are a lot of methods

for doing so again this requires some

sort of social engineering but let me

just give you an interesting example

here it's called the parking lot attack

and it relies on intentionally leaving

actual USB sticks somewhere thrown away

inside of a parking lot where regular

users could find them and they would

find such a USB stick on on the ground

and say boy this is my lucky day I just

found a 256 gigabyte stick for free in

in the parking lot somebody must have

dropped it let me just take it and enjoy

it and they they grab it and they plug

it inside the company laptop and voila

you have the malicious content being

injected directly inside of a company

computer bypassing any kind of firewall

controls ips's IDs that you might

encounter if you were to try to inject

that same type of code from the outside

over the Internet so that's a parking

lot attack of course you can imagine

this attack happening in any number of

ways you know leaving those USB sticks

in the in the launch area in in the

lobby anywhere you know regular

employees that are not so security

concerned might grab them and stick them

in their own company devices Wireless is

another very common attack Vector simply

because it's open and not open as in

anybody can connect but the signal

itself is not constrained to a specific

path I mean anybody can intercept that

signal even though it's encrypted most

of the time but you don't even have to

be inside of a building to catch that

wireless signal you could be outside in

the parking lot even outside of the the

company perimeter outside of the fence

you and you could still get some packets

receive some packets that are actually

traveling over the company Network there

are numerous attacks in the Wireless

World we're going to talk about them in

a different video but for now just to

mention a couple of them most of the

time it relies on intercepting that

traffic trying to crack the

authentication credentials the wireless

password of the network in order to gain

access to the company Network or in an

attempt to perform a man in the middle

that is intercepting legitimate company

traffic looking inside of those packets

and then forwarding back to their

original destination now of course we do

have security methods in place that

don't allow this to happen such so

easily but the wireless networks do pose

a much bigger risk than wired Networks

next we have the websites social media

instant messaging services which are not

exactly attack vectors by themselves but

of course they could host malware but

they're most likely going to be used in

a social engineering attempt think think

of a situation where an attacker poses

as a legitimate employee on social media

on an instant messaging platform and

attempts to get more information from

you they could pretend to be from from

it from tech support they could pretend

to be a contractor that doesn't have

access yet to the company Network and

they need some help to figure out how

your internal authentication systems

work so that they can get the access

that they deserve

quote unquote local workstation access

this one is often overlooked people

don't understand how critical this is

it's simply

protecting your computer when you stand

up from your desk and leave your desk

that is don't allow anybody to just sit

down at your desk and start typing at

your computer you might not know if

there are guests in the in your open

space you might not know if everybody is

authorized to be there it doesn't matter

if everybody is authorized to be there

no colleague of yours should have access

to your workstation no matter the reason

so direct local workstation access is

also a potential attack Vector not just

for pranks you know I'm sure you can

think of a couple of pranks here but

we're actually talking about security

risks also the cloud has become an

important attack Vector lately in the

last years or so and simply because a

lot of companies now are not exactly

moving completely to the cloud but at

least using a couple of services in some

public cloud provider out there now

what's the problem with this it's not a

problem in itself it's just that in most

situations access to that infrastructure

that cloud infrastructure those Cloud

resources is actually enforced by a

simple account a simple username and a

password it might be just an API

endpoint protecting by a a single secret

key that allows access to the entire

Kingdom behind that authentication

portal so it's enough for an attacker to

try and guess or break or coerce some

employee to reveal those credentials or

Cloud credentials and they suddenly have

access to more infrastructure that they

could ever dream about Cloud

environments are mostly secured just

like web applications for more complex

web applications which is convenient on

one hand but it can also pose a great

security risk because there's so many

resources and critical resources behind

a simple user account and finally an

interesting one is the supply chain

attack Vector now this one doesn't

happen that off often but when it does

it's disastrous that is the supply chain

attack refers to

attacking not the actual network not the

actual devices or the services but the

components or the facilities that come

into play while assembling the hardware

or the software that finally gets

delivered to the end user just think how

bad would be someday to discover that

all the Intel processors in the world

have some back door installed into them

that allows some potential attackers out

there to gain access to your computer

that's one type of exploit that has to

be installed in the device from the

factory itself which is part of the

supply chain and this is also the reason

why a lot of the companies especially

bid companies when they purchase

equipment network devices and user

devices they only purchase from

well-known vendors which have validated

and thoroughly checked and secured

Supply chains so that the risk of

interfering with the production process

in a malicious manner is minimized as

much as possible alright that's it about

attack and attacker categories don't

forget to leave a comment if you want to

talk more discuss some more about this

topic like And subscribe and good luck

on the exam see you on the next video

bye bye

[Music]

foreign


555

[Music]

foreign

[Music]

we're going to talk about threat

intelligence now threat intelligence

basically refers to how much do you know

or how much do you understand about the

potential attack methods out there

and it pays to to have this kind of

information from two different

perspectives first of all because you

need to be a good security professional

of course you need to be kept up to date

to know what's going on in the security

world and how to better protect whatever

you're paid to protect right in your

company and secondly it also helps us to

better configure select and even install

deploy actual Security countermeasures

in our networks so first you need to

figure out where do you get your

information from and secondly you need a

method to actually get this information

down to those devices that protect your

network so in an official definition

threat intelligence refers to

researching the actual ttps of the

attacks TTP stands for tactic technique

and procedure which is basically a way

of saying how is that attack being

conducted how does an attack happen and

threat intelligence is all about

research watching these attack methods

so where do we get this information from

now of course it would be great nice

beautiful to have one single source of

information one single sort of Truth a

Wikipedia of of all the security threats

out there unfortunately there's no such

thing but things don't actually look so

glum they actually are a lot of sources

out there you just have to select the

right ones and to combine what is

relevant for you for your environment

for your network for your use case not

everything out there is going to be

relevant even though it's relevant to

security it might not be relevant to

your environment and to your needs so

let's see a couple of these sources that

we can use to get more information to

research more about potential threats

that we might be facing starting with

and in no particular order because there

cannot be an order in in selecting these

potential sources starting with

companies and universities they usually

publish white papers they publish

journals they publish papers on specific

threats or potential attack methods that

can be performed or have been discovered

and analyzed in the real world

and so it's basically a way of avoiding

doing this research for yourself and

reading the research already done by

other people out there second we have

the dark net and the dark web well the

Dark Knight and the dark web actually

the dark net is an overlay Network on

top of the internet which can be

accessed using the Tor Network The Onion

router Network you can download a tour

browser for free and the content that is

being hosted on this type of network is

usually called the dark web now this

content issue is now this content of

course is don't expect it to be indexed

as nicely as you can just search for it

on Google you're not gonna find this

content you have to know where the

websites and where the content is

actually located so it has to be

disseminated from person to person using

bulletin boards using feeds using

instant messaging using any type of

communication Channel but this is not

the type of Internet that can be easily

searched well why is that because a lot

of the content in there is completely

illegal this is the place where you can

buy things that uh I don't even want to

think about at the very least you can

buy cyber attacks you can you can buy a

denial of service attack for a specific

Target for a specific period of time for

just a couple of dollars and again you

can do

a lot of nasty stuff in there and I

don't want to mention everything that

can be done uh just so I don't get

flagged by YouTube but it's it's a place

where anything goes

now why is this an important source of

information for threat research well

because attacks are actually sold and

disseminated over this dark web cyber

attacks exploits new vulnerabilities

that are being discovered zero day

exploits are being uh monetized over

this network in an attempt of course to

gain money out of these exploits

monitoring researching water is being

traded in this network can provide a

useful insight as to what potential

attacks you might expect in the future

behavioral research is more on the lines

of Storytelling so to say it's basically

a description of how an attack is being

conducted how it was observed in the

wild in the real life and how you could

probably attempt to protect from such an

attack reputation sources on the other

hand are much more useful because these

are the actual feeds lists of malicious

or potentially malicious IP addresses

domain names that have been observed to

host malware to send spam to generate

denial of service attack to act as

command and control servers for general

service attacks and any kind of

malicious behavior and there are

security researchers out there in most

cases they belong to one of the major

security vendors you know Cisco Fortinet

Palo Alto checkpoint and so on which

actually maintain on a daily basis on an

hourly basis these up-to-date lists of

malicious destinations on the internet

now the good thing is that their devices

their firewalls there's an exchange for

firewalls can dynamically update these

lists and Implement them inside of their

traffic filtering policies so the moment

a Potential Threat is being detected on

the internet coming from a specific IP

address or a specific domain name you

could actually be protected in a matter

of seconds and that domain name that's

the IP address could be instantly added

to a denied statement inside of your

firewall blocking any type of

communication with that destination thus

protecting you and your network from any

kind of exposure from that location of

course in some situations you have to

pay for this type of updates fortunately

there are also free and open source

feeds that help you protect your network

without actually breaking the piggy bank

also on the topic of updates and dynamic

updates we have attack signatures these

are mostly used by intrusion prevention

systems those are the devices or the

software Security Solutions that deal

with analyzing the actual traffic that

comes into your network looking for

patterns that might indicate an attack

going on inside of that traffic now in

order to be able to detect such an

attack of course the IPS device needs to

know how that attacks looks like and

that attack is being described as an

attack signature it might be just a

single packet with a specific sequence

of bytes in it it might be a sequence of

packets it might be a set of fragmented

packets there are tens even hundreds of

thousands of signatures out there that

indicate attacks that have been observed

to happen in real life and just like

with the reputation sources you can get

these for a fee or for free

of course they're not going to be the

same content you can expect usually

these types of dynamically updatable

feeds to have more up-to-date content if

they come from a from a paid Source next

up we have the Cyber threat intelligence

feeds which are pretty much what we just

talked about right attack signatures

reputation sources but these are more

concerned with actual seam solutions

that is security information event

Management Solutions these are complex

solutions that attempt to gather events

whatever happens in your network and try

to correlate those events and understand

what's going on in there and their

purpose is to be able to correlate

potentially uninteresting events that

when analyzed together might indicate a

potential for an attack for example

let's let's take this event uh I Andrew

have just connected over VPN from

Romania to my company VPN server all

right that's a completely legitimate

event now we also take another event

that says I and you have just connected

from Germany to the same company Network

that's also a legitimate event

now what if those two events which

separate don't cause any any concern

what if those two events happened in a

time interval of 30 seconds that's

probably going to match a signature in

that same solution that says impossible

travel time it's impossible for me to

connect using the same user account from

two different countries over 30 seconds

which can raise a flag can raise an

alarm that potentially my account has

been compromised so that's one of the

reasons why Sim Solutions are pretty

expensive because they're really smart

and they can help you a lot now just

like we said before most security

vendors out there provide their own

security updates it might be antivirus

signatures it might be about intrusion

prevention signature it might be

potentially malicious URL lists or IP

addresses so these are vendor

proprietary thread feeds and in most

cases these thread feeds only work with

their own devices with their own

Security Solutions now I know people

don't really like dark and they don't

really like writing it they don't really

like reading it but there's a whole lot

of information in the official vendor

documentation for your Security

Solutions so for example let's say you

buy a firewall from checkpoint you might

just think that you're gonna wing it you

know just install the firewall in there

just create some access list and create

some traffic policies and there you

you're good to go well there might be

that checkpoint has thought of writing a

paper writing a guide a security guide

for actually hardening your network or

hardening your firewalls you might want

to look into those guys because they

might be addressing some potential

attacks or exploits or vulnerabilities

that you might not even know about so

they might have some security features

that you could enable in those devices

you just have to know about them so read

the documentation another source of

information are The Isaacs the Isaac

stands for information sharing and

Analysis centers now these are threat

into intelligence sources that are

specifically maintained and developed

for specific Industries like oil gas

Aviation Powers the power distribution

and so on and they address the risk

security risks that these critical

infrastructures might be facing so this

is probably going to be relevant to you

only if you're working for such an an

industry provider but these Publications

are in most cases free so you could have

a look over these in order to better

understand what's going on in the

security world because they're mostly

state sponsored and they have a lot of

resources dedicated into maintaining

these the information Behind These

Isaacs

here's an example of Isaac's at

nationalizacs.org so it's a list of most

of the Isaacs in the world for example

you can see we have uh we have some for

Aviation Communications uh gas electric

elections and infrastructure not the

electronic infrastructure elections

actually electricity as well and they

all have their own their own websites

let's visit one of them so this is the

electricity information sharing and

Analysis Center uh you can see right

here if you click on the about the E

Isaac says the um this one offers the

electricity industry quality analysis

and Rapid sharing of security

information on how to mitigate complex

evolving threats to the grid that sounds

like Tron in here but it's about the

electric grid right anyway all this

information is public all this

information is free have a look over

them or at least try to remember that

they exist for the exam now open source

intelligence as I said before these are

the security information sources that

are being provided in an open manner so

you don't have to pay for the actual

information but in most cases these are

maintained by companies that make their

money from consulting services from

actually providing you with help

implementation services for your

security infrastructure but they provide

you the the threat information to

provide you the security information for

free now there are a lot of companies

out there that do this just to give you

a couple of examples we have for example

from Alien Vault

otx that is the open threat exchange you

can see here it provides you free access

to over 19 million threat indicators

daily all right uh quickly identify if

your endpoints have been compromised

share your threat research so you're

probably gonna have to you know to share

your own information if you want to use

this so you'll have to contribute back

to the community that would be the nice

thing to do and all this information is

provided as a feed so it can be

automatically downloaded by your

security devices and automatically

implemented in your security policies

one interesting feature that we have in

here is if you click on the browse

you're going to see a lot of honeypots

in here

which are basically

um intentionally left open services on

the internet for example this is just an

sh server right this is intentionally

left open which is monitored as to what

kind of attacks are trying to hit it and

in which way is it getting hit is it

being attacked by Brute Force attack is

it being exploited by specific

vulnerabilities to basically gain access

to the logs generated by these honeypots

and the sources and the IP addresses

that are generating these type of

attacks because these are actually the

sources that of potential attacks of

potential

um Brute Force attacks the potential

malware that can be easily then

integrated into security feeds which are

then communicated to everyone who

subscribes to that feed another one is

the Mist project again this one provides

you with a lot of feeds available for

free and different formats depending on

how you want to import this information

into your into your environment so for

example you have feeds for malware

domains you have tour nodes if you don't

want to allow access or traffic with

potential uh Dark Net entities in your

network uh let's see what else we have

here a lot of blacklists Ip blacklists

which are which were detected in the

past as uh generating malware traffic or

attacks a lot of Ip blacklists that have

been detected in the past as sources for

malicious content I like this one right

here bad guys.txt right there it is this

is the list of bad guys how bad do they

look you know this this list is actually

huge right you can see it's actually a

list of IP addresses uh sorted right but

this is basically a list of all the IP

addresses that have been involved in

some sort of a malicious behavior so

it's as simple as this you can see I can

even download these lists without even

authenticating or or requesting access

of any of any kind another one is the

spam house project which as you can

probably guess from the name is a

project that tracks spam and related

cyber threats such as phishing malware

botnet so basically any kind of nasty

thing that can arrive through an email

message and even though it's an open

source project you can see that they

protect over 3 billion user mailboxes I

would probably have to check this so

This asterisk in here and these are

responsible for blocking the vast

majority of spam and malware sent out on

the internet now the mileage may vary of

course maybe there are three billion

users out there but this is still a very

useful and a Priceless source of

information if you if you want to fight

spam and another one that not many

people know about at least not from a

security intelligence perspective is

virus total you probably know about this

this website and you know that you can

submit a file in here and get it scanned

by 50 or something anti-virus engines

what you might not know is that you can

also submit URL in order to detect

malware or the reputation of that

website or you can even search by URL IP

addresses domains or even file hashes so

this is also a very strong security

database of everything that is is nasty

out there on the internet and by the way

they also have some paid Services which

they've introduced quite recently like

the intelligence service and the threat

hunting Service as well so that's it

about open source intelligence a lot of

value when it comes to open source

finally we get all the rest like papers

uh talks recorded talks at security

conferences

rfcs the rfcs the RFC stands for

requests for comment and it's kind of a

bad naming convention for the actual

standards that have ended up as being

the de facto standards that we currently

use in networking and in protocols

applications nowadays but there's a lot

of information in there there's a lot of

information in those rfcs because those

are these actually describe how specific

protocols should behave now a throttle

security analyst could potentially

analyze such an RFC because it at the

end of the day is just a piece of

documentation and find some flaws in it

just by understanding how a specific

protocol was designed to work

can reveal some weaknesses in that

design so simply analyzing those rfcs

can provide some useful security

intelligence as well and I don't need to

tell you about blogs and social media

right we all read those hopefully right

so we briefly mentioned ttp's tactics

techniques and procedures before let's

just put it in a more General context

here ATP a tactic technique and

procedure as a statement about how an

attacker behaves what's the tactic what

is the behavior what is the technique

that is being used to conduct an attack

and what is the actual procedure being

followed in order to exploit the desired

system so when we're saying that we're

performing security research we're

basically researching these tactics

techniques and procedures and another

very important term here is ioc

indicator of compromise an indicator of

compromise just like the name says is

some sort of a proof that we can find on

a machine on assist them even on a

network perhaps that proves that we have

been breached we have been the victim of

an attack we have been exploited now of

course given the vast diversity of

potential attacks out there there's also

a huge amount of proofs that we can look

for so iocs can be a number of things

let's see what are the potential iocs

that we can find in a network let's see

what we're looking for when we're

looking for proof of an attack first of

all we could be looking at a malicious

URL and we should know that the URL is

malicious now that we know that we have

available a lot of threat intelligence

sources even for free so there's no

excuse you should have some sort of

system in place you should have your

devices configured to automatically

detect and flag these URLs as

potentially malicious URLs now these

URLs of course could be found in network

logs in web server logs in proxy logs or

even in actual Network traffic if you

manage to intercept the traffic that is

actually going from the host to the

internet attempting to access to connect

to such a malicious website you could

break that connection from the very

beginning

and perhaps even generate a security

incident or security event in order to

figure out what happened that made that

host that user attempt to access a

malicious destination an ioc could be a

new file appearing on a host it could be

a file that gets downloaded from a

remote website it could be an attachment

from an email it could be a file that

gets added to the system files of the

operating system we could be looking for

proof of execution of a certain process

if we know that we have a list of

certain executable files we might have

an approved pre-approved list like a

white list of all the allowed

applications that can be run on a

specific workstation in our company now

any kind of execute will file any kind

of application that is attempted to be

run outside of that approved list might

raise some Flags an ioc or a proof of

compromise can also be a running process

inside of the memory of your hosts if

you have a well-defined and well

maintained Network of hosts you can

probably expect that most of those hosts

are going to be running the same

processes the same Services the moment a

foreign process a Foreign Service

appears on one of your hosts that could

be a cause of concern a rat is a remote

access tool or remote access Trojan well

this one is a nasty one because if you

find such a remote access tool in your

network

not only is this proof that you've been

breached so that malicious code has been

installed and is running on one of some

of your systems but there's also a

connection from that host to the

attacker a remote access tool or remote

access Trojan is basically a tool that

gets installed on compromised hosts that

in turn allows access to an attacker

from the outside to control your machine

a file hash is a fingerprint that can be

calculated from the contents of a file

it's usually a fixed size but the idea

is that whenever the contents of the

file change the hash automatically is

going to change as well now when is this

useful it is very useful for some tools

that are called file Integrity

monitoring tools these are tools that

are designed to calculate the hashes of

all the let's say legitimate files on a

system such as the files that belong to

the operating system

Windows files all right now the moment

when those windows files

start reporting different hashes from

the ones that have been stored from the

very beginning in that hash database of

the file Integrity monitoring tool that

might be a cause of concern this might

indicate that somebody else a potential

attacker is attempting to change some

system files it's attempting to replace

operating system files with malicious

versions now of course if you're

thinking about well what if somebody

just updates their Windows right isn't

that going to change the windows files

yes it is going to change them but

usually the update process is tightly

integrated with the file Integrity

monitoring tool so this is an allowed

process that actually updates the file

hashes in turn as well the Windows

registry is a huge database of a lot of

information which can potentially hide a

lot of malicious content as well there

are tools out there that periodically

scan the registry for malicious content

or even scammed registry for any

unexpected changes to the registry this

is one of the approaches to security

that you're going to see quite often

nowadays instead of looking for specific

signatures of an attack you're looking

for abnormal behavior you might not know

exactly how an attack is going to look

like you might not have a signature for

it but you know that any change in some

place that should not present any

changes it might be a cause of concern

like the Windows registry resource usage

this isn't not a potential indicator of

compromise if you suddenly see a higher

resource usage on a CPU memory

consumption

disk i o input and output disk usage

Network bandwidth it might be that I

don't know a backup is happening on the

network which might be more than fine

but it also might prove that you're

running some crypto mining software

maybe you're running some crypto Locker

that is attempting to encrypt all your

all your files on your hard drive so a

close monitor of the host sources and is

also a source of potential indicators of

compromise new applications detected on

a system this is very easy to detect and

can be easily enforced using group

policies and windows as well any new

application that your users need to

install should be authorized should be

permitted by the IT department and by

the security department first of course

Network traffic might also be a source

of indicators of compromise that's

simply because many attacks rely on the

network to first get inside of your your

company Network and then to propagate to

their final destination so just by

looking at the traffic you have the

chance theoretical chance of catching

that attack before it even happens now

one source of such indications of

compromise is by monitoring the network

traffic and looking for protocols that

you know should not be present in your

network new devices connected either to

your hosts your endpoints or to the

network you probably should have some

sort of centralized IP address

management system or a tight control

over the dhtp servers in our Network in

order to detect whenever a new endpoint

is connected to the network now of

course not every new device is a threat

to the network it it might be just an

accidental Insider thread as we just

talked about in the previous video it

might be that somebody brought a I don't

know a smart device from home and they

just decided to plug it into into some

free wall socket and finally

exfiltration data exfiltration which is

another word for data theft stealing

files from inside of a company that's

also a cause of concern especially

because it can be prevented and it can

be detected if you're looking at the

traffic that is leaving your company and

you're looking at any file uploads

you're looking at any kind of uh you

know perhaps even VPN tunnels that are

being established from within your

network to the outside world you could

potentially catch those files before

they actually leave the company premises

and prevent data exfiltration of

sensitive information alright so we have

a lot of things to look out for so many

things to Monitor and you might be

thinking at this point well this is a

full-time job for not for a person but

for an army how do we actually make this

happen how can we navigate this huge

amount of information and actually make

sense of it and in real time so that we

don't catch a threat six months after it

happened well we have a lot of things to

look for because malware can be

extremely complex right so we need to

change our way of thinking about malware

and why we look for iocs let's see some

of the things to keep in mind well first

while you could

manually inspect all those ioc that we

talked about you'll get much better

performance and get much better

visibility and well you're analyze much

more information if you use a dedicated

automated tool for this you'll find

tools like these under the names of hips

or hits this is host based intrusion

prevention or host based intrusion

detection the difference being that the

detection part only alerts or reports

and the prevention part actually blocks

the threat you can also find these under

the name of endpoint security suits from

a lot of vendors out there now those are

usually the pieces of software that make

your computer run crappy just because

it's secure

secondly sometimes a single ioc is not

enough to prove that a host has been

compromised because one single anomaly

might be open to interpretation or might

not even raise any alarms but

correlating multiple iocs can show a

pattern this is also one of the reasons

why for some attacks we simply cannot

create static signatures to detect them

and we also have dedicated appliances

and solutions for this we call them

seams or security information event

managers and we're going to talk about

them in a later video and finally third

we still have the problem of identifying

each individual ioc and deciding if it's

good or bad computers create files

processes Network traffic network

connections all the time sometimes they

generate thousands of events every

single second and not to mention that in

large companies you have thousands of

endpoints running at any given point in

time so not every event is also a

security event there's a lot of effort

involved in this triage phase and by the

way since we're here let's introduce one

more term and that is threat modeling so

we have so much information about

attacks about reputation uh malware

signatures attack signatures iocs all of

this is part of one big concept called

threat modeling so describing all this

information is actually modeling this

information related to threats so that's

what threat modeling is all about so

here's another challenge for us how do

we describe all this information in a in

a meaningful and consistent way how do

we write this stuff down leave this

wisdom behind and not just leave it

behind but actually inject it import it

into the actual security devices that

can make use of it so for describing

storing and sharing thread information

we have something of a language called

sticks and a protocol called taxi well

at least they're easy to remember

starting with sticks well sticks is one

of the standard ways of describing those

ioc findings and the relationships

between them now stick stands for

structured threat information expression

and right now the current version of

stakes is version 2 based on Json

version 1 was based on XML so make sure

you remember the difference just in case

the exam asks you about it now the

structure of stakes of course is not

arbitrary it's a standard after all and

it's made up of sdos this is a Styx

domain object you just have to know

about them you don't need to memorize

them so these stos can be just to

quickly review them they can be about

observed data like an IP address a file

a something that would be detected and

recorded by some monitoring system an

URL or something like this an indicator

is a pattern of observable that can be

identified and might be relevant to

cyber security so not every observed

data is an indicator when an observed

data becomes an indicator it's something

that has gained a higher level of

concern from a security perspective we

also have attack patterns these are the

known behaviors of an attacker or the

ttps that we just talked and again this

is one way of saying if this is

happening to your network then you're

most likely the victim of an attack you

also have the threat actors and the

campaigns that those trade actors might

be a part of these are the adversaries

that are launching the attacks along

with the scope of the attack now the

scope refers to uh it might just be you

the one being targeted your company or

your person or your device or it might

be multiple organizations all over the

world in which case we'll call it a

campaign in a course of action or a COA

well that's the mitigation technique

what can you do in order to resolve the

threat or after the attack has happened

what can you do to minimize the damage

from that security incident so for

example if we if we decided to determine

how we can describe a malicious URL

using the sticks language we're going to

head over right here right and click on

this indicator for malicious URL and

this is a way of describing just how the

data model is supposed to look like and

also an implementation for example in

Json this one is going to look something

like this

now if you look in the object section we

can see that the first object is of type

indicator and this is the actual pattern

that that we're looking for to indicate

to us that we are looking at a malicious

URL right so this is the malicious URL

right here you can see a name and a

description for it when it was created a

specific ID for this indicator right so

this is how we mark this URL as being a

host for malicious content now we can

also enrich this information even

further with another type of object this

one is of type malware which actually

describes the actual malware that is

being hosted at that website again this

one has a specific ID right the malware

type in this case is a backdoor or

remote access Trojan which are pretty

much the same thing actually and then we

have some phases from the kill chain

then we see a description of this

malware this malware attempts to

download remote files after establishing

a foothold as a back door so this is the

generic behavior of this type of malware

and file finally we have another type of

object and this is the relationship

relationship between well the indicator

that's the URL that we just talked about

and the malware that we just described

up above right here

so this is one way of encompassing all

this information into a single file and

being a Json file this can be easily

processed by Machine by additional

security software and can be interpreted

and instantly implemented into a

security policy so that you immediately

get protection from this URL as well as

from any malware that is identified as

being this type of vector so this is how

Styx works and well all is good we have

some way of describing malware and

malicious content and potential threats

we also need a way to disseminate this

information to communicate this

information from machine to machine

because well that Json file we just saw

was not meant for human eyes I mean we

can read it but you're not going to be

the one actually blocking the the

traffic that goes to that religious

website all right you do have to

implement this into an actual security

software solution so there's also a

protocol that we're using in order to

disseminate this type of information to

our actual security devices and we have

two methods of doing this first we have

the not so obviously named collection

method which is a way in which clients

connect to the servers and actually

request this information request the the

the description of these potential

indicators of compromise second method

is called the Channel where the producer

of this information stores it on a

server the clients subscribe to that

server server and then the server in

turn pushes this information whenever

new updates come in to all the

subscribers

so make sure you understand the

difference between these two and the

exam might ask you about this

well if you thought that we're done with

all the threat information sources that

we need to cover well we are not done

this in presentation is all about

information overload so that's just

so there are so many sources of

information that can help you out in

securing your network so honestly

there's no excuse nowadays in just to

not use this information in order to

better increase your security posture so

let's talk about a couple more of these

one of them is AIS this is automatic

indicator sharing this one is offered by

the Department of Homeland Security and

it's uh destined for those Isaacs that

we just talked about and by the way it

also uses sticks and taxi the threat

maps are actual maps of the world

perhaps that are revealing most likely

in real time or close to real time the

actual attacks that are happening all

over the world you might have seen this

in in news reports you might have seen

this in in dashboards and I'm going to

show you a couple of them right now now

here's one from Fortinet which kind of

looks like a computer game where your

your nations are you know shooting at

each other they're not actually shooting

but they're launching exploits and well

recognized attacks you can see that the

United States is currently under attack

from from Europe a lot of countries in

Europe and that's probably just an

exception happening right now uh you can

also see the uh the list of actual

attacks uh scrolling by right here at

the at the bottom so we see attacks

attempting uh vulnerabilities in

Microsoft Office Oracle database VLC uh

IIs

uh zendesk huh interesting one uh and so

on and so forth Microsoft Internet

Explorer nobody is surprised by that one

maybe I guess so a lot of shooting

around happening in this threat map

right here from Fortinet uh we could

also head over to another one from a

checkpoint another map of countries

shooting at each other this one this

time is between India and the United

States apparently at this very moment

again you're gonna find a lot of

Statistics in here so it's not just a a

pretty website with some um some HTML

animations in here there's actually a

lot of information behind all this uh

all the all these pretty animations that

you're seeing right here FireEye also

has a similar threat map and again we

can see countries shooting at each other

let's see in full screen here if we can

see more information uh we have top five

reported Industries under attack so

Financial Financial Services apparently

are the number one

under attack right now I believe there

should be yeah right here there's the

attacks today half a million attacks

today I don't know when today started

actually for this website but there's a

lot a lot happening out there so a lot

more a lot a lot more reasons to

actually consider these threat

intelligence sources this is just how

many attacks are happening each and

every second all over the world and

these are all the attacks that we know

about there's a lot of zero day exploits

that we don't know anything about that

are being conducted without anybody

noticing perhaps so these are the threat

Maps uh nice to look at spectacular if

you put them up on a on a dashboard but

there's also real information behind

those attacks and finally we have file

and signature databases uh file

databases are basically referring to

malicious file databases or as you can

see in the latest developments

especially from companies such as Cisco

we do see the emergence of solutions

that actually store hash values of all

the files being detected in networks all

over the world

that is because if you have such

database or file hashes it can basically

replace all the antivirus scanning

effort which just a file hash of that

file ask the cloud service about that

hash which is just a small request

containing just a file hash and the

cloud service is going to tell you I

have seen this file before I have

scanned it it's clean or I have seen

this file before I know it's malicious

make sure you block it before it reaches

uh further into your network so nowadays

we don't just have signatures and hashes

for malicious files also have signatures

and hashes for valid and clean files and

signature databases right when you when

you see a signature database think about

two things think about antivirus and

think about IPS so either you're looking

for in a malware signature in a file or

you're looking for a traffic signature

in some Network traffic and finally we

have a lot of information in

vulnerability database

vulnerables databases are databases of

known and discovered vulnerabilities you

might be thinking well if the

vulnerabilities have been discovered

then they're probably already fixed

right why do we care about them anymore

isn't that funny no unfortunately people

don't install updates that often

apparently and we're not just talking

about Windows Mac OS and Linux devices

but think about your your smart TV at

home think about your home wireless

routers think about your smart light

bulbs in your in your house perhaps

think about all the Internet connected

devices that we currently have on our

bodies in our homes in our offices in

our cars

do you update them all do you sometimes

you don't even have access to an update

interface in order to update the

firmware and to fix those those

vulnerabilities that have been

discovered on those devices so just the

fact that a vulnerability has been

discovered and documented doesn't mean

everybody is protected against it but it

does mean that if we detect a specific

piece of software running a specific

version of that software and we

correlate this with a vulnerability

database that says that specific version

is vulnerable to this and this attack

well that is actual usable information

security intelligence that allows us to

determine that we are now exposed to a

specific security risk and the first

stop one of the first stops for such

vulnerability databases is the

cve.miter.org website or you can just

search here for a specific CV by the way

CV stands for common vulnerabilities and

exposures basically just saying

vulnerabilities right so let's search

for I don't know let's assume that we

have an ASUS router in our home well if

you do have an ASUS router in your home

you better start praying right now this

is how many vulnerabilities were found

in the Asus firmware

and in the last year did you expect to

see that many well if you did

congratulations you're a well-informed

security professional if you did not

well I have bad news for you this is how

bad it is when it comes to

vulnerabilities in the public domain and

of course you can get more information

about each and every one of these

vulnerabilities so for example let's say

if you're selecting this one here

insufficient filtering for special

characters in The HTTP header parameters

so an attacker with General user

privilege can exploit this vulnerability

to inject JavaScript code and perform a

cross-site scripting attack right so

let's see more about this one here I'm

gonna get some links some references and

let's head over to National

vulnerability database

that's

nvd.nest.gov you can see it's the exact

same code the same same vulnerability

code right here I have a base score of

5.4 which is a medium type of

vulnerability now this score is

calculated from multiple metrics uh that

impact the actual device or the the

attack method like how easy this exploit

is to be conducted how dangerous it is

how much does it actually expose or what

kind of privileges are required by the

attacker to actually conduct this this

type of exploit now it's not a critical

exploit but it's still one that might

cause you some concern especially when

you find a text that require a low

attack complexity like this one with low

privileges so this is kind of like a low

hanging fruit for attackers right they

don't need much to conduct this type of

attack fortunately for this type of

vulnerability uh the confidentiality the

integrity and the availability impact

are pretty low or even non-existent so

this is probably the reason why the

score is isn't that high actually so

it's just a 5 on a scale from uh one to

ten well what's next in threat detection

well as you know we're pretty much

throwing Ai and machine learning now to

every product on the market so why not

do it for security intelligence as well

so of course next in threat detection is

artificial intelligence and machine

learning and the reason behind this

approach is the fact that we need to

improve greatly on the decision process

we're seeing something in the network

we're seeing something happening we're

seeing a file being transferred we're

seeing a a domain an IP address being

accessed we're seeing some sort of a

user Behavior we need to just Define

detect decide whether that behavior is

malicious or not even in a situation

where we don't have a specific signature

for that type of behavior that's where

machine learning helps us a lot and I'm

not going to say machine learning and

artificial intelligence because we're

not there just yet we still don't have

ai what we really have is just a

glorified machine learning and this is

one thing that starts being found and

implemented by a lot of uh in a lot of

Security Solutions out there by a lot of

security vendors which is a good thing

because it can help you a lot with

filtering a huge amount of information a

huge amount of event data that normally

would be impossible for a human being to

process but it's also extremely prone to

error because a machine Learning System

a neural network behind that machine

Learning System needs to be educated

needs to be trained with actual data you

need to explain to it

what does a legitimate Behavior look

like so that it can decide when

something goes outside of the norm when

sound when sometimes goes outside of

that Baseline why that thing might be a

cause for concern so there's a lot of

work in here fortunately with all that

information that we have available at

our disposal nowadays especially with

the the open source intelligence and the

all the information sources that we

talked about we can double that

information into those machine learning

algorithms and teach them from those

static signatures from those observables

iocs that we know about what's good and

what's bad and also on the on the same

line pretty much with machine learning

we also have prediction based analysis

this is one way of saying uh well

ideally we would like to be able to

prevent an attack before it even begins

to manifest itself how can we do this

well by for example by monitoring the

dark web chatter

well if we if we see a a concern for a

specific Target if we see a specific

type of attack being traded being

um being discussed

about a specific Target about a specific

company then if you have an automated

system that is able to understand this

type of traffic this type of chatter we

might one day be able to actually block

an attack before the attacker even

decides to perform it now if this sounds

like science fiction to you don't worry

it does sound like science fiction to me

as well all right so that's it about

threat intelligence a lot of useful

content in here and I hope a lot of

interesting content if you want to know

more if you want to talk more about this

leave a comment if you enjoyed this like

And subscribe good luck on the exam and

see you on the next video bye bye

[Music]


666


[Music]

foreign

[Music]

welcome back and today we're going to

talk about Network reconnaissance and

this is a very big topic very important

topic because it refers to identifying

whatever is currently running in our

network from a hardware perspective what

nodes you have connected to the network

what servers what endpoint devices you

have what networking devices you might

have down to the actual software and the

services that are running on those basis

of hardware and this is again it's very

important because it applies to security

from two different and opposing

perspectives first of all from the good

guy perspective when you're performing a

security assessment the first thing you

need to determine is what's currently

running in your network in order to

later determine where your weaknesses

might lie and what you might need to

improve so that's the very basic first

step of any security assessment

performing a network reconnaissance

secondly the second perspective from a

bad guided perspective that's the

attacker's point of view that's because

Network reconnaissance operation or

process is actually the first step in an

attack as well you know attacker has to

discover what's currently in your

network in order to determine what's the

weakest link or what are the actual low

hanging fruits that it might exploit so

we should know what reconnaissance tools

we have at our disposal for both an

audit assessment perspective and also to

better understand and how we should

react when we find ourselves the victims

of a reconnaissance phase that might

announce a much nastier attack

and reconnaissance can actually lead us

to monitor even more than just hardware

and software since most attacks are

being conducted over the network while

monitoring Network traffic is also an

important part heavy Network assessment

and also can be performed using network

reconnaissance tools so looking at

Hardware software and network traffic

alright so let's start with the basics

and when I say Basics I'm actually

referring to the basic ipconfig command

or ifconfig command now who hasn't used

ipconfig at least once simple enough

commands but they are the basics of

other tools as well that deal with

topology discovery that is determining

how the actual Network looks like how it

is structured how many subnet Studies

have how many how many hosts are there

connected to each Network what's the

exit Point what's what are the default

gateways from each and every Subnet in

there so we can start with these basic

commands on a Windows host ipconfig

provides basic information such as the

current IP address assigned to the all

the interfaces actually of your host

also the subnet mask in order to help

you determine what is the network that

the host belongs to and also the default

gateway that's the exit point from your

network whenever your host needs to

connect to some other destination that

is not in inside of its local network

the internet here included as well now

you can also enrich this command with

the Slash all flag at the very end which

is going to provide you a lot more

information especially the MAC address

or the layer 2 information for your

network interfaces and by the way this

is also one way of figuring out if the

IP addresses and the configuration has

been learned from a dhtp server so has

been automatically assigned by a dhdp

server inside of your network the HTTP

stands for dynamic host configuration

protocol it's a very well known and well

used protocol in most local networks

that help us whenever you plug your

network cable or connect to a wireless

network helps you quickly get all the

information that you need in order to

communicate inside of that Network and

even outside of it things such as your

IP address and subnet mask the default

gateway the DNS service that you can use

and a lot more optional information if

needed by the way notice that ipconfig

also provides you with IPv6

configuration information if it is

currently enabled on that specific

Network link on Linux things kind of

look the same if except that it's

ifconfigant stands for interface

configuration.ipconfig and it kind of

matches all the information here in one

single output a little more difficult to

read you can see we have IP address

information in the inet field right here

we have the netmask we have the

broadcast address we also get the IPv6

Network assignments and also the ether

field standing for ethernet this is

going to be the MAC address of your

current network interfaces by the way

network interfaces and Linux they're

going to be often named as eth followed

by a number or ens if it's running

inside of a virtual machine and it also

provides you with a bit more information

here regarding the number of packets

that are currently flowing through that

Network like how many packets have been

seen sent or received over that network

interface and how much traffic in bytes

has been recorded through that interface

this is also a sometimes a good way to

troubleshoot connection errors just to

see if the packets are flowing you might

have a defective link packets might be

flown only in one way and this is one

good way of checking out if something is

not working right and also you have some

statistics here regarding the errors

like seers check some errors on your

frames errors due to misconfiguration

bad cabling mirror maybe errors

generated by too many packets trying to

enter the network interfaces at the same

time and filling its buffers now the

ifconfig command is unofficially a bit

starting to be deprecated in Linux

distributions what we're currently using

nowadays is the IEP command you can type

it as IP address or IP address show or

the way I like to do it in a shorthand

notation is ipas and not only it

provides you with a nicer looking

colorful output here but also the output

is just a bit different you can see it

highlights the the important stuff in

here like the ethernet address the your

IP address Network mask in here

broadcast address right and also the IBC

six addresses that you might have

assigned to your interface

all right so that's how we get IP

information related to the current host

let's go one step further and try

interrogating outside hosts other hosts

on our Network or outside of it and

we're going to start here with ping I

mean everybody has tried ping before I'm

sure of that ping is just a

implementation a command line

implementation of a certain combination

of icmp message codes icmp stands for

internet control message protocol it's

basically a protocol developed a long

long time ago to help provide some sort

of a metadata or connection status

information along with the other

internet protocols out there so it's

basically some sort of a management

reporting protocol in a very let's say

simplistic implementation because it's

very old but nowadays we can use

specific messages in icmp specifically

Echo request and Echo reply and that's

the exact implementation of the Ping

command you're sending an echo request

if the host or the network interface is

programmed to listen to such requests

using icmb protocol responds with an

echo reply and you get the results that

looks something along these lines right

here you're basically being told that

you are receiving a reply notice that by

default on Windows you only get four

requests and four replies also denoted

here at the bottom and the sides of the

message that is being sent how much time

it took for this message

to come back so that's the round trip

time of your communication and also the

time to live here that's the IP Field

Time To Live which is a field set in IP

packets that is decremented by one on

each layer 3 Network hop like router or

firewall and nowadays we use this field

to determine the distance in network

hops between the source and the

destination initially traditionally it

was used to avoid routing Loops to avoid

having a packet Loop infinitely all over

the internet

on Linux the output is somewhat similar

except for the fact that by default the

pin command is going to run indefinitely

so it's not going to stop here you can

break this uh this execution here with

Ctrl C but you can also set the number

of packets to be sent using the dash C

parameter so one two three four and five

and we stopped and we also received the

same summary uh statistics just like in

Windows now how many we sent how many

received how much packet loss we had

zero in this case because we did receive

an answer for each and every one of them

and What's the total time all the

average time taken for these requires to

come back to us now another use case

we're paying that you've probably seen

before is also to check whether the uh

the DNS resolution works I mean there

are better tools out there of course but

simply by pinging something like Google

is going to not only solve google.com

until the actual IP address of Google

and by the way notice that I'm currently

resolving the the IP address of Google

into an IPv6 address all right so this

is going to be a ping over IPv6 but it

also tells us that we are actually have

we have connectivity to google.com

now one thing to keep in mind regarding

the the pink commands I I've seen a lot

of people especially students that are

just learning about networking and

security considering that if a pink man

Works everything else should work and

they're sometimes surprised to see that

they have something like a web server

they ping the web server the web server

replies but when they enter the web

server's address the same very IP

address that they used with the pink man

in a browser to actually receive the

contents from that web server it's not

working and that's simply because the

the Ping command is just like we said

before it's an implementation of the

icmp protocol basically if we are able

to Ping a destination on a network or on

the Internet it only means that we have

icmp connectivity to that destination

not any other type of connectivity not

on any other protocol not on any other

Port so don't forget about this don't be

fooled by the fact that if the host

replies any type of traffic is going to

work in most cases icmp might work but

the actual web traffic might be filtered

in other cases you're going to see that

web traffic is going to work but icmp is

blocked because it's considered to be a

risky protocol that can be used for

Network reconnaissance just like what

we're doing right here so

don't forget about this icmp is just a

simple application just a simple

protocol if it works it only proves that

icmp works not all the other

applications that might be running on

the same destination nevertheless one of

the things that you can use icmp

successfully for or depend command

successfully for is to check for Network

reachability that is just validating

whether you actually have valid routes

and your routing is working in order for

you to reach that destination I mean if

the icmp packets can reach that

destination it's pretty sure there might

be some exceptions in there it's pretty

sure that any kind of traffic can reach

that destination as well if there are

any other firewalls or any other

security rules that might be dropping

that traffic well that's a completely

different story

another simple tool is the ARP command

ARP again is a protocol in itself and it

stands for the address resolution

protocol what does it mean exactly well

it's a protocol that we're using

whenever a host needs to send some

traffic

on a local network so we have the data

nicely packaged we add a TCP or UDP

header on top of it then we add an IP

header on top of it and then we need to

add a Mac layer on top of it so we need

to know the IP address of the

destination that we're talking to and

most likely we are going to know the IP

address because we know where we want to

send that packet right but we're also

going to need to build the layer 2

packet as well so we need a layer 2

Source address which is going to be our

own MAC address on our own local network

interface and we also need a layer to

destination Mac address well now

depending on where that destination is

actually located if it's inside of our

own network then it's going to be the

actual Mac address of the destination

host if it's outside of our local

network then it's going to be the MAC

address of our default gateway of our

exit point

from our local network so one way or

another we need to figure out what is

the MAC address the layer 2 address of

either the host that we intend to

communicate with or of the default

gateway and we have a protocol that

deals exactly with this situation that's

the ARP protocol the r protocol has a

very simplistic implementation it simply

sends a broadcast that's a message that

reaches everyone in the local network

asking hey is there anyone with the IP

address

192.168 0.1 in my network

if you do have this IP address please

reply to me all right everybody receives

that message those who do not have that

IP address simply ignore it but the

default gateway for example that might

have that IP address response with a

unicast message back to the source

saying well I own that IP address here's

my Mac address if you want to

communicate with me please use this Mac

address as your destination so that's

the ARP protocol and of course this all

this information has to be stored

locally on our host because the host

actually are the ones that generate the

network traffic and build the packets

and we can also see the cache being

generated by this R protocol using the

command ARP on Windows it's going to be

ARP minus a

and you can see here that we have a

separate table for each interface on our

system so we have one interface that's

10 100 to 101 right that's one network

interface it's connected to a separate

Network segment and these are the Mac

addresses that they have found out about

from that Network segment notice that

for the second interface for example we

have Dynamic and static entries now the

static entries here most of them deal

with broadcast addresses and multicast

addresses and we're going to talk about

these later on but the dynamic addresses

are the ones that are actually being

learned from the r protocol using the

exact method that we described before so

in pretty much any situation hosts

inside of a network are going to have at

least a dynamic entry for the default

gateway because they're probably

attempted to communicate with the

outside world at least once during their

lifetime since they booted up on Linx we

have pretty much the same command it's

ARP not APR alright and we have again

entries and mappings between IP

addresses and layer 2 addresses right

here harder type means ethernet the

interface that this this mapping is

associated to and also the flags right

here flags of c means a complete entry

this again is a dynamic entry uh static

entries are going to be marked within M

or permanent entries and of course you

can statically add your own as well on

Linux for most commands of course you

probably know this you have access to

demand pages that are going to tell you

all the flags and switches that you can

use for each command and explain some

use cases anyone provides some examples

for them now this our table is actually

a very important weakness in network

security that's because the very

implementation of the r protocol is

completely insecure and under not just

talking about the fact that the the

communication is in clear text but

there's no way of validating the source

of the information that a host receives

whenever they send an API request

and also

unfortunately a host doesn't even need

to send an API request to get a reply

and to learn from that reply there's

something known as a gratuitous ARP

reply which is basically a way of saying

that at any moment in time I can send an

ARP reply to a host that hasn't even

requested one and provide that host with

whatever information I want to provide

it with

for example I could tell that host you

know what the default gateway is not

where you thought it was it's now

actually located at this Mac address

right here

and guess what perhaps that Mac address

actually belongs to my own machine an

attacker's machine inside of the same

network as my Victim and this is one way

of Performing something called ARP

poisoning so injecting fake information

into our tables which leads then to a

man in the middle attack simply because

if I manage to fool to trick a host into

sending me the traffic that is normally

destined for other hosts or for the

default gateway I can intercept the

traffic and inspect it and find out

confidential informational steal data

from it for example but that's

discussion for another video and let's

not forget about routing routing tables

are everywhere not just on routers

because routing the decision itself has

to be performed based on some sort of a

routing table now for most hosts mainly

we're gonna have a very simple routing

table that is we have a route that tells

the host well if the destination is in

the local network then you should be

using this interface to communicate

directly with it and if the if the

destination is not in the local network

then you should send your packets to the

default gateway and then leave the

default gateway to handle that traffic

we don't know where this nation actually

is it might be on another Network it

might be all over the Internet it might

be on the other side of the world we

don't know exactly but we know that we

should send to the default gateway all

the traffic that we don't know how to

get to now as I said we have routing

tables on hosts as well on windows with

the route print command

so we can see the active routes right

here we have an ipv4 route table and of

course separate an IPv6 routing table

because they're two completely different

protocols and for the ip41 for example

we have the network destinations on the

left the net masks because we need to

understand which type of destinations

fall into all these ranges here on the

left uh Gateway just in case we are

using a Gateway default gateway for

example to get outside for the internet

connections right so this network

destination of zero zero zero zero also

known as a quad 0 with a net mask of

quad 0 as well is basically a way of

saying that any destination that there's

no entry in the rest of the table for is

going to be reachable through this

Gateway right here this is the router on

our Network we know this is the only

exit point from our network if

destination is not local it's not on

link

then it should be somewhere outside

right if it's not in our house it's

probably outside of our house and this

is also the network interface that we're

using to to go outside we also have

metrics now I'm not going to talk about

metrics so much here just to remember

that the metrics is a numerical

identifier that helps us prioritize

certain routes over others very relevant

when we have multiple routes for the

same destination like for example when

you have multiple internet service

providers multiple internet connections

now on Linux of course things look

pretty much the same uh we can start

with the route command with the kernel

IP routing table again it's only going

to show us uh the default route here

okay with the default gateway again the

destination of default here is actually

an alias for the quad 0 that we saw

before you can see the mask is quad zero

as well and also we get the local route

right here local route here it basically

tells us that whatever Falls within the

range of

192.168.100 24 that's the uh that's the

mask right here doesn't need a Gateway

because we're directly connected through

the network interface's eth0 now since

we are now starting to use the IEP

toolset we also have the iprs stands for

IB route show command I'm just gonna

provide us pretty much the same

information as before finally we have

the trace route utilities now they're

not actually that different we have

trace route Trace Trace RT they're just

different commands or for different

operating systems out there but they

pretty much do the same thing now their

implementation slightly differs but they

all have one thing in common and that is

they are trying to determine not just if

the destination is answering like the

Ping command but what are all the

network hops along the way

to reach that destination so if we are

directly connected with the destination

we have we're in the same network while

trace route is pretty much gonna work

just like pink but if we are trying to

reach a destination from internet or

from some other network out there we

might be interested to see well what are

network nodes through which our packets

have to pass through in order to reach

that destination and also how long do

those packets actually take in order to

reach that destination on Windows for

example we get the trace RT command

[Music]

um

and then if we were to address the

destination on the internet such as

google.com we can see that

um on every Network hop in here the uh

the utility is actually trying to

resolve that IP address that is hitting

into a valid DNS name providing us with

more information as to where that node

is actually located you can see that

after nine notes or so we have actually

reached the uh the end destination for

google.com you can also see the the

delays how much it took for each node to

reply

now the trace RT utility on Windows

actually relies on icmp packets as well

remember that TTL that we talked about

that time to live inside IP packets well

we can actually play with that field and

send packets with a TTL of one

and that's going to cause the package to

be decremented to have its detail

decremented at the first top and when

that TTL goes down to zero that's a

special icmp message called icmp time

exceeded that's one way of notifying the

source of that traffic that your traffic

has quote unquote expired so we're not

going to be able to forward the tooth

and destination because it's TTL expired

so that's one way of figuring out where

exactly that TTL went down to zero now

if we think about trace route we can

actually imagine that this first message

right here was sent with a TTL F1 which

made my local router reply with a Time

exceeded then we send it with a TTL of 2

which made the next router after my home

router to reply with the time exceeded

and with a ttlo3 which reached another

ISP internal router and then ttl4 which

went even further and so on and so forth

and apparently with TTL number nine we

actually reached the end destination so

we're actually waiting for those time

exceeded messages to be sent back to us

in order to understand where and what

type of node did that time exceed

operation actually happened and this is

how traced house actually builds your

your output right here on Linux we have

trace route so it's not Trace RT we have

traceroute microsoft.com in our example

and you can see that the first items

right here are pretty much the same

because we're using I'm using the same

ISP as before but it's also a bit faster

and that's because the trace route

implementation on Linux actually uses

UDP probes instead of icmp so it's not

waiting for a Time exceeded message and

icmp probes are sometimes slower and

sometimes they're ignored all together

well the trace route implementation on

Linux actually uses UDP probes which are

not only faster but sometimes are even

more reliable one more tool that's worth

mentioning is the pathping tool you can

see the line right here it's path being

followed by a destination you see the

first thing it does is performing uh

kind of like a trace route and then and

that's going to take a while you can see

here Computing statistics for 225

seconds it's actually going to attempt

to generate statistics for latency and

packet loss for each and every node

along the way here's the result right

here

so that's path bang for you now that's

an equivalent for Linux of what you just

saw and that is MTR

my tray stars or something like that now

in most Linux distributions you might

find it available or you might need to

install it from the default repositories

uh in in my distribution here which is a

Kala Linux the version that gets

installed is a graphical user interface

one so if I were to enter in here let's

say amazon.com press enter we're going

to see that we start getting all of

these statistics regarding packet loss

delay how many packets were sent what's

the best round trip time what's the

worst relative time for each and every

node along the way until the the Final

Destination

so remember MTR on Linux for the pretty

much the same type of statistical

information as pathpink and by the way

these types of Statistics are not just

useful from an administrative point of

view like determining which node along

the way is performing the worst maybe

where's the actual delay happening if

the users are complaining but also a

unexpected delay a huge delay on a

single node along the way might also

indicate a potential security incident

happening in there like a router that is

under a denial of service attack so

that's why we're looking for this type

of information in a security training as

well and finally we get to talk about

nmf now nmap is a very popular free open

source utility it's a command line

utility by default it also has a

graphical user interface implementation

called Zen map and it's somewhat the the

Swiss army knife of network discovery

and it can do a number of stuff related

to network Discovery starting with the

actual discovery of the active hosts on

your network now you could probably do

this using the Ping command as well so

you could do something like this you

know just iterate from 1 through 255

and execute a ping command with a count

of one on all the IP addresses starting

with

192.168.15 DOT whatever the counter is

the one from 1 through 255. well you get

this result here you pipe it you send

the result here to the find command and

then you match only the lines that

include a reply keyword let's see how

this works now I'm gonna wait some time

here while it's cycling through all the

possible IP addresses in our Network and

you can see that we get some replies in

here those are the hosts that are up in

our Network now it does take some time

it doesn't provide you with that much

information except for the fact that

they're actually answering for icmp

requests but you could probably do some

sort of of a host Discovery process

using ping just like that

so after a couple of seconds this is the

result these are the hosts that are

answering to icmp Echo requests

so one of the simplest first type of

scans you can perform using nmap is by

just looking at which hosts are up in

your network you can enable this using

the S and flag at the very beginning

this is the equivalent of a ping sweep

which doesn't scan any further than

actually determining where the host is

up or down now as you can see the

results come in much faster you're gonna

receive all the IP addresses that have

responded to nmap requests and you also

get a couple of information here

regarding their host names just to

figure out uh which one is which

that's simple enough but the default

behavior of nmap so if you just enable

nmap followed by the subnet or the IP

address that you intend to scan the

default behavior is going to be to First

perform that type of network discovery

and then perform service Discovery so

this scanning type is going to take just

a bit longer because if a host replies

as being up then nmap is going to

elevate its uh its scanning attempts and

try to determine what type of

applications what type of services are

actually running on that host right so

we got the results in here after a

couple more seconds and let's see if we

can determine some interesting stuff so

starting with the the first host that

was detected from the first pink sweep

as well this is my router right you can

see it has a couple of services open on

it running on Port 80 for the web

interface also import 443 for the https

version I have the printing protocol we

also have some domain name Services

enabled on it because I'm using it as a

DNS server uh let's move over here this

one here is a smart home device from

sensible dealing with air conditioning

an IP camera right here accessible over

Port 80 probably not a good thing and

also the the big one right here the one

that has a bunch of open Services

running Services open here this one is a

Nas a network attached storage device

running in my home you can see I'm using

it for a lot of stuff in here running a

lot of services they're all going to

show up here with their port numbers and

their corresponding protocols all right

you can scroll down here and find more

devices running on your network of

course not all of them are going to be

so open and then you're not going to

always determine the all the services so

you can see that we actually scan 256 IP

addresses with Two Hosts up we found two

act 12 active hosts on our Network

and this scanning took 55 seconds

now nmap is actually a lot more evolved

than this and you can use it with a

couple more switches in here and you can

find all the possible switches in the

man page for uh for nmap that's the

command of man and map and if you scroll

down here to the help section you're

gonna find that we have a number of

methods of Performing host discovery

right the one that we've just used was

SN this is a ping scan actually it's a

way of scanning that disabled Sports

scan which means I'm just determining

where the host is up I'm not going to

move forward and scan the ports on that

host as well now the interesting ones

are down here understand techniques and

these are the techniques that we can use

to discover the services that are

running on host the first one here the S

capital S scan the TCP send scan this is

also called a half open connection scan

remember the TCP three-way handshake

where we first send a scene packet and

wait for a syn ack back before we send

our own acknowledgment back to the

destination well this one right here

attempts to send a syn packet and waits

to see whether a synec comes back but it

never fully closes the connection it is

considered to be or at least the capital

S here stands for sin as well as

stealthy well it's not so stealthy

anymore at least not nowadays but in the

old days with the old firewalls you had

to change chance of not being detected

if you did not fully

complete atcp connection so that

connection would never be logged and

your scanning attempt would never be

detected now it's not the case anymore

but the scanning technique Still Remains

right here the other one here the S

capital T this one is the connect method

this one actually performs the full

three-way handshake and this is the

least stealthy method of course this one

is the the most visible one in all the

logs and the web server logs in the in

the firewall logs everybody's going to

see that you're actually attempting to

scan those Services you can also perform

an X scan where you're pretending that

your packet belongs to an existing

connection and you're initiating the

connection already with an

acknowledgment packet again some

firewalls may be fooled by this others

might not be we also have UDP scanning

techniques and we can also combine a lot

of the options and flags in the TCP

packets by setting specific Flags you

can even set all the flags in a TCP

segment and this one is called a

Christmas scan

uh kind of like you know setting all the

flags lights to pack it up like a

Christmas tree or you can simply

customize which flags you want to enable

a zombie host the SI right here also

called an idle scan this one is a very

smart type of scanning where you're

actually relaying your scanning packets

through another victim through another

zombie host so-called now it doesn't

have to be a compromised host we're

simply looking at the incrementing

sequence numbers that are being

generated by that host in order to

determine whether our replies or relayed

replies have received an answer or not

and another very useful section right

here is the port specification and scan

order we have the dash B parameter where

which specifies the exact Port ranges

that you want to scan you can either

specify a single port one store multiple

times or you can specify an entire range

of ports that you need to scan or or

even list a specific list of known ports

now we can't even go further and start

asking more information about a single

host so for example remember that dot 99

host that I had my network this one was

a network attached storage device we

could either use the dash o flag here at

the front in order to perform OS

fingerprinting that is determining even

what type of operating system it's

running on that device or we can even

combine all the scanning techniques into

one single one with the capital a switch

this one performs as well OS

fingerprinting and service Discovery and

version Discovery and throws everything

it has at this host right here of course

this is going to be a very intrusive

type of scanning it's going to be

detected by all the ips's IDS in your

network so careful when where and to

whom you're doing this type of scan all

right scanning complete after a couple

of seconds here we're gonna receive a

report that tells us what information

and map was able to glean from all those

open ports starting with for example

Port 80 right here you can see that the

service behind it is an nginx Linux

server and tells us the HTTP Title Here

is hello welcome to Synology web station

which immediately tells us that this is

a Synology device how nice is this you

can see it also has some ports open for

Windows file sharing another instance of

nginx design listening on Port 443 for

https for secure connections you can

also get some information about the SSL

certificates that are available right

here and incidentally in the subject

alternative name we can also see the

name that actually leads to this device

through its certificate finally moving

forward here at the bottom there's going

to be a service information this one

right here is attempts to identify the

operating system that is running on the

host now in our case it doesn't know

exactly what type of operating system is

because it's done something non-standard

anyway but it is some sort of Linux and

it is based on a Linux kernel 4.4 so

this is again very useful information

for a security audit from an inventory

perspective but also From perspective of

an attacker because if you're able to

reach devices like these from the

outside network from the internet well

attackers will be able to reach them as

well and they'll be able to determine

the same information as you just did now

nmap comes with a predefined database

which can be updated from time to time

of the platforms that it is aware of as

in all the hardware platforms or the

operating systems out there and this

database is called the common platform

and enumerations database and this one

right here is one such entry this is a

one way of saying in one single line in

one single string what type of device is

this right so coming back to our slide

right here we've seen that we can use

that a map for Network sweeps for

discovering all the active hosts in a

network we can use it to further drill

down and figure out what services are

running on those hosts uh what versions

they are what actually implementations

they're using and also identifying the

operating system behind uh behind that

host now this is not going to be a 100

valid information every single time

there's a lot of assumptions being made

in here and the map tries to look at a

lot of indirect information that is

going to lead it to determine that it

might be a Windows Server it might be a

Linux server with a certain percentage

of certainty but it's never going to be

100 another very simple tool that's

available on both windows and Linux is

netstat Network status basically it's a

simple tool that lists all the active

listening ports open ports and active

connections on your machine it's a great

way if you have enough time and

resources to process all that

information to determine whether there

are malicious Services foreign services

that you might not know nothing about

running on your hosts and which might

indicate that there are some indications

or compromise in there that those hosts

have been compromised here's an example

Nets that output on Windows

you can find the status of the

connection what is the local address and

local port and the destination address

and the destination Port of my

connection you can see connections

constantly being created on the HTTP and

https ports of remote web servers uh

some of them hosted on ec2 probably on

Amazon so these are websites that I

currently have open in my browser that

are periodically refreshing things like

you know Gmail and the calendar and all

the all the resources behind those pages

and by the way on the left hand side

here if you see some services that are

listening right now on ports that you

know nothing about that might be a

potential indicator of compromise now

that's a huge number of network

reconnaissance tools out there just to

mention a couple of more right here we

have the Harvester which is an open

source intelligence gathering tool which

is going to scan things like Google and

social networks and Linkedin for valid

email addresses no domain sub domains in

a specific company so it's a way to

gather publicly accessible information

which provides you some more insight as

to what are the valid email addresses or

how that company is actually organized

internally another tool that most people

don't really consider to be a network

discovery tool is curl C URL that's a

simple command line tool in most cases

used to craft web requests now most

people don't know this but the URL tools

can actually talk over a number of

protocols out there it can talk over

email protocols you can talk to FTP

servers it can even talk to Windows File

shares so we can use this to craft

specific requests to get more

information about the about the status

of a server for example it's Banner

information it's login information

perhaps even an uh in an attempt to

generate some responses from an email

server in order to determine whether a

certain email address is valid or not

nessus is again a very well known tool

commercially available tool for

performing vulnerability scanning now of

course we're going to scan for

vulnerabilities only after we've built a

thorough image or map of our Network so

we scanned our hosts we scanned our

hosts are up what services they're

running what versions they're running

and then we're going to look for certain

vulnerabilities that match those

versions finally scanless is a tool that

attempts to evade intrusion detection

systems that are going to fire up an

alarm whenever they see scanning traffic

scanning traffic is easy to under two to

detect right it's a it's a bunch of

requests coming in a short time span

sent towards a large number of IP

addresses and even an even large number

of port in sequence perhaps so scanless

attempts to use some relays or other

sources on the internet to slowly send

that scanning traffic so that it's going

to evade detection now this might sound

like a tool for hackers or for someone

who's planning an attack but think about

it the the other way if you're on the

defensive side you might try to use this

tool to figure out if your security

systems if your ids's detect this type

of scanning traffic or not so are you

vulnerable to this approach or not and

we should never forget about DNS because

DNS is a at least a public DNS is a huge

publicly available source of information

about what is currently available and

exposed and publicly accessible in our

company so we have some tools in here

some command line tools starting with

nslookup on Windows and Linux dig and

host most likely Unix Linux type of

utilities that allow us to craft

specific DNS requests in order to elicit

some type of response from the DNS

server itself now there are situations

where the DNS server can actually host

accidentally more information that it is

useful for the outside public in which

case they're exposing some valuable

information that can be extracted using

these hosts and in other cases the DNS

servers themselves store some some

additional records that indicate who is

the admin for that specific Zone what

type of security measures are in place

or even what type of third-party tools

out there they're also using which are

some records that are most generally

stored in txt type of Records in DNS

servers now gaining access to all that

kind of information can be a gold mine

sometimes here's some example of outputs

using the aforementioned tools so for

example with nslookup amazon.com we are

first told the DNS server that we're

currently using of course we can

override this and query a specific DNS

server out there and then we get the

answers that are actual IP addresses

that point to amazon.com same goes with

host with the host utility

right here or the Dig utility I've added

the dash T capital a flag in here just

to be more explicit in which case I

wanted to select only the a capital A

type of Records out of this Zone which

means all the ipv4 to name mappings and

again we get the same three results

right here all of them being a capital A

type of record now we can also query for

different types of Records so for

example if I'm interested and what are

the mail exchange servers at Amazon.com

or the email servers basically I can

send a simple request like this and I

can see that the email for amazon.com is

handled by

amazonasmtp.amazon.com this is the

actual server that is delivering mail

sent to amazon.com and then I can craft

a capital A type of record for this

email server and it's going to provide

me with the resulting IP address

now a dangerous practice that sometimes

create a huge vulnerability due to

misconfiguration or to configuration

error is the ability to perform Zone

transfers from the outside world from

the public internet now his own transfer

is a functionality in DNS servers that

is used to synchronize multiple DNS

servers internally so it's a

functionality that should not be

accessible from the outside because it

allows an attacker to Simply dump the

entire database that is stored on that

DNS server now it is a publicly

accessible service out there that allows

you to perform such a Zone transfer for

teaching purposes right and you can see

the actual command for the Dig utility

is axfr that's Zone transfer all right

the first item right here that's going

to be the name server that we're

currently using to perform that zone

transfer and second argument is the

actual Zone that we're requesting now

hit enter and you can see that you're

going to receive a lot of information

this time and a multitude of record

types not just the capital a record not

just the name server but even the

records that point to internal private

IP addresses even records that include

administrative information

right here

so it's basically a way of dumping all

the information all the database inside

of that DNS server this is something

that should not be open to the internet

but sometimes it is

finally there's DNS enum as well which

helps you package in one single request

a lot of tests and a lot of sub-requests

that attempt to display or reveal how

much information you're actually

exposing to the outside world remember

these tools are not for you to become an

attacker these tools are for you to test

your own systems to test how your

company or your domains how your network

looks like from the outside and if it

can be queried this way and how much

information are you giving out for free

and there's one more thing that we can

look out for and that is analyzing

Network traffic in order to perform

Network and host Discovery because by

looking at the network traffic you're

going to see the actual traffic that is

being generated by the hosts on the

network you're going to see the routing

protocols you're going to see the

management protocols that are going back

and forth over there so there's a lot of

information that you can analyze just by

looking at the network traffic that will

help you determine what's inside of that

Network what's running in there now

capturing Network traffic sounds good

but it's the toughest thing to do there

are a number of places where you can

actually capture and decode this type of

networks traffic the most obvious one is

at the network interface itself on a

host and in order to do this we have a

number of utilities such as the TCP dump

utility and wire circuit which you

probably used before or heard about at

least and in a graphical user interface

manner now these utilities rely on the

fact that the network card the network

interface is able to present them with

all the packets even even those that are

not destined for that network interface

card is going to be able to present them

all in a nice output or package them in

some sort of a package capture file in

order for that result to be further

analyzed so later on you can look at

whatever packets were captured and try

to figure out is there some unencrypted

traffic going on in there are we

communicating with illegitimate hosts

hosts that we don't want to communicate

with such as sources for malware or bad

domains with bad reputation so that all

that information can be gleaned from

that packet capture so this is one way

of capturing traffic right on the

network interface it's not going to be

easy to perform this on each and every

host in a network of course so a better

solution would be to think about

capturing traffic on a network segment

that is capturing all the traffic that

is traversing a specific Network segment

for example the Uplink connection from

your from your company switch or floor

switch towards the uh the internet

router or even from the internet powder

to the internet now there are network

devices out there smart network devices

that have appeared on the market lately

that have the ability to actually

perform this type of packet trap capture

by themselves it's not an easy task it

requires a lot of CPU and memory

resources and some disk space to store

the resulting packet capture especially

if it's a if it's a core switch which

probably sees gigabits of traffic every

single second so capturing all that

traffic it's not going to be easy it's

not going to be efficient

but it is possible it is possible that

for specific links you can configure a

switch in a so-called span mode or a or

a port mirroring mode in which all the

traffic on a certain Port is being

mirrored or created a copy of that

traffic and sent on a different port now

on that different port ideally you have

some sort of powerful machine a server

that is able to capture all that traffic

and then store it and analyze it further

so that's another way of doing it and

you can also do this using a passive

device called a tap a test access port

which is basically just a t inside of a

network cable which basically acts like

a mirror of a traffic on a network

segment it's not a switch in itself it's

simply a device that whatever comes in

one port goes out the other and also a

copy of it is being generated on a third

port where your network analysis device

lies now the simplest type of package

capture we can perform with TCP dump is

to Simply specify the capture interface

so I wanted to capture all the packets

that are going through this interface

inbound or outbound of course there's a

lot of filters that we can add so we can

you know get some more sense out of all

this uh this output right here for

example filter only for specific

destinations or only for specific ports

or protocols right only the things that

actually interest us but each line right

here in this output is basically one

packet you can see the timestamp the

protocol who sent it over what type of

protocol what source Port destination

Port of course there's a lot more

information available in the man page

for TCP dump and besides the the count

number of packets that you can capture

or the outputs to a file the most

important parameter here is the capture

expression which acts as a filter

for selecting which type of traffic are

we interested in viewing so if you

scroll down here under Expressions you

can see that expression selects which

packet will be dumped if no expression

all the packets on the net will be

dumped all right so some examples in

here you can see that we can filter only

for traffic arriving or departing from a

specific host or we can even filter down

to specific TCP Flags TCP ports right

here

or you can even filter based on the

packet size you can see here this one

here prints IB packets longer than 550

576 bytes sent through the Gateway s and

up or we can print all the icmp packets

that are not Echo requests and replies

so which are not pink packets so the

expression would be icmp type not equals

icmp Echo and icmp type not equals icmp

Echo reply pretty obvious right

now luckily we also have Wireshark which

can present the same information in a

much nicer graphical user interface so

we can see the protocols right here the

source destination the timestamp and

some information about this packet right

here you can see them flowing around

here we're already

150 packets captured over the course of

like 10 seconds or so so there's a lot

of information right here of course we

can even filter this uh all this display

using a display filter right here at the

top and incidentally the same

Expressions that we can use with TCP

dump can be used with Wireshark as well

so if I'm only interested in let's see

for example ARP requests and replies I

can see only the ARP messages right here

here's an address resolution protocol

packet right here I can see the ethernet

header that's the destination which is a

broadcast right because then it's an ARP

request there's a source generated by

one of my devices right here and there's

the actual payload of the ARP Proto call

right here now the packet capture can be

dumped into a file with a pcap extension

and the format of the files is the same

between Wireshark and TCP Dom so you can

capture package using TCP dumped and

then graphically analyze them using

Wireshark if you wish

finally it's worth mentioning that a

couple of reconnaissance techniques rely

on injecting or crafting fake packets

and sending them into your network just

to see how the network reacts or how the

security devices react well of course if

you're on the defensive side you should

probably take care of analyzing how your

network reacts to such crafted packets

now among the tools here listed are

hping which is uh not just a packet

injection tool not just a packet

crafting tool but can also perform

Network scanning kind of like an end map

and also can be used to generate

flooding traffic like a denial of

service attacks it does its new simple

command line utility that it can

actually test your services your outside

exposed services to see how they behave

if a denial of service attack happens to

hit them another one is scappy that's a

small python utility that can be

configured to generate any type of

traffic you want you want it to generate

fake web requests it can do it you want

it to generate fake B P update it can do

it so you basically a small traffic

generator package crafter that allows

you to configure absolutely anything

from the outside headers to the inner

payload and then send that traffic on

its merry way

TCP replay as the name says it's a tool

that can capture traffic and then replay

it back now the replay attack was for

some time nowadays not so often was a

favorite method of bypassing

authentication systems and the security

measures that is by simply capturing the

authentication sequence between the user

a valid user and an authentication

server and then replaying that same

sequence back without even knowing that

user's password you're sometimes

guaranteed entry through that

authentication Service now of course

there are other situations out there

well where vulnerabilities to replay the

traffic can be found but this tool right

here can help you identify if you are

vulnerable to such type of attacks and

there's also one additional use case if

you have happened to capture some

anomalous traffic some traffic that you

just guess that it might be part of an

attack don't know exactly how you could

capture that entire traffic and then

replay the the back in a controlled

environment through a number of security

devices and scanning engines that might

apply more or less complex traffic

signatures in order to detect whether

that traffic actually included or not an

attack attempt finally there's an

interesting set of tools called

exploitation Frameworks these are more

complex systems that allow especially

attackers to determine first the

available vulnerabilities on a system

and then help them select or even craft

the necessary payload to be sent to that

service in order to exploit that

vulnerability now the end result in most

cases is for the attacker to gain

privileged access on the host that is

hosting that vulnerable service so

through a vulnerable web server for

example an attacker would be able to

execute his or her own commands on the

actual server machine that is hosting

that web server which gives them a

foothold inside your company which of

course makes it so much easier than to

for them to Pivot and to extend their

reach and you know grab some sensitive

information or corrupt some some

important data so a couple of these

exploitation Frameworks and the most

well-known one is Metasploit remember

this one especially for the exam another

one is sniper which just like Metasploit

is actually designed for penetration

testing not it's not just a tool for bad

guys right we're using it as a

penetration testing tool to see how

vulnerable we are to some detected and

well-known vulnerabilities that we found

in our Network and we have a couple more

here that are worth mentioning like

router exploit which is a way to Target

vulnerabilities in embedded systems or

beef the browser exploitation framework

which attempts to Target vulnerabilities

in web browsers through compromised

websites and web pages there's also the

zap The Zed attack proxy which is a tool

that helps you perform tests on web

applications and well those tests on the

wrong hands become attacks hence the

name Zed attack proxy

and finally there's paku that's a tool

dedicated for performing a security

assessment not on your own network but

on a cloud infrastructure that you might

have purchased from vendors like Amazon

Google Oracle Microsoft and so on

carefully careful with this one any type

of security assessment tool is going to

look like is going to look like it's

going to Quack Like an attack in the

eyes of an intrusion detection or

intrusion prevention system and you can

be sure that all the major Cloud vendors

out there have thorough security

measures in place that are going to

detect any type of attempts that look

like a penetration test or like an

attack from the outside so don't forget

to ask for permission there are forms

that are specific maintenance windows

that you can reserve with that specific

cloud provider during which you are

allowed and only during that period you

are allowed to perform these security

assessments because you're basically

penetration testing you're attacking

their own infrastructure which is a bad

thing to do if you don't have proper

authorization

all right so we covered a lot of tools

during the session don't just glance

over them try to install them try to run

them install a distribution such as Kali

Linux or parrot security they're all

free to use so you can install them on

your own machine or your own laptop and

play with them have a look over demand

Pages have a look over how they behave

try to scan your own home network don't

scan anybody else all right and get a

get a feeling of how these tools

actually work in the real life alright

so thank you for watching see you next

time if you enjoy this leave a comment

if you want to discuss more about the

topics that we've covered right here use

the comment section like And subscribe

and see you next time bye

[Music]

thank you


777

[Music]

foreign

[Music]

So today we're going to start talking

about security assessment and the first

thing we're going to address is the

concept the idea of a vulnerability now

the vulnerability as in the name says it

doesn't sound like a good thing

absolutely a vulnerability is a weakness

it can be in Hardware it can be in

software but it's a weakness that can

potentially be exploited giving some

sort of benefit to the attacker now that

benefit could be bypassing an

authentication system it could be

gaining access to some privileged

information or sensitive information it

could be corrupting some databases or

some files it could be replacing those

those files with something else or

amazing some unauthorized changes in a

database it could even be just

destroying data it could even be the

fact that a device is vulnerable to an

attack called the denial of service

attack which is an attack that its only

purpose is to bring down the

functionality of that service of that

device so that it's not available for

the rest of the world so scanning for

these vulnerabilities before the

attackers discovered them and taking

action in order to protect from them is

a big part of any security related or

oriented job out there because a

vulnerability assessment that lists all

the vulnerabilities found on your

systems on your network not only tells

you your current posture your current

status from a security point of view but

also tells you where you should invest

your efforts next should we upgrade our

firewalls should we invest on on

security training perhaps for our

internal employees should we invest on

on a better two-factor authentication

solution right so we first need to see

what our weaknesses lie in order to

determine where our money should go

and there are a number of places where

we can look for those vulnerabilities

number one being the actual applications

the application code itself now the

applications are a security risk because

most applications rely on some sort of

user input otherwise the application

doesn't do much right or we don't really

call it an application there has to be

some type of input even if it's an

application that deals with

communication between machines between

Services there's always going to be some

input not to mention those applications

that are actually exposed over the

Internet or even internally in our own

network that expect users to

authenticate to them to interact with

them to provide them with the ability to

execute some operations some

instructions and maybe allow them to

upload some files some some third-party

data that's going to be stored in that

application so with all this input comes

at Great risk of actually

exploiting a potential vulnerability in

that application and it's worth

mentioning here that the danger doesn't

specifically lie in the fact that an

application can be exploited but in the

fact that an attacker can gain access to

your rest of the network through that

compromised application because if an

attacker manages to execute his or own

code using the same privileges that your

let's say web server that is currently

hosting your website has

well then they're going to be able to

execute whatever commands they want on a

server that belongs to you now on a

server that normally just deals with

delivering the web pages now that's a

server that the attacker can control and

it can gain access the attacker can get

access to that server through a

vulnerable application that allows them

to execute their own code so it's not

just the fact that you'll be losing

let's say access or control over a

single application you might actually

lose access to your entire

infrastructure

just because there's a vulnerable

component in one single vulnerable

internet exposed application

and unfortunately applications are not

the only place where vulnerabilities can

be found we can also look at

vulnerabilities in the actual operating

system or the the OS kernel this one

stands for any type of operating system

out there it can be Windows it can be

Linux it can be Mac OS it can even be

about some very limited small footprint

operating systems that are running on

embedded devices or smart home devices

in your in your home and unfortunately

vulnerability is found in the kernel are

that more dangerous because any type of

code that is running inside of the

kernel inside of the operating system is

most likely running with the highest

privileges possible so an attacker that

manages to exploit the operating system

basically has complete and unrestricted

access to that machine firmware can also

have dangerous vulnerabilities and

unfortunately vulnerabilities inside the

firmware are that more dangerous because

in many cases they're impossible to

patch there are no update dates that can

be installed especially for small

devices like wearables or smart things

around your home

smart light bulbs smarts door locks and

things like that there's a lot of smart

devices out there which are actually not

that smart because they're running

really really small versions of

operating systems simplified versions of

operating systems on which security is

at best an afterthought if not

impossible to implement or to configure

so very often you're going to find that

there are security reports that tell you

there's a vulnerability in a device that

you have in your home and you have no

way of fixing that vulnerability no way

of patching it so what's the worst case

scenario when talking about

vulnerabilities or what's the potential

impact that we can find ourselves facing

if a vulnerability is exploited now

there are a number of impacts available

here of course the one that's most

obvious and the one that is let's say

the most talked about one in the media

is data exfiltration that is gaining

access to a system to a secure system

and then extracting sensitive

information from that secure system like

user databases credit card numbers

passwords uh personally identifiable

information lists of clients lists of

salaries or anything that is considered

to be some sensitive type of information

that's data exfiltration and this one is

the the attack known as a data breach

now the purpose of an attack might be

also to just destroy data hold or to

Simply cause an availability loss for a

specific service such as bringing down a

website of a company that you don't

agree with or a or a government entity

so that's data instruction you can also

face risks of identity theft again

coming back to the data exfiltration

problem which can be performed for

personally identified information and

sensitive information related to

personal data and also there can be

Financial damage not just because the

attackers might be stealing Trade

Secrets or patented information but also

because there's a reputation damage

following these type of data breaches

every single time you're going to be

losing a reputation in front of your

customers you're going to be losing

market share your stock price is going

to drop so there's going to be financial

side effects for a long time after the

incident has actually happened and if

you can put a price or you can ensure

things like information or actual assets

in your company you're probably not

going to be able to put a price on on

reputation

now from a security perspective there

are two additional types of

vulnerabilities that are extremely

dangerous the first category is called

zero day zero day vulnerabilities

associated with potential zero day

exploits or zero day attacks this is a

vulnerability that has been identified

and potentially has been exploited

before the vendor the maker of the

hardware or the affected software device

can get a chance to fix it so it's

something that we know it's out there

and we know it hasn't been fixed just

yet so it's a vulnerability that we know

about or the attackers know about and

it's just sitting right there out in the

open waiting to be exploited and there's

not much you can do about it unless the

vendor actually releases an update or a

patch that addresses that specific

vulnerability usually this type of

information is traded and sold for very

high prices because imagine if somebody

were to find a vulnerability that

applies to all the I iPhones out there

all over the world and you're the only

person who knows about it how much

somebody else would be willing to pay

for this type of information before even

Apple finds out about it that's going to

be a very high price

another source of nasty vulnerabilities

are Legacy devices and Legacy software

that is software or Hardware that is no

longer updated no longer maintained if

somebody detects a vulnerability in that

product that vulnerability is going to

be there from now on until forever

whoever still uses those products is

going to be vulnerable from now on until

forever now there are potential

mitigation controls that we can install

perhaps so for solutions for let's say

iot devices or for embedded systems that

cannot be updated anymore we could think

about installing some sort of some sort

of a packet filtering device in front of

them so that even there if they are

vulnerable to specific exploits maybe we

can catch those exploits before they

even reach their Network right but this

depends a lot on the environment if you

can do this if you can intercept that

traffic because before it reaches them

and there's a lot of ifs involved in

there there's a lot of risk with Legacy

systems in iot devices and Industrial

Systems especially Industrial Systems

those are the computer systems that tend

to be used for a very very long period

of time and they don't see many updates

and they are designed or not designed a

better way to say it to work in a

completely isolated environment so

they're not they don't have any kind of

security embedded into them it's up to

you to just keep them away from the

nasty stuff now from what we've been

talking so far it kind of seems like

talking about vulnerabilities is a way

to blame the programmers of the of the

solution that we find those

vulnerabilities in now the situation in

real life is not so simple it's not

always the the application's fault that

you currently have a vulnerability in

your in your network there's a lot of

potential vulnerabilities out there that

are exploited due to the fact that

somebody misconfigured a a policy a

device or a piece of software so

misconfiguration is actually one of the

top sources that generate

vulnerabilities fortunately this is one

of the easiest types of vulnerabilities

to fix you just have to detect them and

to know that they are there first for

example on on actual hosts it might be

about you know workstations mobile

devices even servers in your network one

of the major problems with all these the

services the applications that are

running on them is the fact that many

administrators rely on the default

settings that come built in to those

products they don't change the default

user accounts you don't change the uh

the root accounts the admin accounts

that those devices those appliances come

embedded with and it's even worse if

these type of misconfigurations apply to

network devices such as routers switches

or firewalls if you're enabling just

anybody to log in with something like

username admin password admin to your

firewall what kind of security is that I

mean it's not the firewall's fault it's

not the the programmer's fault who

programmed the operating system on that

firewall it's your administrator's fault

for forgetting about the fact that

there's a default account enabled in

there so securing administrator account

or root account on all the devices out

there is a number one priority every

single time you add something new or

reconfigure something in your network

and since we briefly mentioned security

policies don't forget not to

misconfigure policies and permissions

that don't allow guest users don't allow

regular users to view sensitive or

confidential data make sure there's some

sort of Access Control happening in

there every single time a user tries to

access a resource take that request

through an authentication system in an

authorization system which decides

whether the user is authorized or not to

access that resource or even if the user

is authorized or not to change to modify

that resource next up we have the

networks now on the network side your

networks could also be vulnerable

because on the network there might be

open ports that lead to vulnerabilities

that you might not even know nothing

about which leads us back to that

default configuration part now normally

an administrator whenever it configures

say a new a new Appliance a new server a

new network device should also check

what kind of services are currently

running on that device and if not all of

them are needed then the unneeded ones

should be shut down should be closed

otherwise nobody is going to know about

them because nobody uses them but

they're still going to be open and

they're going to be open for attacks and

an attacker is going to discover them

using network discovery tools like those

covered in the previous video now also

on the on the side of protocols if you

choose to keep some protocols open some

ports open and available in your network

at least try to use the secured versions

of those protocols as in protocol that

don't send unencrypted traffic and clear

text and protocols that use strong

authentication mechanisms in order to

provide access to confidential sensitive

data and finally an interesting source

of vulnerabilities could be the errors

generated by your applications now

normally developers like to provide more

information whenever they display an

error so that they know where the error

came from sometimes that type of

information can be a gold mine for a

potential attacker telling them what

type of service is running in in the

back end what's the structure of the

database perhaps what execution path did

the application actually take to

generate that error code like the stack

trace for example now it's it's I'm not

saying that this type of information

shouldn't be displayed at all but it

should not be displayed for publicly

facing applications so don't tell

outside users and potential attackers

this type of information keep it inside

keep it only for debugging purposes for

your own development team and remember

that there are exploits out there meant

to crash an application simply to make

that application

spit out errors such as these because in

those errors there might be some very

useful information for an attacker

alright coming back here to other

vulnerability sources and let's start

blaming other people again this time I'm

gonna blame the vendors now

vulnerabilities can hit you back from

the vendor side if the vendor actually

has a problem in developing that product

so choosing a specific vendor for a

product which is also a way of saying

performing vendor management When

selecting it products is a is a big part

of the purchasing process if you trust

the product that comes from a from a

vendors Factory or from a vendor's

development team you should trust that

vendor as well so that's you know you

can be pretty sure that the vendor did

not install some back doors or some

malware in the products that are coming

from it also and this might happen often

with any kind of vendor out there is the

fact that whenever a vulnerability is

discovered in a product you're probably

gonna have to rely and wait for the

vendor to release a fix or a patch in

order for you to be able to protect your

network based on that released patch now

how fast is the vendor going to move in

order to develop that patch in that

solution it depends on the maturity of

that vendor and of course depends on how

much they're willing to invest in r d

and security maintenance in order to

keep their customers security happy

and I'm sure you can think about at

least a couple of vendors that don't

really give a damn about their security

vulnerabilities

now from a developer perspective if

you're a company that develops

applications writes code you're probably

going to be reusing third-party code

you're going to be importing third-party

libraries you're going to be using sdks

maybe code samples from other vendors

out there any type of code that you're

embedding or importing into your main

product can be a source of

vulnerabilities so third party code

third party libraries can also bring new

features but also new bugs and new

vulnerabilities

so a thorough software development

testing process with security embedded

at each step so we're basically looking

for security flaws even starting from

the unit tests

is going to be an important part of the

development process don't forget about

security at every level and nowadays

with the prevalence of cloud providers

and cloud storage solutions even for

production data or for backup data or

for you know a Content delivery networks

in order to better serve different parts

of the globe and to deliver content

closer to the user app with user clients

their user mobile devices for example

there's a lot of Reliance on cloud

storage or on storage offered by

third-party companies so any data

breaches that affect those companies are

going to affect your data as well so if

you have an application that stores user

profile data if I have an application

that stores financial data and you rely

on a third-party company to store that

for you and to distribute it all over

the globe

well their data breaches are going to

become your data breaches

and if Insurance can cover some of the

losses incurred from such a data breach

well no insurers can cover the losses

that you will suffer from a reputation

perspective finally we have Cloud

infrastructure now the cloud is not new

it has been around for more than a

decade and more and more companies are

starting to move at least parts of their

services into some some cloud service

provider even if they're not storing

their entire infrastructure in there

they might be relying on some some email

services and some Cloud it might be

storing some files in some Cloud they

might be using a two-factor

authentication solution and some

cloud-based application so slowly we are

moving things from the on-premises world

to the to the cloud business now

security policies should apply to Cloud

infrastructure as well not everybody

knows how to implement security policies

in a cloud environment not everybody has

complete understanding on how a cloud a

specific Cloud vendor designs its own

authentication and authorization

solution in order to better protect

those resources so more often than not

Cloud infrastructures are less protected

than the actual on-premises the

equivalents that we've had since the

invention of the computer and there's

also a fine line and whenever you're

moving towards the cloud between who's

responsible for what in Cloud

infrastructure in most cases between you

and cloud service provider there's a

share the responsibility model where the

cloud service provider is responsible

for a part of the infrastructure and its

security but you are responsible for

whatever comes on top of that

infrastructure like the operating

systems or the applications not to

mention your own user data that you're

storing in there even though it's stored

on somebody else's infrastructure it's

still going to be your responsibility to

protect access to it and to ensure that

you're taking all the necessary measures

to protect it against outside threats

alright so this is where vulnerabilities

can come from later on I'm gonna talk

about methods of discovering them but

for now if you want to talk more about

this topic leave a comment and if you

enjoyed this like And subscribe thank

you so much for watching and see you

next time bye bye

[Music]


888

thank you

[Music]

hi everyone and welcome back now in the

last video we briefly covered on the

topic of security assessments and we

said that the secret assessment in

itself is a process meant to identify

the endpoints the hosts in your network

the network topology how the network

looks like how are they are all

connected and also the services the

applications that are actually

generating traffic that are running on

those hosts and we're doing all this

because all these items the network

itself the hosts and the applications

running on it these are all the

potential intrusion points in our

Network so these are all the uh all the

elements that make up our attack surface

this is how we are exposed in case of an

attack and of course in order to

properly determine how exposed we are we

also need to go one step further and

actually analyze all those Services all

those hosts for known vulnerability of

course we can only look for

vulnerabilities that have been already

discovered or documented by us or by

someone else right we cannot look for

something that we don't know exactly how

it's supposed to look like we don't know

if a vulnerability exists in a specific

piece of software unless somebody

discovers it and eventually even proves

that the vulnerability itself can be

exploited in some way so we're faced

right now with another step in our

security assessment process and that is

actually identifying looking for those

vulnerabilities in our Network so for

this we're going to have to use some

dedicated software of course we have to

do this in an automated manner that

software has to rely on a database of

known vulnerability so that it knows

exactly what to look for and what kind

of signatures to look for in there and

also we need to rely on some sort of a

scoring system why do we need some

scoring system well because in case we

discover a number of vulnerabilities

let's say 10 or 100 we need some way of

prioritizing them because some of of

them might be more severe than others

some of them could be postponed in

indefinitely I'm not suggesting there is

something you should do but it happens

but some of them should be addressed

yesterday all right so we need some some

way to prioritize these vulnerabilities

once we find them and we're going to

talk about all these ideas in the next

minutes

and I would like just to suggest that a

good starting point if you have no idea

what you're doing if you've perhaps

never done a security assessment in your

inner company or never worked as a

security analyst before a very good

starting point would be the this

official nist document officially called

technical guide to information security

testing and assessment blah blah but it

can be found on Google for free as

special publication

800-115 what is this what is basically a

security assessment for dummies document

if you wish it's a set of

recommendations generated by the

National Institute of Standards and

Technology if you scroll down to the

table of contents pretty much around

this area right here I'm gonna find some

introductory information right here

about security testing in general review

techniques reviewing documentation

reviewing logs or reviewing rules system

configurations and so on pretty much all

the stuff that we've already talked

about then we're moving on to the actual

Network scanning I'm gonna see this the

first step in here is Target

identification which is basically a way

of saying let's see what we have in our

Network first before we actually start

looking for vulnerabilities in there and

guess what we're going to start with

network discovery just what we did in

the previous video right uh then we're

gonna move over to network port and

service identification that is

identifying what type of services are

running on those hosts and then finally

we're going to be moving forward to

vulnerability scanning so we know what

the hosts are we know what they're

running let's see if we know of any

vulnerabilities that match those

specific services and those specific

versions all right we also have a

specific uh chapter here for wireless

scanning because that's an entire entire

separate chapter including Bluetooth as

well and then the next chapter is about

vulnerability validation now this is

another way of saying or of reaching

into the domain of penetration testing

so we've identified the volume ability

let's see if it's really there and let's

see how bad could it manifest if an

attacker were to exploit that

vulnerability so this is where you'll

talk about password cracking and steps

of penetration testing including social

engineering I know I'm repeating myself

but social engineering is one type of

attack that is almost every single time

going to bypass any technical controls

you might have in place so social

engineering is hacking the human right

tricking coercing threatening rewarding

a human for sharing sensitive

information all right and at the very

end you have two chapters about security

assessment so planning and then

executing the security assessment itself

and finally some post-testing activities

mainly about reporting and Remediation

so taking actions based on the actual

findings of that security assessment

document all right so pretty nifty

documented here really useful not so

long wrong just 80 pages long so make

sure you you check it out if you're new

to this to this field now I would like

to take a moment here just to clear this

up why are we doing this security

assessment business why are we doing all

this vulnerability scanning it's

probably obvious and the most obvious

reason is perhaps the last bullet here

on the screen determining our current

security posture determining how secure

we currently are now this determination

basically means that we are we need to

know what exactly our weak points are

now those weak points you don't have to

just identify them and put them in a PDF

document and forget about them and of

course not we'll have to invest or

decide what to do about them right if

you find something that proves to be a

serious vulnerability a piece of

software a device a type of security

policy badly implemented we probably

should take some sort of action we need

to replace that device we need to

replace that control we need to update

that security policy or we need to add

some more secure layers perhaps in order

to mitigate something that cannot be

mitigated with what we currently have in

our Network

which leads us to the first bullet

actually

what if we did buy a security solution

we did buy something like a firewall an

intrusion detection system a two-factor

authentication system a solution that

detects abnormal behavior of users while

navigating a e-commerce website

should you at some point perhaps test

whether that solution actually performs

the way you you expect it to perform

this is also one of the reasons behind

security assessments testing that those

Solutions those devices those controls

the security controls are actually

behaving the way you are expecting them

to behave so you're you're testing what

you just bought

so these are pretty much the reasons

behind security scanning when you hear

security assessments most people think

about something that's mandatory you

just have to put a put a check mark next

to it and generate the document because

you just have to do it well you don't

really just have to do it because there

are tangible benefits for your security

posture for the Integrity of your

business your applications your data and

eventually even your employees

so we said that we're probably going to

be using some sort of an automated tool

for performing this type of

vulnerability scanning now categories

now categorizing the types of tools out

there and the scanning methods of course

it's going to lead us into a lot of

categories and types of scanning just

like we're used to in all the security

trainings out there so starting with the

first type of scanning which is a

network type of scan or a network

vulnerability scanner if we think about

the actual application that we're using

now Network vulnerability scanner is

basically an application that connects

over the network to the actual targets

that need to be scanned your servers

your endpoints your mobile devices even

your intermediary network devices like

routers and switches and firewalls and

ips's and such and over the network

attempts to First make a list make an

inventory of whatever it can be found in

that Network make a list of active hosts

and active devices then try to identify

what type of host what type of device

that is then try to list the actual

services that are running by looking at

the open ports and how they are

answering all right and then moving

forward to the last phase the actual

vulnerability Discovery phase and that's

going to be the most complex phase of

all because the the software has to

interact over the network with those

services and elicit some sort of

responses from those active services

that is if you have a web server running

in your network the the scanner is first

going to try to reach it over Port 80 or

443 right because that those are the

standard ports for HTTP and then if it

receives some sort of an answer it's

going to try to generate some sort of a

directory listing perhaps or get some

better information from that server

maybe request some web pages and look in

the actual HTTP responses to determine

the type of the version of the server

that is running in there now once it has

a pretty good understanding and a pretty

good confidence about what type of

server is running and what version it is

it can then map this information with a

low local vulnerability database which

is going to return a couple of results

saying well for this type of Apache

server and this specific version we

actually know about 10 or 12 different

vulnerabilities each with their own

degree of severity and this is the

information that is going to end up in

the actual security assessment report

now an example of a free open source

vulnerability scanner application is the

green bone security assistance

previously known as open Vas

so this is one of the uh most well-known

tools out there for performing this type

of network vulnerability scanning you

can see it relies on a database on the

left hand side here we can see the cves

this is a code for common

vulnerabilities and exposures so

vulnerability codes right here and also

on the right hand side over here we have

the network vulnerability tests you can

see it it does have a pretty beefy

database by the way this database can

also be uh periodically updated if we

look under

uh feed status right here right behind

my face I'm going to see that we are

performing some updates on all of these

uh databases here and by the way these

are all being performed for free

now in the dashboard section here I'm

gonna see a list of tasks and their

status even if we go under scans you can

see that we currently have a couple of

tasks in here I have a network discovery

test that I just ran this one here

and also a vulnerability scan test that

is currently running we'll get back to

this one after it has finished running

now so far we can even have a peek

inside of the report that is about to be

generated by the scan even though it's

just 56 percent done you can already see

that we have a pretty high severity

rating 7.5 right here that's because we

probably found at least one high

severity vulnerability in this scanning

right here

um if we drill down inside of this

report we can see the results tab for an

overview we can see the first

vulnerability that actually generated

that high severity vulnerability of

score 7.5 you can see it's a report of a

vulnerable Cipher suit for https so

we're using some weak encryption

algorithms for https apparently this one

happens right here on my actual router

I'm home all right so let's say there's

a weakness in my in my actual Gateway

that I'm using at home of course we can

find other types of vulnerabilities in

here as well on different types of hosts

in our in our Network right here all

right you also get a list of detected

hosts active hosts on the network just

like we said before the first thing a

vulnerability scanner does is look for

the active host because well if the host

is not active there's nothing to

actually scan right open ports

identified applications running in there

identify different operating systems

apparently we have a generic Linux and

then a Debian distribution running in

there probably this is one of my

Raspberry Pi's I think and some common

vulnerability and exposure codes right

here all right

so we'll get back to this after it's

done in the meantime let's talk about

other scanning methods next up we have

application scanning Now application

scanning is a bit of a separate category

which overlaps sometimes with web

application scanning because web

applications are just so often found

nowadays I mean a lot of the

applications on your phone which you

think are local applications are

actually web applications or wrappers

for web applications now in scanning

applications the the approach is a bit

different because with scanning

applications we're looking for actually

missing patches uh Missing updates

um identifying weaknesses in the in the

server code that might be exploited by a

malformed client or by a compromised

client all right and as I said before a

special category is the web application

category because web applications

basically are include any type of

website out there any type of

interactive website and pretty much any

type of website nowadays expect some

sort of input from its users so if you

are allowed to provide some input

that's where all the problems begin

right that's where all the the nasty

stuff is going to come into your

application and potentially exploit it

so whenever you're expecting input from

your users you have to thoroughly

analyze validate sanitize that input

because that's how exploits are being

sent to your application right by

accepting unsanitized input now a web

application Scanner of course is going

to focus on the potential exploits that

are specifically crafted for web

applications now things like cross-site

scripting cross-site request forgery SQL

injection I'm going to talk about the

all of these later on but for now

suffice to say that the vulnerabilities

that we're looking inside of a network

and into a specific service that are

running on a network are completely

different from the vulnerabilities that

we're looking for whenever we're

actually interacting with an actual

application hosted perhaps behind one of

those web servers that we identified

with a Network volume ability scanner so

we you could actually find

vulnerabilities at two levels here you

could find some vulnerabilities in the

actual web server be it Apache nginx IIs

whatever you're using and then you could

find a whole bunch of new

vulnerabilities in the actual

application code that is running on top

of that web server like WordPress or

Joomla or whatever application you're

running in there and of course we have

specialized scanners for each and every

one of these types of vulnerability

scans another type of scanning another

category is scanning and this one is a

pretty simple one to understand it's

active versus passive scanning now the

most obvious one is active scanning

where you're actually sending requests

to that web server to that web

application to that whatever type of

server you're finding or what type of

host you're you're detecting on a

network see how it reacts and see if you

can determine it that a specific

vulnerability exists in there that's

active scanning because you're actively

talking to that host in order to elicit

some some responses back can then

determine something from those responses

at the opposite pole we have passive

scanning which is easier to perform

because it relies on capturing Network

traffic generated between the clients

and the and the servers without actually

interacting directly with those those

applications so you're just looking at

the generated traffic and try from that

traffic to determine whether there are

potential vulnerabilities on the on the

server or even perhaps on the client now

of course this sounds nice it's not

always as visible doesn't provide you

with that much confidence as an active

type of scanning but also if we're

talking about penetration testing or so

if we're talking about an actual

reconnaissance phase inside of an attack

this type of scanning is completely

unintrusive it cannot be detected if

you're just intercepting traffic and

passing it over right without making any

changes to it just looking at the

traffic that's not something that can be

detected in your next work on the other

hand if you start hitting that web

server with all types of requests trying

to perform a Brute Force trying to

perform a an SPL injection trying to

access unprotected areas trying to

execute some some remote code well those

attempts are most likely going to be

detected at some point because they're

going to generate a lot of Errors a lot

of logs even some intrusion alerts

perhaps now on the other hand passive

scanning doesn't provide you with that

much information because you're not

allowed to actually send your own

requests but it is completely invisible

so active scanning is a type of very

intrusive scanning but that is also a

Next Level to this the next level of

intrusion is when you're actually trying

to actively exploit the vulnerabilities

that you're detecting and that type of

scanning is called a penetration testing

and that also falls under the active

scanning techniques and finally the last

category of scanning is credentialed and

non-credentialed type of mechanic now in

non-credentialed let's start with the

second one means that the the scanner

the vulnerability scanner the network

scanner simply connects over the network

attempts to generate some some responses

attempts to scan the network traffic

scan the reply is coming back from the

application that it's scanning but

without actually having valid user

accounts or user privileges to interact

with the host or with the application

that it attempts to scan so it's

basically behaving just like an outside

user that doesn't have any kind of

privileges to interact with that

application or with the server that is

hosting the application now on the other

hand we have credential scanning where

apart from the fact that we can directly

interact with the application just like

a regular user we can potentially

leverage a valid user account for the

application or a valid user account for

the host for the server that we're

attempting to scan so that we can

actually log in or the the application

Scanner the network scanner can log in

into the actual Target and then gather

all the information regarding the the

running processes running Services what

versions they're running what type of

configuration files they're using the

security policies that are in place on

that specific host all kind of stuff

that normally you would have to to guess

or to imply or to deduce or to test from

the outside so credential scan is going

to provide a lot more information simply

because you have access to the actual

application or the host itself you can

actually view its configuration station

and then add that information into the

security assessment report now to

perform a credentialed scan and most

vulnerability scanners out there it's

simply a process of pre-configuring a

set of credentials to be used in a

scanning process in case of the Greenbow

security assistant we have the

configuration tab right here and then if

we select credentials right we currently

don't have any credentials but we have a

small button here on the upper left hand

corner the the interface kind of changes

pretty often so it might look different

when you are attempting this if I click

this it's going to lead me to a screen

that says new credential you can just

give it a name right here my creds right

the type of the credentials can be a

combination of a username and a password

could be a username and an SSH key in

which case I have to provide a private

key right here and perhaps even a

passphrase if if the private key was

protected by a passphrase I could be

using a client certificate I could be

using SNMP credentials pgp or just

password and so on and so forth so I can

just generate a simple username and

password set right here let's say that

I'm using something like admin with a

super secure password that's what I'm

writing in here then saving this as a

set of credentials now how do we use the

set of credentials we simply need to

generate a new type of scan and tell the

scanner to use these credentials so

under the scan menu we select the tasks

option

all right again we have this small very

inconspicuous button here in the upper

left hand corner that says new task all

right let's give it a name right here my

is my test cam all right scan targets

the scan Target section means what

exactly am I going to scan am I going to

scan a single host am I going to scan an

entire network maybe a set of subnets I

already have defined an object here that

says my network by the way you can also

click on this new button here to define

a new Target in this case right here we

can uh for example add something like

192 168 15.0 24 and that's going to scan

this entire subnet of course you can

load multiple subnets multiple hosts

from a file and have some more options

in here like the port list

all right uh how to check whether the

host is alive right we can do a simple

ping but we know that ping might be

filtered from time to time to time uh we

can also do a tcpx scan a TCP synth scan

remember these when we talked about nmap

well pretty much same process goes on in

here when we determine whether host is

up before actually trying to scan it

further and so on and so forth we can

even consider it alive from the very

beginning right just trust me it's alive

even if it's not responding

now apart from this uh we could also

check the uh the list of words that we

need to scan so we can perhaps Define a

custom list that only a specific set of

words are going to be a bisciano we're

only interested in a couple of

applications perhaps and then we we

finally find the credentials section so

under the target actually when we Define

a scanning Target this is where we can

actually tell it to use a set of

credentials that we defined a minute ago

so for example if we know that those

credentials are relevant for let's say

windows machines it might be an

administrative account it might be an

account specifically defined and used

for vulnerability scanning we can check

this SMB right here set of credentials

and use these credentials here whenever

the scanner encounters a Windows host

identically we can also select the

credentials for SSH for esxi login for

SNMP and depending on the software that

you're using of course you might have

more or less options in here alright so

we can save this

we're back to the new tasks section in

here and we can also check the scan

configuration now the scan

configurations are predefined for

openvas of course you can Define your

own but basically these are the um the

settings about how many signatures are

we going to use how how much scanning

are we going to do actually for each and

every host How deep the scanning process

is going to be now full and fast is a

pretty much a default type of scanning

we could also do a discovery or a host

discovery type of scan if we are only

interested in determining the active

host in the network right and you can

click save a new task right here has

been has been created as my test

scanning and you can launch it by

clicking on the start for the Play error

right here on the right and by the way

speaking about scanning configurations

you can find under the configuration

menu a scan configs section which are

the predefined scanning methods that

open the as can use you can see we have

a discovery or a network discovery type

of scanning right here and also on the

right hand side there's the nvts that

the network vulnerability tests that are

being performed for each and every scan

type you can see that is system

Discovery for example that simply

discovers the operating systems in your

network doesn't have that many tests

performed in here but something like uh

let's say uh configuration checks for

log4j this one is interesting one right

it does have performed like 32 000 tests

in here or the full and fast uh with an

uh emphasis on full it actually uses all

the 99

000 nvts available in the database all

right if you can of course Define your

own in here there's a new button here in

the upper left hand corner and you can

use it in your own custom scans now

after the scan is done of course you

will be presented with a scan report

which is going to show you all the

findings detected during that scanning

process basically this is going to

include things such as the asset so the

item that was scanned might be host a

mobile device servery Network device

whatever it is the vulnerability that

was discovered identified by a code of

course that can lead you then to read

more find out more about that specific

vulnerability which versions it applies

to if it has been fixed or not if there

is a patch or an update that you can

install for it how can it be mitigated

and finally a CVSs score CVSs stands for

common vulnerability scoring system it's

the scoring system that we talked about

in the very beginning when we said that

we need some way to prioritize these

vulnerabilities in order to figure out

which one is worse than the other right

in order to determine where we should

focus our efforts first okay so this is

basically a metric right for comparing

different vulnerabilities that you can

find on your system now the metric

itself is based

I want to learn a lot of factors it's

not just something like you know this

one looks like a 7.5 to me and it's

definitely worse than a 5.2

all right we actually have to reach

those numbers from a number of factors

that involve how easy that vulnerability

is to exploit how much privilege is

required from the attacker to perform

that attack how much exposure are we

risking in case the vulnerability gets

exploited and so on and so forth we're

gonna have a look in a couple of slides

here

um over all those factors that combined

generate the CVSs score

so let's start with an example and

before digging into this example let's

have a look at our report that was just

generated by openvis and see that the

the CVS that the vulnerability is

detected actually look exactly like this

so let's switch to opengis

and move over to our scan reports all

right we have this vulnerability scanner

report which is almost done 90 done but

we have enough information already so we

can just open it and click on the

results tab right this is where we're

going to find all the vulnerabilities

that were identified during the scanning

process you can see the vulnerability on

the left hand side the severity this is

the actual CVSs score that we talked

about the 7.5 6.1 and so on usually

they're color coded so there's going to

be something like low medium and high so

they they pop up right right away if

you're just looking for some critical

vulnerabilities there's the host that

the vulnerability was identified on the

location the service that exposes this

vulnerability in our case is the actual

web server running on 443 so the https

service on the router and when it was

detected now if we drill down into this

vulnerability right here you can get a

summary detection resolve detection

method uh what type of software is being

affected any mitigation solution that

you might implement in order to fix this

and it's also going to provide some

information about some links that will

teach you more about the actual

vulnerability and ways to mitigate it

now the actual code for this

vulnerability is explained right here

under references section we can see we

actually have three cves for the same

vulnerability let's choose the first one

so the first occurrence and we can see

right here this is the description of

the vulnerability and the base score 7.5

and the base Vector CVSs code following

by followed by a bunch of characters in

here which we're going to discuss in

just a second basically all these

parameters here

are listed below so that's the attack

Vector attack complexity how many

privileges required if user require

interaction is required for not and so

on and so forth let's go back to our

slide here and find out more about this

alright so this is how a vulnerability

code appears the very first time so this

is the code for a vulnerability code

called cve common vulnerability and

exposures and the first number here is

going to be the year when the

vulnerability was discovered and the

second one is just a just a number which

is incremented by one every single time

a new vulnerability is discovered now

the base score is going to be

numerically calculated and then

evaluated as low medium or high and the

vector basically describes all the

parameters that make up this score all

right now the possible scores range from

0 to 10 or 0 is no threat starting with

low medium and high everything above 9

is critical it's something that you

should address immediately

and the code itself is made up of a

number of variables in here the vector

access complexity user interaction scope

how much of confidentiality integrity

and availability is being affected by

exploiting this vulnerability so how is

that number actually calculated well

it's not that simple but it all starts

with base metrics now the base metrics

that characterize that vulnerability no

matter what on top of the base metrics

we add two optional metrics first one

being the temporal ones temporal Matrix

make that vulnerability higher or lower

depending on how much time has passed

since that vulnerability has been

discovered maybe in the meantime that

software has been retired maybe in the

meantime an update has been published so

with the passing of time that score May

actually change due to these temporal

metrics a vulnerability from 30 years

ago probably is not going to be that's

critical nowadays and finally we have

environmental metrics and both of these

are optional environmental metrics are

the metrics that apply to your own

environment so there are things that

depend on how that specific software

that had the vulnerability is

implemented in your environment because

in your environment perhaps a web server

is completely isolated from any outside

network is air gapped for example in

that case a vulnerability in that web

server that can only be exploited over

the Internet is something that doesn't

apply to you doesn't apply to your

environment because it simply cannot be

reached from the internet so we have

some metrics in here we have the base

ones we have the temporal Matrix which

take into account how much time has

passed on what has happened in the

meantime an environmental metrics that

take into account your own environment

your own network

right so starting with the base metrics

we're first going to be looking at the

attack Vector which can be Network

adjacent local or physical let's see

what that means well if we head over to

the CVSs specification document which is

one way of saying read the manual all

right then scroll down here we can see

the base metrics that we just talked

about the temporal meta groups and the

environmental metrics so you can see I

wasn't lying before when I told you that

these metrics are actually all

calculated together so this is the

scoring and finally we start with the

base metrics we have the exploitability

metrics right the first one being the

attack Vector the attack Vector is the

network requirement for the attack to be

successful which basically means that it

can be performed over the network

it has to be performed in an adjacent

Network like the attack is limited at

the protocol level to a logically

adjacent topology so for example this

can mean an attack must be launched from

the same shared physical Network or

logical Network

which is completely different from a

network attack Vector which can also

include the entire internet all right so

a Json means it has to be next to or at

least part of the same subnet

next one is local this one says that it

is not bound to the network stack so it

doesn't have to be performed over the

network but it means that the attacker

must be able to access the system

locally like a keyboard or a console or

remotely over SSH or the attacker might

rely on some user interaction by

coercing or tricking another person into

performing these actions and finally we

have the the physical Vector which

requires the attacker to physically

touch or manipulate the vulnerable

component so of course depending on the

score of this this one is going to

increase or decrease the actual

criticality of our attack Vector next

one we have attack complexity simple

enough low or high attack complexity

lower high if you scroll down here low

means well we don't really need

specialized access conditions by the way

this one right here low is bad right so

the attack complexity doesn't require

any kind of prerequisites in order for

it to be successful so in in attack

complexity required attack complexity is

low this one is going to increase your

CVSs score on the other hand if the

attack complexity is high this one means

that a successful attack depends on

conditions beyond the attacker's control

so it takes a little more work from uh

from the attacker's point of view in

order to successfully conduct an attack

like this so the attacker must gather

knowledge about the environment must be

able to prepare the target environment

or might must inject themselves into the

logical network path between the Target

and the resource requested by the victim

so it has to perform some sort of a man

in the middle so it does take some work

sometimes this type of work is close to

impossible so this is hard this is why

an attack complexity of high is actually

not that worrisome

next up we have privileges how many

privileges are required by the attacker

to successfully conduct this attack none

low or high let's see a brief

description of these as well none

doesn't require any access to settings

or files of the vulnerable system to

carry out an attack again none is the

most dangerous one if it doesn't require

any privileges it means that pretty much

anyone can perform that attack which is

the worst case right low privileges it

might require that the attacker can

impersonate some basic user a regular

user now of course on the other hand we

have high privileges that require an

attacker to have administrative control

over the exploited device or the

exploited system

what's next user interaction does the

attack require no user interaction or

some user interaction all right the

vulnerable system can be exploited

without interaction from any user again

this is bad okay you don't rely on

anything else in order to conduct the

attack or anybody else or required

because the successful exploitation

requires a user to take some action such

as clicking a malicious link downloading

some file executing some files inserting

a USB stick with malware on it any kind

of action performed by a user of course

if it requires the user interaction then

complexity increases and then the score

decreases because it's less likely for

that attack to succeed at least when you

compare it with the situation where

there is no user interaction required to

successfully conduct that attack

then we move over to the scope

and the scope basically means whether

the attack can impact

other components outside the intended

target

so is the scope unchanged that is if I'm

targeting a specific Target that's the

only Target that gets affected or

changed if other entities are going to

be affected as well you can probably

guess which one is worse than the other

right so unchanged means that exploited

vulnerability can only affect resources

managed by the same security Authority

uh pretty complicated way of saying that

you're not affecting any other resources

well changed means that we are actually

affecting other resources as well and

finally we have the impact metrics

how are we impacted from a

confidentiality perspective Integrity

perspective or availability perspective

if that vulnerability gets exploited and

you can probably guess what high low or

none means for each and every one of

these

for example for confidentiality Phi

means a total loss of confidentiality

resulting in all resources being

divulged to the attacker so the attacker

gains access to all the privileged

information

while low

might be for example that there is some

loss of confidentiality but the attacker

for example doesn't have control over

what information is obtained so it can

get some information it just doesn't

have a choice into what exactly is it

going to to get in return in return for

uh for a successful attack and of course

no loss of confidentiality means that

the vulnerability doesn't disclose any

confidential data right the same goes

for it integrity

and availability

basically a high loss of availability is

the equivalent of a denial of service

attack so Bringing Down the application

Bringing Down the service making it

unusable while a low availability impact

means that just the performance is

impacted is reduced you're gonna get

some annoyed users that complain that

the service is low but the service is

still going to be available

next up we have the temporal metrics

which we can talk about here and these

include the exploit code maturity is

there an exploit code already developed

for this specific vulnerability if there

is no exploit code available or that we

know about then of course the score is

not going to be so high because the risk

is not so high for somebody to actually

use that exploit code and exploit the

vulnerability remediation level as you

can probably guess is there a patch is

there an update a fix that we can

install to remediate this vulnerability

not Define that is it doesn't apply you

cannot have a patch that can address

this vulnerability unavailable just yet

we can might have a work route

better than nothing white have a

temporary fix or we might have an

official fix all right now report

confidence

if we scroll down here again in the

official documentation report confidence

means how much can we trust the actual

existence of this vulnerability like

detailed reports exist or a functional

reproduction is possible we can at every

moment in time demonstrate that this

vulnerability exists and it can be

exploited

or reasonable like do we have some

details published but the research

hasn't been fully completed

finally we have the environmental metric

right the last one right here security

requirements as we said before this one

applies to your own environment so a

definition for this actually it's a

pretty good one right here in the

official documentation that says that

the environmental metrics and especially

the security requirements

confidentiality integrity and

availability enable us to tweak the CVSs

score depending on the importance of the

affected iot asset to a user's

organization how important the loss of

confidentiality Integrity or

availability is to us

so for example it means that a loss of C

or I or a is likely to have a

catastrophic adverse effect on the

organization or on the individuals

associated with the organization like

your employees or your customers same

goes for the other levels in here

all right so now if we go back to the

example from before that CV that we

looked into you can see that the vector

now can kind of make sense right we have

an attack Vector of network have an

attack complexity of low we have

privilege required none we have user

interaction required we have a scope we

have an impact of c and I and an a right

so this is what that Vector actually

so moving back to our vulnerability

scanner we can actually read this base

Vector now with different eyes right and

then understand what exactly is going on

and within all these metrics that make

up that 7.5 cpss core now of course you

don't really need to know the exact

formula that goes into calculating this

here it's going to take like five

seconds to search it on Google but it's

not going to be required for the exam

anyway

now I know I've mentioned this before

but there's another big source of

vulnerabilities and that's the source

where we don't blame the developers but

we should blame the network admin or the

sys admins and that's the the place

where vulnerability is stem from Bad

configurations you have the firewall in

place you have all the functionality

available in there you have all the

security methods that you can enable you

just don't enable them or you just

enable them in a way that is too

permissive and opens use yourself to

other attacks and that's why it's part

of a security assessment or a

vulnerability scan a big part of it is

the review of the configurations of your

servers of your network devices even of

the security policies installed on your

host you can find things in here such as

security policies not enabled at all too

permissive security policies updates not

being performed for intrusion detection

for antivirus Solutions

password policies that allow users to

set passwords such as one two three that

are immediately broken and and your

account get immediately compromised

so configuration vulnerabilities can be

done as a configuration scan or

configuration vulnerabilities scan now

of course in order to access the

configurations on your hosts on your

network devices the type of scanning

that you need to perform is going to be

a credentialed scan you probably guessed

this right because otherwise you don't

have access to the configuration files

or the security policies that are

deployed on that host you need to read

the actual file you need to read the

actual security policy the group policy

that is being configured on that host in

order for you to be able to determine if

there's something misconfigured in there

and we have some methods of automating

this one of them being the scap protocol

the security content automation protocol

this one is a standard protocol used by

scanners to determine whether a

workstation an endpoint matches a

well-known predefined configuration that

we agreed on so normally when you start

looking for misconfigurations you need

to have some sort of a baseline you need

to have a predefined model an ideal

configuration that you can share with

your vulnerability scanner and and tell

it you know try to match the

configurations that you find on these

hosts with this ideal Baseline and see

if there are any discrepancies in there

if there's something that doesn't match

otherwise the vulnerability scanner is

going to have a very limited view as to

what is right and what is wrong what

should be in there what shouldn't be in

there because it has nothing to compare

it to so you need to start with a valid

Baseline and one of the methods for

describing that Baseline is by using the

language called Oval open vulnerability

and assessment language which is just an

XML type of file that describes your

ideal Baseline it describes your your

system security policies describes how

your configuration should look like and

what are the elements that a

vulnerability scanner should be on a

lookout for and also on this chapter we

have xccgf extensible configuration

checklist description format all right

remember that one now you just have to

remember the acronym here but uh this

one is another another XML standard for

XML type of file actually for describing

best practices or checklists

for providing that security Baseline so

this is basically a file that means look

for this item make sure it's in this

state look for this item make sure it's

in this state right if everything checks

out then you get 100 score at the end of

it you're pretty sure that the

configuration the security configuration

matches the Baseline and you're good to

go and by the way these uh methods of

automatically comparing your

configurations with predefined baselines

can be made can be simplified a lot

especially using commercial software

such as nessus because such products

come pre-packaged with pre-defined

baselines for what a web server should

look like what's configuration for a web

server should look like what's the

configuration of foreign Microsoft SQL

database server should look like and

stuff like that so you don't really have

to try to write these configurations by

hand line by line in order to validate

your security configurations right you

can already get some validated templates

but in most cases these come

pre-packaged in commercial software and

also these types of software usually

include specialized tanning types called

compliance scans so for example if you

are facing an audit if you're running an

online business that processes credit

card information you might be interested

to see whether your infrastructure

matches the PCI DSS requirements for a

payment card industry now you could of

course manually try to validate every

single requirement of the PCI DSS

standard requirements or you could use a

predefined template on a commercial

scanner such as nasus that is going to

automatically validate all those fields

for you and in just a matter of minutes

it's going to return to a report saying

this is where you're compliant and this

is where you're not complying and also

give you some recommendations as to what

you might need to improve similar

compliance scans could be done for

example for gdpr for personally

identifiable information how are you

protecting or how are you processing

personal identified information or let's

say HIPAA right for medical records and

so on automated scanners are not perfect

of course they sometimes generate errors

but the errors that they generate are

actually let's say small white lies

which are called false negatives and

false positives now false positive let's

start with the second one and false

positive means that a vulnerability that

is found is not actually there or is not

relevant to you which is not that bad

right because we're identifying

something it just takes us a little

while to determine it at the worst we're

just wasting some time right to

determine that the vulnerability that we

see in the report actually we don't care

about it it doesn't apply to us now the

unfortunate situation is where the

scanner returns a false negative and

actually it's not going to return a

false negative it's not it's not going

to return anything a false negative

means that there is a vulnerability in

there that the scanner did not catch and

of course it's not not going to be

included in the report it's the absence

of that vulnerability in the report that

we call a a false negative

now what can you do against false

negatives think about the situation

where you're running an antivirus scan

you know a file is infected but the

antivirus doesn't report it as infected

what do you do well you could probably

try scanning it with a different

antivirus solution right that's exactly

what you could do in the vulnerability

scanning world as well you could try

multiple vulnerability scanners on the

same network on the same topology see if

those results match some of them might

catch some vulnerabilities some of them

might not

on the other hand you could of course

keep your signatures your vulnerability

signatures up to date that's something

that you should always do before

attempting a new scam and at the very

end of the day you could try to enhance

those vulnerability results with some

other source of information you could

try manually analyzing some suspicious

hosts that you might just think that are

not behaving the way they should be

behaving right analyze running processes

in there let's see if they've generated

some traffic with some unknown

destinations maybe potentially bad

reputation destinations out there right

things like that if you suspect that

there's more out there that the variable

scanner doesn't detect maybe you should

investigate trust your gut from time to

time

all right so how can you avoid these

false results well there's not that much

you can do about false results but for

example let's make sure that the scanner

is being performed correctly so we're

not missing anything we're not missing a

big part of the network because we might

be filtering the actual scanning traffic

if you're performing a network-wide scan

you should probably temporarily disable

all those intrusion detection and

intrusion prevention systems that you

might have in there because a

vulnerability scan looks awfully like

the reconnaissance phase before an

attack and it's going to raise some

Flags going to raise some alarms you

have some ips's in there they might try

to block your scanning traffic and your

report will be incomplete so make sure

that your scanning traffic is allowed

and is not filtered by any security

devices in your network

other than that try to perform

credentials can whenever it's possible

because it's going to provide you with a

lot more usable and useful information

about the the systems and the the

services that are running in our Network

you're not going to be able to view the

active processes where you're not going

to be able to view the actual

configuration files if you're not

performing an uh a credentials type of

scam now you might determine that your

scanning software needs some fine tuning

maybe it's going to constantly alert you

about some vulnerabilities that don't

apply to your environment maybe you need

to remove those from the actual

vulnerability database or you might have

to fine tune it because some Services

respond very slowly right and the

vulnerability scanner is a bit more

impatient so there are a lot of tweaks

my fine tuning techniques that you can

perform in each vulnerability scanner

that can better match the uh the way

your environment behaves

if you're performing configuration

scanning make sure that the Baseline

you're comparing those configuration to

is okay and is up to date a baseline

created five years ago might not apply

today so make sure you invest some

research invest some effort into

maintaining those baselines up to date

because those are the baselines that

you're going to be comparing all your

security policies all over the network

too and finally make sure that a result

no matter how scary it looks like in

that vulnerability report actually

applies to your network you might be

receiving some vulnerabilities that were

mistakenly identified as

affecting some of your let's say IIs web

servers in your network

and if you think about it for a second

you realize I don't have any Windows

servers in my networks how could I have

an IIs vulnerability well first you

should probably investigate just to make

sure that nobody is running some virtual

machines you're running Windows server

that you might not know nothing about

and also think about the fact that many

of these

scanning methods especially the on

credential scanning methods rely on some

very fine type of information that can

be deduced from the network traffic from

the way the server behaves from the way

the server answers in order to determine

what type of service is running in there

and what type of application is behind

that open port sometimes vulnerability

scanners make mistakes and mistakenly

identify something that is an nginx

server a web server as an IIs web server

right simply because it's it's

configured a bit atypical perhaps so

make sure you're validating those

results don't just trust them blindly

make sure they actually apply to real

resources hosts applications and

versions that can be found in your

environment in your network

and well here's a bit of a good news

well at the end of the day think about

well I did find this vulnerability

is it worth the effort is it really that

critical in uh it does it really put me

up to that much risk so that we need to

actively invest time effort and money

into fixing it

think about that there's going to be a

lot of vulnerability of low score

vulnerabilities out there that you're

gonna read you're gonna see that it's

there and you're gonna say like meh it's

okay I don't really care about that one

right let's leave it right there maybe

next time we're just we'll just do a

massive update of all our our uh you

know web servers in our server farm and

probably that one is going to be fixed

as well but really they don't care if

somebody exploits that minor

vulnerability now I'm not saying be lazy

about this of course but try to focus

your efforts on what really matters

word of advice for life as well

alright so that's it about vulnerability

scanning and results I would strongly

encourage you to play at least with open

vas because it's available for free

install it in a Docker container if you

wish I'm going to provide you with the

docker command and the repository you

can install it from in the video

description you can play with it for

free keep in mind that it takes a long

time to build up because it's going to

need to update its vulnerability

databases and all the databases that it

relies on so they'll be impatient give

it some time to build up other than that

if you want to continue discussing on

this topic leave a message in the

comment section if you enjoyed this if

you like this if you found it useful

like And subscribe good luck on the exam

and see you on the next video bye bye

[Music]

thank you


999


[Music]

foreign

[Music]

hi there today we're going to talk a bit

about pen testing or penetration testing

now remember in the previous videos we

talked about discovering network devices

Network reconnaissance and then we

talked about methods for identifying

what services are running on those

network devices what open ports they

have what's running behind those ports

what services what versions they have we

use that information to identify

specific vulnerabilities that might

apply to those applications and those

versions and we ended up with a

vulnerability report now there's one

more level we can go

in the the depth of our security

assessment process and that is to

perform what is called as a penetration

test so after we've discovered the

vulnerabilities and we have them on

paper listed nicely in a table what

about trying to actively exploit those

vulnerabilities just to prove that the

danger is real and can happen at any

time that is penetration testing the use

of real hacking tools and hacking

techniques to exploit the

vulnerabilities that we just found in

our vulnerability scan as you can

probably guess this approach comes with

a couple of trouble or potential for

trouble from a lot of different

perspectives so let's talk more about

this in the following minutes

first of all let's talk about the

difference between threat hunting and

penetration testing now threat hunting

means looking for threats before they

actually get a chance to happen looking

inside of your network traffic in your

network events the logs are generated by

your network devices or your host your

endpoints the list of processes that

they're running on each and every

endpoint stuff like that monitoring the

network looking for potential indicators

of compromise so that is threat hunting

is considered to be not so disruptive

it's a way of saying look but don't

touch we're just analyzing the

information that we have at our disposal

in order to find potential threats in

there or vulnerabilities but it doesn't

interact directly with any of our

systems so it's a way to determine

threats without actually bothering

anyone or creating any type of

disruption

on the other hand we have pen testing

which is completely opposite to it right

this is a way of saying let's say how

the network could be attacked let's see

if those vulnerabilities that we just

found can be actually exploited and how

bad the result would be if they were to

be exploited the pen testing itself the

process of fan testing actually is not

just about exploiting those

vulnerabilities it also includes the uh

the discovery of those vulnerabilities

as well but the main difference is that

in this case we're actively trying to

break the network to break the services

to crack that authentication logging

page to even to trick the users into

divulging sensitive information that's a

really interesting part of pen testing

most people think about pen testing you

know just take all your hacking tools

out there and start throwing everything

that you have to at that web server no

it can also be done by impersonating an

I.T support technician and calling an

employee and making them divulge their

password because you need to perform

some updates on your on their account

because otherwise they'll lose access to

email or something like that that's also

a part of penetration testing so you're

not just testing the security of your

IET security systems you're also testing

the security of your human weakest link

but enough about that let's let's come

back and talk about the actual technical

part of pen testing one very important

item here is the fact that penetration

testing is always going to be extremely

disruptive that's because actively

attempting to exploit a vulnerability a

weakness in a system is going to cause

that exploit to manifest itself which

can be an exploit that causes a denial

of service brings down an active

character server brings down the website

that is hosting the company website or

company email it might be an exploit

that actually corrupts a database it

might be something that extracts

sensitive information

so you're basically simulating a

successful

attack

it can be done from the inside it can be

done from the outside but the end result

can be disastrous because it behaves

just like a normal attack that's why a

penetration test it's pretty tough to

fully deploy in real life especially in

a live network with live users but it's

going to provide you with a lot of

valuable information as to how

vulnerable your network and your

services actually are so the purpose of

pen testing is to identify

vulnerabilities and to prove that they

actually exist and they can be exploited

think about this you might be going to

top management and say you know the the

server that is processing or that is

hosting our HR application that is

processing all our employee data is not

so secure here's a report that says that

the server is running an outdated

version an outdated library and this

server is at risk right now and the the

you know someone from management might

look at this and say you know what yeah

I get it you're saying that we have some

risk in there I don't really understand

what's going on with this what are those

protocols what are those versions you

know yeah we'll we'll discuss this

sometime in the next board meeting maybe

next quarter because you don't really

need to invest right now anymore in

security and people just tend to forget

about these reports well think about it

this way if you as an authorized

penetration tester go to top management

and hand over a security assessment

report along with an Excel sheet that

includes the salaries of everybody in

the company just saying you know what I

told you this one is a vulnerable server

here I am an outsider that doesn't even

have a valid user account in your

company I was able to get this

spreadsheet with everybody's salaries

from your company here it is

you know how much more impactful would

this Behavior be and uh even though it's

a bit theatrical what I've just said

here uh actually the the purpose of

penetration testing is exactly this one

right here to create awareness and to

actually teach people of about the

importance of implementing correct

security controls and security measures

so in order to be able to perform this

type of very intrusive and risky type of

test

we first need to get approval and that

approval is basically a way of saying

this is how I'm going to behave this is

what I'm going to scan and all these

rules that we're agreeing upon are going

to be put down in writing in something

called a document for Rules of

Engagement right it's uh it's basically

a war term but we're using it because

we're basically simulating an attack

against our own network so what's going

to be inside of this Rules of Engagement

document we're going to find first of

all authorization we need to have signed

authorization from everybody who agrees

that we are going to be attacking that

Network we're not going to be performing

this outside

the necessary approvals because what

you're doing then is called a Cyber

attack which is punishable by law all

right next up we need to specify when is

the attack going to happen it has to be

specifically time Bound for a specific

time frame we know how long is it going

to take that's going to be some

something that's going to look like a

maintenance window where we don't expect

the services to be available we don't

expect uh to be a critical time for our

users or for our employees and also have

to define the scope what's going to be

affected what are we attacking are we

just performing a penetration test on

our web server or public facing web

server are we performing a penetration

test on the uh let's say the email

application that our employees are using

maybe against our internal application

that HR application that might be only

accessible from the inside all right so

we have to clearly Define what it is

that we are going to attack

so

penetration testing rules are sometimes

a gray area in many countries because

some countries don't have a legislation

that makes a clear distinction between a

penetration test and a Cyber attack

and if the let's say an internet service

provider detects something that looks

like an attack you might say that you

know it's not attack here's the right

paperwork it's actually a penetration

test and they might say well our law

doesn't specify what a penetration test

is it looks like an attack you're going

to be prosecuted so careful with this

careful about the territory laws that

you're into and especially the laws of a

territory where you're launching the

Cyber attack or the penetration test

from also Define what type of tests are

going to be performed all right we're

testing applications we're trying to

bring down the network we're hitting the

VPN endpoint we're trying to crack the

uh the email Gateway are we going to

perform social engineering or not again

all the all these test types should be

thoroughly documented in the Rules of

Engagement also what tools are we going

to be using what techniques are going to

be using so for example we might agree

that we'll be using social engineering

so we can trick users into revealing

personal or sensitive information but

you're probably not going to be allowed

to

beat up a user into convincing them to

give up their password you're probably

going to be allowed to impersonate

somebody on the phone but if that

doesn't work you're probably not allowed

to wait for that user in the parking lot

and give them a good beating until they

give up their password all right so

again that's gonna be and uh that's

probably not going to be an approved

tool and technique right

also uh the point of view that the

attack is being performed from

that is how much knowledge we have about

the network that we are currently

attacking that we're currently

penetration testing divides these

penetration tests in uh about three

categories white box penetration tests

are usually the penetration tests that

simulate an Insider threat with uh

Advanced knowledge of the systems white

box means that we're attacking a system

that we know everything about we know

how it works we know what's inside we

know what versions it's running we know

probably even have some some privileges

to interact with it that's a white box

penetration test we know everything

about the system now at the other end of

course we have a black box penetration

test where we behave just like an

external attacker with no privileges

would have if they suddenly decide to

attack or network so it's an attacker

that's uh can simply scan our internet

facing resources like the VPN endpoint

maybe the email server DNS server made

with web servers and such and we're

going to behave just like an external

attacker that doesn't know anything

about the network but of course they're

trying to discover more about the

network using open source intelligence

scanning techniques and such somewhere

in between we have gray box testing

which is kind of like white box so we're

kind of simulating an Insider threat

somebody that's already inside of the

network with some knowledge but not

Advanced knowledge we have just partial

knowledge about the network we might be

simulating an attack performed by let's

say a user a non-technical user in the

company

all right so that's the difference

between white Ray and black box testing

we should also define whether we can

engage the staff or not and I'm again

I'm not talking about beating up the

staff but talking about whether the

human uh the human element is going to

be involved or not again we could create

disruption we might agree that we're

going to create disruption in some

services or applications that are being

used inside of the company but you might

not be allowed for example to keep the

employees from doing their job you know

by interviewing them or trying to coerce

them into revealing some information

again part of social engineering and

finally of course we need to clear the

state what should be included in the end

report normally a penetration test is

going to

be legally

bound and obligated and sometimes even

ethically

obligated to generate a report with all

the findings the secret analyst that

performs a test if they discover a

vulnerability they are mortally and

legally obligated to disclose it they

should not keep it secret they should

not silently exploit it for their own

benefit they should include everything

in this report and also in most cases

these penetration tests are useful

because the reports also include

recommendations onto how to address how

to fix how to mitigate the

vulnerabilities that were found

including those social engineering

vulnerabilities that we just talked

about now an interesting part of hunting

for vulnerabilities are the bug bounties

you need to know about this at least for

the exam but it's also an interesting

item to discuss in the real world it's

um it basically refers to a couple of

programs that are being actively

maintained by Major software Avengers

out there I'm talking about big names in

here like Microsoft Dell HP work and so

on where these companies actually

offered to pay real money to security

analysts or hackers let's say that

discover vulnerabilities in their

products and instead of selling them to

the highest bidder or exploiting them

they report those vulnerabilities back

to the vendor in order for them to get a

chance to fix them before somebody else

discovers the same vulnerability or has

a chance to exploit it so that's a way

of rewarding a potential hacker for

good behavior right for reporting what

they find instead of exploiting for

their own benefit

let's give an example of this you can

Google for 10 essential bug Bounty

programs you're probably gonna find a

more recent version of this one so

starting with apple minimum payout is

five thousand dollars maximum one

million right not bad Facebook starts

from 5000 but doesn't have any upper

limit uh GitHub Google

hacker one Intel Microsoft Mozilla

pentagon

pretty low payments in here right

and uh and zoom right now they're not

the only ones of course there are a lot

of companies out there that have bug

Bounty programs uh and also even if they

don't have an official bug Bounty

program if you discover a vulnerability

and you try to contact the company

they're probably going to react in some

way and reward you anyway

now penetration testing can also be

performed in a completely let's say safe

and gamified environment call these war

games and this is an environment where

we split the so-called attackers and the

so-called Defenders into two different

teams just to perform an attack exercise

and see how each team reacts so you're

going to have the red team which are

going to be the attackers I'm going to

have the blue team we're gonna be the

Defenders or the people that are

reacting to a security incident that is

currently happening now these are the

major teams depending on the complexity

of the game we could also have something

called a white team uh this is the one

that sets the rules of the game The

Rules of Engagement and makes sure that

everybody plays nice and that everything

that is found is being reported and the

rules of the game are being followed and

sometimes we can even find a purple team

which is made up of so-called Arbiters

that make sure that the interaction

between red and blue is constructive

they don't start hating each other and

they it doesn't become a competition

between the actual members of those

teams because the purpose of this is to

find those vulnerabilities see how they

how bad they are how easy can be they

can be exploited and uh if they can be

mitigated by a different response from

The Blue Team now some people might take

this personally of course and they can

take it as a personal challenge now the

purple team is rare to make sure that

this doesn't happen and people don't

forget the the final goal of the game

now pen testing as you can probably

guess by this point is very similar to

an actual attack that an actual Cyber

attack conducted from the inside or from

the outside of the company now if the

attack is conducted from the outside the

first step in an attack is going to be

reconnaissance finding out more about

your your target your victim and that

information

first is going to be determined

especially from open source intelligence

that is the internet the media social

media using specialized tools such as

the Harvester job postings Financial

reports any kind of information DNS

server records for example any type of

information that is publicly available

without actually hacking anything or

anyone this is considered to be a

passive type of reconnaissance of

information gathering a more active type

of information gathering relies on

social engineering again this is hacking

the human interacting with real humans

pretending to be somebody else

impersonating I.T support impersonating

a law officer impersonating a manager

from another department asking for

confidential information asking about

how the company is structured maybe even

asking for actual credentials to gain

access to further inside of that Network

inside of that company or even just uh

asking someone nicely to keep the door

open for you so you don't have to use a

badge to enter the building premises

still on the active side we have digital

footprinting this is where you use

specialized tools for active scanning

such as nmap which we discussed a couple

of videos ago for finding out more

information about what is running inside

of that Network how is the network

structured what's the topology what

services are running in there what

authentication mechanisms are in place

what security measures are in place

finally we have a concept called War

driving now concept of Ward driving is a

pretty old and initially it used to

refer to the act of driving around the

neighborhood or around a building campus

and just scanning the available

frequencies for Wi-Fi looking for

networks and then of course documenting

whether those networks have open

authentication what type of

authentication they have if they have

any what type of security mechanisms are

in place in order for you to determine a

potential point of entry maybe somebody

has a non-secure wireless network

somewhere in the office that's uh spills

over in the parking lot or outside of

the of the building premises if you can

reach that Network and connect to it

even from its Edge you have a point of

entry inside of that company Network now

nowadays we can also do this with drones

right of course not talking about how

legal this is but it is an attack method

and it's also a method that can be used

in an attempt for a penetration test and

this is where the example that I've

given you a couple of videos ago comes

in too where you can simply drop a

couple of USB sticks in the parking lot

like you can just throw them over the

fence if you wish or just leave them in

the guest area the lobby of the building

and just hope that somebody from the

company an employee is going to pick

them up and be happy about something

that they just found on the floor a good

USB stick that it can use or perhaps

just being a Good Samaritan and thinking

that I'm gonna stick this USB drive into

my computer and figure out who it

belongs to so I can return it well of

course that USB stick contains malware

and that can become a point of entry for

an attacker inside of your own private

Network

all right so to wrap things up how does

a penetration test actually look like

what are the phases of penetration test

and consequently luckily the phases of

penetration tests are exactly the phases

that we're going to find in an actual

attack and an actual Cyber attack and

everything is going to start with a

reconnaissance phase if the attack is

being conducted from the outside and

then with an attempt to gain access

inside of the network now in most cases

the penetration test actually skips

these phases so once in a checker

manages to gain access inside of a

network physical or logical axis doesn't

matter the first thing it might do is to

establish persistence that is install

some piece of software install some

piece of code run some code inside of

that Network in order to ensure that the

next time they want to interact with

that Network they already have a

foothold in there they have something to

connect to that's going to be something

like a remote access Trojan it's going

to be a back doors installed somewhere

it's going to be some way for the

attacker to later come in and interact

with a device in that Network without

having to go through the entire

reconnaissance and gaining access

process every single time next up the

attacker is going to attempt to perform

some privileged escalation that is they

might have access inside of the network

but they might not have administrative

access so they're probably going to need

to access some confidential information

which requires some elevated privileges

so they're going to look for some

weaknesses some vulnerabilities in the

systems that they have access to in

order to escalate their privileges to go

from a simple user to an admin user or

for to a user that has the necessary

read or write permissions in the area

where they're interested in accessing

that information from now in the course

of gaining more access an attacker might

attempt to gain access to other systems

as well in the same network or in a Json

Network this is called lateral movement

infecting or compromising other network

hosts which in turn might open up other

network segments and more resources for

the attacker to exploit sometimes this

behavior is also called pivoting that is

when the attacker attempts to access

some resources that are normally not

accessible from the outside which most

let's say databases or file storage

devices normally you should not be

accessible for the outside but the

attacker could for example leverage or

compromise an intermediary host inside

of that Network and then relay its

attack through that host that has real

access to those backend systems that the

attacker is interested in accessing a

frequent example of pivoting is for the

for an attacker to try to compromise a

web server in order to Pivot from it and

access the backend databases that the

web server does have access to in order

for the web server to be able to run its

web applications but that web server in

this case becomes some sort of a Gateway

for the attacker inside of the private

Network finally the actions on objective

phase is the well the actual purpose of

the attack it might be just to bring

down a service it might be to stealing

confidential information maybe to delete

destroy data that's the actual phase

that's called actions on objectives and

finally not mandatory of course not

everybody cares about this but a really

dangerous attack is the one that you

don't even know that it happened so

stealing data doesn't mean that the data

is not there anymore you're just making

a copy of that confidential information

if you manage to clear all the traces

that lead to you and to any indicators

of compromise that might be detected in

the future that prove that the attack

has happened well you're good to go

right how successful that attack is

and how successful and how impactful

that penetration testing report is going

to be for top management

all right now the Security Plus exam is

not exactly going to make a penetration

tester out of use so there's not much

more that they should know about

regarding this topic even though it's a

really interesting topic actually so

make sure you remember what we talked

about in this in this episode if you

want to discuss more about this leave a

message in the comment section if you

enjoyed this if you like this if you

found this useful like And subscribe and

see you on the next video thank you and

bye bye

[Music]

thank you


1010

[Music]

foreign

[Music]

briefly during the past few videos now

let's spend a bit more time

understanding all the intricacies all

the details that make up this very

interesting type of attack now social

engineering or how I like to call it and

I'm not the only one who likes to call

it that way is hacking the human that is

attacking not necessarily physically but

that's a valid option as well attacking

or trying to exploit the weaknesses in

human behavior the tendency of people to

trust the tendency of people to obey

Authority and the end result is to

convince a person to provide you with

sensitive information or to convince a

person to execute some actions on your

behalf in most cases social engineering

is being performed against employees of

a company that you're targeting so that

they can either disclose some sensitive

information about the company about

Network or the security systems in there

or even their password or in order to

convince them to click on a link to

download or execute some piece of

malware that helps you establish a

foothold for a future attack so the

fundamental principles of social

engineering can be summed up in one

single World impersonation pretending to

be somebody else pretending to be

somebody else that either has authority

over the person that you're targeting or

is trusted by the person that you're

you're targeting you could for example

impersonate somebody from the IT

department and convince a user to click

a link or to reset their password using

a link crafted by you of course a

malicious link or to convince them to

install some piece of software on your

machine saying that it's part of a

company-wide security deployment or

pretending to be some subcontractor or a

partner of that company asking even the

IIT Department to help them to generate

a valid user account or to help them

connect through the VPN and

impersonation can even be performed in a

physical manner as in for gaining

physical access inside of a building

there's an old joke and insecurity

saying that there's no telling how far

you can get inside of a building if

you're if you're wearing some uh a

maintenance vest if you act like a

delivery man if you're pretending to

deliver pizza if you're pretending to be

working on the air conditioning system

or you need access in the basement to to

fix something in the in the data center

or any method of impersonating someone

that suggests that their very presence

is there to be helpful tends to bypass

the normal Security checks that are

being done while entering a building

tends to bypass any kind of security

measures that are in place and on the

basis of impersonation you could rely on

the fact that people who appear to be

likable to be familiar have better

chance chances of convincing other

people to do stuff for them I mean if

you if you ask nicely if you look like

uh you would be very grateful if you

would receive help a lot of people might

offer themselves to help you out to

enter the building maybe to set up your

email account or any any other security

related tasks such as those and the the

danger of this is that there's almost no

risk to it I mean if the person that

you're targeting doesn't want to help

you it's not going to be a security

incident it's simply gonna be a I'm

sorry cannot help you right now or the

company policy doesn't allow me to do

this but you're not going to be flagged

as an attacker so you can try a

different person you can try somebody

else in the next minute

a very interesting principle is social

proof this one describes the fact that

in absence of any further instructions

most people will behave as they see

people behaving around them it's kind of

like a I know it sounds bad but it's

some type of herd Behavior right if

people don't know what to do they'll go

where everyone goes if people don't know

what to to buy they'll buy what the

three people in front of them have

already bought if people don't know

whether a request coming from the

so-called I.T department is valid or not

simply implying the fact that everybody

else has complied so far you're the

you're the last person we weren't able

to find you during the lunch break right

now you're the last person who hasn't

clicked on this link who hasn't

installed this security update on your

machine so everybody else did it it

should be okay it must be okay for me to

do it as well that's social proof this

one can be easily exploited especially

for people who are not that security

conscious in order to make them perform

specific actions on behalf of an

attacker Authority is another difficult

one and dangerous one that's because

most people are you know educated to

respect authority to respect Law

Officers to respect people in charge to

respect when they're being told by a

manager to do something so if you were

able to impersonate somebody that is

supposed to have a position of authority

over that victim

that much easier to convince them to do

something that they should comply with

immediately next one artificial scarcity

or false urgency I really like this one

this one this is the one that you're

always going to see manifested in sales

especially in online or TV commercials

it used to be very often used in

teleshopping telemarketers use this

extremely often that is creating the

impression the false impression

suggesting the fact that if you don't

make up your mind and you don't take

action right now it's going to be too

late later on you're missing out on some

things so it appeals to the the fomo the

fear of missing out of people also

appears to their sentiment of guilt I

mean false urgency might be coming back

to the first example where you know

everybody else in your department has

already installed this piece of software

we really need this done right now

because otherwise we're gonna we're

gonna exceed the deadline and we are

exposed and you're going to be the only

person responsible for not implementing

this security update and imagine what

your boss is gonna say about this you

have to act right now you don't have

time to go ask your boss if you you're

allowed to do this or not you're the

last person you have to act right now

that's false urgency artificial scarcity

well this one applies more to sales

right because if you're not buying right

now the last item on sale You're Gonna

Miss it forever and you're gonna regret

it for the rest of your life or it might

be in case of social engineering from a

security perspective masked as a let's

say a link in an email that you are the

lucky winner of something that you have

been especially selected by invitation

you have this selected out of a thousand

participants to access this this bonus

feature to download this price this this

piece of malware right

I'm sure you've seen those ads online

that try to suggest that your computer

is infected with malware and you have to

click on the ad to download their

solution their anti-malware solution

which is actually their anti-malware

problem and install it on your on your

machine that again is an example of

false urgency and one more time don't

forget about physical social engineering

directly interacting with people uh in

order for them to provide you access to

secure areas or to gain physical access

to real documents and one example of

this one that I really like is called

dumpster diving that is diving through

the garbage generated by a company

usually that garbage is not secured or

it is not in a secure Enclave somewhere

it might not even be on their perimeter

but that garbage might include a lot of

confidential sensitive data confidential

documents interesting information that

might be a gold mine for a security

researcher or an attacker another way to

exploit the human factor when gaining

physical access to a building is called

tailgating you know what that is

that is watching for somebody open a

secure door for example like the company

door and then quickly following after

that person before the door gets a

chance to close that's tailgating you

don't want to do it like that is it

going to look awkward and suspicious

well you can do it in a piggybacking

manner piggybacking means that you are

actually asking somebody to hold the

door Hodor right hold the door open for

me or just help me out because my hands

are full I'm carrying all these boxes in

here and trying to make a delivery and

trying to make a living here just please

open the open the door for me so I can

enter the building uh quicker right

that's piggybacking that's basically

tailgating with the approval of a of an

authorized person and social engineering

unfortunately doesn't stop here doesn't

stop with the actual attempts to steal

credentials or to gain access to

confidential information it can even go

further and lead to

impersonation from

identity theft

is really bad this can be used to

impersonate somebody or to create some

fake credentials it is extremely bad

because in case of digital identities

inside of a company well the attacker

basically is going to gain access just

like a regular user the attacker might

become from the perspective of the

internal security mechanisms a valid

employee which can act

with no restrictions this can be

performed by stealing credentials

compromising credentials there are a lot

of methods of doing so apart from you

know guessing them or stealing them from

the actual people a lot of the data

breaches out there actually Target a

credential databases when a company a

website a web service a database is

compromised and is the victim of a data

breach all those user accounts perhaps

even along with their personally

identifiable information financial

information credit card info sometimes

even the passwords even though the

password should not be stored in clear

text but sometimes they are that

information gets exposed and those

credentials become compromised now

there's a website called

haveibinpond.com which you can use to

enter your email or your phone number

and see if that email or phone number

has been part of a known data breach go

ahead and try it right now pause this

video Try it right now before it's too

late you will be surprised I can

guarantee you this

another method of stealing credentials

basic one actually is shoulder surfing

what is that well just watching what a

person does what type of credentials

they're entering their username their

password over their shoulder it happens

all the time especially in open spaces

and even though it refers to actually

being close to that person right next to

it and looking over their shoulder it

can be performed using even remote video

capture remote cameras even drones

outside the windows lunchtime attacks

these are another very interesting

category of attacks which is kind of

basic if you think about it a lunchtime

attack refers to the fact that very

often a workstation is strongly

dependent on the physical security of

that workstation that is if an attacker

has direct access can interact with that

workstation with that laptop for example

what a lot of the security measures have

already been bypassed a lunchtime attack

is an attack that can happen during the

so-called lunch time when employees get

up from their desk and forget to lock

their computers so that anybody who goes

through that open space through those

offices can sit at any desk and interact

with those computers now as you can

probably guess of course this attack

doesn't always happen during the lunch

time

and finally a couple of the objectives

of stealing these credentials could be

for performing identity fraud just like

we talked before stealing credentials in

order to access the resources that those

users have access to so for stating

confidential information or for creating

financial fraud based on fake invoicing

if you are able to generate fake

invoices that are automatically accepted

by the finance department you can

basically you know pay yourself from the

money of that compromised company and

yes there are even more methods of

social engineering some of them based on

a specific Communication channel such as

most often than not email and the most

often method for performing social

engineering over email is called

phishing this is about tricking somebody

into accessing the resource that they

perceive as being trustworthy when in

fact the resource well is not it belongs

to the attacker it can host a sort of a

malicious content it might be just a

fake authentication page aimed at

stealing the credentials of the person

that enters their credentials in there

and we have a couple of subcategories

here for phishing uh first one being

spear fishing spearfishing means that

the target to get is not just

opportunistic so it's not some sort of a

mass spam campaign that's targets

anybody who is full enough to click on

the link but it is a directed campaign

to a specific department or a specific

company of course such an attack becomes

more dangerous because in this case the

the attacker can actually customize or

Custom Tailor those messages so that

they appear much more trustworthy they

can use the internal let's say the

signature that they use inside of the

company they can direct that email to or

CC that email to some other valid

accounts inside of the company so it

looks like a legitimate email and people

tend to trust emails that are being sent

by their work colleagues and even higher

up the chain we have whaling not hunting

whales but we are hunting high level

Executives like CEOs cxos inside of a

company we're targeting their computers

their account their credentials which

are more often than not a gold mine for

a potential attacker because they do

have access to all the confidential

information inside of the company

and they can also be sometimes

blackmailed

fishing is the same type of attack but

this time conducted over a voice

connection over the phone for example

voice conference over instant messaging

uh smiching kind of bad name here

actually this one refers to those spam

messages sent over SMS usually these

Target vulnerabilities in the phone or

the data that is stored on that victim's

mobile phone of course Android devices

are a bit more vulnerable to this type

of attack because iOS devices are much

more locked down than Android ones

finally on the lines of spam and email

in general of course we find spam

everybody knows what is Spam unsolicited

email that you're receiving and might

tempt you to click on a specific Link

email hoaxes usually chain emails emails

that warn you about bogus security

threats out there and try to convince

you to install a specific security

countermeasure which of course is is a

malware itself and email prepending is a

stupidly simple method of making an

email message look trustworthy there are

situations I'm sure you've seen them

where if an email passes through a

security device it might say in the

subject line that you know uh attachment

safe or scanned or something like that

well you can of course craft that

subject line and make it look part of an

email chain with some replies in front

of it and then some tags in there that

says that this email has been scanned by

this security solution and has been

validated as being safe and then of

course comes the actual content of the

email which is far from being safe but

people who are used to seeing that type

of notice especially if it's a security

solution or an antivirus solution that

is widely used inside of that company

while people automatically trust it

always say okay this email has been

validated I don't know what that file is

inside of instead of that attachment in

there but if the if our security

solution says that the email is safe

then I'm gonna click it all right why

not and to introduce some new terms in

here still on the page of stealing

credentials we have three terms that we

need to know about first of all there's

farming with a pH now farming relies on

a technical type of attack which makes

that victim's computer

resolve a domain name to a fake IP

address

so it relies on corrupting the DNS cache

or to or it relies on hacking the actual

DNS server uh that the the victim

computer is using but whenever they try

to access their Bank website.com instead

of resolving that domain name to a valid

website that belongs to their bank it's

going to resolve it to a website that is

hosted by the attacker all right and of

course if the website looks the same the

user is going to enter their credentials

and they're going to receive an error

when in fact those credentials have been

nicely forwarded to the attacker a type

of squatting again is a very simple

method of trying to gather valid user

accounts and simply by registering

domain names that closely resemble

well-known services or well-known

companies on the internet simply by

changing an O to a zero or just a

doubling a letter or just making an

intentional typo between two adjacent

letters on the keyboard because many

people some sometimes mistype those

domain names when they try to access

websites such as Google or Amazon or or

Netflix or any uh any well-known

Services out there and sometimes they're

going to type I don't know Netflix

all right with an M well somebody might

register that name make a page that

looks like the Netflix Regular login

page and steal your Netflix credentials

when you happen to hit that web page and

enter your credentials in there that's

typo squatting

and another type of attack is called The

Watering Hole attack

refers to the habit of you know animals

who wild animals who periodically gather

around watering holes in order to to

drink water well that also might happen

inside of a company let's say if

everybody in a company frequently visits

the same pizza delivery website right in

order to order pizza for somebody's

birthday or for just for lunch all right

if you know that a lot of people in the

company use from time to time that

website has a watering hole what do you

think what's going to be easier to crack

the authentication system of an IT

company or to crack the website

of a pizza company

so if you crack the website of a pizza

company you can inject some malware in

there which then you can be sure that

it's going to reflect it's going to

attack the victims from the company that

you're targeting whenever they access

that website on a regular basis right so

basically instead of infecting the

victim you're infecting the food source

for that victim right

and finally we also have a special type

of social engineering which is called an

influence campaign it's no it's not

about those type of influencers it's

about those who influence public opinion

on political matters on elections on

anything that the public opinion should

not be influenced on

oftentimes these are networks of bots of

fake accounts some of them directed by

by Machine learning algorithms that

constantly scan social media try to

promote fake news fake websites right

even to comment on on news giving them

the appearance of being from a

legitimate source and trying to change

the public opinions or to influence the

public opinions on a specific sensitive

matter I'm sure you've had plenty of

examples during the past years of this

happening unfortunately it's a mass

scale level type of social engineering

which is really really tough to control

and it is at home in most

social media platforms

well social engineering is one of my

favorite topics actually in in all cyber

security and as you can see it is about

cyber security but it's not about cyber

security it's about a human element it's

about human nature which is

an endless source of interesting

information and of fun sometimes

so if you want to contribute more if you

want to talk more about this topic leave

a comment in the comment section if you

like this and if you enjoyed this like

And subscribe good luck on your studies

and see you on the next video thank you

and bye bye

[Music]


11 11

[Music]

foreign

[Music]

here we are we need to talk about

malware as well now I guess everybody

knows the term of malware which is

basically a piece of software or a piece

of code that does something bad that

does something that we don't want it to

do without our explicit consent most

likely so this is where we find things

such as viruses Trojans remote access

Trojans and worms and fileless malware

and so on and so forth we're going to

talk about all of these and see the

differences between all of those because

it's a very important topic to discuss

not just for the exam but also for your

real life experience with security

because malware has been around forever

we have malware even before we had

networks imagine that all right so let's

let's see what the categories of malware

are and how they behave

all right so starting with the first

classification of malwareby their

infection Vector this is where we find

first viruses and worms this is the type

of malware code that usually attaches to

a file or to an executable process in an

attempt to either execute itself when

the user double clicks the file executes

the file or propagates itself in the

case of worms whenever the vulnerability

in the network is being discovered so

one difference between viruses and worms

is that viruses infect files and expect

user interaction in order to manifest

themselves to execute themselves while

worms infect a process in memory and

attempt to replicate themselves by

themselves without user interaction by

scanning the network for potential

vulnerabilities that they can further

exploit and then propagate and infect

other hosts on the same network we also

have Trojans which just like the name

says they appear to be good software but

their package with some bad code as well

so they're hidden in a legitimate

application a legitimate installation

executable code and MSI packet and exe

but along with the main program they

also include some additional unfortunate

bonus malware code and also on the topic

of unwanted code that comes

pre-installed with another software we

also have the so-called gray area of

grayware also called called the

potentially unwanted programs bloatware

adware any type of program that simply

annoys you suggests that you click on

some link makes you buy stuff make you

makes you use their own weird search

engine replaces the home page of your

browser you know what I'm talking about

this is not exactly classified as

malware as in it doesn't really do

something malicious by definition but

it's annoying

and it might have a potential

performance impact on your computer so

that's why we we put the malware stamp

on it because we don't want it all right

all right so come back to the first item

that is the virus computer virus is the

most well-known type of malware because

everybody has faced a virus infection at

some point probably now a virus is a

type of malware that is based on a file

it infects an executable file and then

expects a user to execute that file in

order to manifest itself to execute its

own malicious code a virus can virtually

do anything it can execute any type of

instructions and in most cases it's

going to execute with the same

privileges as the user that launches the

infected file currently has and we can

have different classification methods

for viruses as well depending on the

media that they're infecting they can be

file based the exact example that we

talked about so far they're infecting

executable files on the disk now

exigular files can be also files that

include some type of executable code

such as you could have office documents

that have macros in them macros are

scripts basically that can be executed

whenever the document is launched PDF

files can have automatic validation

rules that again they're just scripts

that get executed whenever you open the

PDF file so don't just expect to be

something like a.com or dot

msi.axe extension in order for the file

to contain executable code we also have

memory resident viruses sometimes they

don't persist on the disk but they

persist in running processes in the

computer's memory now they usually do

have some way of persisting on a disk

either in some registry entry or they

are being launched as as a result of a

user clicking some malicious link

because they do need some way to reach

that memory as an executable process as

an executable file in order to reside in

the computer's memory now from there of

course they can execute virtually any

type of action including potentially

infecting other computers in the same

network well also have boot sector

viruses which infect the boot sector of

hard drives or more often than not of

external removable drives like USB

sticks and external hard drives again

this is just a method of ensuring

persistency because the the executable

in the end is going to manifest itself

in the computer's memory and that's

where it's going to execute its code and

we also have script or macro based

viruses they can be hidden in plain

sight and visible scripts that you might

download know nothing about that

scripting language and then execute it

knowing that it's supposed to do

something when in fact it's it's not

it's just malware code or it could be

about scripts that are embedded in

office documents just like we we've said

before

then we also have two more let's say

more exotic subtypes of viruses first of

all being the multi-partite virus type

which uses multiple vectors for

infection not just one like the ones

that we've discussed so far or we also

have polymorphic viruses that can

dynamically change their code why do we

do this well because traditional

antivirus Solutions rely on signatures

static signatures that look for a

specific sequence of bytes in files if

they find that sequence of y's then they

can say for sure that that's a virus

right there now if the code for that

virus changes automatically maybe even

randomizes itself that type of pattern

matching using static signatures becomes

a lot more difficult to perform

next up worms worms are types of malware

that are characterized by the fact that

they don't necessarily reside on disk

but they mainly reside in computer

memory as running processes so they live

as long as the host lives or the host

runs they normally try to propagate

themselves they try to find their

programmed to find weaknesses and

vulnerabilities and network file share

protocols and file transfer protocols

over the network in order to propagate

themselves to multiply and infect other

hosts in the same network as well there

are situations where worms don't require

any kind of file infection but in most

cases they will rely on some sort of

persistency or at least some sort of

mechanisms that launches them in inside

that computer's memory and the

propagation of worms is usually not

performed or not easily performed on a

well-secured network I mean normally you

cannot just you know replicate a file

from one host workstation to another

workstation without passing some sort of

authentication credentials some sort of

permissions maybe using the elevated

credentials of a user that has right

access or an administrative user so in

the case of worms they're usually

designed for to attack a specific

vulnerability now those modern abilities

are more often than not going to be

found in many networks simply because

people don't keep their operating

systems up to date there have been

numerous situations dangerous malware

that has multiplied like crazy in the

wild in the real world and they've

spanned all the continents and hundreds

of thousands of companies simply because

they were exploiting a vulnerability

that was patched months ago in Windows

systems but those companies did not

install the necessary updates to patch

that vulnerability so it doesn't have to

exploit a zero day vulnerability you

just have to rely

on human ignorance unfortunately

another category of let's say fileless

malware or malware that doesn't rely on

a specific file on the disk we can call

them memory resident fileless malware it

could use as I said before it probably

uses the disk to compile some

instructions or execute some script that

perhaps even downloads dynamically that

executable code from the internet and

then immediately launches a process

based on it so that's how it becomes

memory resident without being disk

resident as well but in many cases you

will be able to find some sort of

indicator of compromise on the disk as

well or in the Windows registry for

example and in many cases they're based

on a small piece of code called a Shell

Code now the shell code is usually just

a one-liner series of commands that can

be executed by the default interpreter

on that system such as CMD or Powershell

on Windows or a bash on Linux

it's just a small piece of executable

code that can be it's so small actually

that it can be hidden in a link that you

can trick a user into clicking on a on a

on a phishing email for example it can

be hidden in a in a link in an instant

message or in an ad that user might

click on a website

it doesn't require anything on a disk it

has all the code in there necessary to

download the rest of the payload

malicious payload and execute it and

this is how you become infected without

even finding any kind of traces for that

virus on your disk and what's

interesting about these uh these

Flawless types of malware is that

because they're so small they don't

really have a lot of space to implement

a lot of functionality they only have

code to do some very basic stuff and

because they don't have all the

necessary tools perhaps to perform Arrow

password cracking maybe pivoting maybe

stealing credentials and such they're

going to be using tools that are readily

available on the compromised host such

as the command line tools for text

processing for uh for encrypting

information in case of a crypto Locker

they don't even have to download the

encryption algorithm or the encryption

method because most operatings doesn't

already have some sort of a encryption

methods or or utilities built into them

so if uh if a malware tool actually uses

all the available

executable tools legitimate tools on

your system this is called living off

the land so it's about using the tools

that the compromised workstations

already gives you and allows you to use

as a as a normal executable file that

can launch other processes on that

compromised host

another nasty category of malware is

spyware now normally spyware is about a

software that monitors the activity on

your host of course it's it's more

interesting to monitor the activity of

the user of that host rather than of the

host itself but you know what I mean

right and the most well-known type of

spyware is the key logger it's a program

that runs covertly hidden in the list of

processes you're probably going to look

at the list of process you're not going

to see it's in there or it's going to

look like like a legitimate Windows

process or on the service and its

purpose is to catch the keystrokes the

keys that you're pressing on your

keyboard and record all that and perhaps

even periodically send all that

information back to the attacker to the

one that actually installed that

software on your own machine this is a

of course I don't need to tell you that

this is going to allow the attacker to

see what destination it's your accessing

what websites you're accessing what are

your usernames and passwords that you're

typing on on the keyboard your

conversation station or private email

your anything that you're typing on the

keyboard becomes public knowledge for

that attacker spyware can also Implement

itself in adware that is a software

sponsored by ads as you as we all know

nowadays if a product is free it means

that you are the product which it's a

concept that thoroughly applies in

advertising so just by providing your

preferences or providing allowing an

application to track your behavior and

to show you relevant ads well that

becomes an important source of

information in itself so spyware can be

implemented in an adware or an ad based

program simply because it's designed to

track your activity to track your

shopping habits to track whatever you're

doing in order to show you

so-called relevant ads which is in case

of most web applications performed by

using tracking cookies cookies are small

pieces of code injected in web requests

and replies that identify a specific

session information there are cookies

that are meant to track your behavior

and report it back to other Platforms in

order again to learn your habits and

potentially offer you better products

and it's questionable because

it is spyware it is spying on you it

might not be doing you any explicit harm

that's why it's questionable

a back door is a specific type of

malware that is designed to give access

to an attacker to your system

from a distance of course that's why

it's called sometimes called a remote

access Trojan that's because well it's a

Trojan because it's probably uh

masquerading itself as a legitimate

application and then it's a remote

access Trojan because it allows remote

access from the attacker to your machine

which in turn is going to cause the

attacker to not only visualize or see

what you're doing on your machine and

get some reports of your activity but it

can also execute code your machine can

use your machine to send let's say spam

or become part of a distributed denial

of service attack or it can you know

encrypt your files demand some some

Ransom that's crypto Locker malware or

ransomware it can do any number of

things it basically owns your

workstation it can do anything on its

just like you can as a regular user

so in many cases they're not exactly

viruses as in they don't do anything

malicious other than allowing access to

some other person to control your

computer but by themselves they don't

alter your computer in any malicious way

now if your workstation is infected with

such a backdoor or remote access Trojan

most likely your workstation is going to

become part of a botnet so that's a

network under the attacker's control

that can be used to perform

large-scale attacks such as sending spam

or delivering denial of service attack

distributed enough service attack now

luckily this type of communication from

the outside with your host can be

sometimes even the only indicator of

compromise that you can detect so by

looking at the traffic by looking at

what type of traffic your computer is

doing with the outside world you will

eventually if you know how to look for

the right stuff in there you will

eventually see that command and control

traffic coming from the attacker's

workstation going to your computer which

is in turn telling it to either report

some status or to perform some sort of

attack now this type of CNC traffic can

be detected by itself just by looking at

it and there are specific signatures in

IPS idea solutions that look for this

type of command and control traffic or

can be detected by simply looking at the

destination that your computer is

communicating with because in many cases

the IEP addresses or the domain names

that your installed back to or your

Trojan is communicating to are already

part of some Blacklist out there some

sort of a bad reputation list of

websites or Internet destinations that

you should not be talking to anyway now

there are a lot of protocols that can be

used for this command and control

traffic most often it's going to be HTTP

because inside of an HTTP nowadays you

can hide pretty much anything most

applications nowadays run over HTTP so

simply by noticing that it looks like

web traffic is not enough for you to

determine what type of application is

communicating in there and what type of

content or payload is being delivered we

also use more obscure Communications

channels such as IRC nowadays RC is kind

of easy to detect because it's not so

used anymore as it was in the 90s and

the 2000s but it's probably a red flag

anyway if you see IRC traffic in a

corporate Network DNS is another

Preferred channel for command and

control traffic simply because DNS is

pretty much everywhere allowed I mean

we're allowing everyone to talk to any

DNS server they want because they're

probably just going to results on IP

addresses there's no harm in that right

well what if we're using the same DNS

ports and the same DNS messages but

instead of using them to request some IP

addresses or to results on domain names

we're actually talking to our parent

attacker over the same protocol or the

same ports completely ignored by most

Security Solutions out there

recently social media has been used as a

as a channel for communicating to

command and control domains how does

this work well you could have a specific

page on Facebook you could have a

specific Twitter account that posts from

time to time some random stuff in there

let's say from some encoded messages

that might not mean anything to a

regular user when they see them or just

post some pictures that have embedded in

them some instructions that only the

compromised clients compromised by the

same attacker who owns that Twitter

account know how to interpret and

perhaps from time to time that's malware

code that Rats the the back door

installed in your host goes online and

connects to Facebook and checks a

specific page or connects Twitter and

checks whether a specific account has

posted something new this again if

detected by a firewall looks like a

perfectly legitimate user Behavior just

open Facebook from time to time just

look at a a Twitter account from time to

time but instead of just looking at a

Twitter account you're actually checking

to see if new instructions are being

provided for your backdoor to launch a

new attack maybe to compromise some

other hosts or maybe to report back some

some information gathered from your from

your network so there's a lot of smart

methods of uh of implementing these

botnets and these command and control

networks out there so a lot of smart

methods for implementing Distributing

and controlling these botnets out there

hackers or smart guys be sure of that

and this type of persistency where you

have some remote access tool in Trojan

installed on your host that the attacker

can contact at any time is usually the

first step for the persistent

establishment phase in an uh in an

advanced persistent threat type of an

attack an apt attack usually as name

says it's a persistent threat relies on

installing some sort of a back door

without the user of transcend without

the user's knowledge onto a compromised

host so that later on when we need that

host to do something for us we can

easily contact it and then send it the

necessary instructions and of course it

is going to obey us

another dangerous category of malware is

called a root kit now this term actually

comes from the Linux world where we have

the root account and the rootkit was

designed to be a piece of malware that

replaces a regular operating system file

so whenever the user or the operating

system attempts to access or to execute

that file that a library that component

of the operating system along with the

component itself executes the malware

code as well now the greatest advantage

to replacing operating system files

especially on Linux is that operating

system files and processes run with the

highest privilege level as root hence

the name of a root kit so if an attacker

manages to compromise the workstation

and this way they basically have Supreme

privileges on that workstation now on

Windows things are surprisingly enough

they're a bit more on the on the side of

good news that's because on Windows we

actually have administrative privileges

though was owned by the administrator

account and we also have system with

capital letters privileges which is the

system account now most kernel root

processes in Windows run under the

system account while everything else

that is being launched by the

administrator runs with administrative

privileges which are slightly lower than

the system account has which means that

whenever a malicious piece of software

gets executed accidentally or

intentionally I don't know by an

administrator that process cannot be

hidden in the task list for example that

process it cannot be hidden in the

services list because it doesn't have

enough privileges to hide itself from

the rest of the system which is why if

an attacker manages to compromise a

Windows workstation it can be a server

of course and manages to install a piece

of software that can execute itself with

system privileges then that is called a

root kit on Windows and of course it's

going to rely on replacing operating

system files now again this is not

exactly as simple to do because nowadays

most files in Windows 10 and windows 11

are digitally signed so it's not going

to be that easy

and in most cases this uh this type of

um let's say interaction with system

files has to be done by exploiting some

sort of a vulnerability that allows a

regular user or even an administrative

user a compromised administrative

account to run code with system

privileges because as we said before

normally an administrator cannot run

processes with system privileges but by

exploiting a certain vulnerability in a

driver and the kernel and some windows

libraries that are dynamically loaded

perhaps it might offer the attacker the

possibility to inject their own code

into that code that gets executed with

system privileges and thus becoming a

root kit and as I said before the

greatest advantage of rootkit is that is

that if it's part of the system files it

can hide itself it can basically tell

Windows whenever you're displaying the

list of processes skip displaying this

file whenever you're displaying the list

of services that are running skip

playing this file whenever you're

listing the open port that I'm using to

communicate with my command and control

server skip this port don't show it up

so good luck detecting that piece of

malware good luck detecting any

indicators of compromise on a machine

infected like this finally another

category of malware that I'm sure

everybody knows about is ransomware or

more specifically crypto lockers those

are the types of malware that once they

infect your workstation they start

encrypting your files and then they show

up a pop-up screen saying that if you

don't pay up in Bitcoin this amount in

the next 48 hours your files will be

lost forever that is we're destroying

the encryption key and we're never

giving it to you now of course it's up

to you if you're going to trust that

message I mean the attacker doesn't play

by any rules they're not mandated by

anyone to actually give you the

description the decryption key if you

manage to pay that amount but it's a

very dangerous type of malware

specifically because in many situations

people don't have up-to-date backups in

order to mitigate this this threat I

mean you're not going to be able to

probably to crack that encryption key so

don't even try it but there's a very

simple method of mitigating this type of

attack first of all it'll try to not

make it happen right don't let it happen

in the first place but then if it did

happen make sure you have up-to-date

backups and those backups are kept safe

as well so that they're not affected by

the same crypto Locker attack that is

affecting all your workstations if you

have backup of your files all right go

ahead destroy my encryption key destroy

my destroy my files I don't care I'm

gonna restore them from backup and then

you have to make sure that that type of

compromise doesn't happen again now

there's also the another category here

called crypto malware which is uh kind

of like a naming overlap because we're

talking about crypto from a an

encryption point of view we also talk

about crypto from a cryptocurrency point

of view and you can probably know what

I'm what I'm going with this this is the

type of malware that installs on your

machine without your consent and then

starts using your machine to mine

cryptocurrency to use your CPU and

memory resources to uh to mine those

cryptocurrencies into the wallet of an

attacker of course this is easily

detected by extreme resource usage most

let's say educated attackers were

probably going to limit the performance

of that crypto Miner to something like

25 or 50 of the CPU so that it doesn't

Spike and become a really big red flag

when you're using at the resource

consumption on your system I also

there's another type of malware here

called the logic bomb now the logic bomb

is the type of malware that doesn't

immediately execute itself

it's a type of malware that schedules

itself in in cron in the task scheduler

or in any type of scheduling mechanism

in order to execute itself at some time

in the future or when a specific

condition is met an example here would

be for example an employee who wanted to

make sure that he is never going to be

fired or if he is fired there's going to

be some unfortunate consequences so for

example it can install a script on the

domain controller of the network a

script that once a day or once a week

checks the list of valid users and

checks whether his user is still enabled

and still active in the system so the

moment he is

fired from the company and the logic

bomb is still in there the script

detonates itself and starts perhaps

destroying data exfiltrating data or

defacing the company website for example

if the if it's a disgruntled employee

employee who doesn't agree with the

company anymore that's the type of a

logic bomb

all right so we talked a lot about

malware how do we detect it

now there are a number of ways of

detecting malware of course we're going

to start with antivirus Solutions

because nowadays call them anti-malware

Solutions because they they've gotten

pretty smart they can detect a lot of

different malware types not just viruses

but it's still the antivirus term that

has stuck with us for many many years so

antivirus Solutions including endpoint

protection suits those are the solutions

that make your computer behave crappy

but they protect you by scanning all the

search results or the websites that

you're visiting or the emails that

you're receiving uh all the destinations

that you're accessing you know more than

just antivirus scanning and these

anti-malware Solutions especially

referring to malware here these are

strongly dependent on static signatures

that is you need to keep a database of

signatures of virus signatures up to

date in order for the antivirus engine

to know what to look for if you're

behind with that signature database or

if the vendor of the antivirus solution

is behind with updating the database

you're going to be exposed with you know

exposure to zero day viruses zero day

threats that have just emerged another

method of detecting viruses and malware

is by executing them inside of a Sandbox

and our sandbox is an isolated

environment usually a virtual machine

that is created with the very purpose of

executing the malware inside of it and

then using a bunch of tools that monitor

the behavior of the process the files

being accessed by that process the

network connections being initiated by

the process in order to determine

whether the behavior of of that

executable is legitimate or malware this

is very useful for situations where we

don't have a valid signature for a file

but we just want to execute it to see

what it does in an isolated perfectly

safe environment that environment is

called a Sandbox now we could do this on

premises we do this in Cloud

environments there are a lot of security

vendors out there that resort to this

method whenever they cannot give a a

clear verdict about a specific file that

they they haven't seen before now not

matching a specific file with your

database of predefined signatures

doesn't mean that the file is clean it

might be some new type of malware that

hasn't been detected just yet maybe it

was specifically crafted for you right

it might be a targeted attack you don't

know what it does unless you actually

execute that code

and you'd better do it in a safe

environment monitoring resources is very

useful for viruses and that type of

malware that either

leverages your resources for crypto

mining for launching denial of service

attacks for example but also for malware

that is poorly written it happens right

you might find malware that it gets

stuck in a in an infinite Loop and

starts eating up resources in your

system for no reason we could also be

using file Integrity monitoring tools

this one this is a very strong example

here that you should probably remember

for the exam and the software is called

tripwire a tripwire is a type of file

Integrity monitoring solution or fim

solution that monitors system or even

user files how does it monitor them well

it calculates a cache a fingerprint of

those files and periodically checks

whether the hashes of the real files

have changed from the ones that it has

stored in its local database and now if

those files have changed chances are

that a malware has changed those files

it might be facing a rootkit it might be

facing some malware that has persisted

on a disk and is trying to replace some

of your uh some of your system files

where it's trying to infect some of your

user files your documents now of course

these Solutions are strongly correlated

with operating system update methods so

that whenever the operating system

performs an update and changes its own

files or the file Integrity marketing

solution is not going to fire up

screaming like crazy that half of your

Windows installation has been

compromised

we could also be looking at the network

traffic again most malware propagates

somehow over the network or is being

downloaded over the network so by

strongly analyzing Network traffic

there's a good chance of us catching

that malware before it even reaches the

the hosts or the endpoints that it's

trying to infect not just talking here

about worms there are self-propagating

but viruses as well because viruses do

need to reach that first compromised

host somehow it's probably going to be

an executable file that gets downloaded

or from the Internet it's probably

something that's a link that a person

has clicked nevertheless that type of

traffic can be detected at the network

level if you have the right tools if you

have the ability to inspect even

encrypted traffic because that's most of

the traffic nowadays at least web

traffic then you have a good chance of

catching those potential threats before

they even manifest

finally we can have a look at the

processes that are running on our hosts

of course we need to have some strong

Baseline predefined in order to have

something to compare it to we probably

can guess that a fresh installation of a

specific workstation or a host uh is

clean from any malware so we can make a

baseline make a list of the approved

processes the allowed processes that we

can find on a clean installation and

periodically check whether our other

workstations still comply to that

Baseline if we find new processes then

it might be reason to investigate of

course this is probably going to be

combined with a white list of

applications those are the applications

that we expect our users to normally

launch during their work days right so

we combine the Baseline of processes

with the white list of known

applications and allowed applications

whatever it falls outside of that range

that's going to be a security alert

potentially a security incident

so that's it about malware a lot of

categories a lot of types of malware a

lot of behaviors and guess what you

gotta know them well fortunately they

make a lot of sense or at least I hope

they did so if you found this

interesting and informative you want to

talk more about this leave a comment in

the comment section if you enjoyed it

like And subscribe and good luck on your

studies and see you next time on the

next video bye bye

[Music]

thank you


12 12

[Music]

foreign

[Music]

comes the more difficult to digest part

of this training about cryptography now

don't worry you don't really have to

know the math behind of it we have

computers for that but there are a

couple of ideas that you really have to

understand a couple of terminology

methods algorithms that you should be

able to explain in order to pass the

exam now this cryptography discussion is

going to last a couple more videos but

for now we're just introducing some

terms clearing up some definitions and

making sure that we all know what we're

talking about and what's going on

whenever we talk about cryptography so

let's get started okay so let's start

with some of the official terms that you

will find when discussing cryptography

and one of the main topics in

cryptography is encryption now hiding

information uh so that it cannot be

decoded by somebody else now before

talking about encryption we need to talk

about the different stages or shapes in

which our content our data that we want

to encrypt can be presented in and the

first one is going to be the plain text

also known as clear text this is the

unencrypted version of the data this is

the version that anybody can read don't

need any type of keys credentials any

process you need to go through in order

to read this content it's open available

readable interpretable it's out there in

the open next we have the Cyber text

this one refers to the encrypted version

of the same plain text so this one

cannot be read by anyone except for the

people that have the decryption key and

then we have the cipher the this is the

algorithm that we're using to perform

the encryption operation and of course

we're going to be using a different

version of the same algorithm to perform

decryption from the ciphertext in order

to bring back the plain text in most

situation whenever we deal with

encryption or encrypted data keep in

mind that in order to actually use that

data in order for that data to be used

by users by applications by devices that

data needs to be decrypted first so we

can only work with plain text we cannot

work with ciphertext but we can store

and we can transmit cyber text whenever

we need to protect that information and

finally we have cryptanalysis now

cryptanalysis is the process of

analyzing encrypted data and trying to

figure out or to decode it or to break

the encryption Cipher or the encryption

key so it's a way to reverse engineer

the encryption process now in the world

of cryptography there are two large

categories of algorithms that deal and

here we have algorithms that deal with

hashing and hashing is a mathematical

operation that receives a variable input

it can receive any type of input

actually and produces a fixed length

output always a fixed length output now

hashing is not encryption we're going to

talk about each of those in following

slides but for now keep in mind that

hashing cannot be reversed hashing can

take any input and it's always going to

provide a fixed length output which

means that the process cannot be

reversed so it cannot be used instead of

encryption now encryption on the other

hand receives any kind of input and then

produces a variable length of output in

order to represent the encrypted version

of that same input data encryption of

course can be reversed depending on the

algorithm depending on what keys were

used but this again is a discussion that

we're going to have in the file

following minutes

so let's talk about hashing first

because hashing functions are the

simplest implementation of algorithms

that you will find in the cryptography

world so a hashing algorithm is a an

algorithm or the function that as we

just said before takes a variable length

input it can take any input out there it

can be a simple password it can be a

word it can be an entire document it can

be an entire 10 gigabytes movie file

and always produces a fixed length

cryptographic output called a hash now

that fixed length depends on the

algorithm that we're using it can be 64

bits in length 128 256 bytes and so on

that's a typo right there on the screen

it should be 256 right now if we think

about it for a second since we can take

a password and generate a 64-bit output

string and we can also take a 10

gigabytes video file and output a 64

bits output string

it's pretty obvious that we're not going

to be able to reverse this operation

otherwise we would be able to obtain

that original 10 gigabyte video file

from those 64 bits of output which is

mathematically impossible this makes

hashing functions One Way only how does

this help us I mean what's the use of

transforming your data into something

that basically loses the original

content that cannot be used to recover

the original content well the main use

case

for hashing functions is for ensuring

Integrity of data that is because while

the same input is always going to

produce the same output changing even

one bit in that input is going to

produce a completely different output

which leads us to situations where we

need to ensure Integrity of data and

remember Integrity is one of the three

pillars like right next to

confidentiality and availability

so this becomes a method of ensuring

Integrity of data you're sending an

email message you want to be sure that

the email message hasn't been changed or

altered in transfer you calculate the

hash of that email message on the

delivery side and then on the receiving

side if the hashes match then the

message hasn't been altered

you can use a hash to Hash files on your

hard drives in order to determine

whether those file contents have changed

for example to determine if they have

been altered by some piece of malware or

buy some crypto Locker again ensuring

Integrity this is actually the way file

Integrity monitoring tools work so we

have a couple more use cases for hashing

functions but for now let's just think

of hashing functions as a way to

preserve or to validate Integrity of

data

now there are situations where hashing

functions can produce collisions I mean

if you just think about the fact that a

10 gigabyte file as an input can produce

64 bits of output now obviously there

are more variations of possible inputs

that we can provide to that hashing

functions than the possible results that

can be generated by that hashing

functions in those 64 bits of output

which leads us to situations where

potentially multiple inputs can cause

the same output this is called a hashing

Collision now these are not desirable

because this is a way to break Integrity

which basically means that we cannot be

100 sure from now on that any changes

that we perform on that input are going

to generate a different hashing output

and while talking about use cases for

hashing functions we just mentioned that

we use them to ensure Integrity of data

we can also use them to store passwords

that's because normally we should never

never store passwords in clear text or

actually we should never even store

passwords doesn't matter if they're

obfuscated or encrypted or in any way we

should never store user passwords let's

think about your web application maybe

you have an online store where users can

create their own accounts they set their

passwords

where do you store those passwords where

you should not store them in any

database you should not store them in

clear text nor encrypt it what you

should do is you should be storing a

hash of the user's password

remember the hash is always going to be

a fixed length now the fixed length hash

is also non-reversible which means that

if your web application is at some point

breached the victim of a data breach and

let's say your user database gets

compromised and gets published somewhere

in the internet well at least the

passwords are not going to be

compromised as well because you're not

storing the password you're only storing

the hashes for those passwords how are

you using those hashes when you're

actually validating user identities well

that's simple enough right you receive

the credentials from the user when they

try to authenticate and instead of

comparing letter by letter their

passwords you're actually comparing the

hash generated from the user provided

password with the hash stored in your

database if those two hashes match then

the password provided by user was the

right one it doesn't matter if you

cannot know what that password is you

just know it's the right one it was the

right one that was set from the very

beginning by that user

some examples of hashing algorithms

you're going to find md5 that stands for

message digest 5 or sha secure hash

algorithm there are multiple versions of

the secure hash algorithm some of them

differ by the length of the output of

how many bits they produce as the as the

digest message that they generate but

for now remember these two items right

here hashing is not encryption and

hashing is not reversible you cannot

obtain the original content just by

analyzing the resulting hash by the way

you can find a lot of hash calculators

online the process itself is not a very

CPU intensive one is at least if you're

not using it for very large data sets so

for example using this very simple

website here I could for example type

Andrew right here in the in the text

field click on hash

we scroll down here gonna find all the

results for different hashing algorithms

for this original text called Andrew

here's the md5 algorithm that we just

talked before here are the different

versions of the Sha algorithms notice

that the 256 384 512 here at the at the

end actually represent the length of the

resulting bit Stream So shot 256 means

we have 256 bits of data this is a

hexadecimal representation each

hexadecimal letter here represents four

binary digits four bits which means that

we're basically looking at a 64

hexadecimal character string right here

now just to show you that this uh these

hashing algorithms are actually

dependent on the input let me just grab

the same input right here and then

change the a in Android with a capital A

and then press hash

scroll down one more time let's compare

left to right and you can see that

neither of the hashes on the left even

closely resemble the hashes on the right

so it was enough just to change a letter

from lowercase to uppercase and we get

completely different results now on the

other hand of course if I were to

generate the same ask for the same input

and click hash calculate it one more

time this time we're going to get the

exact same results left hand side equals

right hand side down to every bit

also on the topic of ensuring Integrity

you might have noticed that on the file

download sites legitimate file download

sites you are sometimes presented right

next to the download link with a hash

value of that installation file this is

for you to be able to check after you

download that installation file or that

executable file that it actually matches

the hash that it was generated from the

vendor of that software product this way

you can be sure that the the executable

file hasn't been altered in transit or

the website hasn't been cracked in the

meantime and somebody some attacker has

replaced that executable file with a

malicious version of it so that's one

way of ensuring Integrity when you're

even downloading files digital

signatures on documents work following

the same principle you attach to the

document a hash value of that document

so that whoever receives it can then

validate that their file hasn't been

tampered in the meantime now in real

life we're combining this hashtag value

with some personally identifiable

information so that we can be sure that

the signature actually belongs to a

specific person but the algorithms

behind this Behavior are exactly the

same ones as you saw in the previous

page

next on the list are encryption

algorithms now encryption has a

mathematical operation in itself again

receives any kind of input we can

encrypt any type of data but it's also

going to present as a result a variable

length output that is because encryption

is reversible so we can reverse the

encryption process if we have the

corresponding key used for encryption

now we need a key for the encryption

because otherwise there's no protection

for the data that we're trying to

actually protect right if we're just

relying on a specific algorithm well

algorithms are well known encryption

algorithms are well known so there's

actually no protection involved in there

anybody could reverse that same

algorithm without having the necessary

key to access that data how is

encryption performed at a binary level

at a character level bit level well it's

basically trying to preserve the

original content so there are only two

things you can do that can be reversed

and don't run the risk of losing that

original content first of all we can

perform transposition that is just

switching letters and bits around that's

transposition and substitution

substitution means replace any

occurrence of a certain character with

another character or any occurrence of a

certain byte sequence with another byte

sequence and as long as you don't lose

the mapping between the original by

sequence and the replace by sequence

then you can reverse this process but

basically all encryption actually relies

on these two operations transposition

and substitutions anything else

cannot be reversed if you add more

content then you don't know what content

you need to remove in order to obtain

the original original file if you delete

any content and again you're losing the

original file the original version and a

very big idea very important idea and uh

in cryptography and in the encryption

specifically is that the key is the one

that has to be secret the algorithm is

the one that has to be public so you're

never hiding a message by relying on the

fact that nobody knows the decryption

algorithm you have to rely on the fact

that nobody knows the decryption key and

the combination of an encryption

algorithm and an encryption key has to

be secure enough so that you can ensure

confidentiality without even protecting

access to the encrypted data you

basically have to reach a point where

you don't care who has access to the

encrypted data because you're 100

certain that in the absence of the right

decryption key they will not be able to

access that information that's basically

how we are relying on let's say online

shopping every single day I mean we are

transmitting our credentials our credit

card information over the public

internet where anyone can intercept that

data anyone can listen to it and anyone

can try to decrypt it we just have so

much trust in the encryption algorithm

and the encryption keys that our browser

are automatically using behind the

scenes whenever we're we're buying

whatever it's in our shopping cart that

we don't care about the fact that our

traffic might be intercepted We Trust

technology We Trust encryption

algorithms and keys to keep our data

secure so never rely on the secrecy of

the algorithm that's one of the the

Commandments of of encryption relying on

the secrecy of the algorithm is

something called security through

obscurity or security by obscurity this

is bad this is not considered to be true

security because with computers hiding

information without encrypting it it's

not a valid option if it's in there

somebody will find it at some point and

on the topic of secret encryption

algorithms the idea here is that the

algorithms are just mathematical

operations now some of them have

weaknesses some of the algorithms have

weaknesses that make them more

susceptible to being broken by

cryptanalysis so the idea here is that

you're probably not going to be able to

develop from scratch a better algorithm

than the ones that have been thoroughly

tested and attempted to be broken in the

past 20 or 30 years or so so you're

probably not going to create an

algorithm better than those so why not

use those thoroughly tested algorithms

and rely on the fact that the secrecy of

your data relies on the secrecy of the

encryption key and on the topic of

encryption we actually have two types of

encryption we can perform cinematic

encryption or asymmetric encryption

let's start with symmetric encryption

because this is the one that it's the

easiest one to understand and the

easiest one to implement actually now

semantic encryption relies on the fact

that you're using a single key

to both encrypt the data and to decrypt

the data when necessary and by the way

when we refer to keys and encryption

what do you think a key looks like

it's just a string of bits it's just a

number of bits it could be something

that looks like a password if those bits

can be interpreted as a as a word or as

a sequence of characters but it might be

just a randomly generated sequence of

bits of a specific length that's your

key it doesn't matter how it looks like

it doesn't have to to have any meaning

it doesn't have to look in a specific

way it's just a sequence of bits that

you and only you and only those people

authorize to access that data should

know which leads us to the big problem

of symmetric encryption and that is how

do you manage that key if you if I want

to communicate something securely to you

then I can send you that encrypted data

and I can be sure that whoever

intercepts that data is not going to be

able to use it because it's not going to

be able to read it but how am I going to

send the key to you

so this is one of the big problems in

cryptography actually I mean we can

secure data using keys but how do we

secure the keys all right now there are

a number of solutions for this and there

are thoroughly discussed in the cyber

security analyst course in the size plus

course because they're a bit more

advanced but in general whenever we need

to perform this type of key distribution

secure key distribution we either use

a specific algorithm that deals with

this key negotiation phase or we simply

use a different channel so I could send

you the encrypted data over email for

example or just post it somewhere online

where you can download it from and then

I would send you the the decryption key

or the password for that data using some

other means over I know SMS over instant

messaging I could even dictate it to you

over the phone for example but it should

be on a different Channel

another problem tied to symmetric

encryption is the fact that the key that

we're using to encrypt and decrypt is

the same key that everybody has to use

to encrypt and decrypt so if I were to

send that data to a group of people to a

number of people well then I have to

share that key with all those people as

well now since there's no identity

information connected to that key first

of all if somebody sends me encrypted

information using that key I have no

idea who sent it

and secondly if that key becomes

compromised if somebody loses it if

somebody writes it on a Post-It note and

sticks it to their to their display and

somebody else comes by and sees that

password and starts using it I'll have

no idea that the key has been

compromised and I'll have no control

over the distribution of that key I mean

everybody who has access to that key can

share it to whoever they want which is

not that good from a security standpoint

now on the positive side of symmetric

encryption is the fact that it's a very

fast method it can be Hardware

accelerated because it's easy to

implement in Hardware so we can encrypt

and decrypt large amounts of data quite

fast actually it's the number one method

of encryption used for large sets of

data such as VPN traffic whatever we're

sending through a VPN connection uh

storing encrypted files on disk or even

encrypting entire disks sending

encrypted emails sending encrypted files

over any kind of protocol and any kind

of protocol that uses encryption is

going to rely at some point on symmetric

encryption inside of its payload what

are the cons of it well everything else

we talked about we have no control over

identity over the distribution how do

you store it how do you how do you share

it in a secure manner right we'll lose

all that control because we have one

single key that is being shared by

everyone else

not only I cannot use symmetric

encryption to ensure authentication

because I don't have any identity

information connected to that key but I

also cannot use it to ensure integrity

and that's because if multiple people

know that the same encryption key I lose

the confidence that whenever I send a

message from A to B that message hasn't

been intercepted and altered in transit

by somebody else who knows the same

decryption key because theoretically at

least somebody could have intercepted

that message decrypted it made some

changes in it encrypted it back with

same key and then send it to its

destination I have no control if the

something like this happens and I have

no method of detecting something like

this happening now the way encryption

actually behaves under the hood it also

depends on the type of traffic or the

type of data that we are trying to

encrypt that's why we have two actual

methods of Performing encryption those

two methods are based either on stream

ciphers or on block ciphers now let's

focus on stream ciphers for just a

second here now stream Cipher means that

we're going to have to apply encryption

to a constant stream of data of bits

this kind of looks like what we would

have to do if we were to encrypt

streaming traffic for example Netflix

traffic or when you have to encrypt

something like a VPN connection now the

VPN connection is always active it might

pass traffic it might pause for some

time you might send some request and you

might send some bulk data in there but

there's always going to be a constant

stream of data passing through that VPN

tunnel that you'll have to constantly

encrypt and decrypt on the other side

so this type of encryption has to be

performed bit by bit because we don't

know the exact length of the data that

we're supposed to encrypt like we would

know for example if we just have to

encrypt one single file on the disk but

with VPN traffic for example we just see

those bits flowing in there we have to

dynamically on the Fly apply those

encryption algorithms to all those bits

now since we cannot start from the very

first bits how do we encrypt a bit right

if if I give you a bit of one how do you

encrypt that

what are you gonna do You're Gonna

Change it to zero right so that's all

you can do right as far as encryption

goes no we don't start from the very

first bit we actually start with

something called an initialization

Vector we start from a predefined

randomly generated set of data that we

pretend to be the beginning of our

stream Cipher and then we start

concatenating the rest of the data that

gets generated to that initialization

Vector so that's the very very short

explanation of how a stream Cipher is

implemented now on the other hand we

have block ciphers block ciphers work

with blocks of data so they perhaps know

exactly what type of data they expect to

encrypt then they slice that data into

fixed blocks which can be 64 bits 128

bits doesn't matter how big the block is

the idea here is that each and every

block is going to be encrypted

individually so we take one block of

data and we performed all those

transpositions and substitutions on that

block

we get a resulting encrypted block and

then we move on to the next one right

then we concatenate all those blocks and

there's the resulting encrypted data of

course we need to perform some padding

if we cannot exactly slice

the data that we have into a fixed

number of equally sized blocks so again

we're going to have to generate some

additional padding additional data just

to provide a nice alignment for those

blocks and the main problem here at

least with the simplest implementations

of block ciphers is the fact that since

we apply the encryption algorithm

individually to each block it means that

two identical blocks and that can happen

of course two identical blocks can

generate identical ciphertext

which is really bad in situations where

you're trying to perform crypto analysis

or attackers trying to perform crypto

analysis because let's face it not every

data is unique for example any email

message might start with the same

introductory section an email message

might end with the same signature now

the blocks representing the signatures

for example at the end of that email

message are all going to look the same

even in the encrypted version of that

email which is going to help that

attacker that is trying to perform the

cryptanalysis to decrypt your message is

going to help them a lot to determine

well this right here probably look like

a signature let's see what types of

signature this user is using and there

you go it already has something to work

with so we have a solution to this and

this solution is called block chaining

let me show you an example on Wikipedia

because it does have a pretty nice

representation of the problem that we're

currently talking about now the first

version right here called electronic

code book or ECB this is the first

implementation of block encryption you

can see we have the plain text here at

the top we have the key

and then combining the plaintiffs with

the key inside of the encryption

algorithm results in ciphertext and we

do this over and over again for each and

every block you can see here that's the

simplest and not to be used anymore of

the encryption methods now in order to

avoid this problem here where we always

get the same ciphertext if we provide

the same plain text as an input we also

have an implementation called Cipher

block chaining now Cipher block chaining

relies on the fact that we start with an

initialization Vector just like the one

we talked about when we mentioned

symmetric encryption so we start with

some random data here we combine the

plain text with the IV and the key we

perform encryption and then we have a

resulting cyber text now look what

happens next we take the resulting

ciphertext and we provide it as an input

to the next block encryption operation

which kind of creates a Block Chain

right it's actually the one of the

principles on which the blockchain

technology relies as well so in this

situation right here even though we

provide the same plain text inputs even

though it might happen that two

different blocks here are going to look

exactly the same in plain text the

resulting ciphertext for both of them

are going to be different because the

second one relies on the previous block

which means that the input that gets

calculated inside of this encryption

block is already different from the

previous block so this encryption method

creates a lot of difficulty when

performing cryptanalysis and trying to

break the encryption algorithm now there

are more implementation methods of

course but we're going to stop right

here because this is enough at least for

this exam alright so since we just

talked about symmetric encryption you

can probably guess that we have

something called asymmetric encryption

as well why is it asymmetric well

because we're not using the same key

anymore to both encrypt and decrypt

we're using you guessed it two keys

and those two keys are being generated

together and they're called a key pair

not surprising I know and that keeper is

made up of a private key this one is a

key that you're supposed to hold on to

for dear life this is a key that you'll

never have to share with anyone and I

mean anyone you shouldn't share it with

your your girlfriend your boss your dog

nobody should ever get their hands on

your private key

that's how private it's supposed to be

have the public key which completely

opposed to the private key you're

supposed to give to everyone

and to anyone what's the purpose of the

private key you might be thinking right

now I mean it's a key right if I if I

lock my house with a key am I supposed

to give that key to anyone out there

what's the point of it well in

asymmetric encryption and asymmetric

cryptography yes you're supposed to give

the public key to anyone let's see how

this works actually first of all why do

we have two keys well we have two keys

because those two keys are

interconnected mathematically and that

type of interconnection

makes it possible so that whatever one

key encrypts only the other key can

decrypt

so if you're encrypting something with

the private key you can only decrypt it

with the public key if you're encrypting

something with the public key you can

only decrypt it with the private key but

never using the same key you cannot

perform both operations with the same

key

and there's a way to derive the public

key from the private one because what

you're basically generating from the

very beginning is a private key and then

you're using that private key to

generate a public key that's the one

that you can share to anyone but nobody

else can deduce the private key from the

public key that you're giving them right

so we can only generate them one way

first the private key then the public

one but not in Reverse so why is this so

complicated I mean okay we're using two

keys instead of one is this really more

secure

well yes that's because this

implementation helps us solve the

problem of key distribution remember the

problem we had with symmetric encryption

we we can send the encrypted message but

how do we send the decryption key so

that it's not going to be intercepted or

or used by unintended persons so the

public private key pair implementation

makes it possible so that if you want to

send me an encrypted message

I can't give you my public key and I

don't care how I give it to you I can

just post it online I can send it over

email I it's public I don't care if the

whole world has it but eventually that

publicly gets to you reaches you and

then you can use that public key to

encrypt a piece of data for me

you send me that piece of data and I am

the only one because I'm the only owner

of the private key that can decrypt that

data and there you have it you have

confidentiality

and you also solved the problem of

Distributing the encryption keys because

now I don't care who owns my public key

the public key can only be used to

encrypt information for me that is

destined for me only see where this is

going see how this kind of starts making

sense when we're trying to protect

encrypted data all right so apparently

asymmetric encryption solves everything

right so why do we still have symmetric

encryption

the problem with asymmetric encryption

is that is painfully slower than

symmetric encryption it's mathematically

complex and computationally very

intensive it takes a lot of CPU

resources to perform asymmetric

encryption secondly that's the biggest

downside actually you can only protect

as much data as the length of the

encryption key allows you to so you can

never protect more information than the

length of a key

if you have a

2048-bit key an asymmetric key of 2048

bits that's how much data you can

encrypt with it that's it um

so we can see that's a very big downside

which doesn't mean that asymmetric

encryption is not usable

well it's not going to be usable for

encrypting an entire movie of course but

we can use it to encrypt things such as

authentication data like user

credentials and passwords and we can

even use it for a more spectacular use

case

you guessed it we can use asymmetric

encryption

to encrypt the symmetric key that we're

going to use from now on to encrypt a

large amount of data so that's exactly

what happens whenever you establish a

secure connection to a website over

https or whenever you're connecting over

a VPN to your company's VPN endpoint the

first thing you do is to negotiate based

on public keys on certificates and

probably in private Keys you're going to

negotiate you're going to exchange just

enough information for you and the VPN

endpoint to negotiate a symmetric key

that you'll be using to encrypt the rest

of the data because since we cannot use

the public and private key pairs to

encrypt the entire VPN contents but we

can use them to encrypt just a single

password maybe a randomly generated

string that from now on is going to be

used as the symmetric encryption key for

all the rest of the data this is pretty

much how the real world implementations

work so hopefully that makes sense I

really hope it made sense

now the implementation of public key

cryptography or the algorithm that can

help us generate those public and

private key pairs or the major ones RSA

this one is the one used for encryption

specifically and it's called a trapdoor

algorithm because it's a type of

function or a type of algorithm that can

be easily computed if you know the

public key but it cannot be easily

reversed if you don't know the private

key right so this that's basically a

consequence of the fact that you cannot

deduce the private key from the public

one we also have DSA which also relies

on public Eco photography but we use

this for digital signatures and we also

have ECC or elliptic curve cryptography

which uses a completely different

mathematical model but with a major

advantage of being able to provide

pretty much the same level of security

as the RSA implementation for example

but at a tenth of the length of the key

so so if RSA let's say can provide

decent security using

2048-bit keys well ECC can pretty much

generate the same level of security

using only 256 bits Keys which also

makes it extremely convenient for low

powered and battery operated devices

such as wearables iot devices and until

not so long ago even mobile phones but

nowadays mobile phones are just

workhorses they pack a lot of power a

lot of processing power so ECC is not

really a requirement for mobile phones

anymore well tough content I know but I

tried to cover it in a as simple manner

as possible trust me things are much

more complicated when you start looking

under the hood see what exactly is

happening in in cryptography I try to

keep it simple hopefully I did if you

want to know more about this you want to

discuss some more leave a comment in the

comments section and also if you found

this useful and informative don't forget

to like And subscribe see you next time

where we'll keep talking about

implementations where cryptography is a

godsend it actually makes things like

online shopping and online banking and

and the cloud possible nowadays but

until next time good luck thank you for

watching and see you on the next video

bye bye

[Music]

foreign


13 13

[Music]

foreign

[Music]

for just a quick recap remember in the

previous videos we introduced a couple

of very important cryptography related

Concepts starting with hashing functions

remember hashing functions are those

functions that receive any kind of input

and they always produce a fixed length

output and whenever we change one bit in

that input we always get a completely

different output that way we can use

hashing functions to provide Integrity

for data to detect whether somebody has

tampered with that data in the meantime

we also talked about another category of

functions and those are encryption

functions remember we talked about two

different types of algorithms here we

talked about symmetric encryption

algorithms which use the same key for

both the encryption operation and the

decryption operation and we said that we

have a couple of problems now because we

need to figure out a way to communicate

in a secure manner or over a another

secret channel that encryption key we

also lose any kind of visibility as to

who is using that key so we don't have

any kind of identity information

connected to it because everybody's

using the same key all right and the

most complicated part in encryption uh

we also talked about the public key

cryptography or about asymmetric

encryption that's uh the encryption type

where we use two different Keys we have

a private key which is never supposed to

leave your your possession and we have a

public key which can be freely

distributed to anyone even over the

Internet it doesn't need a secure

Channel you can just send it over email

you can post it in a website you can

just package it in a in a certificate

and have it freely distributed to anyone

who wants to communicate with you now

these two keys are used together always

whatever one key encrypt only the other

key can decrypt so that way we simplify

the problem of key distribution right we

can give the public key to anyone and

when they want to communicate something

to us when they want to send us secure

encrypted information all they need to

do is just take that public key which

everybody can have you use it to encrypt

the information and only us because we

are the only ones that own the private

key only us can decrypt that information

so we get much better security when it

comes to actually allowing other

entities to send us encrypted

information now all this sounds okay I

hope it makes sense but it's still just

a theoretical aspect of cryptography we

need a practical implementation we need

to use it in our day-to-day work in in

our daily interaction with websites with

vpns with digitally signed files and

emails all right so let's talk about the

actual use cases from real life where we

can apply the concepts that we just

talked about so let's go back just one

step and remember what we just said a

couple of seconds ago about public key

cryptography remember that we are the

only ones that own a specific private

key

which means that that certain private

key can be used to a uniquely identify

us as a person as an identity which kind

of makes sense now if you think about it

this would be one way for us to actually

add some sort of a signature or digital

signature to documents or to data that

we send that we generate that uniquely

identifies us and this allows any

recipient of that data anyone who we

send that data to to uniquely identify

us as being the senders of that data so

we're we're closely getting to the realm

of authentication here because a

recipient now over the internet can look

at a piece of data and determine well

this piece of data has been encrypted by

Andrew because Andrew is the only one

who owns that private key that was used

to encrypt that piece of data now

there's also a big limitation regarding

public key cryptography remember which

one that was it's the limitation of the

fact that you can only encrypt

as much data as the length of the key so

if you're using

2048-bit keys 4096 bit Keys that's all

the amount of data that you can encrypt

so you're not going to be able to

encrypt all the VPN traffic you're not

going to be able to encrypt even an

entire email message

so what can we encrypt actually to help

us get this benefit of uniquely

identifying a piece of data simply by

you know modifying it just a bit

tampering with it just a bit but still

by using that private key because that

private key uniquely identifies us which

leads us to discussion about digital

signatures and basically a digital

signature becomes a combination between

a hash of the original message

and then encryption performed by our

private key of that hashed result now we

know that hashes are always limited and

they're small in size they're just a

couple of hundreds of bytes in size

which is more than enough for us to be

able to use that private key to encrypt

that hash result we might send a 10

megabyte email we can hash it down to

128 bits of data and then we can encrypt

that hash with our private key and guess

what the result of that encrypted hash

becomes what we today refer to as a

digital signature

all right so let's see how this actually

works all right let's pretend that we

have the well-known situation where

Alice on the left hand side wants to

send a message to Bob on the right hand

side all right then they have a

Communication channel right here in the

middle probably not secure we don't care

about that one now what Alex is going to

do from the very beginning is that she

is going to prepare a clear text message

we're going to call this m capital M now

what Alice is going to do next is that

she's going to take the contents of this

clear text message and it's going to

enter it into a hashing function

and we'll call the result of this the

hash of message m all right so we start

with a clear text message now we also

have the hash of that clear text message

now there's one more step here performed

by Alice and that is she takes now the

hash of this clear text message and

encrypts it

with her own

private key resulting in an encrypted

hash

so the result of this is going to be an

encrypted version with the private key

of that hash of that original message

now this result right here at the bottom

this is what becomes now a digital

signature

so all that Alice now needs to do is to

take this resulting piece of data and

attach it to the original message

which in turn becomes a digitally signed

message now this exact very same message

gets delivered now to Bob which is going

to receive the same

document

but this time

with that little encryption part

attached to it with the little digital

signature

now what's Bob going to do well Bob has

to validate this digital signature

remember we're not replacing the entire

message we're just attaching a digital

signature to it so the original clear

text message is still there right it's

the exact same one that we started with

so Bob checks the original clear text

message he can read that message but

wants to authenticate it wants to be

sure that it actually came from Alice so

looks at this little digital signature

right here this red square attached to

the original message and the first thing

Bob does is perform the process in

reverse that is he's going to decrypt

that hashed

message that he just received

using Alice's public key this time and

he's using Alice's public key because

Alice's public key is the only key that

can decrypt whatever was encrypted with

Alice's private key here on the left

what Bob gets after this successful

operation is the original hash of the

message that was generated by Alice so

now Bob can look at this hash right here

and compare it with his own calculation

of the hash that he can perform by

himself from that original message that

he received from Alice now if these two

hashes match so if they received hash

equals the calculated hash Bob can be

sure that the message Integrity is okay

so the message hasn't been modified in

transit there's also one more thing that

this process tells to Bob the fact that

he has been able to use Alice's public

key to successfully decrypt that message

confirms the fact that the message has

been authenticated as actually coming

from Alice so get two things here we get

message Integrity we know that nobody

has tampered with the message in transit

we know that's the original message that

we're looking at and we also know that

the message was actually sent by Alice

because nobody else

could have encrypted that message in

such a way so that we could decrypt it

with Alice's public key

that's how digital signatures work so

when coming back here to our slide we

basically now can tell for sure that a

digital signature provides us with

Integrity because we have the hashing

process if those hashes match the hash

that we receive along with the message

and hash that we can calculate by

ourselves from the message that we're

receiving if those two match then we

know that the message is the original

one you also get authentication because

this asymmetric encryption process

ensures us that nobody else apart from

Alice could have encrypted that hashed

message

right so if we are able to decrypt it

with Alice's public key then 100 sure

mathematically proven that message could

only have been encrypted using Alice's

private key

and finally we also get an additional

bonus called non-repudiation it's an

interesting one you know what uh we know

for sure that Alice is the only one who

sent that message but what if Alice

denies having sent that message maybe

it's a it's an illegal act right maybe

it's a a Cyber attack that is digitally

signed by by Alice and we can trace it

back to Alice now Alice cannot even deny

having sent that message because Alice

is the only person in the world that

owns that private key which is a very

important concept that ties this

authentication process to accountability

we can actually Trace actions now back

to human identities

by using this public key cryptography

implementation based on digital

signatures the long story short all the

story about digital signatures is

basically just a method to encrypt a

hash of an original message that's it

there's an encrypted hash

another very important use case in

cryptography is called a digital

envelope

did you just see a problem with the

process that we described before using

visual signatures I've said it several

times we're not encrypting the entire

message we're just encrypting the hash

of the original message so the original

message remains in clear text which

means that we don't get any kind of

confidentiality when using digital

signatures that's that's all it is if

you think about it a an official

document it has your signature on it it

doesn't make that document unusable

unreadable it's just a way to

authenticate that document but it's

still in clear text for anybody else to

see and read and use alright so we don't

get confidentiality but of course there

are methods I'm going to talk about them

right now in which we can use the

concepts that we already know about such

as symmetric encryption and asymmetric

encryption to provide confidentiality as

well

so how exactly does a digital envelope

work well we'll start with the the same

Alice and Bob

and the same insecure communication

medium that we might have between these

two

the first thing Alice does is that she

is going to obtain from Bob

a copy of Bob's public key and we're

going to call this one B Pub

K now of course Alice has its document

ready the file that he needs to send in

clear text

what she does she takes that clear text

document and encrypts it

with a symmetric

key

so we're using the type of key that we

can use for both encryption and

decryption we're going to call this one

symk right this is the symmetric key

randomly chosen by Alice

next what Alice does is that she is

going to encrypt this symmetric key

using

Bob's public key

which results and something that we're

going to call an encrypted

symmetrical

key

they're not encrypting caches anymore

we're actually encrypting encryption

keys now what s does next is that she

sends both the encrypted message

this one right here

and the encrypted symmetric key

to Bob

now when Bob's receives this type of

information he's going to take the

encrypted symmetric key and decrypt it

with his own private key remember

because it was encrypted from the very

beginning with his own public Key by

Alice so

Bob in return obtains a clear text

symmetric encryption key which then in

turn can be used to decrypt the original

message because remember the original

message was actually encrypted with the

symmetric key chosen by Alice so after

this operation of course Bob obtains the

original clear text message

so what we're doing here is actually

we're encrypting the original message

using a randomly chosen symmetric key

and then we're protecting that symmetric

key using public key cryptography

because an encryption key again is a

pretty small set of data just a number

of bytes hundreds maybe thousands of

bytes but more than enough so we can

just encrypt it and protect it using

public key cryptography so with digital

envelopes we get the benefit of

confidentiality because we're protecting

the entire message with asymmetric key

which then in turn can be protected by

public key cryptography symmetric

encryption keys are not going to be very

long probably just some tens hundreds

even a couple of thousands bytes in

length more than enough so that we can

protect it with public key cryptography

now unfortunately we're losing something

here we're kind of losing authentication

because as opposed to digital signatures

where we actually encrypt with the

private key and then anyone can decrypt

with our public key in order to validate

our identity well right here we're

actually encrypting with the recipient's

public key

so that we can be sure that only the

recipient can access the information by

decrypting it with its private key but

we're losing this authentication part

because anybody can theoretically

generate that digital envelope that

anybody can use that recipient's public

key so we don't have out of the box

authentication we can have but we need

to combine the concepts from digital

signatures with the concepts from

digital envelopes in order to provide

both confidentiality on authentication

to our messages so you can use that

digital envelopes now to solve the

problem of communicating the encrypted

message along with the encryption key

because that's the main problem right

we're using an encrypted message because

we don't trust the communication medium

we we think that it might be intercepted

or sniffed so how can we send the

decryption key along with the message

because the decryption key could also be

intercepted as well well a digital

envelope solves this problem because

relies on public private key

infrastructure and in real life this

type of negotiation that we just talked

about happens as a process called key

exchange whenever you're negotiating the

encryption keys that you will be using

in order to communicate with a secure

website or the keys that you'll be using

to transfer data over a VPN you're going

to go through a process kind of like

this one that we just described right

here of course this all happens

transparently in the background while

the connection is being set up

so in both examples so far we're relying

on some sort of a public key being

communicated to the to the second party

so we're we need the public key to

validate a digital signature we also

need the recipient's public key in order

to send them a digital envelope so how

do we communicate this public key

actually in real life well in real life

we're rapping we're packaging these

public keys in something called a

digital certificate now a digital

certificate basically becomes just a a

recipient a container a wrapper if you

wish for a public key along with some

additional information of course but the

public key is the main information that

we're interested in along with the the

fields that are uniquely identify the

name of the person or the the domain of

the website that we're trying to

communicate with or validate its

identity so we could say that a digital

certificate is basically a piece of

digital information that we can

associate with a real life identity so

this certificate right here I can say

that it's a reflection of a real person

in the real life right we can use it to

identify uniquely identify someone just

like you use for example a government

issued ID or driver's license in real

life to uniquely identify and

authenticate a person now we have a

problem here as well

and so we we talked about these public

keys that were given to anyone and that

we use digital certificates to wrap

these public keys and then send those

digital certificates actually

there's still a big problem right here

the problem that anybody can generate a

public-private key pair anybody can

generate a digital certificate anybody

can share that digital certificate with

anyone and they could be they could

write anything in it they could

impersonate someone else they could

impersonate a different person right

they could be sending emails digitally

signed with a fake identity so how does

this actually help us I mean we do have

the technology out there but apparently

we cannot rely on it and the same

problem goes in real life now imagine if

I were to authenticate myself to you and

you asked me for a proof that I am

actually Andrew that my name is actually

Andrew and let's pretend that I just use

a napkin and right on that napkin my

name is Andrew and I just show it to you

are you going to trust me more now that

I actually generated a document that

says that I'm Andrew are you gonna trust

me even one percent more probably not

not even one percent right so what do

you do in real life in situations such

as these We're Not Gonna accept the

napkin of course but we are going to

accept a government-issued ID we're

gonna accept a passport we're gonna

accept a driver's license why do we

accept those and not a napkin well

because those documents

are methods of identifying ourselves as

a certain person but they are also

trusted

you trust

The Entity that generates government

issued IDs you trust the entity that

generates passports you trust the entity

that generates a driver's licenses and

you know that those documents are very

difficult next to impossible to be

forced so that's exactly the concept

that we're going to apply to digital

certificates as well because anybody can

generate a digital certificate so how do

we actually trust the owner of digital

certificate that they they are the

person that the digital certificate

states that they are how do we do this

well we get a third party we get a

higher authority to digitally sign those

digital certificates and put their own

signature in there and if everybody

trusts that higher authority when they

say that they vouch for me for being

Andrew Well if everybody trusts it then

everybody is going to believe it that

okay if I can show you a document even

if it's a napkin that is actually signed

by some high level Authority that

everybody trusts if that napkin says

that I'm Andrew then I am really Andrew

everybody's going to believe this and

and digital certificates world and uh in

the public key infrastructure World

actually we call this higher level

entity a certification Authority or a CA

and of course in order for this to work

Everybody Must trust the ca

Everybody Must trust that whatever the

ca signs is valid so the ca must have

some verification methods and not

everybody can just go to a CA and ask

them to generate a certificate that says

that they're Bill Gates right it

shouldn't be possible so if the ca put

their signature on a document on a

digital certificate saying that I am

Andrew they probably made some checks in

order to prove that I'm actually Andrew

so whenever you see a document signed by

that CA you're gonna trust it now how do

we know which Cas to trust well most

operating systems and especially most

browsers out there come pre-packaged

with a list of trusted Cas from all over

the world those are the cas that have

been known to provide a good reputation

good service they haven't been breached

or at least not as far as we know so

that whatever they are generating as a

digital signature for our certificates

it's going to be valid and it's going to

be trusted let me show a list of such

approved cas

now I could take Firefox like you could

take any browser you want uh then you

can head over to the settings section

I'm going to search here for search

certificates and have a button here that

says view certificates if you click on

this one right here you're gonna find

the last tab here on the on the upper

right hand corner called authorities

which is basically certificate

authorities and there's a huge list in

here

these are all valid well-known and

built-in certificate authorities that

your browser is going to automatically

trust so if your browser finds that a

website is signed by the Amazon root ta

number one right here then it's going to

trust it automatically you're probably

going to recognize a couple of these

such as search sign digicert

interest Global sign and so on and so

forth right so this is a lot of

certification authorities in here and in

most cases very sign as well in most

cases if you just visit a website such

as I don't know google.com all right so

let's head over to google.com right now

if I click on this uh lock sign right

here it says connection is secure

verified by Google Trust Services LLC I

can click on more information drag this

window right here and cite and under the

security section I can view the

certificate for this specific website

right you can see it's a certificate

that applies to all the subdomains

inside Google so it's star.google.com

you can see it's um it's issued by

Google Trust Services LLC which is

officially called

gtsca1c3 all right so this is a

certificate Authority right here

right you can also click on this one and

see the actual certificate of the

certification Authority all right

certification Authority yes it is what

is we having here

this is the public key information the

algorithm is RSA 2048 bits as the key

right here also has a serial number

uniquely identified you can also

download the certificate in pen format

this is a printable ASCII type format

for uh for digital certificates that's

the fingerprint the shot 256 or the shot

one hashes of the public key and you can

see that the key usages right here says

that this certificate can be used for

digital signature certificate signing

and crl so I'm going to talk about this

one later on all right so coming back

here to the certificate of google.com

you can see that we also have some

subject alternative names so it's the

same certificate that gets applied to

all of these alternate domains inside

Google so covering a lot of countries

covering a lot of Google services in

here the algorithm that is being used

it's an elliptic curve algorithm with a

key size of 256 as the key right here

again we have a serial number a

signature algorithm we can also download

the certificate and so on and so forth

now of course if we really want to to

try and check this we could be looking

at this

gtsca1c3 so if you go back here the

certificate section

you should be able to find

GTS

there it is Google Trust Services GTS

ca1c3 right and this is why when you

visit Google you don't get a warning

saying that you're not going to trust

that certificate that certificate is

there's a mismatch or is it expired was

it is not signed by well-known Authority

that's because Google certificate is

actually signed by this CA right here

and this CA is built into Firefox

right so d well-known trusted CA same

those with any site out there go ahead

try a couple of well-known sites see

what their Cas are see who signed their

certificates and see why are you

automatically trusting the communication

with those websites

now there's also an interesting concept

here called perfect forward secrecy if

you just look at this this term it

doesn't tell you anything right it kind

of suggests something about encryption

but pretty much that's it now perfect

forward secrecy address is a problem

that we just covered when we talked

about digital envelopes we said that in

order to encrypt the bulk of the data

that we're about to send we need to

generate a symmetric key a symmetric key

one symmetric key all right and that's a

metric key then we're going to protect

it using the public key infrastructure

that we're relying upon right the the

public private key pair now the problem

is that in theory at least if at some

point that entire communication session

gets recorded by somebody who is

snooping on the traffic I'm somebody who

is intercepting that traffic and then at

some point in the future the private key

of the server you're communicating with

or the private key of the recipient

you're communicating with gets

compromised well all that communicate

station could be potentially decrypted

the the symmetric Keys would be shown

would be revealed and the entire content

of the communication could be decrypted

and thus we would lose uh

confidentiality so perfect forward

secrecy is just a way to mitigate this

problem by generating what is called an

ephemeral or a session key or a temporal

key that is being used for a limited

amount of time or a limited amount of

data while communicating with that

specific destination and what's even

more important is that these ephemeral

keys are not being protected now by the

server's private key so in case the

service private key has compromised

we're not going to be automatically risk

revealing those symmetric keys that we

use no there's a mathematical set of

operations that is being performed known

as a key exchange with an implementation

called the diffie-hellman algorithm now

difficult my algorithm is basically a is

an algorithm that don't really need have

to know the the bits and pieces of it in

order to understand how it works but

it's an algorithm that relies on a an

exchange of messages over an unsecured

channel that helps Alice and Bob reach

the same conclusion reach the same

agreed upon symmetric key without

actually exchanging that symmetric key

over the unsecured medium now that's a

very good picture here that I like to

show it's actually available from

Wikipedia that depicts in a graphical

manner how difficult one actually works

so if you head over to the Wikipedia

page of diffie-hellman key exchange

we can scroll down right here I'm gonna

see this picture

and I like this picture here because it

doesn't rely on any mathematical

Concepts in order for you to be able to

understand it so we have Alice and Bob

all right how do Alice and Bob can agree

upon a common secret over an unsecured

channel right here in the middle without

actually communicating that secret ever

over the unsecured channel right how do

I tell you something without actually

telling you that that thing right and

the way it works is something like this

they agree first and they freely

communicate over the unsecure Channel a

common starting point such as a common

collar such as yellow right here right

then they each generate their own secret

colors without communicating them over

the unsecure medium in case of Alice

Alice generates an orange Bob generates

teal I think this one is right and then

Alice combines these two combines the

common paint with the secret paint and

results in some light orange or

something like that Bob on the other

hand combines yellow with teal and

results in some light blue color what

they do is now they exchange these

Colors Over the unsecured medium over

the public transport medium right they

just change it and then each of them

recombines

the other ones result with their own

secret color

so Alice uses the light blue color from

Bob and combines it with her own orange

Bob uses the light orange from Alice and

combines it with his own teal at the end

we get the same brownish color right

here which is the common secret without

ever actually communicating this

brownish color over the unsecured medium

also in the unsecured medium we need to

assume that this mixture separation is

expensive that is it's next to

Impossible work to computationally

Impossible or unfeasible to determine

from which colors did these light blue

or light light yellows light light

orange colors actually came from so this

is one way of showing how difficult

works now if we had someone intercepting

this communication in the mid in the

middle they would see the first the

common paint they would see the

combine colors in here that were being

sent they would never see the common

secret the resulting value that both

Alice and Bob finally get to and this

common secret from now on can be used to

actually protect as an encryption key

the data that we're about to send

and we both know it so it can be used as

a symmetric key

now PVS can also be implemented using

diffie-hellman in this ephemeral mode

that we just talked about before in

which we're not deriving those keys from

the private key we're just deriving it

from this Dynamic key exchange and

periodically change that key over uh

over a certain number of bytes after a

certain number of bytes have been sent

through that channel we refresh the key

or after a number of minutes or seconds

have have lapsed we are regenerating the

key again just in case the key gets

compromised at some point now whenever

the element is combined with this

ephemeral algorithms we get something

such as diffie-hellman ephemeral or

ephemeral diffie-hellman or elective

curve based difficult man ephemeral and

so on basically if you find yourself in

the exam having to identify difficult

implementations that use perfect forward

secrecy look for something with Tiffy

helmet and E in the name d h e or e d h

something that's going to be what you're

looking for those are the

implementations that use perfect for

secrecy

now the encryption algorithms also have

some modes of operation that is in their

real life implementation

and first we have the so-called

unauthenticator or non-authenticated

modes of operation that is performing

encryption without actually

authenticating the source of that data

these two modes are the ones that we

actually uh we touched upon in the

previous video Cipher block chaining

mode and counter mode when we talked

about Cypher block chaining before

I'm going to go back to this Wikipedia

page right here called block Cipher

modes of operation if we jump down to

cypher block chaining in the middle

you're probably going to recognize this

this picture right here right where we

just split our encrypted data into a

number of fixed blocks we combine these

blocks with uh the first one with an

initialization Vector right then we use

the encryption key and then we get the

result under a ciphertext then we reuse

the ciphertext as an input for the next

block again we combine it with the with

the encryption key again we get the

cyber text and so on and so forth so

this is cipher blockchaining we're

encrypting each block individually but

we are reusing encrypted material from

the previous block so that no two inputs

no two blocks even if they are identical

are never going to produce the same

exact encrypted result

which helps us defeat cryptanalysis

attempts the second one here is counter

mode which is kind of similar to what we

just talked about

and counter mode also known as integer

counter mode is basically also a type of

block Cipher

but it generates the next keystream

block by encrypting success with values

of a so-called counter so instead of

reusing encryption material from the

previous block we are encrypting the

original clear text along with a counter

value you can see here for the first

block it's going to be all zeros for the

second one is going to be all zeros and

one all zeros and two and so on and so

forth

again in an attempt to generate

different inputs even for completely

identical blocks so that we can get

different encrypted outputs now these

two modes of operation that we just

talked about they're considered to be

unauthenticated because there's no

identity information related to the

encryption operation and also

theoretically a person could potentially

perform some cryptanalysis on this text

and introduce their own values in there

maybe insert additional encrypted data

if they know how the encryption

mechanism works and we would not be able

to detect this now one method of

providing authentication in the

encryption process is by implementing

something called a message

authentication code or a Mac don't

confuse this with the layer 2 Mac and

network packets it has nothing to do

with that so Mac stands for message

authentication code and it kind of looks

like this

so basically we're taking the message or

the encrypted message passing it through

a Mac algorithm with a Mac algorithm

does pretty much what a hashing function

does except that this time the hashing

is performed not just on the original

message but on the original message plus

a secret key

all right so we get that end result

called in Mac that message

authentication code we attach that Mac

to the message we send it to the

destination and then the destination

after decrypting the message and after

analyzing the Mac tag that is attached

to the message they can determine when

they recalculate that hash along with

the known secret key that they're

supposed to know already whether the

hashes match or not now if those hashes

match we can now know for sure that the

message hasn't been tampered with in in

transit because in order to tamper with

the message you would not only have to

intercept it modify it and then

recalculate its hash you would also have

to know the secret key that was used in

order to calculate that resulting hash

because the secret key is never

communicated with the rest of the data

if previously we thought about hashing

functions as being sufficient for just

validating the Integrity of the data now

we think about the situation where what

if somebody intercepted that message in

transit made some changes in that

message message and then nicely

recalculated the hash value because the

hash is based on some well-known

algorithm anybody could recalculate it

and reattach it to that message the hash

would still be valid but it would not

prove the Integrity of the message well

in this case with the message

authentication code this situation is

not so easily reproducible anymore

because if somebody intercepts that

message and they try to make some

changes in it and recalculate the hash

of that message well those hashes are

not going to match anymore because they

are not going to be able to generate a

valid hash without knowing the secret

key that goes in that calculation as

well now in real life you're going to

find algorithms that implement this this

type of Mac under the names of uh AES

CBC for example for cyber block chaining

or age Mac sha right the hashing

algorithm with an hash based message

authentication code attached to it so

it's more than just a hash it's a hash

of the data plus a secret key and

unfortunately and this is something you

should know for the exam some of these

implementations are vulnerable to

something called a padding Oracle attack

check out this link right here for more

information about this type of an attack

and finally we have some more exotic

modes also based on this authenticated

encryption or Mac implementation called

the authenticated encryption with

additional data with what kind of

additional data where we usually use

this additional data from the actual

data header or the actual data

Communications session in order to

generate some messages or some

communication encrypted packets that are

unique to that specific communication

session why are we doing this well to

avoid replay attacks replay attacks are

the attacks in which an attacker

intercepts a specific communication even

if it's encrypted and then replays it

back resends those same packets at a

later time now if we don't have some way

of identifying which packets belong to

each session anytime an attacker would

Replay for example let's say an

authentication session

captured from a legitimate user they

would be authenticated even if they

don't even know what the user's

credentials are they're simply sending

the same encrypted data as they've seen

that user doing so authentication

encryption with additional data allows

us to add more information to the

encryption and hashing process so as to

make these replay attacks impossible

so now let's go back to the main topic

of the training right talking about

security controls how can we implement

the

encryption the hashing methods that we

talked about the the implementation

methods that we just that we discovered

in real life in actual controls or where

actually can we use these Concepts to

better increase the security of our

Network

so coming back to the idea behind public

key cryptography when we said that a

private key must only belong to a single

person that basically means that we can

tie that person's identity to something

that has been done using that private

key like a digital signature so we can

use the concepts that we just talked

about hashing functions encryption

functions to uniquely identify a person

which leads us to an implementation of

these Concepts in authentication systems

where we need to prove that a single

person has actually proven their

identity and has a way of proving their

identity in order for them to gain

access for example in a in an

application or in a network

and using private keys that can uniquely

identify a person becomes the basis of

an access control system

as a consequence to this we also get not

a repudiation if a certain message has

been encrypted in a certain way that we

know for sure that can be done only by a

specific private key then the owner of

that private key cannot deny ever having

done that operation ever having sent

that message ever having signed that

message ever having generated that

encrypted content

so that's non-repudiation

your inability to deny having done an

action because you are the only owner of

the key that can do that action

we can use cryptography for well

encryption of course that's one of the

the first use cases but in general we're

going to be using something called

hybrid encryption hybrid decryption

means that we're combining symmetric

encryption with a symmetric key that

we're using to encrypt a bulk of data

with with asymmetric encryption in which

we're just protecting that symmetric

encryption key because remember we

cannot use asymmetric encryption to

encrypt huge amounts of data and also

because symmetric encryption is much

faster so it's more resource efficient

to use a symmetric key to encrypt a

large amount of data such as Network

traffic or files on a disk or entire

disk even and then protect that

symmetric key using asymmetric

cryptography

so in order to encrypt files such as a

bit Locker for example the way BitLocker

works well in case of BitLocker the user

is being assigned is being generated a

public and a private key pair and the

private key pair is stored somewhere in

a secure area of the computer such as a

TPM chip that only becomes available to

the user when they are authenticated to

the domain or to the machine that

they're using

then the public key is being used to

generate a random symmetric key and that

random symmetric key is actually used to

encrypt the data on the disk now when

somebody needs access to the data on the

disk they can use the private key stored

in the TPM of course after they've

properly authenticated to decrypt that

symmetric key and then use that

symmetric key to decrypt the actual

files on the disk the same goes even

with websites when you're visiting a

website over https what you're doing the

first thing your browser does is

download the public certificate from

that website that you're accessing that

certificate includes a public key and

that type of key now can be used to

communicate with the server right

whatever you're encrypting with the

server's public key can only be

decrypted by the server which owns the

private key and then you can use this

communication channel to further

negotiate a symmetric key that can be

used to encrypt the actual traffic that

you're about to send and download or

upload to and from that website

of course we can also use cryptography

to ensure Integrity of data at rest or

at data in transit to make sure that

those messages though that data hasn't

been tampered with just like we said

before we can combine that hashing

operation with a secret key that can

prevent a man in the middle attack

intercepting that message making some

changes and then repackaging it down to

its final destination it's not possible

anymore with a message authentication

code because the hash is being

calculated from the message as well as a

secret key finally there's the idea of

obfuscation now obfuscation can mean a

lot of things but in general it means

that it's a it's an attempt to make

something difficult to read not

impossible just difficult to read and to

interpret for example you might have

heard about obfuscation regarding source

code now an obfuscated source code makes

it impossible or really difficult for

somebody who tries to reverse engineer a

piece of software down to its original

source code and makes it really hard to

understand by by humans of course

machines won't have any problem with

that code because the code is still

functional but it's just really hard to

read and to follow by by human eyes now

with cryptography we could think about

trying to implement something close to

obfuscation because we're basically

scrambling data right we make it

difficult to read now unfortunately the

way encryption scrambles data also makes

that data unusable even by computers

because regardless of how much you

encrypt your data whenever you're

storing it whenever you're transferring

it whenever you're you're using that

data at some point at least for a couple

of milliseconds right there while you

are actually processing that data you

need to decrypt it computers cannot work

with encrypted data they have to at

least at the CPU level at the inside of

their memory inside of the actual

process that uses that data it has to be

decrypted before it can be used

so protecting application code or source

code this way

doesn't really work think about it

because if you provide encrypted code

for your CPU to execute first of all

it's not going to be able to do it right

so you need to provide the decryption

key as well well how do you provide the

decryption key along with the code along

with the executable code in such a way

so that an attacker or somebody who

wants to take advantage or crack the

protection of that software it's not

going to be able to find that decryption

key it's impossible to hide something

inside of a computer right this even

starts to get closer to that concept of

security through obscurity so you simply

cannot protect data by bundling it with

the decryption key as well right it

makes no sense this is also sometimes

called box cryptography because in the

same box you get the encrypted data and

also the decryption key and more or less

this is how DRM kind of works digital

Rights Management and we all know that

all the methods that rely on and DRM for

protecting video content music games

software apps and so on and so forth

that pretty much all of them have been

cracked for this specific reason

now when talking about cryptography

performance is also an important topic

simply because it requires additional

effort and sometimes we don't have the

necessary resources to perform that

additional Raffles you might be trying

to perform cryptographic functions

on a on a smart watch on a mobile device

on a smart doorbell on a on an IP camera

for example you probably don't have that

many resources available so you're gonna

have to make some compromises you might

be forced to use lower complexity

encryption algorithms or use shorter

keys that don't take that much time much

that much computational effort to

process and also try to keep in mind

that in general symmetric encryption is

much much faster than asymmetric

encryption then we also have the problem

of latency especially in interactive

applications or authentication systems

sometimes we are bound by time by the

execution time to finish all our

cryptographic processes in a predefined

amount of time most likely because if

that cryptographic process is involved

in an authentication system nothing can

be performed the entire system is

non-functional unless the authentication

system agrees that the person has been

authenticated and authorized to perform

those operations Ford no data can be

transferred over a VPN or no

communication can be performed with a a

secure website unless the cryptographic

part finishes in a predefined amount of

time

key size in general as long as we talk

about the same algorithm means a more

secure encryption method so the same

algorithm with a shorter key is

theoretically easier to break same

algorithm with a longer key is going to

be more difficult to break but of course

it's going to take more resources as

well now don't compare key lengths

between different algorithms it doesn't

have any kind of relevance I mean I I

think I've covered this one before but

for example in elliptic curve

cryptography a 256 bits of a key length

provides pretty much the same security

as a 2048 bit key length in uh in an RSA

keeper

overhead not just from a resource

consumption perspective but this is

extremely important especially for small

battery-powered devices or very limited

devices but also because these

cryptographic operations have to be

dynamically on the Fly executed and

inserted before each and every access to

that data every time you access a file

on an encrypted disk you have to go

transparently through the decryption

process in order to be able to access

that data so more operations are

required whenever you're accessing

protected data and a lot of problems

occur whenever you're working with low

power devices iot devices battery

powered devices devices that only have a

very limited CPU power that cannot

implement or takes too long or consumes

too much power to implement mature and

strong encryption algorithms

entropy is a measure of disorder how

much disorder we have in our data which

means that a clear text document an

unencrypted document should have low

entropy on the other hand an encrypted

document should have high entropy so

there should be a lot of disorder in

there so that there's no way we could

just look at an encrypted file and see

well this piece right here

kind of looks like the the header in an

email message or the signature in an

email message now we shouldn't be able

to do this right there should be

anything there shouldn't be anything

that closely resembles or remotely

resembles something from uh from the

original text

and this is relevant because in some

situations even though the mathematics

behind the encryption algorithm is sound

is okay is proven to be okay here and

reliable the actual implementation in

programming code of that algorithm might

have some clause for example in the way

that program actually generates those

random numbers those those random

symmetric keys for example that were we

we just talked about that we're using to

encrypt the bulk of the data now if that

random number generator doesn't exhibit

enough entropy we Face the risk that by

performing cryptanalysis on the on the

way that algorithm Works to be able to

determine what the next random number is

going to be which would be very very bad

and could open us to a huge security

risk also on the top of keys in general

because the keys are the actual random

material that gets generated there are

specific keys

that end specific implementations of

specific algorithms generate low entropy

so so certain keys that when used to

encrypt data they don't encrypt it that

well right it still retains some of the

characteristics of the original text now

in most uh in most algorithms out there

the implementations should take into

account these exceptions so there are

some known keys that generate low

entropy and whenever the algorithm

generates a random key if it happens to

generate one of these low entropy Keys

it should ignore it and generate another

one and this is actually one of the

reasons why the implementation of the

algorithm itself is one of the important

factors that comes into play when

evaluating the performance and the level

of security offered by an encryption

method

so some ways to fight against these

problems related to predictable numbers

or predictable random numbers have a

couple of them right here the first one

is by using a so-called nonsense number

used only once that's a nonsense so

whenever we need to generate some unique

material we are we can concatenate that

unique material with a randomly

generated number called the nonce which

can also be a counter for example just

like the one that we we saw and use in

uh in blockchaining

it it doesn't necessarily have to be

random it just has to be unique

and never reused we also see

initialization vectors again sets of

data that are randomly generated

supposedly not to be reused anymore that

make that initial exchange or the

initial encryption that is based on

those initialization vectors unique

finally we also have salting

salting is a technique that can be used

along with hashing and it's especially

used with hashing passwords whenever

you're storing passwords for an

authentication system for the website

for an application if you're storing

user profiles you should never store the

user passwords as well instead you

should be storing a hash of that user's

password

and now whenever the user presents uh

his or her authentication credentials

you take the user's password you hash it

and then you compare it with the hash

that you have in your own database if

the hashes match well the user is good

to go it's authenticated now why are we

doing this well because whenever we are

storing the passwords in clear text or

even in encrypted format we risk them

being compromised as a result of a data

breach but on the other hand if we just

store the hashes well if we happen to be

facing a data breach we'll be losing

those hashes those hashes will become

public but as you know there's no way to

reverse engineer a hash to figure out

what the original password was

unfortunately

there is a way of doing this but not by

reversing during the hashes instead

there's a concept called a rainbow table

rainbow table is a pre-calculated

table of hash values of all possible

inputs that can generate those hash

values so for example I can just take

all the letters of the alphabet all the

numbers all the punctuation signs and

start from all the combination of one

character two characters three four five

six and so on and so forth and I start

generating all those combinations and

calculate the hashes of all those

combinations now it's going to result in

a huge table of course it's probably

going to be tens or hundreds of

gigabytes in size but guess what now if

I happen to get my hands on a hash

database on a compromised web server or

a compromised application authentication

system I can just search for that hash

in my rainbow table and see what

password was used to generate it and the

advantage of doing this is a linear

search in a huge database it's much

faster than trying to generate all those

hashes until I finally find the one that

actually matches the one that's in my

database so I just calculate them once

or download those tables because there

are public rainbow tables as well and

even paid rainbow tables if you wish and

then I can just search the hash value in

that rainbow table to find which

password was used to generate it so

apparently storing the hash values of

the passwords isn't so secure over

either this is where salting comes into

place salting means that we are now not

just calculating the hash from the

password but we're calculating the hash

from the password and a small string of

bytes that we add before or right after

that password and then we calculate the

hash what does this do well this

invalidates my rainbow table because my

rainbow table was calculated for Clear

passwords not for passwords plus a hash

now whenever I provide a password to

that authentication system the

authentication system gets my password

concatenates the small salt and then

calculates the hash and then Compares it

with the one in in its own database now

the interesting thing is that that sold

doesn't even have to be secret it can

just be a small string of bytes that can

be stored right next to user profile I

mean I don't even have to secure it

everybody can know it but it's going to

invalidate all the possible rainbow

tables that have been pre-computed to

use just the password not the salt so

that's one way of enhancing

authentication systems by salting

password and that's actually the way

passwords are currently stored on Linux

systems want to see how this looks like

on a Linux system well you probably know

that by listing the Etsy password file

in a Linux system I'm going to see the

list of users what shells they're

currently using uh the groups that they

belong to their user IDs and so on and

so forth now this Andre user right here

that's the username should be followed

by the password but the password is just

an X in here you can see all of them

have access in here because the

passwords are not being stored in uh

Slash

Etsy password haven't been stored for

some time where they are actually stored

or under Etsy shadow

and I'm gonna have to pseudo this

and there you have it this is my

username right here this one right here

is the field that stores the information

related to my password now this first

section here between these two dollar

signs this indicates the uh the hashing

algorithm of my password and then the

next section down to the next dollar

sign this one right here is the salt you

can see the salt is stored in clear text

what's next that's the actual hash so

right now if I were to search for this

hash in a rainbow table I would probably

find some sort of input that generates

this hash but that input is not going to

be the valid password for my account

because whenever I provide that input it

has a password that input is going to be

concatenated with this salt value

and the end result is going to be a

completely different hash so this is how

you store username and password

information on Linux systems

now some of the risks that we're facing

with encryption and some of the things

that we should keep an eye out whenever

we're choosing an algorithm or key for

encryption are just a number of ideas

here listed on the slides first one

being the age of the encryption

algorithm how old is the actual

encryption algorithm it might be that it

used to be a valid algorithm like 20

years ago but in the meantime weaknesses

have been discovered the computational

power has increased which has made any

attempt at cryptanalysis at breaking

that algorithm much more possible

nowadays than it they were 20 years ago

so choosing an up-to-date algorithm one

that is okay for the current year that

we're in and the corresponding key

length that's an important decision a

lot of the algorithms that have been

discovered over time nowadays have been

deprecated which means that you

shouldn't use them it's not that they

are gone of course the algorithms are

still there but sometimes people use

them simply because they don't know

these are old and vulnerable algorithms

so not or encryption is equal you also

have to take into account the age of the

actual encrypted data or how long should

we keep that data encrypted because the

longer we keep it encrypted

the longer we risk that encryption

method to be broken because things are

evolving every single day CPUs are

becoming more and more powerful better

at cryptanalysis weaknesses are being

found in encryption algorithms every day

as well well maybe not every day but

every year perhaps right so how long we

store that data is going to affect how

secure that data is going to be after

let's say 20 years from now in the

future

so talking about risks that we're facing

or that our encrypted data is facing uh

we can think about first of all men in

the middle of attacks now men in the

middle attack has a general concept

relies on the fact that there's a third

party an attacker that intercepts the

communication between Alice and Bob for

example and then they either just

inspect it so they gain access to

confidential information or they alter

it so they they change the Integrity of

that data and a special category of man

in the middle attacks are those that

address that negotiation part of keys

before the actual transfer of encrypted

information that negotiation part has to

be done over an unsecure medium so it's

very important what exactly do Alice and

Bob exchange over the public internet or

over in unsecure Network before they

actually agree upon an encryption method

an encryption key and encryption

algorithm and they start sending data

because in some implementations if an

attacker is able to intercept that

communication then they can pose

themselves as either Alice or Bob

or even reuse some of the keys that were

negotiated in that process

for example when we talked about digital

certificates or digital envelopes we're

relying on the fact that either Alice or

Bob have to communicate their public

keys to the other party well what if the

attacker intercepts that public key and

injects their own public key in there

from the very beginning you have no idea

that it happened and you start

negotiating and start talking and you

start negotiating keys and establishing

session keys and perfect forward secrets

and everything else but you're doing it

with the wrong person you're not doing

it with with Bob you're doing it with

the attacker and you're negotiating a

secure Channel with the attacker simply

because you've accepted from the very

beginning a public key that did not come

from Bob but came from the attacker so

we can mitigate this using certificates

you can mitigate it using science

certificates valid certificates and the

entire public infrastructure Concepts

that we talked about

downgrade attack is another type of

attack that it's actually very smart you

know you have this negotiation phase

whenever you're connecting to an https

website you're negotiating with that

website

um something like well this is the list

of algorithms and the key lengths that I

know how to use give me your list so we

can we can match it right we can find

some some common ground and then use the

best algorithm in that list well of

course an attacker could pose as

somebody who doesn't know all the

high-end algorithms and key lengths and

only presents the weakest possible

encryption algorithms out there saying

well that's all I know I'm sorry that's

that's all I can use if you want to talk

to me well if a badly configured web

server is in place they might be open to

accept all the possible encryption

algorithms

maybe there's no security analyst in

there that uh decided at some point well

we shouldn't be accepting these because

they're too old they have been

deprecated and whoever installed the web

server just enabled everything that's a

downgrade attack because you're

downgrading the quality and the

correctness of the encryption algorithm

down to something that is easily broken

or completely unsafe nowadays

the key stretching is another method of

fighting attacks against uh cracking

passwords for example or guessing

passwords or encryption keys because in

many many situations a the key provided

as a password by a user for example

whenever they authenticate and uh and

they want to gain access to some

BitLocker protected disk or they're

going to enter their username the

password and maybe they have something

like the password of one two three four

five

well it would be a bad idea to use

password one two three four five to

encrypt the entire disk so we're not

using the actual password from the user

we're taking that password and we're

passing it through a number of

transformation operations so that we're

making it longer and more complex we're

repeating it a number of times we're

hashing it uh we're mixing the

characters around we're replacing

characters we're basically doing some

sort of a low end encryption on it just

to obtain some sort of a cryptographic

material that is valid to be used as an

actual key not just one two three four

five that's key stretching and key

solving what we just talked about well

combining the key the password with an

additional salt with just a sequence of

characters that makes the hash generated

by that password unique and thus cannot

be defeated by the use of rainbow tables

collisions if you remember we talked

about collisions when we introduced

hashing functions we said that a

collision is a situation where two

different inputs create the same

resulting output of a hash function

that's bad such a collision is bad

because it defeats the concept behind

integrity

which means that there are potential

situations where an attacker can

maliciously change a file or the

contents of a network traffic

in such a way so that the resulting hash

applied to the new set of data is the

same that's one way of exploiting such a

such a collision

so the attacker managed to make to alter

the changes but also found a way in

which those changes don't change the

actual resulting hash think about how

important this is for digital design

documents we trust the digitally signed

document that it hasn't been tampered

with and that's the original document

that we're looking at but what if the

attacker manages to add some content to

that original document and still

maintain the same digital signature and

even though this sounds terribly

theoretical let's say it's sometimes

connected to something called a birthday

Paradox and the birthday Paradox is a

simple question that says

how many people do you think need to be

in a group so that the chance of two of

them sharing the same birthday

is 50 percent

just think about it for a second how

many people do you need in a group so

that there's a 50 chance of two of them

sharing a birthday

now many people would say something

along the lines like 180 like the half

the days in a year or something like

that the actual answer is as low as 23.

and the reason people think about this

problem in a in a in a wrong manner in a

wrong approach is the fact that while

the chances of two people having an

exact same birthday specific same

birthday or low well the chances of two

people having any identical birthday are

much higher so we only need 23 people in

a group to have a 50 chance of two of

them sharing a birthday what's even more

spectacular is that if you go up to 60

people you're already up to 99

probability

so this is connected to the the act of

exploiting collisions because it's

actually not that difficult to generate

different inputs that could generate the

same output in in a hashing function

that's why most hashing algorithms or

the security of the hashing algorithms

is measured or well quote unquote

measured and how resistant they are

against Collision attacks or how

difficult it is to determine different

inputs that provide the same output now

finally some thoughts about what's next

what's what's next in this field of

cryptography now we probably heard about

Quantum Computing and Quantum

cryptography well quantum computers base

their calculations or store the data not

with bits because a bit can only have a

value of zero or one but with qubits

Quantum bits which can uh it can either

either store zero or one but they can

also store with a certain probability

any value in between 0 and 1. and that

exact state that cannot be determined is

called a superposition you might think

okay so we have just more values now the

actual benefits of quantum Computing is

that these qubits can be entangled that

is they can be connected to one another

so when one qubit is being collapsed to

either zero or one all the other

entangled qubits also collapse in turn

which is a process that consumes much

less computing power than a normal

cpu-based operations that normally

change CPU registers and perform

mathematical operations and such so you

can have a huge number of states of

variables of values in memory all

changing at the same time all connected

to the same operation which provides us

a lot more computing power both for

generating encryption material and for

tracking or for breaking encrypted data

there's one thing that should be

mentioned here regardless of how strong

the encryption algorithm or hashing

algorithms they are it's some point they

are all vulnerable to Brute Force

attacks I mean regardless of how long of

a key you're using regardless of what

how complex the actual encryption

algorithm is

if you have the necessary computational

power of trying each and every possible

key

that can be used with that algorithm at

some point in theory you will be able to

crack that encrypted data now what we're

relying on nowadays is the fact that the

algorithms and the key lengths that

we're currently using make this

computational operation impossible or

make it take so long that it becomes

irrelevant now here's a nice website

that you can play with just to

understand the complexity of breaking a

secure key or a password so let's add a

password right here let's say the

password is one two three four that's it

all right you can see how that password

is being characterized and in an online

attack let's say that you can try 1 000

attempts per second in an authentication

system you could break it in 11 seconds

now in an offline fast attack so this is

one of the situations where you gained

access let's say to the hash database

and you're attempting to generate all

the possible combinations in an attempt

to break this password it might take you

like one what is that right less than

one second okay let's add some more

complexity here one two three four a b c

well we're up to almost one second here

for an offline attack definitely more

difficult now let's add some punctuation

in here for example let's change this to

capital A and add in exclamation mark at

the end

there we go

we're up to 2 000 centuries for an

online attack and 18 hours in an offline

attack

let's try a passphrase that is something

such as uh hello world and everyone

let's see how long would this take

to be cracked by an online or an offline

attack

so you can see right here if we're going

up in the key length and key complexity

actually we just went up in key length I

mean how much complexity we have in here

it's just alphabet letters lowercase and

in some spaces and that's it it's not

much of a complex password but look how

tough it is to crack this type of

password even in an offline attack or

even with using a massive cracking array

it's not even worth to try right

this is what we're based on right now

now if at some point somebody invents a

CPU that is

10 trillion times faster than anything

we have right now

but we're gonna have some problems with

our current encryption algorithms and

our current key lengths and we might not

be so trustworthy now uh with online

shopping as we were as we were before

there's a lot of research being

performed that allows low power devices

especially iot devices and small sensors

to implement Advanced cryptography

functions it's a lot of research here

because they are extremely Limited in

processing power and the in the

instructions that can they know how to

execute homomorphic encryption is an

interesting one especially related to

processing personally identifiable

information any type of sensitive data

it's a way to allow the processing at

least the statistical processing of

protected data which might be in some

sort of an encrypted form without

actually having access to the data

itself so you are able to perform let's

say statistical evaluations on a data

set but you're not able to view the

individual data points in that data set

which is great for collecting personal

information and generating statistics

and reports but without actually having

access to that personal information and

everybody knows about blockchain right

it's just a list of transactions that is

distributed all over the world now each

record in that list of transactions is

called a block and it is mathematically

connected using hashing algorithms 2D

blocks before it so anybody in the world

can validate that a certain block

belongs in a blockchain that the

transaction has been validated and all

this distributed database acts like a

public Ledger that everybody has access

to so it's completely decentralized you

can use blockchain for as you probably

know for cryptocurrency for recording

transaction for recording consent for

recording uh notary operations for a lot

of stuff basically on every situation

where you need to record a piece of

information and be able to allow

everyone to validate that the record

hasn't been tampered with hasn't been

forged and finally we also have

steganography it's not exactly related

to the future but it's a it's a

connected cryptographic concept

steganography uh basically means secret

writing it's a way to hide information

in plain sight you can hide information

in the white spaces of a document how

many white spaces you're using after

each word how many uh let's say you can

hide information inside the color data

of a picture

as in just shifting the color codes on

each pixel just by a value of one and

then being able to reverse this process

allows you to hide information in a

place where somebody else would not even

guess that the information is hidden now

this is not exactly cryptography this is

more like security through obscurity but

it's a very smart method of exfiltrating

data out of a company for example if you

know that the company DLP solution or

filters or firewalls aren't going to

allow you to create to send files to

create a VPN connection to the outside

but you are allowed for example to send

pictures because your perhaps your email

signature contains a picture or company

logo well you could hide confidential

information or confidential documents

inside those pictures inside inside that

company logo and send it outside of the

company without somebody even noticing

we could also use technography to hide

information in network protocols how

about

sending ping messages in Morse code

to communicate something right who

expects that or how about hiding

information in TCP Flags or in DNS

requests

because nobody looks at those right

whatever is in a DNS request apart from

the actual URL that you're interrogating

is probably legitimate information what

about the frequency that you're sending

those requests with

there's a lot of methods here to

exfiltrate data and to hide it in plain

sight

just for a minute now let me just show

you how steganography actually works I'm

going to use for this the small utility

called Tego suit which is a free utility

that you can download from the default

repositories in Cali all right so I'm

just going to load a picture go to file

open I have a beach sunset nice picture

in here let's open this one that's the

picture right I can now embed either a

secret message or a file within this

picture without changing visibly

anything regarding to that picture so

it's going to look exactly the same so

let's say that the secret message right

here is password is one two three four

five that's the information I want to

hide within this picture I'm going to

click on embed

wait for a couple of seconds here tells

me that he made it completed saved to

blah blah blah Beach Sunset embed jpeg

so let's move over to the location

which is right here in the downloads

folder let's open up this file and this

is the original JPEG file and this is

the JPEG file with the embedded hidden

information I'm gonna switch back and

forth between them

and I am completely unable to see any

difference between these two files all

right now let's go back here to Sega

suit let's open up another file this

time let's open the embedded file that

we just created notice that it is

slightly larger in size right just uh

just a few kilobytes in size let's open

this one up

and then click on extract by the way you

can also protect this information with a

password so you can basically encrypt

the data that your yours you're hiding

within that image file but since I did

not use a password when I first embedded

it I can just click on extract

and there we have it extracting complete

and the text now is again password is

one two three four five so hidden

information hidden in play site so you

can simply attach this JPEG file to an

email message send it over instant

message and send it however you want it

however you are allowed to send files

from your company and you can exfiltrate

information this way

so those are the major cryptography use

cases for you I don't think anyone would

have expected cryptography to be a

simple topic so I know this has been a

lot of information a lot of topics we

cover here but try to make sure that all

this makes sense in your mind so thank

you so much for watching if you want to

discuss more about the topics that we

covered here leave a comment in the

comment section if you like this of

course like And subscribe on YouTube

good luck on the exam good luck in your

studies and see you on the next video

bye bye

[Music]

thank you


14 14


[Music]

foreign

[Music]

now I did talk about a lot of stuff in

the previous video and there's no way

you can talk about certificates and

public keys and signatures and so on

without mentioning public key

infrastructure because that's the actual

infrastructure that allows us to

validate the identity within a digital

certificate because anyone can generate

a digital certificate at the end of the

day is just a public key and in a file

anyone can generate that content but

it's all about who is able to vouch for

us for our identity so that when we use

that digital certificate when we present

it to somebody else they can be sure and

they have a valid method of verifying

the information in that certificate so

pki or public key infrastructure is the

the network and all the elements that

come into play whenever we want to

validate somebody's identity okay so to

have an actual working public

infrastructure this infrastructure that

helps us validate identities we need to

find a way to to connect the keys that

we're using for all this encryption and

signing business in a way to connect

these keys to our unique identities to

us as as people in the end so in order

to do this we're going to rely on the

concept of asymmetric cryptography based

on a private key and a public key so you

already know that you should keep the

private key safe only for you you should

already know that you can freely share

the public key with anyone out there and

you know that whatever one key encrypts

the other one can decrypt the same goes

for digital signatures as well because

even with digital signatures we're

encrypting hashes of our messages

so we know that these keys can be used

in encryption for example if I want to

send some encrypted information to you I

can request your public key through a

certificate for example and I can use

that public key to encrypt data that I

know that only you can decrypt with your

private key all right that's one use

case the Second Use case is when I want

to prove my identity to someone so I

need to do something with my private key

that I can then later on show that

something to another person and they

would be able to determine that indeed I

was the one that performed that

operation using my private key so it has

to be some piece of information that was

digitally encrypted or signed by me so

I'm going to authenticate myself using a

digital signature how do we do this well

we can watch the previous video about

this but long story short we're going to

take a message we're going to Hash that

message and we're going to encrypt it

with our private key now whoever

receives that message along with the

encrypted hash is able to decrypt the

hash validate the fact that the hash

matches with the content that they

receive and they can determine this way

that that piece of data actually came

from me because I'm the only person who

is able to sign it in such a way so that

my public key can be used to validate

its identity I am the only holder and

owner of my private key and another

benefit fit of this is that absolutely

anyone up there can use the same process

to validate your identity you don't need

to set up a secure Channel you don't

need to communicate any secure

information you just really give up

anyone your public key and if they are

able to decrypt your digital signature

or any kind of content encrypted by your

private key that's how your identity is

being proven now the problem we have

here is that well we keep saying that

you're sharing that public key with

anyone but but simply getting a hold of

somebody's public key or downloading the

public key from a website that says that

this is Andrew's public key that's not a

guarantee of an actual identity an

attacker could potentially intercept

those public keys while Alice sends her

key to blob and intercept that public

key and injects the attacker's key

instead of it so how do we protect

against this type of scenario well pki

addresses this exact problem the problem

of validating the information that we're

receiving related to a public key I'm

basically validating whatever comes

inside of a certificate so you can say

that pki is a way of validating the

ownership of a public key because a

public key can be freely distributed and

downloaded

but we need to know it's the right

public key and the way apki is

implemented is by using digital

certificates which is just a wrapper

just a container for a public key now

that container actually includes a lot

more Fields than just the public key it

includes some information that uniquely

identifies you as a person your your

name your country maybe the scenarios in

which that certificate can be used for

like for digital signatures or for

encrypting files and so on and the most

important part about the certificate is

that it has to be vowed by somebody else

it has to be

confirmed by an higher level Authority a

certification Authority that the

contents of that digital certificate are

real valid and true so what we do in

order to validate this well we ask a

certificate Authority that everybody

trusts to sign our own digital

certificate and how does the ca actually

sign our certificate well the the same

way we sign anything with a digital

signature right the ca calculates a hash

of our certificate and then encrypts it

with the ca's private key now everyone

else on the internet whoever receives

our certificate sees the digital

signature in it can freely download or

they most likely already have the public

key of the well-known Cas out there they

use the public key to decrypted Hash

they validate the hash they validate the

signature and they know that the

contents in that certificate that state

that this is Andrew and this is his

public key are to be trusted and of

course the cas must be trusted by anyone

because if you don't trust the ca then

you're back to square one how do I trust

that I am Andrew or how do I trust that

the this is very sign the ca that I'm

supposed to trust it's the same problem

I mean you have to trust at some point

in order to create this hierarchy of

trust from that point on and if the ca

is trusted then we can use this

probability to validate the certificate

and then trust the identity of the one

person that is actually mentioned in

that certificate as well so that proves

that my certificate is a valid one

now as you mentioned in a previous video

most operating systems and browsers out

there have a built-in list of trusted

Cas so everything that comes signed by

those trusted Cas you know even in a

deeper level hierarchy I mean you could

have a certificate that is uh signed by

one CA and then that's the a certificate

is signed by another CA and so on and so

forth well at the end of that hierarchy

there has to be a CA that you trust in

your browser in your operating system so

this is a screenshot right here shows

the list of trusted root certification

authorities as you can see here on the

left hand side which are built into in

my installation of windows in the

previous video we saw that there's a

separate list maintained for example for

each and every browser out there for

example Firefox Chrome Opera and so on

now a CA is responsible for generating

digital signatures which actually end up

as being valid certificates but again

anyone can do this right it's basically

just a piece of software that generates

digital signatures you can install a

certificate Authority locally on your

own laptop if you wish in fact in many

companies we do have local certification

authorities which are local to the

Enterprise to the network inside of that

company only which means that we can

actually have our own little island of

trust so that everything that is signed

by a local CA inside of our network is

automatically trusted now of course if

we try to sign any resources that need

to be checked or validated outside of

our local network like over the Internet

that signature that digital signature is

not going to pass validation but within

a company if everybody is configured to

trust the the ca that is local to that

company that is locally installed in in

the company's data center than any other

certificates that we're generating using

that CA in any certificates that we're

we're signing using that CA are going to

be automatically trusted but if you go

outside in the wild wild internet you

want to communicate from one company to

the next then you have to rely on some

public CA out there the one that is

trusted and recognized by everyone else

now the ca actually does a bit more than

just generating digital signatures

normally in the process of generating a

certificate that has to be some sort of

a validation process because I I could

be submitting a certificate for for it

to be signed to to very sign and they

should probably ask me for some proof

like providing some sort of ID that

proves that I'm actually Andrew then

that is actually my name or that I

really own the website for which I'm

trying to get my certificate signed so

there has to be some sort of a

registration process where you have to

pass some checks in order for your

certificate to be generated now the CEO

isn't by themselves are not just

isolated Islands out there on the

internet we usually have a hierarchy of

CAS in which all these Cas are related

to one another in a hierarchy of trust

so to start with the simplest example

out there from a single CA just one

single CA now you could have one single

CA generating all your certificates and

that's it now the problem is that the ca

of course is going to be exposed

vulnerable because everyone interacts

with it and potentially open to exploit

and compromise and if a CA gets

compromised if the private key of A CA

gets compromised the rule says that

every certificate ever generated by that

CA becomes invalid that's because if the

private key has been compromised then

the private key now could be in the

hands of somebody else who is using that

private key to generate

fake certificates or certificates that

don't include real information so we

lose that trust that we should have had

from the very beginning in that CA

we don't know which certificates are now

valid generated by that CA and which

certificates are not valid so we

invalidate them all the moment the

private key gets compromised so we call

this a single point of failure right one

CA doesn't sound like a very good idea

so we have the second scenario where we

rely on a hierarchy of CAS so we have

multiple Cas each one signing the

certificates of those below them which

creates a hierarchy in which we have

root Cas we have intermediate Cas and

then we have Leaf Cas at the end of this

hierarchic tree now this model creates

what is called as certificate chaining

or a chain of trust that is because each

and every certificate that is generated

by a leaf CA can be traced back to its

parent in the hierarchy of trust up to

the root CA that actually signed all

those intermediate and leave cas

why do we need to over complicate this

so I mean what's the benefit instead of

having just the one single Routier well

the benefit is that by Distributing this

infrastructure this way at some point we

can safely take the root CA completely

offline

I mean we don't want to keep it online

and exposed and open to attacks because

otherwise it becomes the same single

point of figure that we had with just

one CA so once we have instantiated the

intermediate and leave Cas that are

actually going to deal with the

certificate generation process for us we

can safely bring the root CA offline and

completely disconnect it from the

network that way we can be close to 100

sure that the private key of that CA is

never going to be compromised even more

so if at some point it just happens that

one of the leaf Cas gets compromised

well we're not going to be losing the

all the certificates that were generated

within that pki we're just invalidating

the certificates generated by that

specific leave CA not by all the other

ones

and you can easily view this even in

Windows if you open the certificate

store and navigate to one of the

well-known root certificates out there

or just select one of the certificates

that you're using for a specific website

you gotta find a tab in there that says

certification path in this case right

here we actually have two additional Cas

so one root CA and one leaf CA the

GoDaddy root certificate Authority and

the GoDaddy secure certificate Authority

which in turn has actually signed the

comptia.org certificate that you're

you're receiving whenever you're

visiting the the CompTIA website and as

far as the route goes as we said before

we can safely take it offline because

we're we're only using your root CA to

create other

sub ca's other intermediariess other

leaves yeah so we're not signing end

user certificates we are just empowering

other Cas to do this for us so once

you've generated you've generated the

the certificates you've signed the

certificates of all your necessary Cas

you can safely bring it offline now the

process of registration when it comes to

Cas is basically a process of

authentication over the process of

creating an account with that CA so that

your identity is validated and then you

gain the rights of requesting further

certificates for example once I have

proven my identity as I am Andrew right

to to my favorite CA I can then ask that

CA well give me a certificate for email

signatures give me one for a web server

that I own give me one for disk

encryption and so on so that's the

registration part it's the identity

checks I wouldn't say background checks

actually but it's a it's a sort of

validating the the true identity of the

entity that is requesting that

certificate for example in case of the

people who are want to use a digital

certificate to sign their email you

might be required to present some sort

of an identification like a government

issued idea or in case of a website if

you want to secure your website to allow

clients to connect over https and you

want to install a certificate on that

website you have to prove ownership of

that website by publishing something in

the DNS domain or by sending an email

from the domain that has the same name

as the website and anyway you have to

prove that you're an admin and you are

authorized to request a certificate for

that specific domain

there can be even simpler situations

such as in Microsoft Windows Active

Directory there are policies in active

directory which allow users to generate

a certificate simply by authenticating

themselves inside of the domain so once

you you authenticate using a username

and a password or a smart card or

whatever you're using to log into

Windows once you're authenticated in the

domain you can freely request as many

certificates as you want for example for

a BitLocker or disk encryption

but the official method by which any

person can receive a certificate from a

CA is by filling in a form basically

that could be digital form of course

which is called a CSR that's a

certificate signing request I'm

requesting you you my Dr CA to sign the

certificate for me that's a CSR now in

digital form don't imagine it's a it's

not a PDF file or anything like that

it's basically an ASCII file it's an

ASCII string of characters encoded

actually in base64. and that file

includes all the information that I want

to end up with in my resulting

certificate such as my identity my name

maybe the domain names that I want to

cover if it's a web server certificate

and of course my public key

and that's the information that the ca

actually has to validate before actually

emitting that certificate the

information submitted in the CSR now

again in some cases simply because the

this process of generating and receiving

csrs creates the ca to be extremely

exposed because it constantly receives

input information from from outside

users the process of managing csrs is

sometimes outsourced to a different

entity which is called a registration

Authority this one is also part of the

pki but it's a separate server separate

entity that only deals with receiving

and validating csrs they don't actually

emit the end user certificates but they

do give a verdict as whether the CSR is

valid or not so finally if we pass all

those checks we end up with a digital

certificates received from the CA and

signed by that CA so it's basically just

a container for your public key with

some additional information that

identifies you as a person or as a

machine as web server as an email server

depending on the use case for that

specific certificate generally

certificates nowadays are based on the

x509 ietf standard remember that one but

there is also an additional set of

Standards created by RSA you have the

same name as the algorithm which is pkcs

a very generic name that stands for

public key cryptography standards

standards themselves Define What fields

are allowed within a certificate where

they should be positioned what data type

is accepted in there and the use case is

acceptable by each certificate type

now among the information that is

available within a certificate we're

going to find a serial number this is

just a unique number that uniquely

identifies the certificate very useful

when we want to check the validity of a

specific certificate or when we want to

revoke it from the ca so the ca can

actually publish a list or respond to

some requests that are going to say that

this specific list of serial numbers or

this specific list of certificates

basically are not valid anymore have

been retired we also have the signature

algorithm of the ca the algorithm that

was used to sign that certificate why do

we need this well we need to know the

signature algorithm so that we can check

that signature right we need to

calculate the hash on our own so that we

can have something to compare it with so

we need to know the algorithm that was

used from the very beginning

specifically we need to know the

signature hash algorithm as well we're

going to find the issuer in there that's

basically the name of the ca who signed

that certificate or who issued the

certificate we're going to see a Time

range described as a valid 2 and valid

from fields which indicates the period

of time in which the certificate is

valid all certificates out there have an

expiration date

we also get this subject that is the

entity that the certificate represents

it might be your name it might be your

email address if you're using for email

signing it might be part of the web

server fully qualified domain name if

you plan on using it in a network device

of course we get the public key because

we're basically talking about a wrapper

for the public key so it has to be in

there somewhere and some more extensions

couple of them will be covered in the in

the next sections

so going back to the topic of that

subject because that's the identifier of

the actual person or entity or server

that is using that certificate we have a

number of ways in which we can describe

that subject information first of all we

had had with an emphasis on the past

time here CN that's common name usually

this one was designed to be the fully

qualified domain name of the of the

website or of the server that

certificate is supposed to belong to now

since the CN actually did not specify an

exact syntax that is to be followed it

is nowadays deprecated because some

browsers some validation entities had

some problems in uh in double checking

this field and actually figuring out

which entities the certificate belongs

to so nowadays it was replaced with

something called Sam subject alternative

names and now the name itself might

suggest that a San is uh is just an

alternative to

to the actual subject no it's just

basically a list of all the subjects

covered by the certificate itself

in the example here on the slide we can

see a certificate from CompTIA which has

a subject section that uses the CN field

you can see here it's

cnlearn.comti.org now on the other hand

we have a certificate from cisco.com you

get the certificate if you access

cisco.com in your browser and there's a

section of subject alternative names

and you can see here it's an actual list

of alternative domain names that this

certificate can protect so if you visit

any of the Cisco www.cisco.com media

files score static Cisco the websites or

the browser visits them in the

background then it's going to use them

and validate those destinations by using

this same certificate now from a more

practical point of view listing all the

domains in here just like Cisco did is a

bit more secure but in reality you're

going to find wild card notations in

here like

star.cisco.com something like that which

implies that any subdomain that belongs

to that parent domain is going to be

protected by that certificate not all

certificates are equal that is not all

certificates have the same type the type

actually refers to the key usage what

can that certificate be used for could

we use it for signing emails for

encrypting files for encrypted disk and

so on and so forth and these user

scenarios are described in the key usage

field as part of the certificate itself

and of course since the contents of the

certificate are digitally signed by the

ca

so are validated first by the CA and

then the digital signature is applied in

there you cannot just freely change this

use cases for a specific certificate if

a certificate was generated only for

email signing then you will not be able

to use that certificate for disk

encryption

alternatively we can find a field called

extended key usage or the way Microsoft

likes to call it if you open up a

certificate in Windows is enhanced key

usage which is just another way a more

flexible way of defining use cases for

the certificate but the end result is

pretty much the same

so among the use case examples that we

can select inside of this key use it or

extended key usage field are server

authentication client authentication can

use this for code signing that's the

same type of certificate by the way that

is used when you're downloading and

validating applications downloaded from

an official app store on your mobile

device that's also going to be validated

using some sort of a code signing

certificate and email protection now you

can see that we have a couple more

extensions apart from these standard

fields that we find in the certificate

now of course these extensions can be or

might not be recognized by all the

clients and all the software out there

which brings us to the discussion about

critical and non-critical extensions in

a certificate if an extension is tagged

as critical then the application that

processes the certificate that uses it

in any way must be able to recognize

that extension if the application

doesn't recognize the extension maybe

it's an optional one it shouldn't use

the certificate at all it should reject

it completely and you can probably guess

what non-critical extension means well

it's a non-critical extension even if

the application doesn't recognize that

specific extension it's still going to

use the rest of the fields in the

certificate and the way the application

was programmed to use that certificate

even if it doesn't understand its

contents 100 percent

now when it comes to websites the

certificate that the website presents to

all its clients to all their browsers is

basically a proof of the website's

identity which is very important if

you're interacting with a with an

e-commerce site or with a banking site

or with any site that requires you

provide some sensitive data personally

identified or confidential information

so you need to validate the identity of

the entity that you're talking to that

you're actually communicating with

you're giving your credit card details

to Amazon and not to I don't know Amazon

with double o's at the ends.com

and that's a real problem actually there

are situations where anybody can just

set up a new domain name and perhaps

even submit a certificate signing

request for that new domain name such as

amazon.com to a real CA trusted by

anyone and they would get a valid

certificate for that website which then

they can use to impersonate amazon.com

and steal credit card data so we have

different levels of security involved

whenever the checks are being performed

before actually emitting web server

certificates from publicly trusted cas

and the way we can Implement these

checks we have two methods we have

domain validation which is a very simple

check which uh just proves that you're

the owner of the domain that you're

trying to register a certificate for it

might require you to fill in some DNS

records temporarily that can be publicly

checked by the ca or by the ra the

registration Authority or you might be

required to send an email from the

domain name with the same name as the

the website you're trying to register

the certificate for now for a higher

profile websites there's also an

additional more complex process called

extended validation which checks the

legal ownership the legal identity of

the owner of that of that resource that

we're trying to create a certificate for

and we avoid situations such as those

that are trying or attempting to create

valid certificates for spoofed or or

phishing domains

now the other certificate types that

you're going to encounter because users

and websites are not the only ones that

need certificates we're going to start

with users all right we can generate

certificates for users for them to be

able to use them for email signing or

for this encryption we can also generate

certificates for servers and

applications we can use those

certificates to prove the identity of

the server or the application that is

being accessed you can also use

certificates to sign code files and

applications and we can also have

self-site certificates because nobody

stops you from generating a certificate

that you are signing by yourself this

comes back to the discussion about the

napkin one or two videos ago I mean it's

nobody's going to trust it right

nobody's going to be able to validate it

but it is still a true and correct

certificate now the self-signed

certificates are usually the ones that

get installed in internal networks in

lab environments in demo environments

and pocs and those are the situations

where we get that warning in the browser

that says the certificate is not trusted

well it's not trusted because the

signature on that certificate is the

signature of somebody that we can cannot

validate its identity we don't know who

that is all right I can sign my own

certificates are you going to trust me

no because that's the point of all the

process right to trust my identity to

find another method of validating my

identity my signature means nothing you

need a CA for that also keep in mind

that in many cases the authentication

process for example gaining access to a

network can be performed at two

different levels we can validate the

identity of the user or the admin that

is trying to access the network and we

can also validate the identity of the

machine that the user or the admin is

trying to connect to the network so we

can have two levels in there

authenticate user and also the laptop

that is trying to gain access to the

network that's why they also have

machine certificates and user

certificates ever found yourself in a

situation where if you're using a

company laptop you can easily plug

anything red cable into it and gain

instant access to the local network

while if you bring your own laptop from

home you're not getting any kind of

access well that's because that laptop

in there has some sort of authentication

information built into it most likely a

certificate that it presents as a

machine certificate and authenticates

itself to the access control system that

allows access to the rest of your

network your home laptop doesn't have

that certificate doesn't have a valid

identity that it can present so it is

denied access

so a certificate is going to go through

a number of stages during its lifetime

starting with the creation of the keying

material that is the creation of the

private key and the public key right

we're using just a public key to grade a

certificate but we need a private key as

well because the public key is derived

from the private key not the other way

around you should know this by now

then we move on to the certificate

creation that is filling in that CSR

sending the CSR and receiving a valid

certificate from the ca certificate

storage is important not necessarily

from a security perspective but more

from a usability perspective you need to

store that certificate load it into a

certificate store where it can be

accessed by any applications that need

to use it to validate someone's identity

now on the other hand you should store

in a very secure manner the private key

that was used to generate that

certificate and finally we have

revocation of that certificate or

putting the certificate out of business

it might be because the certificate has

expired or it might be because the

private key has been compromised in any

situation a certificate can always be

renewed now if the private key has been

compromised you're probably gonna want

to use a new key and generate a new

public key pair for the new certificate

but if the certificate just happened to

expire because it reached its end of

life its expiration date you can will

reuse the same keying material you don't

need to generate a new key and keep in

mind that all certificates expire at

some point there is always going to be

an expiration date on certificates

now in general storing secure Keys is a

big problem in security because if you

back up the key just to say you're

you're storing it in multiple versions

just to make sure that you're not going

to lose it it exponentially increases

the risk of that Key's exposure on the

other hand if you don't have a backup

for the key then the place you're

actually storing that key becomes a

single point of failure which can cause

in case of failure your inability to

ever access your encrypted data so there

have been invented some processes for

dealing with this type of key recovery

in which we're trying to store the

private key somewhere but in a as secure

manner as possible for example we we

store its segmented into a different

number of storage devices or we need a

specific number like two or three admins

with access at the same time in order to

recover all the pieces and and build

that key back again then we're using all

these security measures to avoid any

kind of collusion or exploitation that

might happen against that key storage

system now key escrow is kind of similar

but it refers from a legal standpoint to

the practice of giving that key to some

third party for the purpose of safe

storage if you don't want to invest in

some Secure Storage infrastructure for

your keys you can pay a third-party

company to do that for you now of course

the liability that comes from a

potential keep compromise can be

transferred as a risk to that

third-party company but don't forget

that even if they are the ones now

responsible for the security of the key

any side effects that might occur from

that key being compromised are going to

hit back your own company and your own

reputation

and we talked about the fact that all

certificates expire at some point

normally these certificates that are

generated for end users have a shorter

lifespan maybe a couple of months maybe

even 30 days maybe even one year or so

but real certificates are usually

created for a longer period of time such

as one three five ten years or so now

generally when a certificate expires

there's a very simple procedure to just

renew it and in case of CAS or

registration authorities the process

itself if the user already has a valid

certificate if the user wants to just

renew it the process is going to be much

more smooth so not so many checks are

going to be performed if the user is

already holding a valid certificate

now certificate can also be revoked that

is manually and explicitly taken out of

commission so it's a process where we

suddenly decide that these certificates

are not going to be valid anymore maybe

the company went out of business the

company doesn't exist anymore maybe the

uh the private Keys has been compromised

maybe the servers that were storing them

are have been the victim of a data

breach and we don't know exactly how

much data was lost in there but we

decide to to revoke all those

certificates how can we do this well

there are two methods for doing this the

first one relies on the actual CA and

the ca can inform the end users what are

the revoked certificates that it manages

and that's called a certificate

revocation list crl now the way this

works is that when clients attempt to

validate a certificate with a CA well

they grab the public key of that CA they

decrypt the signature and so on so forth

but they also should check the serial

number of the ca to see whether it is

found in one of the crls that they can

download from the from the ca of course

this is up to the client if they perform

this additional check or not

which means that certain clients might

not perform this check at all and other

clients might perform this check maybe

once a day once a week or so when they

just download those crls and then they

don't update them until let's say a

number of days have passed it also might

happen that the cas don't update those

crls immediately for everybody else to

download so revoking a certificate might

not happen instantaneously we have

another method of providing the

certificate expiration revocation list

dynamically to our users and that is

based on the ocsp online certification

status protocol now this instead of

downloading an entire list of serial

numbers of expired certificates or

revoke certificates we're simply relying

on a type of request reply protocol

where we simply send a query about a

specific serial number and then we'll

receive a response based on that serial

number telling us whether the

certificate is still valid or not now of

course it depends on the server

implementation how they're performing

this type of query processing so some

servers might be acquiring the database

of certificates directly others might be

querying the crl list so in case the

serial list is a bit behind or up to

date then ocsp is also going to provide

a less than ideal or less than

up-to-date answer and since this entire

process of request reply request reply

puts a lot of stress on the actual CA

server we can actually delegate the web

server that we're trying to access to

respond on behalf of the ca with these

ocsp status responses how does this work

well the web server obtains from the ca

a timestamped response which then in

turn it can use to provide as an answer

to any request that might come into the

web server in order to validate its

certificates so it doesn't have to go

back and forth to the ca every single

time somebody validates that certificate

asks the ca once receives a signed

response and then shows everyone this is

the signed response from the ca stating

that my certificate is still valid trust

this one and this process is called

ocasb stapling

there's another problem here that we can

address and that is a problem of another

man in the middle type of attack because

theoretically at least when you're

accessing a site such as google.com

you're performing a certificate exchange

you're requesting the certificate from

Google in order to validate it now what

if somebody in the middle of that

conversation intercepts that certificate

and injects their own certificate

signed certificate trusted certificate

what are you going to do with that

certificate well you're going to accept

it and you're going to think that Google

certificate is the one that you just

received and then what you're going to

do well you're going to send your

authentication data you're going to send

your emails you're going to upload your

files

you're going to perform all your tasks

and you're going to encrypt those with

the public key that came

from within that bogus certificate that

was just injected and of course all that

information now can be safely inspected

and snooped by the attacker that

injected that certificate

so in order to avoid this situation we

have something called certificate

pinning or hbkp

which stands for HTTP public key pinning

which is just a method of embedding the

information in the original certificate

in the actual Google certificate

somewhere within the application code so

somewhere within the the web page code

of Gmail for example there's going to be

the contents of Google certificate now

the browser of course has to know to

look for this has to be configured to

understand hpkp so if it finds a set of

information that describes the

certificate within the application code

then it can compare it with the actual

certificate that it received now if the

certificate has been tampered with and

has been injected by a foreign attacker

then of course they're not going to

match so that's how the browser can

detect an attempt for a man-in-the-mill

attack and unfortunately it doesn't

always happen for a malicious purpose

this type of man in the middle

interception because in many companies

you have dedicated firewalls Next

Generation firewalls especially that

perform SSL decryption in order to

inspect the web traffic that the

employees are sending back and forth in

order to block them from accessing

unwanted websites in order to block them

from downloading malware from unwanted

destinations and so on but every pretty

much all the web traffic nowadays is

encrypted so you have to perform SSL

decryption on the traffic before you can

actually look at the traffic which means

that you'll have to replace the

certificate that the user is actually

expecting to come from Google with your

own self-signed certificate or some

internal company certificate which is

basically just the same example as

before it's performing a man in the

middle attack now if that website uses

hpkp or certificate pinning that man in

the middle approach is not going to work

anymore it doesn't matter if it's

performed in a legitimate manner or by

an attacker so that was one of the

reasons why at some point hpkp

implementation started to back off just

a bit because they were creating a lot

of issues with legitimate company

approved and an employee approved

traffic inspection that's happening all

over the the Enterprise world

okay so how do you store certificates

well at the end of the day don't forget

that a certificate is nothing more than

a simple file so we store it as a file

on the disk with a certain extension

perhaps to help you recognize them

easier now one of the first types is a

binary format with the Der extension

you're not going to find these very

often the one that you will find more

often are the pem extension files these

are certificates stored in ASCII format

which means that they're easily

selectable copy and pasteable you can

attach them to email you can even paste

them inside of an email if you wish and

you can paste them in a in a web

interface for an API access for example

so they're much easier to you know to

move from one place to another

and the screenshot right here on the

slide shows you the contents of a PM

format certificate now don't expect to

be able to read the contents by yourself

because it's a base64 encoding but

base64 is easily reversible in one of

the simplest thing coding methods out

there so you can immediately get to the

actual contents of the certificate and

you're also going to find certificates

using the extensions such as CRT or CER

which unfortunately don't happen to

agree on a specific format so they don't

tell you if it's binary or ASCII format

what's stored in there and we also have

some specific file extensions and file

types that can store more than one

certificate for example the pkcs trail

format allows us to bundle the private

key and the public key together in the

same certificate this is normally

atypical because a certificate is meant

to store only the public key right but

there are situations for example when

you need to move the private key along

with the public key from one machine to

another for example when you're

performing an upgrade you're replacing a

server your web server right and you

want to move the the certificate content

the cryptographic content from one

machine to the next you can export it as

a pfx or p12 format file and then import

it on the next machine

and it's also used for backup purposes

if you want to back up your private keys

and you want to store them somewhere

safe you can use the pfx format or p12

ideally you should also protect this

type of certificate format with a

password because it contains sensitive

information

and we also have the p7b format which

stores the entire certificate chain

sometimes a host that uses a certificate

or has to validate it doesn't have the

ability of dynamically downloading the

entire certificate chain in order to

validate the certificate it's CA this

the one the ca that signed that CA and

so on and so forth so it might help

especially for embedded devices small

devices to help them by providing the

entire certificate chain so that they

can use it to validate whatever

certificates have been generated by the

by the leaf CA in that chain

managing certificates depend on which

operating system you're using on Windows

all the certificate business is most

likely managed by active directory

and there are some command line tools

out there as well especially the search

util Windows utility that can help you

manually generate interact with or

validate digital certificates now in

Linux we very often use the open SSL

series of utilities

and you can use an open SSL for a number

of tasks for example you can even make

yourself ACA you can generate a

certificate signing request you can

generate an actual certificate you can

validate a certificate and so on and so

forth you get the ability to manage

everything related to certificates

on the example on the slide you can see

that we're generating an RSA type of

public-private key pair of 2048 bits

we're generating a certificate that is

going to have an expiration date of one

year and we are outputting it as a PM

format in the file called certificate.pm

now of course this is going to be a

self-signed certificate

also notice the information that is

required for you to provide before

actually generating this user

certificate

and for your reference here are some

basic open SSL commands that you can use

to generate and manage certificates by

default of course you can run these on a

Linux system but you can also get access

to openssl if you're running a Windows

subsystem for Linux on top of Windows 10

or 11. so starting with a generation of

an RSA key pair the first command is

going to generate the private key for

you while the second one as you can see

uses the private key as an input in

order to generate the public key

remember we talked about this we said

that the public key can be derived from

the private one but not the other way

around the length the 1496 at the end is

the length of the key and the AES 256

parameter in there indicates that we

intend to encrypt which is going to

require a passphrase from you as well

we're going to encrypt the private key

because that is truly sensitive

information moving forward you can also

use openssl to make yourself a CA and

start signing certificates for accepting

csrs certificate signing requests first

you need to generate the CSR on the

server for which you want to generate

the certificate for that's a command for

this one and then you assign the CSR on

your own CA

finally a couple of commands for viewing

and validating certificates generated by

you or generated by anyone else and

signed by any public CA out there right

so a lot of information here about

digital certificates I know it's not

light not easy to process but they're

everywhere nowadays we have to know

about them you have to know about them

for the exam as well so I really hope

you found this video informative and

useful if you want to discuss more leave

a comment and if you like this oh like

And subscribe and good luck on the exam

see you on the next video thank you and

bye bye

foreign

[Music]


15 15

thank you

[Music]

identity and access management is not

only a big Topic in security but also a

very generic one you're going to find

various implementations in various

products that claim to deal with

identity access management from

on-premises products to to cloud

services and basically it's all about

managing user identities

starting with the information that

actually identifies a user such as a

username followed by the methods by

which those users can authenticate it

might be passwords it might be a private

key or any kind of authentication method

going further and dealing with the

permissions that those users receive

automatically after they have proven

their identity and even up to the level

where we are actually keeping an eye on

those users and keeping track of their

actions which leads us to the official

definition of those Concepts behind

identity Nexus management which comes

under the name of AAA a AAA and the

first bullet in this AAA is actually an

I it's not it's not an a it's about

identification so before moving forward

to the authentication part there's

usually going to be some sort of an

identification process where you provide

a unique piece of information that

uniquely identifies you as a user it

doesn't yet prove who you are it doesn't

yet prove that you actually own that

identity but it's the identity that you

claim it belongs to use so the

identification part in this AAA process

is going to be the action of you

providing some sort of a username or a

phone number or an email address

something that identifies you as a user

second comes the authentication part now

this is the section where you have to

provide some additional information that

again is unique to you but that

additional information is supposed to

prove that the identity that you just

claimed in the identification part is

true how do you do this well by

providing something like a password that

only you are supposed to know or by

signing something with your private key

which again should belong only to you so

that's the authentication part sometimes

uh written in shorthand notation as auth

and then comes the authorization part

this is where you are automatically

assigned some privileges so you have

proven who you are now let's see what

you can do and these privileges are

going to be assigned by a centralized

system the system where you're actually

delivering those credentials to are

going to receive back a set of

permissions that tell you well you are

allowed since you are Andrew and you

have just proven that you're Andrew

you're allowed to access these servers

maybe these vlans you are allowed to

connect over the VPN and you're allowed

to let's say go outside and navigate on

the internet but only limited to a

specific set of destinations so any part

that relates to policies and permissions

gets applied right here in the

authorization part this is also the

place where we differentiate between

regular users and admin users for

example

finally the last part which is not so

much the last part as it's some sort of

a continuous part

constantly monitoring the actions of the

logged in users what are they doing what

resources they're accessing in what way

what operations what changes what

modifications are they performing on

those resources this is the accounting

part down to the actual

statistics such as how much traffic did

that user generate how long did the

login session last that's the accounting

part so normally when we refer to AAA we

actually refer to authentication

authorization and accounting the

identification part well you could

theoretically consider it a separate

process but in most cases it is built

into the first authentication step

because in most cases you will be

providing your identity like your

username or an email address along with

some secret credentials like a password

or a private key also it's worth

mentioning here that the authorized part

can also be a continuous process so

there might be systems where you're

simply downloading a list of permissions

the moment you're logged into the

network but in other implementations

perhaps every action that you perform

has to go through an authorization

server and that server has to provide

you with a verdict of allow or deny

whether that operation that you're

trying to submit is being allowed or not

for example are you allowed to log into

the company router and change the

routing table are those commands allowed

to you even though you're probably an

admin which already has access to those

networking devices but you might not be

allowed to perform any kind of

operations on those devices and this is

also filtered as part of the

authorization part generally all this

authentication process applies to two

large categories we have the subjects

these are the ones that initiate the

actions you could be a subject or even a

machine or an application could be a

subject because they're also acting with

a specific set of privileges even though

there not real persons also we have

objects the objects are the resources

that we're interacting with so an

example policy here here would be a

policy that states that I Andrew as a

subject I'm allowed to make some changes

to write some files on a file server

which in case of AAA is going to be

considered an object I'm going to be the

subject this file server is going to be

the object consequently if you implement

a policy that deals with machine to

machine communication such as a web

server having access to a specific

database you might have a policy in

there that authorizes any requests

coming from that web server and permits

them organize them for example a web

server might only have read-only access

to a database but any write operations

any insert or delete operations on that

SQL database would be denied in that

case the web server would be the subject

and the database would be the object now

as we said before the authentication

part is the moment where you have to

provide some sort of unique credentials

that uniquely identify you as a user

those credentials are sometimes called

authentication factors and of course

these credentials have to be stored

somehow on the server as well so that

the server that authentication server

that evaluates your authentication

request can validate whether what you're

presenting as an authentication factor

is correct is legit or not now the first

and the most common type of

authentication factor is the simple

password which falls into the category

of something that you know now normally

as part of the authentication process as

we said before because the

identification part becomes part of the

authentication process you're also going

to be presenting a username along with

that password

in theory at least the username is not

secret information even though sometimes

it's better to keep the username format

at least the secret because for an

attacker to know how all the usernames

look like inside of an organization it's

going to help him just a bit in an

attempt to perhaps try to crack some

passwords or even impersonate some users

so try to keep the username secret as

well and of course you need to keep the

password secret because that is

something that you know and that is

something that only you should know also

in these categories we're going to find

past phrases which are just longer

passwords usually made up of words or

phrases that have the greatest advantage

of being extremely easy to remember for

human beings and extremely difficult to

crack by Brute Force by machines also

pins fall into this category pins right

uh personal identification numbers the

pins that you use to unlock your phone

depends that you can use to unlock your

your Windows device and so on there

these are all something that you know

and even swipe patterns on Android

phones they allow you to generate a

swipe pattern to unlock the screen this

is also something that you know and you

provide it as an authentication factor

and finally also in this category this

is where those uh verification questions

fall into whenever you're trying to

reset a password you know what's your

birthplace what's the maiden name of

your mother and any questions such as

those right this is also something that

you know next category of factors is the

something that you have now ideally this

should be something that only you have

of course so it should be some sort of a

security device it could be a key fob it

could be a smart card it could be a

unique number generator that is

available only on your keychain or only

on your mobile device as an application

those one-time password generators fall

into the category of something that you

have because only you can generate those

numbers using your own devices and

finally we get to the biometric factors

which is something that you are right we

could talk here about retinal scans

fingerprints uh the blood vessels in

your palm the iris scans and so on

everything that relates to your

biological features and that can be

uniquely tied to you as a person well

that factor can also be used as an

authentication factor with the right

systems of course now this category can

also include some more exotic methods of

authentication such as the way a person

walks the way a person types at the

keyboard or the way a person scribbles

their signature and since the title of

the slide is multi-factor authentication

well in order to increase the security

level of an authentication system

ideally you should at least consider

combining two of these categories so you

know order to have multi-factor

authentication or two-factor

authentication right anything that's

higher than 2 becomes multi-factor

authentication in order to have at least

two factors it's not enough just to have

two factors they also have to belong to

different categories so a combination of

a password and a pin is not multi-factor

authentication and it's not two-factor

authentication you need to combine

something you know with something you

have or something you know with

something that you are right that's true

multi-factor authentication because if

you're combining factors from the same

category you're not increasing the level

of security then a pin can be

compromised just as easily and most

likely they're going to be compromised

at the same time anyway so there's no

benefit in combining two factors that

belong to the same category on the other

hand if you're combining a password with

a one-time password generator

the password that you know with the

password that you need to generate and

it's valid for 30 seconds or one minute

on your phone well that's a combination

of something that you know and something

that you have if the password becomes

compromised well the attacker cannot use

it because it doesn't have access to

your phone or to the application that

generates unique codes on your phone now

in addition to the categories that we

just talked about we also have some

authentication attributes that can be

taken into consideration in a completely

independent manner during the

authentication process for example we

could base our authentication decision

on the actual location of the device or

of the user that is attempting

authentication we could be looking at

the actual geographical location by

using the GPS or location services in

the device if it's a mobile device or we

could be looking at the IP address that

the device is using by looking at the IP

address we could determine first of all

if it's inside the company in which VLAN

to which VLAN is it currently connected

so to which department does the device

belong to or or we could decide whether

it is currently connected over a cable

or over Wi-Fi if it's connected from the

outside is it connected over the

Internet is it connected over the VPN so

a lot of factors here just by looking at

the IP address now you might want to

create some security policies that take

this into consideration because in some

situations any devices that are mobile

and are not within company premises are

more exposed to risk by default so you

might want to assign less privileges to

the same device if you detect that it

has connected over an insecure Network

and then when that same device comes

back home in in your home company in

your home network you could just provide

all the necessary privileges just like

anybody else who's inside the perimeter

a very frequently used method of taking

location into consideration is by

looking at the country to which the IP

address that you're connecting from

belongs to so you might be allowing

connections as long as your employees

are within the premier of your country

but you might be denying them or you

might be assigning less privileges if

you do take that they're connecting from

I don't know another country overseas

because different laws might apply or

perhaps they're just in a less secure

location the second one is regarding

behavioral authentication now again this

is not going to be an authentication

Factor so we're not going to be looking

at the way a person signs themselves or

walks or types at the computer in order

to provide them with authentication but

we could run a continuous process of

analyzing that person's Behavior after

they have passed their one two or three

authentication factors in the very

beginning so if after five or ten

minutes we determine by the way we

analyze the person on CCTV the way he

walks or the way they type at the

keyboard the way they sign themselves on

a digital pad that they don't exactly

match the templates that we have in our

database we could cut their access at

any moment in an attempt to mitigate a

potential intrusion user Behavior can

also be taken into consideration that is

different from what we just talked

before and user Behavior here refers to

the actions of the user after they've

connected to a service to a network or

to an application what type of web pages

do they visit every single time when

they connect to an internal application

for example what operations they usually

perform when they connect to their

banking website if we're able to build

such a baseline from multiple

authentication attempts to learn from

the user's Behavior then we could at

some point Identify some abnormal

behavior in an attempt to mitigate

impersonation or fraud and finally

there's also an authentication method

based on people who can vouch for you I

know this doesn't really sound that

secure right it's a someone you know

authentication scheme and this is

actually implemented in real life as pgp

pretty good privacy which relies on a

so-called web of trust where people just

vouch for each other identities without

relying on a centralized infrastructure

such as bki and relying on centralized

Cas to validate their identities so it's

a way in which instead of asking a CA to

validate a certificate for me Andrew I

can just show you 10 people who can

vouch for me that I'm actually Andrew

that's the way pgp works now bringing

the discussion back to a more technical

point of view when it comes to

authenticating yourself to a computer

system it might be connection to a

remote connection to a server it might

be an authentication to a VPN service it

might be an authentication to an

application in most cases the method by

which you'll be providing your

credentials is going to be focused on a

something that you know so in most

computer-based systems the

authentication is knowledge based that

is you're providing a password a

passphrase a pin something that you know

and can immediately prove your identity

now at the operating system level of

course in both Linux and Windows and Mac

OS and on every operating system out

there we have dedicated subsystems that

deal with user authentication and login

in most cases the identity validation

based on a password is performed by

checking the password against a local

database of hashes I know I've said this

before a couple of times but you're

never supposed to store a user's

password in clear text what you should

do is Hash the user's password with your

favorite hashing algorithm store that

hash in your database so that whenever a

user tries to authenticate and sends you

their credentials you take that user's

password you hash it again using the

same algorithm and then you compare the

hashes that way you're never going to

store the user's password you will never

even get a chance to know the user's

password and the user's password is safe

against data breaches and admin abuses

even on Windows for example we have

different types of login methods we have

local sign-in we have Network sign in

and also remote sign-in now the local

sign-in works just as described D4 we

have something called the local security

Authority that's an actual service

within windows that compares the

credentials that you're sending with the

hashes stored in a database in case of

Windows that database is called the Sam

database that is security accounts

manager database for the network sign in

it means that the credentials are not

going to be validated against a local

database but against a centralized

Network connected database now in most

networks nowadays this service is called

Kerberos and Kerberos is the one that

deals with authentication and

authorization for each and every user in

each and every operation performed in a

Windows domain and older Windows systems

we had something called the ntlm or the

NT Lan manager service and finally the

remote sign in that is also a type of

network sign-in but in case the user is

farther outside the local network it's

usually designed to perform

authentication over the public internet

so it's about value dating user

credentials whenever they connect over a

VPN or directly to some web application

portal for Linux the identification part

happens whenever a user is checked

against the database within the Etsy

password file where all the local users

are being defined and then the user's

password is being checked against the

hashes stored in Etsy Shadow which kind

of looks like this and right here and

the last line you can see my username

followed by a hashing algorithm a salt

right here we talked about salts in a

previous video and then the actual hash

that is stored right here in the local

database all right now Kerberos is the

number one authentication system in

Windows networks and it's also the

number one single sign-on service

available on Windows domains now single

sign-on basically means instead of

requesting access to each and every

resource that you need to access as long

as all these resources are within the

same management and security domain you

could potentially present your

credentials only once once you connect

to the network and then and then receive

some sort of a temporary pass that

allows you access to all the related

services within the same network this is

single sign on it it is implemented in

Windows networks through Kerberos as

well now Kerberos is based on three

large components just like the

three-headed dog in Greek mythology

first we have the principle this is the

device or the user that is requesting

access to the network or to a service so

this is the one that we need to

authenticate second we have the key

distribution center this is a major

component of Kerberos because we're

going to have a really close

relationship to this one and this is the

place where we'll be presenting our

credentials and where we'll be getting

our permissions from and finally we have

the application server which is the

actual resource that the principal

attempts to access so this could be for

example a file server that is local on

our Network and can only be accessed by

authenticated users so the way Kerberos

kind of works in a very very very

simplified explanation because it's

actually quite complicated what's going

on in the back end goes like this the

principle sends a logon request to the

key distribution center again which is

part of the turbos infrastructure

that's actually what you're doing

without even knowing whenever you're

logging in into a domain account in uh

in Windows your Windows laptop contacts

the key distribution center and sends a

login request that includes the user's

identity their password and any

additional factors that might be

required for that user to authenticate

now the key distribution center is

actually made up of two different sub

Services one of them is the

authentication Service

and the second one is the ticket

granting service

and the service that actually evaluates

our login request is going to be the

authentication Service but this is the

first one that we're going to be talking

to

now if the authentication Service

decides that it liked your logon request

and it agreed with it and you are now

authenticated then it's going to reply

back to you

with something called a TGT that is a

ticket granting ticket

now this ticket as weird as the name

sounds doesn't provide you with access

to any resources it's just a proof that

you have been authenticated to The

Domain and then you can further request

access to specific resources such as the

application server here on the right

so this was the authentication part once

you get the ticket grinding ticket you

can consider yourself authenticated to

the Windows domain

next up comes the authorization part now

the principal has a ticket granting

ticket so when it tries to access the

application server the first thing it

does is to go back to the key

distribution center and this time he's

going to talk to the ticket granting

service now to this ticket granting

service the principal is going to

present its ticket granting ticket which

is a proof that I am currently

authenticated I am part of this network

and the principle is also going to be

providing a couple more information

along with this ticket grinding ticket

specifically the resource that he is

trying to access the resource that he is

requesting access to and also a

timestamp

and a client identifier

that uniquely identifies me as a

principal so this request now heads over

to the ticket granting service and the

ticket granting service is going to

first perform some checks first of all

is going to check whether the TGT is

valid because it I need to be providing

a valid TGT in order to gain access to

further resources and also is going to

check things such as the timestamp and

the Nic identifier here to protect

against replay attacks to make sure that

somebody hasn't captured this

communication and is trying to replay it

at a later time to make sure that this

specific request hasn't been performed

sometimes in the past

now if the TGs agrees with the request

coming from the principal they're going

to reply back to the principal with

something called a service ticket

now the service ticket is the one that

is actually going to allow the principal

now access to the desired resource such

as this application server right here so

the principle now presents the service

ticket to the application server and

service ticket of course is encrypted

it's signed by the KDC is signed by the

ticket running service and the

application service can validate all

this information by checking back and

validating this with the KDC and if all

the parameters match and the signatures

match then the application replies back

to the principal saying that you're okay

now you can just continue communicating

with me and I'll be accepting your

requests

so the principal gained access to the

application server and to the resources

behind that server now the actual

implementation of Kerberos is a lot more

complicated than this you can read more

about it online but I doubt that the

exam is going to ask you about things in

so much detail what you should remember

though is that the KDC works on Port 88

both TCP and UDP which is a very

important piece of information

especially when you're performing

Network reconnaissance if you find Port

88 open you can pretty much be sure that

it's a domain controller it's a server

that performs Kerberos type of

Authentication

to I wouldn't say disadvantages of

Kerberos that but two things that you

should keep in mind is the fact that

Kerberos by itself the way it is

designed is sometimes a single point of

failure in the network which is even

worse considering that it is also the

enforcement point for single sign-on so

it holds the key to the entire Kingdom

it holds the ability of every user in

the network to access every resource in

the network secondly is a strongly

dependent on correct time being set on

the servers on the KDC and even on the

client because each and every request in

there is authenticated and timestamp to

protect against replay attacks against

impersonation against Brute Force

attacks and by the way the entire

process that we talked about doesn't

really happen every single time you need

to access a single resource on the

network the authentication part or the

ticket granting ticket actually that

you're receiving from the very beginning

has a default lifetime of 8 to 10 hours

which kinda resembles the workday right

when we log in the first thing in the

morning when you you you go to the

office and you log into your windows

account you receive a ticket granting

ticket which then you can reuse for the

next 10 hours or so to receive access to

any resource within the same domain of

course this all happens in the

background you never even know or even

see this exchange happening between your

machine and the domain controller or the

Kerberos server now Kerberos is

complicated enough but it works well

enough unfortunately it only works

inside of our local network what if we

need to perform authentication on

authorization for users connecting from

the outside like over a VPN connection

and one very old Authentication Protocol

designed in the old days for dial-up

connections and serial lines was called

the pap authentication method password

Authentication Protocol such a simple

name such simple times

and it has an awfully simple

implementation it simply sends the

username and the password in clear text

and that's it the server to validates

the username and the password and tells

you if you're authenticated or not

everything in clear text of course it's

not being used anymore because sending

things in clear text nowadays is just

something that we don't do we haven't

been doing for some time

still there are situations where you

could use a Pap authentication method if

the exchange of usernames and passwords

happens over an already secured line

such as over and already established VPN

connection so if the channel is already

secure go ahead send your passwords into

your text but we also have a better

implementation called chap challenge

handshake Authentication Protocol which

this time relies on an encrypted

exchange based on a challenge now this

challenge in the title is nothing more

than just a randomly generated value so

the exchange over chap basically relies

on you generating a random value sending

it to the other side and the other side

is going to calculate a hash from that

random value and a predefined secret key

or password that both of you should know

finally you will be sending me back your

calculated hash then I'm going to

calculate my own hash from the same

value that I just generated and the same

secret that we both should know and if

those hashes match then I can

authenticate you and Grant you access

now this exchange is periodically

repeated during the lifetime of a

connection so different challenges are

being generated over time even inside of

an already active connection to protect

against replay attacks well finally we

get to the interesting part cracking

passwords well not exactly going to be

breaking passwords or perhaps I'll show

you just a quick demo but for now let's

just introduce a couple of Concepts here

first of all we're going to start with

the concept of a plain text attack the

plaintext tag basically is just password

sniffing if you detect protocols that

don't employ encryption that you manage

to access a a password database that

stores databases in clear text well

that's a plain text attack or in a

non-encrypted attack these passwords can

be gathered from unencrypted protocols

such as telnet or HTTP or a or a Pap

exchange just like the one we talked

about sometimes these passwords are even

stored in application code or

application scripts online attacks

represent an attack Behavior where

you're actually dynamically interacting

with your authentication server in an

attempt to crack a password so it's

probably going to be about performing

brute force or a dictionary attack as in

trying a large number of passwords until

you find the right one but you'll be

doing so by interacting directly with

the authentication Service or with the

login page You're simply inputting as

many passwords as possible until you

find the right one now as you can see

this approach does have a few issues the

first one being the fact that you're not

going to be able to try as many

passwords in a short amount of time it's

probably going to take you a huge amount

of time sometimes so long that it

becomes completely impossible to perform

in general most authentication Services

take some time to process your request

before they reply with a positive or

negative response even if that time is

half a second or a second the moment you

you decide that you need to try

trillions and trillions of combinations

you then are going to realize that you

simply don't have that many seconds in

your life another disadvantage of online

attacks is the fact that there are so

easily detected in logs or in security

events attempting and a large number of

passwords coming from the same username

or the same IP address in a short amount

of time is going to raise some Flags

it's going to raise some alarms and most

likely it's going to end up in Block

listing that specific Source or that

specific IP address or that user who

probably only had a chance of trying I

don't know three five or ten passwords

many authentication systems lock users

out of their authentication attempts

after too many failed attempts other

authentication systems employ a sort of

a back off mechanism where each and

every subsequent attempt is going to

take more and more time to evaluate or

you're going to be allowed to try again

after 10 seconds 30 seconds one minute

five minutes and so on it's an

exponentially increasing back off time

if you want to try this try entering the

wrong PIN multiple times in a row on

your mobile phone see what's going to

happen you're not going to be locked out

completely but at some point the phone

is not going to allow you to try again

immediately you'll have to wait a

certain amount time before you can

attempt the next value offline attacks

are the ideal attacks against passwords

because they rely on compromised hashed

databases of passwords now normally as

we said before you shouldn't store

passwords and clear text what you should

do is Hash those passwords and then

store those hashes well if an attacker

gets their hands on such a password

database of hashes then they can take

this database and try to recompute all

the possible entries that can generate

those hashes in an attempt to find the

actual passwords now there are multiple

ways of doing this password spraying is

a very interesting concept and kind of

reverses The Brute Force concept as in

instead of choosing a username such as I

don't know admin on Andrew and then

trying all the possible passwords in an

attempt to find the password for that

user well why not do things the other

way around let's choose a simple

password such as password One Two Three

or one two three four five six or

something like that and then try all the

possible usernames in an attempt to find

a valid username inside of a company

that probably isn't that security

conscious and is using that very simple

password because in most cases an

attacker only needs a valid user account

it doesn't matter which user account it

is but it needs some sort of user

account to get a foothold inside of that

Network to compromise it Brute Force

attacks basically mean that you're going

to try every single password until you

find the right one even if you're doing

an online attack even if you're doing an

offline attack Brute Force means try

everything until you succeed it's the

type of an attack that takes the longest

but it's also the type of attack that

guarantees success if you have enough

time and if you have enough resources if

you don't have enough time and if you

don't have enough resources you also

have dictionary attacks now dictionary

attacks rely on predefined word lists

simple lists in text files that include

the most

frequently used passwords or dictionary

words or even small combinations such as

adding a couple of numbers or digits

before or after that dictionary word

sometimes this is called a hybrid attack

which uses combines just a bit the

dictionary attack with a Brute Force

attack the advantage of this is that the

search space is going to be much smaller

so if it takes you I don't know maybe

five hours to try all the seven

character passwords out there it's

probably going to take just a couple of

seconds to try all the seven character

words in a in such a word list so it's

much much faster but of course it

doesn't guarantee success it could be

that the password that you're looking

for simply is not in that dictionary

file or if it's randomly generated it

simply cannot be defeated by a

dictionary attack what is truly

dangerous against uh passwords stored as

hashes or rainbow tables we talked about

this in a previous video we said that

rainbow tables are pre-calculator

pre-compiled data databases of hashes so

it's basically a database in which

somebody took the time and resources to

generate all the possible hashes for all

the possible inputs let's say for

example every alphanumeric password from

one up to eight characters calculate

them all generate all those combinations

and then calculate the hash of that

result store those hashes in a database

and there you have your Rainbow table

next when an attacker gets their hands

on a password database from a an

application or an operating system all

they need to do is now search the hashes

from the database inside of this rainbow

table which takes a lot less time you

know searching in a database takes a lot

less time than building and actually

Computing the database now this rainbow

table approach a rainbow table attack

can be mitigated by using password

salting that is adding a unique set of

characters whenever your calculator

relating the hash for each password you

don't even need to keep those those

characters that sold secret it can be

stored right next to the hash in fact or

right next to the username but this

defeats the use of rainbow tables

because now the hash that gets generated

is not generated from the pure password

but from the password and a small set of

characters known as the salt so if you

find that hash in a rainbow table the

input corresponding to that hash is not

going to be your password it's going to

be something else that has no meaning a

very well known software used for

cracking hash passwords is called

hashcad can be freely installed and it's

freely available on Linux distribution

especially in Cali I believe it comes

pre-installed with Cali by the way and

also there's a website in here I'm sure

I've shown it to you before a website

that you can play with and where you can

input some of your passwords try not to

input your real passwords perhaps but

it's still going to give you quite a

interesting insight into how difficult

it would it be to crack a a password

like this assuming a Brute Force attack

of course now to show you how hashcat

can be used and actually there are a lot

of methods in which hashtag can be used

but just to play with a couple of hashes

let's assume that this input txt file

includes some let's say real passwords

from real users what I'm doing here is

actually I am echoing this password

right here one on every line and I'm

passing it over to the md5 sum utility

which is going to calculate an md5 hash

of this password right the dash and

right here allows me to remove the the

new line at the end of echo this TR

Command right here allows me to remove

any white spaces and dashes from the

output of md5 sum and then I'm going to

redirect the calculated hash into this

target hashes txt file which kind of

looks like this

there you go this is a list of mt5

hashes that correspond to these one two

three seven passwords okay let's assume

that this is a hash database that I've

managed to get my hands on from a real

compromised server or a web application

how can I crack these hashes now and

retrieve the original passwords well I

have two methods of doing so I could try

perhaps brute forcing all the possible

combinations that can lead me to

potential passwords all the possible

character and letter and symbol

combinations let's try this first of all

let's have a look for just a second in

the man page for hash cat we are

focusing on this built-in Char sets

first because you can see that by using

these switches on the left we can choose

to crack based on specific character

sets like lowercase letters uppercase

letters numbers

hexadecimal letters symbols or we can

just combine them all in this question

mark a question mark a actually includes

lowercase uppercase numbers and symbols

right so this is pretty much going to

cover every possible symbol that can be

used inside of a password so we have

this set all right next up we have the

attack mode what type of attack do we

want to conduct with hash cap now we

could be using a Brute Force we could be

using a word list but for now we're

going to be focusing on Brute Force

right finally we have the hash type

notice that we have a lot of hash types

in here not just the traditional nd5

Shaw hashes and so on but we have MySQL

hashes ntlm hashes right uh PHP hashes

and so on so what we are trying to crack

right now is the first type of hash

which is a simple md5 now that we know

these parameters let's try building our

hash gas command all right that's the

hashcat command that we're going to be

using Dash A3 is the attack type

remember this one was Brute Force Dash

m0 is the hash type this was md5 Dash o

is the output file so whatever I managed

to crack is going to be stored in this

cracked password txt file this is the

Target hashes that we just saw before

and this is the pattern that I'll be

trying question mark a one two three

four five six times let's see how long

is this going to take and if we find any

passwords I'm going to press enter here

and you can see here it actually uses

discrete Hardware so if you have a

dedicated graphic cards or a beefier CPU

that you can use it's actually able to

set them on fire right

it even has a I believe that's mentioned

right here temperature abort trigger set

to 90 degrees Celsius so it is it is

extremely CPU intensive the process of

cracking passwords you also get some

hints in here if you want to improve the

the cracking performance also the line

right here at the bottom tells us that

we can periodically check for the status

using letter s let's press s right here

all right so it's telling us that it's

currently running an md5

cracking operation

and this is the pattern that we've

chosen

apparently we've already recovered one

out of seven hashes which is not bad

actually right

what is kind of bad let's run the status

command one more time is that now we've

been running it for half a minute but we

still have about two hours left

to wait and that's just for six

characters

let's quit this let's see how long it

would take us if we were to expect seven

characters notice we don't even know how

long the passwords are so we just have

to try it so I've added one more to the

pattern in there

let's choose status and this time it's

going to take us 10 days

and I must say this is pretty good in 10

days it seems a lot to you this is

actually pretty good because we're

running on a pretty good CPU right here

it's not an old CPU it's kind of last

generation right now at the time of this

recording so it's not a bad performance

but it's it's going to take a while

nevertheless right let's quit this

because we're not going to wait 10 days

in here and see the end results right

now we have a crack Pass for txt

and inside of it we can see that it was

able to determine the simplest password

out there which was once just one two

three four five six just a quick

reminder

these were the original passwords so it

was only able to crack this password

right here now if we were to give it

some more time it would probably reach

this this password as well and this one

and it would never be able to crack this

one because we were limited to uh seven

characters

all right now let's see if there's a

better way of doing this instead of just

brute forcing everything blindly we

could be using a word list or a

dictionary attack and it's actually not

exactly a dictionary attack it's not

more like a direct type of an attack so

we're basically just looking for those

passwords in this list right here this

Rocky list comes embedded with many

links distributions just search for it

or if not you can just download it for

free from the Internet it's just a huge

txt list of words it might happen to

include passwords it might happen to not

include all the passwords but it's worth

trying especially because it's going to

take a lot less time to validate this

list again the hash type that we're

looking for is going to be md5 we're

going to Output the results in this

crack password txt file the same one and

we're using the same Target hashes as

before so let's press enter here

let's wait a couple of seconds and it's

done I mean how long did this take

two seconds and it estimated that it

should have lasted zero seconds so it it

did have some better expectations from

the CPU actually so it did recover four

out of seven passwords now it was not

able to continue looking for passwords

because it reached the end of that word

list so it did not have anything else to

go and go on with but it's more than

enough so let's have a look inside of

this crack password TFT file there we go

now more passwords in here you have

password we have test1234 and we have

the secret you can see they're pretty

much

kind of dictionary words right so

they're they're simple passwords that

can be easily cracked using dictionary

attacks the other ones let's see the

ones that we were not able to track

are the ones that actually mix lowercase

and uppercase and letters were symbols

in their in their structure

right but it's still a start I mean for

for two seconds I would say this is a

success right ideally you should combine

this dictionary attack with a little bit

of brute force and hashcat can do this

in order for you to be able to uh you

know interpolate numbers between words

and the replace for example alphabet

letters with numbers or symbols like

most people do in their passwords but

anyway you do get a lot of flexibility

with hashcad play with it it's

completely free and open source see if

you can crack some hashes on your own

now moving over for just a bit to the

other side of the battlefield and this

time talking a bit about securing

passwords now whenever you think about

securing passwords start by thinking

about just securing data right you have

to think about how to secure data when

when it's stored that is data at rest

and how to secure that data whenever it

is in transit whenever it is

communicated to someone else now when it

comes to passwords again the same

principles apply here you have to find a

way to secure store them long term and

you also have to find a way to securely

communicate them and I'm not here

talking about sharing passwords not

about communicating them to your work

colleague but to any type of

authentication system because whenever

you're logging into something you'll

have to send your credentials somehow

over a potentially unsecured medium but

coming back here to our discussion about

how to securely store passwords and

traditionally password storage is a is a

very big potential security risk

especially in a large Enterprise because

because if you just leave people to

manage their own passwords however they

want you're going to run into situations

where they start reusing the same

passwords that they're using onto their

personal accounts they're going to be

sharing accounts they're going to be

using very weak passwords so there are

solutions which by the way can be

software or Hardware which we call

password managers these password

managers actually deal with two very

important pieces of the puzzle when it

comes to securing passwords first of all

generating secure and unique passwords

for each and every service that you're

using preferably completely random

without any kind of meaning and secondly

they deal with storing these passwords

in a secure let's say compartment

because if we're randomly generating a

20 character

alphanumeric and punctuation signs in

their perhaps password for each and

every service that we're using most

likely we're not going to be remembering

them all by heart so we have to store

this information somewhere

so the first method of storing these

passwords would be on a physical device

such as a password key which can be

attached to your keychain for example it

can be an actual physical USB key or an

NFC device for example the UB key series

from ubico has been for quite some time

uh one of the best Integrated Solutions

out there regarding security Keys you

also have USB and NFC variants for all

these security keys and of course you

can also use a softer password manager

such as one password or LastPass or

keepass which you can store your

passwords in an encrypted database it

can be stored in the cloud if you don't

trust the cloud you can just store them

locally but then you'll really have to

take care of that database and in some

situations you can even combine these

password vaults software password vaults

with actual physical Hardware keys so

you can have a physical key that unlocks

the password Vault where all your

individual service passwords are stored

I personally like to use keepass XC

which is a form of the original keepass

I I like it because it's completely free

it doesn't tie me to any specific

platform it's completely open source and

it also integrates quite well with uh

additional authentication factors such

as Windows hello or uh the fingerprint

on a Mac OS laptop or your face ID on

the iOS application so go ahead if you

want to try a completely free solution

as a password manager just just keep in

mind the fact that it's not going to

store your database in any Cloud you

have to take care of that database and

perhaps synchronize it across multiple

devices if you have them

all right now the authentication process

in itself or the authentication

Technologies involved in this process

are a big part in any Enterprise

organization and it's not just about

password management like we just talked

before but it's also about the entire

authentication process and it usually

involves more than one simple Factor so

we're going to talk about a few

technologies that not only help us

perform password Management in a secure

manner but also allow us to implement

multi-factor authentication in an

Enterprise environment starting for

example with the smart card now the

smart card in itself or the the smart

part in that card is basically just a

small cryptographic processor so it's a

card that is able to process some data

in most cases this card is used to store

the certificate of that user along with

the private key that was used to

generate that certificate that's one of

the reasons why these smart cards you

really have to take care of them right

you have to guard them just like the

keys to your apartment

make sure nobody else gets their hands

on that smart card because that's also

where your private key lies and this is

why you use Smart cards in an Enterprise

environment to sign emails perhaps even

to authenticate in in Kerberos in a

Windows active directory domain with

Kerberos for example you can use a smart

card or the private key store doing that

smart card to generate a unique ticket

granting ticket request in order for you

to get access to the rest of the

environment the rest of the services in

the network which is signed uniquely

signed by you and we all know by now

that for a digital signature you need a

private key which is stored on the smart

card now of course you will need a

device able to read these smart cards

and be able to use the information

stored on them and because mobile

devices nowadays don't really have smart

card slots anymore but we do have some

smart card readers out there I'll some

people thought that why not just embed

everything into a simple USB device and

call that USB device your actual key

right so instead of a smart card we have

a smart USB device that does pretty much

the same thing as a smart car stores

cryptographic information also is able

to generate new cryptographic material

such as when you need to use the same

private key to generate a certificate

for a different purpose like for example

encrypting files and another one for

signing emails while smart cards and USB

keys can be stolen can be lost can be

shared one technology that cannot be

lost stolen or shared is a TPM chip

let's say called a trusted platform

module chip which is an embedded chip

into your motherboard in your mobile

device in your laptop even in your in

the motherboard of your desktop PC and

it's basically a so-called secure

Enclave it's a very secure area where

your level of interaction is quite

limited you can treat it as a black box

for example you can ask that black box

that TPM chip generate a certificate for

me generate some cryptographic material

give me a randomly generated key for me

to use in a secure communication but

you're not allowed to change the

contents within that black box and for

let's say Legacy apps or operating

systems you can even convince through

software of course you can even convince

the TPM chip to present itself as a

so-called virtual smart card because

again it pretty much does the same thing

now all three so far are considered to

be user devices they're things that

regular users have to interact with well

we also have some secure enclaves some

secure cryptographic modules that can be

installed in actual servers because you

know servers must use cryptographic

information as well and especially those

servers that act as registration

authorities or certificate authorities

or even root Cas now for those

situations we also have some dedicated

types of equipment called hsms Hardware

security modules now even though the

name suggests that it's a module that

it's supposed to be plugged into a

server which in most cases it actually

is most hsms are are just a PCI Express

cards that you can plug into a PCI

Express slot in your server you can also

have them as dedicated appliances rack

mounted appliances or even external

peripheral devices connected through USB

it kind of makes them some very smart

Enterprise grade USB keys

again we use them for the same purposes

we use them to store cryptographic

information and to generate new

cryptographic information so they are

really resistant to outside tampering

and or attacks and you also get a big

Advantage with hsms the fact that the

actual cryptographic module is not tied

to the server anymore you can at any

moment just remove the the card from one

server and insert it to another one for

example if you need to upgrade the

hardware in our company's root CA now

you can Simply Save the same

cryptographic information onto that HSM

and just pop it out from the first

server and plug it into the next one now

the authentication methods and

Technologies discussed so far assume

that the device the computer is already

connected to the network and the user is

the last entity that needs to

authenticate but there are situations

where we need to provide authentication

services for users connecting to the

actual Network and we have a couple of

methods of reaching a network for

example simply by plugging the network

cable into our computer we probably want

to authenticate any devices that

randomly happen to connect to our wired

Network the same goes for wireless of

course both for Enterprise wireless

networks and for guest networks as well

and we also have users connecting from a

remote location those are going to be

the users connecting to a VPN endpoint

where of course there has to be some

sort of authentication going on and for

these situations we have something

called EAP extensible Authentication

Protocol now even though the name says

protocol it's actually a a suit of

protocols a grouping of protocols which

is often known under the name of a

framework so we're going to call it the

AAP framework and this framework is

actually a wrapper a some sort of an

encapsulation let's say generic

encapsulation for a multitude of

authentication methods ranging from

passwords down to Biometrics or relying

on user server certificates either one

or both even authentication methods

relying on the SIM card that is

currently in your mobile device that is

attempting to access a specific

Enterprise Network so it's a framework

that supports a bunch of authentication

methods and while the framework sounds

nice the actual implementation has to be

an actual protocol that protocol is

802.1x it's an IEEE standard as you can

probably guess by the by the naming

format and it's a protocol that selects

or establishes which authentication

method is going to be used within this

EAP framework whenever a device tries to

access a network either directly over a

cable over Wireless or over a VPN

connection and we have a couple of terms

that we need to be familiar with when

talking about 802.1x the first one being

supplicant the supplicant is the actual

device requesting access next one we

have the authenticator which might sound

a bit counter-intuitive because the

authenticator is the device through

which you get to access the network if

it's a cable network it's going to be

the switch if it's a wireless network is

going to be the access point or some

implementation down to the wireless LAN

controller if it's a VPN connection of

course it's going to be the VPN endpoint

that you're connecting to so that's

going to be the authenticator that's a

device that decides whether you will

receive or not access to the network and

finally we have the authentication

server or the the AAA server

authentication authorization accounting

right and that's the actual server

located somewhere where it's supposed to

be reachable by the authenticator

because on the authentication server the

actual database of the users and their

hashed passwords is stored so what

happens is the supplicant sends their

own authentication credentials to the

authenticator like the switch for

example the switch then contacts the

authentication server checking whether

those credentials are valid if they are

the authenticator receives a valid

response from the AAA server and then

unblocks the network Port the actual

network interface through which that

device is attempting to access the

network and of course if a negative

response is received then the port

remains in a blocked State allowing only

authentication traffic to go through but

not any other type of data now you might

have noticed that in this deployment

that we just explained the actual switch

or the access point of the VPN endpoint

doesn't need to store the entire user

database which is great because we might

have hundreds of switches and thousands

of access points right in a large

Network it wouldn't be feasible to

download it and keep that database

updated onto each and every Network

device and it wouldn't be secure either

right so the AAA architecture allows us

to implement authentication uh policies

at the edge of the network when user

where users actually get to connect and

also store that database in a

centralized location that everybody can

reach and check whether whoever tries to

access the network has valid credentials

or not and that database is going to be

stored in something called AAA server or

the authentication server and we have

two large types of authentication

servers nowadays differentiated by the

protocol through which we're accessing

them and those two are called radius and

tacx plus now generically speaking

radius supports Pap Chap and EAP as

authentication methods but since step in

chap are kind of old and not so secure

anymore pretty much everybody nowadays

uses some version of EAP some

implementation of EAP so what happens is

that when your computer attempts to

access the network through a switch port

for example the communication between

your computer and the switch is going to

be limited to EAP over land traffic

that's eapol EAP Overland traffic

basically means that we're allowing any

type of traffic that relates to EAP

authentication and that's the only type

of traffic that we're allowing through

that port for now before the user is

authenticated now the switch in turn is

going to encapsulate that authentication

information into a radius message which

encrypts that authentication data and

then sends it to the radius server as an

access request radius message and that

communication happens over

UDP ports 1812 or 1813. now there are

going to be a few exchanges of

additional messages between the AAA

server and the actual supplicant your

laptop your computer has a couple of

messages called access request or access

challenge the purpose is for your

computer your supplicant to be able to

respond to those challenges in order to

demonstrate that it actually holds valid

credentials which correspond to The

Chosen EAP method so if we're

authenticating using certificates you're

gonna have a chance to present your

certificate if we're authenticating

using multi-factor authentication

relying on biometric factors then the

supplicant is going to have the chance

to send that biometric data down to the

AAA server for verification finally

according to the AAA service decision it

can reply back to the network switch

with a message of access accept or

access reject depending on whether the

user or the device managed to properly

perform Authentication

so that's the authentication and

authorization part there's also the

third a the accounting phase which can

also happen using the radius server that

is monitoring the user activity the

login times and any any authorization

request for example coming from that

user over the entire duration of that

users connected State and this uh

Gathering of information and accounting

communication happens over the second

UDP Port that's Port 1813. now in real

life you're going to encounter radius

implementation especially for user and

device authentication requirements

there's also another requirement for AAA

environments that is when you need to

manage the administrative access of your

admins to your your servers your network

switches your firewalls your routers

within the network so that each user

each admin in this case would not only

be able to access all the devices in the

network using the same credentials but

they would also be able to receive

different permissions or different

privileges depending on the device that

they're trying to connect to now attack

X on the other hand comes with a couple

of improvements not only it works over

TCP so the communication is more

reliable Port 49 by the way but it also

encrypts the entire data not just the

authentication information like with

radius that's simply because attack axis

is mostly used with administrative

accounts logging into network devices

for example and in that case it's not

just the authentication information that

it's sensitive but also the actual

commands and the configuration files and

the the settings that are being changed

in there so that's why it's much better

to have the encryption covering the

entire communication not just the

authentication part and the separation

between all the AAA functions is is much

better established which leads us to

situations where we can even perform

authorization not just for the entire

user that is logging into a network

switch for example but also for each and

every command that the user submits to

that switch is a CLI so you can have per

command authorization and accounting of

course because we need to keep track of

who is doing what especially in the

administrative world

now one-time passwords we all know them

right it's a type of two-factor

authentication it's the type of a

another Factor authentication that

relies on something that you have so you

need a device or a software program that

generates unique codes that are unique

just for you and sometimes they're

unique even depending on the current

time and date now this uniqueness or

whatever

makes a one-time password generator

unique just for you is ensured by the

fact that all these generators rely on

some sort of a starting seed value

that's an initial value based on which

all the subsequent unique passwords or

codes are going to be generated now the

one-time password generated and the

authentication server should be

configured with the same shared secret

or the same secret password which can be

delivered as a string or as a QR code

you probably saw this whenever you're

enrolling in two-factor authentication

you can scan a QR code with your phone

and that becomes the seed for any

subsequent passwords that are going to

be generated by your app now in order to

provide uniqueness the seed can be

combined with a counter which makes it

an hotp that's a hmac based one-time

password and that counter of course is

being incremented with each new password

generation request alternatively and

this is probably the method that you're

most familiar with is the time-based

one-time password generator where the

actual value of the password is

generated depending on the shared secret

of course but also on the current time

of the day down to the minutes or

through the second these are the codes

that in your one-time password generator

app you're going to see them as expiring

in a couple of seconds usually they are

valid for 30 seconds or one minute or so

just to give you enough time to enter

the generated code into whatever

authentication system you're logging

into and we also have some additional

methods of delivering the second factor

and these methods are sometimes called

out of band verification or two-step

verification and probably familiar with

these because many online services ask

you to validate your account perhaps to

validate your login by sending you a

one-time code over email for example or

over SMS or even over a phone call or an

automated phone call and more recently

with applications such as OCTA or

Microsoft authenticator or Duo you can

even send this request as a push

notification to your mobile app and then

you need to interact with the mobile app

to provide your agreement with that

authentication request another widely

used authentication technology is

biometric authentication this one takes

into consideration certain features that

characterize you as a human being or as

a particular human being things such as

your iris your retina your fingerprint

or even the way you sign yourself on

paper now as can probably guess relying

solely on biometric authentication is

not 100 recommended because there are a

lot of potential error or

misidentifications that can happen

whenever you are scanning for actual

physical characteristics it's not just

comparing ones and zeros anymore like we

did with passwords or one-time passwords

but now we're looking at how closely are

your facial features for example

matching what we have in your database

it's never going to be 100 of course so

there is going to be some margin for

error so the efficiency or the

reliability of a biometric

authentication system is actually

measured in how many errors does it

produce and we have two types of errors

and they're actually called type 1

errors and type 2 errors the type 1

error is the false rejection error or

the false rejection rate if we consider

how often this happens and it happens

when the biometric authentication system

fails to authenticate a legitimate

person it's bad it's inconvenient it's

not exactly a security risk so that's a

type 1 error now the type 2 error is a

bit worse from a security perspective

this is a false acceptance rate the

false acceptance rate the far indicates

how often does the biometric system

allow somebody who is unauthorized to

gain access to the system so it

mistakenly identifies that person as a

legitimate user when in fact they are

not of course this is a security concern

because you are providing access for

unauthorized people these error rates

can be corrected over time by performing

some fine tuning and it also relies

strongly on the enrollment process that

is the initial process where you're

actually capturing those initial you

know fingerprints your your face the

shape of your face for face ID for

example or a retina scan the first time

you capture those details and you store

them in an abstract format in a database

that is called the enrollment process

the accuracy of all the subsequent

identifications performed by that

biometric authentication system strongly

depends on the quality of that initial

material that was stored during the

enrollment phase and we also have the

crossover error rate of the equal error

rate that's the point on a graph I'm

going to show you in just a second where

these two types of Errors meet so if you

just perform a quick Google search by

searching for false rejection rate

versus false acceptance rate and I've

just clicked images here you can see

that pretty much all the graphs look the

same right so if you look at the first

one right here on the left hand side on

the vertical right here we have the

number of errors and on the horizontal

axis we have the sensitivity or the

level of security of that system so the

higher the level of security or

sensitivity of our system the less false

acceptance events we are going to have

consequently the higher the level of

security or sensitivity the higher the

level of force rejection events we're

also going to have so the more sensitive

the system is the more picky it becomes

up to the point where it's going to

reject valid people simply because

they've suffered some minor changes

let's say I don't know they grew a beard

from one day to the next door or they

simply positioned their finger on the

fingerprint reader in a slightly changed

position from the original enrollment

image that the authentication system

stored so ideally we're going to try to

fine-tune the biometric system to match

this crossover error rate or the equal

error rate that's the The Sweet Spot for

a biometric system some of the issues

that you might encounter with biometric

systems I'm sure you can think about at

least a couple of them first of all we

have reliability how reliable is uh is

my fingerprints going to be every single

time it's being read or my retina or my

face

consider that I might be wearing glasses

maybe I'm wearing a mask maybe I grew a

beard maybe I had a haircut all right so

we're gonna have to accept some sort of

margin of error which is going to lower

the reliability of the system itself

there are also privacy concerns not

everybody is comfortable having their

physical features stored in some

database of course there's higher cost

because those sensors well they cost

money and the more sensitive we want

them to be and the less errors we want

them to produce of course the cost is

going to be proportionate with these

requirements and we might also encounter

some accessibility issues not everybody

might be able to use those biometric

authentication systems due to some

accessibility problems that they might

have so make sure that you do not

discriminate anyone by forcing them to

use a specific biometric authentication

system so the main types of biometric

authentication systems rely on scanning

fingerprints these are the most common

ones the cheapest one to implement and

probably you can find them pretty much

everywhere nowadays now the problem with

them is that they can be fooled by a

either a high resolution scan of a

fingerprint or even by a mold of that

fingerprint created from plastic or

silicon there are more advanced scanners

so-called Palm scanners which instead of

just scanning one or two fingers they're

going to scan the entire shape of your

hand and also the blood vessel

positioning in your palm of course the

sensors are not going to be as small as

as with the fingerprint ones and the

entire solution cost is going to go up

quite a bit but I have seen even laptops

implementing this type of palm scanning

technique now face recognition can be

done in a number of ways it can range

from a simple image recognition of how

your face looks like or it can go up to

the technology within face ID for

example which creates a

three-dimensional model of your face

which enables the biometric system to

scan your face with better accuracy also

makes it harder to fool harder to trick

using just a just a picture of

somebody's face we can even go deeper

and scan specific features of the human

eye like the iris or the back of the

retina

both rely on features that normally do

not change from birth to death apart

from some specific disease situations

but in general the retinal scan is a bit

difficult to perform because it needs to

scan using an infrared light the back of

your eye while the iris is at the front

so it's much easier accessible

of these two which one do you think can

be fooled by a high resolution photo

that's right the iris one

the iris scan can be fooled because it

doesn't rely on any infrared scanning

work three-dimensional model it's

basically just a picture of your iris

finally we have some more exotic

measurements of biometric factors such

as the way a person walks the way a

person no doesn't talks right uh yeah

actually even the way a person talks

right because that's going to be voice

recognition even the way a person signs

themselves on a paper with a with a pen

how they perform they at their actual

handwritten signature

normally these factors because they

produce a lot of errors are used as a

let's say continuous authentication

after the user has already been granted

access so we've identified you using

your I don't know perhaps your your

fingerprint and your password you've

gained access now for the duration of

your session we're also going to monitor

how you type on the keyboard uh what's

the tone of the voice that you're using

how are you signing yourself on a

digital path for example and if

necessary we might decide at some point

that you do not match those features

that we have in our database and we

might decide to cut off your connection

until we actually clarify whether you

are the person that has passed that

authentication and identification

process in the beginning so in other

words even if you have the right

credentials but you don't behave like

the person that we know you should be we

might decide to take some action right

so a lot of stuff in this chapter but

hopefully a lot lot of useful and

interesting stuff that you can even find

around yourself every single day alright

so thank you so much for watching if you

have any more questions if you want to

continue this discussion please use the

comment section if you found this

informative like And subscribe good luck

on your studies and see you on the next

video bye bye

[Music]

 
16 16 


foreign

[Music]

and welcome back now today we're going

to start talking about securing networks

and this is actually going to be the

first video in a series of videos about

network security but before diving into

the actual security part it pays to have

just a big and clear picture about what

network design is all about now you

might not be the person responsible for

Network design in your company of course

if you're on a strictly security role

but understanding how the network that

you are you're tasked with protecting

was designed from the very beginning and

which flaws might indicate that specific

areas of the network might be vulnerable

to specific vulnerabilities and types of

attacks well that's going to help you a

lot on your job so let's build some sort

of context about networks in general and

network designs in particular all right

so when talking about network security

here comes the first problem bit of an

unexpected one but the main idea here is

that whenever we only have a network in

a company that is running applications

it's ensuring access to to files to

storage databases it's perhaps even the

same network that ensures access to your

customers your clients to your your

business well the first thing the first

thing on in the order of business is is

going to be for that Network to be up

and running it should work right if the

network got working then the business is

not running and we're not making money

the same goes with your home network

right you want first of all to have

internet access you want your smart

device to be connected

and then you think about security if you

ever think about security so that's one

of the major issues with networks

nowadays and actually since the very

beginning we tend to focus so much on

availability of the network

that sometimes we forget about integrity

and confidentiality another Network

design flaw is the fact that we tend to

focus so much on Perimeter security and

only on Perimeter security which means

that we're only validating traffic and

connection attempts and access and

whatever we're filtering inside of a

network only people try to get in that

Network like for remote VPN connections

like from clients connecting from the

outside right we have a firewall we have

some sort of ips IDs device uh right at

the border of the network and that's it

now unfortunately this is a design flaw

because once an attacker is able to buy

it as any of your perimeter security

measures basically they have complete

freedom of movement they have access to

your entire network and that's why a lot

of the solutions nowadays of modern

smarter solutions that have been

developed in the security area lately

they focus not just on the security of

the perimeter but also on the security

of the instance of the network this is

sometimes called the zero trust approach

that is we don't trust the device or a

user simply because they are within the

perimeter of the network we just don't

trust them at all we verify each and

every connection attempt piece of

traffic that is traveling over the

network core or authentication attempt

because we might have compromised hosts

we might have Insider threats that are

just as dangerous if not even more

dangerous than the ones trying to

penetrate from the outside another

design issue that I'm sure you've heard

about is called single point of failures

just like name says it's basically a

situation where in a network design

there is a single point or a single

device a single service that either

allows or denies access to the rest of

the network or to a specific resource

now there's nothing bad about that right

we expect to have you know proxies

authentication portals firewalls and so

on the problem is that if you have only

one

and that device fails well what's going

to happen you either lose access to the

resource or device is smart enough to do

something called a fail open where it

basically seizes to stop or to filter

any type of connection attempt and all

of them can go freely through that

failed device again this is not

desirable now it's not just a matter of

availability here that is if you're

losing your main internet router well of

course you will lose access to the rest

of the network but also if you have a

single firewall if you have a single

security device at your network Edge and

that single device gets compromised well

there's nothing else besides that

compromise device that would stop a

potential attacker so we have single

points of failure from two different

perspectives from availability

perspective and from a security

perspective another one a bit of a funny

one is having a configuration that is

too complex or a network design that is

overly complicated and and again there

are two perspectives that we can apply

to this issue the first one being well a

configuration that is so complex that no

admin can actually follow it and

understand the traffic flows in there

when something needs to be fixed or a

security audit indicates that a specific

policy needs to be hardened well you

have no idea where that policy is

applied and what type of traffic it

affects and so on now the second

perspective here that is worth

mentioning is that a too complex

configuration might actually cause

such complex interdependencies between

your network Services between your

application components

that it kind of becomes very difficult

to have everything up and running at the

same time if an application depends on

20 additional services and virtual

machines and Cloud environments and

remote storage devices and security

devices and so on well that means that

you actually have 20 more times the

potential points of failure in your your

applications functionality and this

becomes extremely hard to manage and

especially from a security perspective

it's if any one of those 20 Services

gets compromised or is under a denial of

service attack then your application is

going to be down because it depends on

so many components and it's really

really tough to have everything neatly

and smoothly up and running at any given

point in time and finally I believe this

last one doesn't surprise anyone is the

fact that most networks nowadays from

small one to huge ones they lack proper

documentation or or change management if

you wanna if you want to call it

actually have not having change

management is even worse than not having

the augmentation the idea here is that

whenever A change is being performed in

the network right whenever something is

changed moved added deleted removed from

the network uh that seems to be

documented not to mention that normally

a change shouldn't be performed unless

there is also a rollback procedure in

case the change doesn't work smoothly

well at the end of the day not having

documentation leads us to a lot of

problems whenever something goes wrong

or whenever we need to perform an

additional update or upgrade in our

Network and it also causes problems and

security audits while you unfortunately

might discover that you are running some

unsecure services or applications that

you know nothing about because nobody

documented them and it also continuously

exposes you to security risks having

undocumented assets running undocumented

services on ports that nobody knows

about

that's really bad because nobody's going

to include them in a security assessment

nobody is going to uh update them and

nobody is going to know about them until

the day they become the cause of your

data breach

all right let's also talk a bit about

the basic networking devices that you

need to know about because later on I'm

going to address some risks and security

vulnerabilities that apply to them so if

we were to start with the basic ones

right we're going to start with the

switches and access points these are the

layer 2 devices and when we say there

two layer three layer 4 we're basically

referring to the OSI stack the seven

layers starting with layer 1 referring

to the physical medium this is where we

find the actual electrical or

electromagnetic or Optical signals that

travel over you know cables uh or The

Ether right

next up we have Layer Two that's the

data link this is where we find frames

and the data link layer is the layer

where communication happens only within

a local network that is within a single

subnet next up we have the network layer

right just like the name says this is

we're talking about routing between

multiple networks between multiple

subnets so this is where we find IP

addressing so we are referencing our

social destination by using IP addresses

this is layer three just like with layer

2 we're using Mac addresses all right

finally layer four that's basically the

last relevant one at least for this

discussion uh is the layer where we

introduce Port like TCP UDP ports uh

this allows to Multiplex or have

multiple simultaneous connections uh

from the same source to the same

destination or for multiple sources to a

single destination basically these allow

us to have multiple simultaneous

connections or multiple types of

communications based on what protocols

we are using so a switch or an access

point we'll call them layer 2 devices

because they only take care of moving

frames around so based on the source and

destination Mac addresses within a

single local network they don't know

anything about anything that's outside

of their local network and we say that

these devices extend broadcast domains

because broadcast is basically the area

inside of the network that is affected

by a broadcast message now a broadcast

message by default at least it's only

going to reach the hosts within a

network that are within the same subnet

so it's not going to go through a router

right it's not going to go through a

layer 3 device it's going to stop at the

layer 3 device on the other hand if we

have multiple switches we call them

layer 2 extensions these basically

extend the broadcast domain because the

broadcast can pass through them next on

layer 3 we have the routers and the

routers are layer 3 devices because they

interconnect multiple networks and

they're able to Route hence the name

router they were to Route packets or

messages from one network to the next

now this routing happens based on IP

addresses we can route on both source

and destination IP addresses not so

often routing by Source but it can be

done and we also say that these routers

limit project has no maze because the

broadcast doesn't pass through a layer 3

device since the layer 3 device is the

actual Network boundary also we have

firewalls now nowadays we don't really

draw such a strict distinction between

routers and firewalls and other layer 3

devices pretty much nowadays every

firewall has a routing functionality

because even the home routers that you

might be using or those provided by your

by your ISP do have some basic firewall

functionality in there built into them

so it's not really a separate device as

it is a separate type of functionality

that nowadays is found within liter 3

devices now what a Firewheel does is

basically a device that decides whether

to allow a certain type of traffic to

pass or not that's it now how does it

decide this well it's going to use a

list we call that list an access control

list because that's exactly what it does

it controls access it's a list that says

well this destination can communicate

with that destination or this host can

connect with the internet can

communicate with the Internet or this

host is not allowed to connect to the

printer at the second floor or this host

is not allowed to connect to the

internet because it's a risky device

still got all these kinds of rules

mashed up into what's called an access

control list and that's the basis for

any type of firewall now normally a

firewall a traditional firewall is going

to apply filtering at layer 3 and layer

4. so we can filter based on IP

addresses and we can also filter based

on ports or types of applications that

are going through that traffic now more

recent firewalls actually have

application layer visibility there which

allows them to actually analyze the

actual content of the packets that are

being sent not just their headers not

just their layer three or four headers

so they're able to decode the fact that

you are actually accessing a a web

server and that web server belongs to

Facebook and within phase Facebook you

are currently

watching a video so they're able to

identify not just the applications but

actually the type of traffic that is

being performed within that application

so we're talking about deep packet

inspection here or application layer

firewalls another type of device which

again has become a recent additional

functionality for routers or firewalls

or UTM devices is a load balancer now a

load balancer does exactly what the name

says balances the connection load among

multiple destinations so for example you

could think that you are running a small

server farm that is hosting a website or

an e-commerce website right and you

might have two or three servers in there

because one is just not enough or you

don't want to have a single point of

failure well having three servers in in

that back end requires you to be able to

actually send connections dynamically to

one of those three servers how do you

decide which server you're going to use

well you could use a device called the

load balancer now load balancer have

many additional functionality is in

there such as ensuring session

persistency or making sure that the

server in the back end is still alive

and up and running and is able to

actually serve the requests that are

coming from users so we got a lot of

functionality here and whenever we're

talking about load balancers and

whenever you're reading about load

balancers you might find the name of

reverse proxy used instead which is

basically the same thing we call it a

reverse proxy because a forward proxy is

usually the proxy that we're using ever

a client needs to go outside of the

network you know when you're connecting

to the internet through a proxy the

forward proxy well a reverse proxy

applies the other way around applies for

clients from the internet attempting to

reach a resource such as your server

Farm your website inside of your network

so we call that a reverse proxy because

it applies to your connection in Reverse

coming from the internet and it's kind

of a proxy because everybody has to go

through it before they reach their

desired resource and again since we're

talking about making decisions based on

that traffic we could be looking just at

the IP addresses we could be looking at

the ports or we could be looking at the

actual uh HTTP request or the URL within

the HTTP request if we have a load

balancer that is able to analyze traffic

at the application layer

and since we did talk about moving

packets around from one source to your

destination we also mentioned that we

have different types of devices that

make these decisions based on different

information that is found within those

those packets now for switches and

access points we said that we are

talking about layer 2 devices at layer 2

we're talking about destination Mac

addresses so a switch or an access point

is going to slowly learn the Mac

addresses that it sees through the the

network segment that it's connected to

so that later on when a specific frame

comes in with a specific destination

it's going to look up that Mac address

that destination Mac address and its

internal table it's also called a cam

table a Content addressable memory table

and that table is going to indicate well

this Frame here is destined to a host

that is currently located on Port 16.

right and it's going to know to send

that frame on to Port 16. now how does

it learn to do this well it simply

listens for Network traffic Now the

default behavior of switch of a layer 2

switch is to not have anything in its

internal memory whenever it boots up so

it's a completely blank memory it

doesn't know where any destination is

located so how is it still able to

switch packets towards the destinations

well it actually does something very

simple the moment a switch receives a

frame that it doesn't have a destination

for in its internal table it sends it on

all the ports at the same time so it

basically transforms it into some kind

of broadcast knowing that at least one

of those copies one of those frames is

going to reach the internal destination

now at the same time there's one thing

that the switch can learn about that

frame that is is the source Mac address

where did I see this source Mac address

coming from I might have seen it coming

in from Port 5. all right okay so I'm

just add an entry right there in the cam

table saying this Mac address is found

on Port 5. now following this this

broadcast that the switch just did one

of these destinations in the network is

actually going to be the right

destination it's gonna actually gonna be

the network interface card that actually

has the destination of Mac address that

card on that host and that operating

system is most often going to elicit

some sort of a response some sort of a

reply from a specific Port back to the

same switch and heading to the first

destination that actually sends the

original message now again the switch is

going to do two things first of all it's

going to learn the source of the traffic

and it's going to make an entry in the

cam table about which Port it saw that

that frame coming in and also it's going

to know this time where the destination

is because it's a reply to the first

packet that went through the same switch

and it already knows that the first

packet came from Port let's say number

five and it's going to direct it

directly to port number five

so that's basically attitude forwarding

not very complicated so keep in mind

that the layer 2 switch only learns

about Mac addresses by looking at the

source Mac address of any traffic that

enters its ports alright so when it

comes to moving packets inside or around

networks we have two ways of looking at

this from a layer 2 perspective and this

is where we find switches Bluetooth

switches and we call this layer to

forwarding or sometimes layer 2

switching and at layer 3 when we involve

routers this is where we finally l314 or

layer 3 switching and we sometimes call

it layer 3 switching as well because

layer 3 switches are quite common

nowadays those are switches that also

have routing functionality built into

them now again this is not going to be a

networking course so we're gonna jump

into the relevant information right here

because there's a lot to talk about when

actually the describing what happens uh

in the nitty-gritty details of packet

forwarding now what you need to know

here starting with Layer Two is what

exactly happens inside of a switch when

it encounters a frame or a packet that

needs to be sent on a specific Port then

this is relevant because later on we're

going to introduce a couple of attacks

that rely on this default behavior and

they try to exploit this default

behavior that is found in pretty much

every switch out there all right let's

start with a very simple example here

I'm gonna take out my awesome drawing

skills which I honestly hope you are

able to follow and understand because I

know they're awful but here it goes well

at least this training is free right

we have a very simple Network topology

here with a layer 2 switch in the middle

and let's assume we have a couple of

hosts directly connected to it we have a

host a on the left hand side which is

going to send some packets and we have

VC and D on the right hand side and for

the sake of some Simplicity here let's

also assume that this is port number one

this is going to be port number two on

the switch uh three and four okay now

when host a wants to send a frame to

host C it's going to put on wire a frame

that has a source Mac address which is

going to be of course the MAC address of

host a and the destination Mac address

as well which is going to be the

destination Mac address of host C all

right so what does the switch do when it

sees a frame like this because it has to

decide on which Port is going to send

this frame on now what the switch does

right now is use its internal memory in

order to determine the exit interface

the exit port and the internal memory

inside of the switch is a table which is

called a cam table

which includes some pieces of

information including the MAC address

the port that it is assigned to and this

is something we're going to talk about

later the VLAN it belongs to Now by

default if you just take a switch out of

the box and you install it inside of a

network local network you connect a

bunch of workstations to it you know

that it it magically starts working you

don't have to do anything with it and as

you can probably expect well the cam

table by default is an empty table

because it doesn't know anything about

your network doesn't know anything about

your Mac your ports or anything right so

it's completely empty so how does the

switch know what to do with this Frame

well by default it doesn't and actually

what it does it's it's the only thing it

could do right

it takes this Frame here coming from

host a and it's going to send a copy of

it

onto every port that it has a connected

host onto every active port

it basically transforms it into a

broadcast it floods it we call this

flooding to all the destination ports

hoping that will eventually one of these

packets here is going to reach the

internal destination now the hosts that

are not meant to receive this Frame

their network interface cards are simply

going to reject it because they're

receiving host B for example is

receiving a frame with a destination of

Mac address of host C and it's not their

Mac address which means I don't care

about this traffic I'm gonna just dump

it reject it now whole C on the other

hand is going to receive this Frame

right and it's going to process it and

probably it's also going to respond to

it but before we get there there's one

more thing that happens inside of the

switch now the switch doesn't know where

the destination is located as we just

said but there's one thing it can learn

right now and that is where is The

Source located because it just received

the frame from host a

on Port 1. which means that inside of

his cam table we can actually add some

information here we can say that Mac a

is now located on Port 1. I know perhaps

a VLAN here but again we're going to

talk about this later on right so it

does it does learn something from the

source of the traffic and that is

actually the default behavior of any

switch and this is how these switches

learn and populate their internal memory

they just wait for a specific type of

traffic to go through them and they

learn from the source of that traffic

now later on at some point of course how

C is going to respond because most

protocols nowadays are the type of

request response so who C is going to

reply back to a with a frame here that

has a source of c and a destination of a

well this time this Frame comes into the

switch and again the switch is going to

learn from the source of this packet

it's going to look at the source and

it's going to say oh so Mac c is now

located on Port 3 because this is where

I received this Frame from I just

learned something all right now what

about the destination because it does

need to forward it to do the right

destination now the destination is Mac a

but guess what Mac a is already in its

cam table right there so it's able to

switch it to the right to the correct

Port immediately without flooding it

again

right and this is how we have

bi-directional communication and also

this is how the switch learns this

information about the network now future

communication between a and C of course

is not going to be a broadcast anymore

because the switch already knows where

these hosts are located and by the way

cam table stands for Content addressable

memory table now you don't really have

to concern yourself with this but just

in case you're curious uh it means that

it's a type of memory that as opposed to

normal memory where you you request a

specific data at a specific memory

address you might remember this from

your programming days in a Content

addressable memory you're basically

providing the content and the memory

Returns the memory address which is

pretty much what happens inside of these

switches as well because we're providing

the content we're providing a MAC

address and I want you to tell me at

which location in memory which

corresponds to a certain Port is that

Mac address located and they're pretty

fast we use cam tables because they're

much faster when searching for specific

pieces of information we can basically

uh extract some information in a single

operation out of that memory we don't

have to linearly go through the entire

memory to search for that information

because imagine well we only have five

hosts and four or five hosts in here but

if we have thousands or tens of

thousands of uh of course each of them

communicating at gigabits tens of

hundreds of gigabits per second there's

a lot of traffic in there and we cannot

afford to have a bottleneck in the

middle of the network caused by the

layer to switch so it has to be pretty

fast uh we also sometimes find the term

of tcam ternary content addressable

memory and this is uh mostly located in

layer 3 switches all right again this is

not something you need to concern

yourself about for the exam but in case

you're you'll find this terminology in

other source of study now you know what

it stands for and what it does

and of course we also have layer 3

forwarding this involves routers and

since we're talking about layer 3 we are

not going to forward packets now based

on Mac addresses but based on IP

addresses and this is where we find the

term of a route hence the name routers

and our route is basically just an entry

inside of a router's memory that says a

specific destination or a specific

Network identified by its IP address is

located on the specific interface or you

need to reach a specific next hub or you

need to send the traffic to a specific

next hop in order to reach that

destination now normally we don't store

each and every possible destination

because this would make that memory huge

absolutely here so we try to summarize

these destinations into larger and

larger networks up to what is called the

default route now on default route you

probably know this one uh also known as

the quad zero router that's the default

route that most in most cases in most

networks it's going to send all your

traffic towards the internet now you

don't really need to store all the

destinations on internet in your in your

computer you just have to know that

whatever is not in your network that's

probably out there so you need to

forward it to the default gateway to

your isps router to some sort of Gateway

that leads you outside into the wild

wild internet

so that's layer 340. now the information

inside of these routing tables can

actually come from three different

sources uh the most obvious ones are the

connected networks we have a router that

has a number of interfaces and each

interface of course belongs to a

separate network if the router is

configured with some IP addresses on

those interfaces it's obviously going to

be aware of the fact that it's connected

to well one two three networks and it's

going to know what those networks are

now connected networks are pretty easy

next up we also have static routes

static routes can be manually

administered and can be entered into the

router by the Admin static means that

well of course they're not dynamic they

don't change right unless the admin

changes them so it's basically just a

manual configuration telling the router

hey make your router just keep in mind

that this network right here is

accessible through that router or

through that interface so we had

connected networks and static routes

also have Dynamic routes now Dynamic

routes are those routes that are learned

from a router to router through

something called a routing protocol now

routing protocol is just an internal

language spoken between two routers and

they're using this language to

communicate routing information saying

that you know uh I know about these

networks let me tell you my second

router let me tell you a little bit to

tell you about those as well so that you

know how to send packets to those

destinations as well now of course this

happens automatically or can happen

automatically uh it's much scalable than

working just with static routes but of

course these routing protocols do have

some vulnerabilities and they can be

exploited by specific attacks now

another protocol here that is at the

root of many many layer 2 attacks

especially is the address resolution

protocol or the ARP protocol now what

does this do well let's get back just a

moment to uh to this drawing right here

remember when you said that host a is

attempting to send the frame here with

the source of a Mac a and the

destination for Max C well well how does

host a know how to populate this

information well about Source that's

pretty obvious right it belongs to its

network interface card so it knows that

it needs to send frames with the source

Mac address of a what about destination

how does host a know about C is Mac

address when the switch doesn't know

about it in the beginning at all well

how does it find out about it well this

is where the r protocol comes in

now the way the r protocol is designed

is that it's supposed to be communicated

between hosts before even the first

frame or the first packet can actually

be sent so what a is going to do here is

going to first build up an ARP request

and that ARP request is going to include

something along the lines of who has

who has the IP address of host C now you

might be wondering well okay so how does

host a know about the IP address of host

C well it kind of has to know about it

because otherwise who are you actually

talking to if you're accessing a website

you are entering a a domain name a host

name a web address that gets resolved to

an IP address if you're connecting to a

server on your network again you're

using a a locally resolvable hostname or

directly an IP address so in most cases

directly or indirectly you will know the

IP address of the destination that

you're trying to communicate with

because otherwise you don't know who are

communicating with all right now since

this is a general question here sent to

the entire network it's going to be sent

as a broadcast so everybody in the

network is going to receive this message

here

and since B doesn't have IP address C

it's going to ignore it D doesn't have

it D is going to ignore it as well seal

can say oh this one is mine all right so

somebody's asking about my IP address

let me reply to them this time using a

unicast communication that is going

directly to host a saying that I have

the IP address of c and also this is my

Mac address

because we're in the same network and we

can see each other's Mac addresses now

having this Mac address now sent through

the r protocol back to host 8 allows

host a to finally build the frame that

we talked about in the beginning with

the source of a in this nation Mac of C

right and they're going to be able to

communicate with host C this way now the

r protocol as you can see it's a pretty

simple right it's basically a broadcast

asking about an IP address and then a

simple reply unicast reply coming from

the actual host that has that IP address

as you can see there's no security built

in here I'm going to talk about this

later on as well all right so just to

summarize what we just talked about carp

is going to be used to find out the

layer 2 address of a layer 3 destination

you know the IP address you need to know

the MAC address as well because

otherwise we cannot build the frame and

we need to build a frame because

otherwise we don't have enough layer 2

information to communicate now if the uh

if this nation is the same network we

expect that destination to answer to us

if it's not in the same network well

depending on how network is configured

we might have the router reply to us on

behalf of some other destination that is

in a connected Network behind that

router this needs to be configured

specifically because by default this is

not going to work and this is called

proxy orb proxy ARP it's broadcast based

because we need to reach out to everyone

I don't know what this nation is

actually located so we need to ask

everyone and it also doesn't have any

kind of authentication encryption

information in there we have no way of

knowing if whoever responds to us

telling us that we they are the owners

of that specific IP address

their lives was or not that we have no

way of checking this which is pretty bad

actually

but the r protocol has been developed

very very long long time ago when

security wasn't really the first concern

now pretty pretty much everyone was

concerned with oh my God we had

something that works we have a network

that works that's so awesome uh let's

make it as easy and simple to implement

as possible and unfortunately we're

still using it nowadays our protocol

works exactly the same way as it was

designed a long long time ago in

networks nowadays and since we mentioned

IP addresses as well again there's a lot

of talk about Here If This Were a

networking course we would be talking

about this for an hour keep in mind that

we currently have two versions of Ip in

use we have ipv4 which relies on an IP

address of 32 bits in length and IPv6

which has 128 bits in length now the

ipv4 address space at least the public

address space is has been for some time

dangerously close to being exhausted and

we kind of developed a lot of solutions

around it just to drag this on as as

much as possible for as long as possible

and we're still using it nowadays now

isps recently have introduced IPv6

Services as well you might be surprised

to check your home router to see whether

they have received an IPv6 address from

your router as well along with the ipv41

now the ipv4 packet header that's where

the all the additional information is

stored about the actual data uh kind of

looks like this so we get this picture

from Wikipedia we can easily search for

the ipv4 header or ipv4 packet on

Wikipedia we have a couple of fields

here that indicate the length of the

packet the class of service in case we

want to prioritize the uh the specific

type of traffic we have a time to live

which is not exactly related to time but

it's basically just a way to avoid a

packet infinitely looping through a

network and this TTL here is decremented

by one on every router on every Hub a

common values here would be 64 or 128 or

something like that we have the protocol

here which is is uh not the version of

the protocol this is the the version

field here on the left but instead the

protocol is actually the uh the upper

layer protocol so this is how IP

announced what type of protocol follows

it what's inside of it so this would be

something like TCP or UDP right uh what

we're interested in is Source address

destination address right here these are

the actual 32 bits as you can see here

from 0 to 31. these are the 32-bit

addresses both source and destination a

couple of options and finally the rest

of the data as it is encapsulated within

the ip4 packet surprisingly enough IPv6

is a whole lot simplified from ipv4

because again MP4 was designed a very

long time ago and no time we figured out

that we don't really need all these

fields anymore it's not exactly

efficient to include them all whenever

we don't need them in a specific type of

traffic so we have a much smaller number

of fields in an IPv6 a header right here

you can and also see that we have a

source address and a destination address

this time of 128 bits in leg now for

ipv4 addresses you probably know this we

tend to write them in decimal format

that is we divided in four octets four

bytes and the equivalent in base 10 of

each of these bytes becomes the actual

value that we use to describe the ipv4

address so in total we have 32 bits

which means four bytes 4 times 8 32. now

on the other hand with ibv6 since the

addresses cover a lot more space there

are a lot more bits in there we use the

hexadecimal notation because it helps us

write fewer characters so we divide them

onto eight sequences of four hexadecimal

characters now each pair of hexadecimal

character here is basically one byte so

each grouping here has two bytes well

two bytes times eight groups makes it 16

bytes and then if you multiply this by 8

16 times 8 it's 1 128 bits in length and

as we mentioned before routing

information can come from directly

connected networks or from static routes

but of course this is not going to scale

it's not going to be really easy to

maintain because adding new destinations

adding new networks to making changes in

there is going to require manual

Intervention which is extremely error

prone we can much better rely on routing

protocols running protocols allow

routers to talk to each other and

communicate this routing information

basically communicate destinations and

how to reach those destinations now

among the most important routing

protocols nowadays we find rep routing

information protocol ospf open shortest

path first pretty much the most widely

used internal routing protocol inside of

the company Network or a data center

have bgp border Gateway protocol which

we're using whenever we have larger

networks and we need to announce over

the internet and it's also used by isps

to communicate between one another Isis

intermediate system to intermediate

system with a bit of a straight Ranger

protocol not so often used nowadays but

also similar to ospf and finally ergrp

enhanced interior Gateway routing

protocol that's a mouthful it's a Cisco

proprietary protocol it's pretty easy to

use pretty nifty and uh nicely done but

unfortunately it only works on Cisco

Hardware now for a security training or

a security certification you don't

really need to know more about this just

be sure that you can recognize these

protocols if and when they will be shown

to you what an exam now you might

encounter the term Network segmentation

on the exam and another segment is

basically a region inside the network

where hosts can freely communicate with

each other usually through a layer 2

addressing method that is going through

a switch or an access point and we also

call these Network segments sometimes

subnets or vlans or broadcast domains

broadcast domains because as we

mentioned before a broadcast can only

travel freely within a single Network it

doesn't go outside the boundary of the

network doesn't go through any routers

so the domain over which a broadcast can

reach we call this a broadcast domain so

that broadcast domain becomes the entire

local network or the network segment

where all the hosts can freely talk one

way of implementing segmentation is

simply by using routers or layer 3

switches so we have a couple of hosts

connected to a switch and one network

other hosts collect a difference between

a different network they can only

communicate through that router and

router also has the opportunity to allow

our deny that traffic between networks

And Thus We've created two segments

segments can also be created within a

single layer 2 switch and this is where

we introduce the vlans now VLAN it's

basically stands for virtual local area

networks the VLAN is basically a way of

segmenting networks without relying on a

layer 3 device we can configure a switch

of course we need a man and switch for

this to have each port in a specific

VLAN now only ports that belong to the

same VLAN same VLAN number can freely

communicate with each other the rest of

them are going to have to go through a

layer 3 device which can be routed all

layer 3 switch this is how we can ensure

Network segmentation without using layer

3 devices vlans are supported on pretty

much every manage switch out there

including layer 2 ones and generally

since we have completely separate

networks created by these vlans the IP

addressing scheme also assigns different

subnet addresses to these vlans so in

most networks the term View are going to

be the same as the term for a subnet or

a network segment and they're pretty

much all going to mean the same thing

useful concept here is the term of

topology first the topology is basically

the way a certain network is designed or

of how the hosts that will not create

the subnets or the segments are are

located and organized now the building

block of a topology is called a Zone and

this is a term that is found in a lot of

security documentations for firewalls

and other networking security devices

and the zone is basically a location

inside of a network where all the

members of that zone get the same

security treatment so the same security

policies apply to everyone and since the

zone maps to a specific security policy

you can probably imagine something like

well the entirety of the internal

network is going to belong to the same

security policy because everybody who's

inside of network is going to get the

same security treatment and we call this

the internet Zone on the other hand

whatever it's not doesn't belong to us

it's not inside of our local network

which is probably on the internet I'm

going to call this the internet zone of

course I'm going to trust the internet

much more than we trust the internet and

we're going to make sure that we

carefully filter and allow only desired

traffic that goes on between the

internet and the intranet and somewhere

in between we can find something called

the Extranet this is usually regarded as

the network that is made up of remote

connections that you that you trust as

in vpns with partners with suppliers

maybe even the VPN connections with your

remote workers or other offices that's

going to be the uh the Extranet now of

course this doesn't mean that these are

the only three zones possible on every

Network it's up to you to find as many

zones you need according to your

business requirements your network

topology to the purpose that you're

using that Network for so might have a

different network for the data center it

might have a different network for or a

zone for the guest wireless access you

might even want a different zones for

different compartments within your

company it's up to you but the idea here

is that a security policy now becomes

just a set of rules on an access control

list that dictates how traffic should

flow if it should flow between these

zones so we're not just focusing on a

specific source and a specific

destination but the policy that we're

building the security policy that we're

building is going to address traffic

between zones and of course a member of

any Zone that is trying to communicate

with a member from another zone is going

to obey those specific security policies

another very important concept and Zone

design and in firewall design actually

and security is called a DMZ or a

demilitarized zone and the idea of a DMZ

has been introduced along with the fact

that there are certain situations

whenever you're designing your zones in

your network where certain hosts or

servers need to be exposed in the

internet so we might have an internet

facing host that is is hosting a website

and it's hosting an email service that

is hosting a VPN endpoint that allows

users from the internet your own

employees perhaps to connect to your

local uh at your entire internal network

over VPN but this type of design

requires you to have a number of hosts

that have some sort of Internet exposure

and those hosts that are exposed to the

internet are most likely going to be

placed in a specific Zone in a special

Zone called a DMZ demilitarized zone now

of course this TMZ here I'm gonna have

some very strict security policies to it

as to avoid situations where an internet

facing host gets compromised and then

the attacker through that host gains

access to the rest of your internal

Network this is something that you don't

want to happen in another use case for a

host located inside of a DMZ is called a

Bastion host now Bastion host it's

basically just a special heart and host

or just a server basically that accepts

coming connections from the internet

authenticates the users authorizes them

and then it allows access to the rest of

of the infrastructure this is sometimes

found in Cloud environments where you

don't want to expose the entire Cloud

infrastructure to the internet but

instead you only expose a single point

of entry and you harden that point of

entry as much as possible of course so

that you have access or legitimate

admins have access to that

infrastructure without compromising the

the Integrity of the entire

infrastructure

and we have a couple of possible

topologies using DMZ the first one being

screened subnet which kind of looks like

this so between the local area network

and the internet on the right hand side

we have a couple of firewalls number one

and number two right here and the

segment with between those two that's

the DMZ all right this is where we host

a bunch of services like email or web

services or vpns or whatever there is

but this entire subnet right here is

called the screen subnet now of course

this doesn't really require you to

invest in two actual firewalls it can

also be implemented as a single firewall

here where these two firewalls are

basically two contacts or two virtual

machines inside of that this larger box

so you can have traffic going in through

context number two being routed through

a subnet in here which hosts a bunch of

services and then coming out through

Qantas number one going forward towards

the land and vice versa and your

policies are going to be implemented in

both contexts in here here so you're

going to have one type of policy for

traffic that goes from the internet and

it's trying to reach the DMZ and another

type of policy probably very restrictive

coming from the DMZ and trying to reach

the internal Network most likely this

connection here is not going to be a lot

because this is exactly what an attacker

would attempt if they manage to

compromise the service from within the

DMZ they're going to try to upgrade

their access leverage other resources

inside of your local network and you

don't want this type of communication

here to happen not to mention that of

course communication between internet

and local area network directly

communication direct communication here

is also not going to be allowed either

all right so this is the screen subnet

second one is the three-legged firewall

which is probably the most common one

where we have a firewall right here in

the middle and we have the local area

network on the left we have the internet

on the right and then we have a separate

interface on the firewall which we use

it to hold the DMZ services and that's

it now course these policies here are

going to be implemented exactly the same

way that is going to have a type of

policy from the internet going through

the DMZ another one from the DMZ to the

land which is probably going to be a big

No-No and of course back and forth here

depending on your requirements onto each

and every uh Zone that you have in this

topology as I said before uh Zone design

and firewall basically transforms your

security policies as policies that are

implemented and enforced between zones

not just specific sources and

destinations and that's a three-legged

firewall

finally the last example here is the

cheapest type of DMZ called a screened

host we have topology that looks like

this we have a router here that connects

us to the internet we have the screen

host right behind this router we don't

have a true DMZ here but on the router

we probably have some port forwarding

rules here that allow specific

connections to reach this screened host

for the rest of them of course the

traffic is going to be denied going

through uh the Sprint hosting now this

this implementation is usually found in

very small networks where just a simple

server needs to be exposed on the

outside world probably just for email or

web or something like that it's not a

true DMZ and it's often implemented

whenever the actual router doesn't

really have true DMZ functionality or

doesn't have enough interfaces to

implement it finally a couple of design

accelerations when it comes to securing

networks starting with IPv6 policies

whenever you have IPv6 in your network

be very careful that the security

policies that apply tip before should

also apply to IPv6 in many situations uh

applications or services that you

install from third-party vendors and

even network security devices or even

regular network devices like switches

and routers they're going to come with

IPv6 enabled but unconfigured but not

configured which means that if you

forget about it if you forget completely

about IVs they don't even know it's

there it's basically a very open attack

Vector because you focus on designing

your security policies you know traffic

flows on ipv4 but you completely forget

about ibv6 and ibv6 by default is going

to be really permissive I mean if you

don't have any kind of security policies

in place depending on the networking

Hardware the network device traffic

might be allowed to flow freely so don't

forget Implement security policies in

IPv6 if you're using it and if you're

not using it make sure you disable it

don't leave it as it is by default

hackers and attackers are not picky

they're not going to complain that ipv 4

is not available

virtual machine communicates with which

virtual machines with data which

databases which storage appliances and

if any of the components in your

application becomes compromised you

might not be able to see the extent that

compromise is going to affect your

entire network because if you're only

implementing perimeter security you're

only looking at North South traffic

traffic that goes in and out of your

network and you're not looking at

traffic that travels within your network

between different Services between

different virtual machines perhaps

you're going to lose a lot of visibility

it might not be able to identify the

fact that you've been breached so

East-West traffic becomes traffic that

it's internal to your data center

between your applications between your

services but don't forget about that one

either a lot of security appliances

nowadays especially virtualized ones

have the ability to inspect traffic that

travels between virtual machines that

doesn't even go outside of your day of

your data center

and also on the topic of East-West and

north south a concept called zero trust

was introduced not so recently but it

actually came to be as a as a marketing

term but fortunately it got a lot of

traction and it was actually implemented

in a lot of security products out there

which means that and zero trust actually

means that we are not going to trust a

device or a user simply because they are

located within the network perimeter

because it might be a compromised user

it might be a compromised host and this

is a way of saying that we should stop

relying on secure on Perimeter security

only don't just assume that if something

is in your network is to be trusted so

in order to have zero trust we include

Security Solutions that continuously

monitor the traffic that travels even

within the network who communicates with

with who and which device communicates

with which device who initiated a

connection what type of protocol they're

using are they supposed to be running

that service that protocol or not how

often are they communicating at what

hour are they doing it so it's a bit

difficult to pinpoint exactly how zero

trust is supposed to be implemented it's

more of a concept that encourages you to

check and verify an authenticate and

validate each and every connection

attempt that happens even within your

local network right so stop trusting

things simply because they went past the

the perimeter firewall alright so that's

it for today I know we had a lot to

cover in this chapter but I hope you

found it useful and informative so if

you like this you know what to do with

the like And subscribe buttons and if

you want to support this channel there

are some methods available to you in the

video description so thank you for

watching and see you on the next video

bye bye

[Music]

foreign

[Music]



17 17 


foreign

[Music]

welcome back quick and easy chapter

today about security built into these

switches and the routers that you

already have but before investing into

more complicated and more complex

security devices let's properly leverage

what's already in our Network now as we

talked in the previous video a lot of

the traditional protocols that we still

use nowadays starting with IP or ipv4

and the address resolution Protocols are

inherently insecure that is there's no

security built into them because they

just weren't designed with security in

mind back then when well things were so

young and everybody was so eager to

invent something new that simply worked

and didn't have to think so much about

security Now nowadays we do have to

think about security and fortunately a

lot of the traditional devices that we

already have in the network like

switches and routers and access points

and wireless LAN controllers they do

have security function now that can be

enabled now it's built into them it's

not enabled by default but it's there

and should be aware of that before going

on and buying expensive Hardware

security dedicated hardware and starting

with switches even layer 2 switches can

enable security functions that are

extremely effective and even though they

are extremely simple actually and at

layer 2 fortunately there's not much

that can happen from a security

perspective but most attacks are going

to focus on eavesdropping on network

traffic that is intercepting that

traffic and being able to read it even

though it wasn't destined for the

attackers it doesn't necessarily require

the attacker to be on the traffic path

we're trying to focus on a couple of

methods that we can use to trick the

networking devices especially the layer

2 switches and the way the r protocol

works that we are the legitimate

destination for that traffic all right

so we're going to see some interesting

examples right now now the most common

method of intercepting traffic and also

the most generic one is called The Man

in the middle like or the on path attack

this will be requires the attacker to

actually position themselves within the

traffic flow between the source and the

devastation now of course a couple of

methods in place can ensure that this

doesn't happen such as not being able

for the attacker to position itself

between the source and the destination

or by using encryption so we are

assuming that an attacker could

intercept the traffic but we can be

pretty sure that they will not be able

to decrypt it now not everything can be

implemented in Layer Two again we're

focusing just on Layer Two so Matt in

the middle could be a Bowsman attack

replacing themselves instead of the

traffic path it could also be about uh

spoof for example DNS requests and then

replying to a simple client that is

trying to access a website with a fake

website thus the attacker being able to

intercept perhaps the login credentials

to that website it's also a man in the

middle attack it's not just about

eavesdropping on traffic if you manage

to intercept that traffic you can

probably modify it or alter it in some

way thus affecting the Integrity of the

the traffic and the most carbon method

for performing a man in the middle

attack on layer 2 So within a single

subnet is by performing Mac address

spoofing that is basically about

announcing a fake Mac address instead of

the real one now it's not just a matter

of you know generating a random number

for for that Mac address but of course

ideally an attacker should announce

themselves with the MAC address of

somebody else on the same network

segment thus attempting to overwrite the

entries in the cam tables of local

switches and after correctly answering a

couple of ARB requests with spoofed ARP

replies all the traffic that is

legitimately destined for another

destination in the network is going to

reach you as an attacker instead now Mac

address proofing can easily be done in

most operating systems including a

virtualized environment so it's not

really a method that requires a lot of

expertise simply override the MAC

address that the host is going to

announce sometimes this feature is going

to be called Mac close owning especially

when you're actually stealing somebody

else's Mac address and you start using

it and actually the biggest and most

problematic protocol that we find in

layer 2 is the the protocol that allows

to mitigate to layer 2 that is ARP

address resolution protocol if you

remember from the previous video we said

that it's used whenever a host attempts

to communicate with another host they

know their their IP address but they

don't know their Mac address in order to

build those frames right so they send an

ARP request it's a broadcast everybody

receives it and the legitimate host that

actually owns that IP address replies

with the unicast message saying this is

me this is I do have this IP address and

this is my Mac address so you can start

sending traffic to me now there's no

security here there's no authentication

there's no encryption everybody can see

those ARP requests everybody can answer

those ARB requests with fake ARP replies

which means that if somebody else wants

to impersonate us it's on the same

network as us nobody's stopping them

from answering

instead of us right without with a fake

ARP uh reply basically becoming the

destination for any traffic That was

supposed to reach us which is pretty bad

but actually the bad news don't end here

unfortunately the ARP protocol was

designed in such a way so that a host

can learn from an art reply even without

having sent an ARP request from the very

beginning because ARP is completely

stateless it doesn't hold any state

information it cannot actually connect

requests with replies so whenever reply

comes in

every host is basically going to say

that wow this is useful information I'm

going to use this who cares if I did not

request it I've received an unsolicited

ARP reply with useful information I'm

going to learn from this information and

start using it which means that it's

awfully easy or in an attacker's hole

it's a subnet to basically tell everyone

on that subnet fake information about

specific destinations now the most

widely encountered scenario involving

art proofing and Max proofing is for an

attacker to present themselves as the

default gateway in the network telling

everyone hey the default game we just

changed you know this is the new Mac

address of the default gateway if you

have anything to sell to the default

gateway which is probably going to be

traffic destined for the internet send

it to me because I'm the default gateway

and everybody's going to believe them

right and there you go you suddenly

start receiving all the real traffic

that is supposed to go to the Internet

that's a legitimate and powerful man in

the middle attack now of course you

should perhaps take care to reroute that

traffic to the real internet gateway so

that you can be able to actually look at

the real uh conversation between your

your clients and any destinations on the

internet because you're probably trying

to intercept some passwords in there

you're going to want to look at some uh

some chat messages perhaps emails and

such so let them flow right don't just

break a connection right there make sure

that the uh the actual traffic can reach

the intended destination even though

you're in the middle right you're you're

the man in the middle so basically our

spoofing or our poisoning is about

injecting this defect information and uh

somebody else's art table right every

operating system stores on our table

they remember who they communicated with

in the past and all the replies they can

that came in in the past so that they

won't have to send a request and reply

every single time they want to

communicate with somebody on the network

and keep in mind that unsolicited our

replies are a very dangerous behavior

that is enabled by default in every

Network and is a special by the actual

implementation of the r protocol now a

couple of the tools available that you

can use to perform attacks such as these

or tools that attacker is going to be

using are called error cap D sniff or

spoof or even the metal sploit framework

has plugins and modules built into it

that can launch in our spoofing attack

now if you also have an an older

operating system because it's not

supported anymore you could be using the

cane software as well if you're running

on an older OS that one that tool also

had a built-in functionality for

Performing Arts spoofing again for the

exam you don't really need to know how

to use these tools just make sure you

can recognize them out of the list if

the exam asks you to

now we also have later two attacks that

are destined toward the actual switches

that ensure communication between the

hosts now as you remember from the

previous video switches do have a cam

table that they use to forward traffic

to the right ports and they learn the

information that reaches those cam

tables simply by looking at the source

of traffic if they see a specific

address coming in from a specific Port

they store this information just in case

at some point in the future somebody's

going to want to communicate with that

destination and they're going to know

exactly where it is located now when the

cam table is completely empty is for the

switch to broadcast any message that it

receives onto all the ports because it

doesn't know where the destination

actually is but it knows that if it

forwards it to all the ports eventually

is going to reach the internal

destination

now there's also a behavior that happens

whenever the switch memory is full so

when the switch cannot learn new

information and the destination is not

within that table what it do well

exactly the same thing it starts

flooding information flooding traffic

out all the ports which means I'm

already thinking about this well what if

we start sending bogus traffic with fake

randomly generated Mac addresses

to the switch

up to the point where the switch memory

becomes completely full well when the

switch memory becomes completely full

any traffic that tries to reach that

switch is not going to be able to find a

valid destination because we just filled

it with bogus information right and the

switch is not going to be able to learn

new information again because the memory

is full so what is the switch going to

do well it's basically going to

transform any unicast communication in

the network into broadcast communication

which means that if we are an attacker

connected to the same network segment

we just have to

listen up and all the traffic within any

host inside of that network is going to

reach us as well

so it's a very let's say uh violent type

of man in the middle attack that can be

performed basically tricking the switch

and sending all the traffic that it sees

onto all the ports that it has including

the one that you're connected to you as

an attacker so that's another type of

Mac flooding attack Loops at Layer Two

basically represents specific types of

topologies where the networking devices

the switches layer two switches are

connected in a cycle all right so Loops

for what physical perspective are good

because if any connection within that

Loop breaks let's say there's a cable

Force maybe an interface dies maybe

maybe even an entire switch uh sees the

function we still have an alternate path

available to us and to all the other

devices that can connect to the other

switches so that they can still

communicate with each other so we have

physical Loops which are okay now

logical Loops that is Loops in the

actual traffic path well at layer 2

they're not so good because at layer 2

if we look at the generic ethernet frame

structure unfortunately there's no such

thing as a time to live or any Loop

prevention mechanism so if it just

happens that due to a faulty design

our frames start cycling around

indefinitely inside of our Network

they're going to keep doing this forever

unless we actually pull the plug on on a

network cable or on a on the actual

power of a switch so there's no Loop

prevention mechanism built into layer 2

frames which means that we need to rely

on protocols that ensure that these

logical Loops when they happen they

don't break the network this is where

STP comes in that's a spanning tree

protocol now Spanish protocol again

without going into too much detail

because this is not a networking

training it's a protocol that runs

between layer 2 switches and they

constantly communicate information on

the links between those switches so that

whenever a physical Loop is detected

those switches take care of manually

shutting down specific interfaces so

that a logical Loop doesn't happen so

basically what what it does is that they

transform a cyclic topology into a tree

topology if you know from if you

remember from data structures and

algorithms perhaps back in your college

days a tree data structure doesn't have

any Loops just like the the branches of

a tree right there's no Loops in there

it's just branching and branching and

branching and that's it but there's no

way for a packet to cycle back to the

same device now the tiny packets that

are communicated between the switches

that are running STP are called BPD use

which stands for bridge protocol data

unit it's just a small packets including

some identifiers that helps these

switches decide which ports they're

going to shut down temporarily just to

avoid Loops which is going to be the

root of the the actual tree that is

being built as per the STP algorithm and

so on now again STP is a very old

protocol bpus don't have any kind of

security built into them or potentially

an attacker connected to the network

could present themselves even though

they only have a workstation or a laptop

they could present themselves as a

switch as a layer 2 switch and they

could fool the other switches in the

same network into believing that they

the attacker the attacker's device is an

actual switch that can switch traffic

now by using these fake crafted bpdu

packets they could potentially change

the action topology of the stp3 and this

would be another way to implement man in

the middle present yourself as a switch

make sure that all the other switches

reconfigure their topology so that all

the traffic flows through you

all right now in order to avoid this we

can simply Mark specific ports on our

switches configure specific ports to

reject any bpdus and that's implemented

as something called bpdu Guard we're

just rejecting ppdu packets because we

know that ppus are only supposed to be

sent by legitimate switches if we know

that all our access support supports

that connect to actual workstations are

not designed to connect to any other

switches we can simply block the video

traffic onto all of these ports thus

avoiding situations where an attacker

might present themselves as a fake

switch finally another very simple

method of avoiding potential attack

especially denial of service attack in a

layer 2 network is by enabling something

called a broadcast storm control or just

storm control sometimes what this

actually means is that as you probably

know a broadcast is going to pass

through a switch on impeded so a switch

by default forwards broadcast messages

onto all this all the reports now

potentially an attacker could attack the

STP infrastructure and create a loop

inside of the network intentionally

create a look inside of a network now if

a broadcast message were to circulate to

reach that Loop is going to continue

looping in that specific piece of

infrastructure indefinitely this is

going to lead to very high CPU

utilization on those switches saturated

links that cannot send legitimate

traffic anymore thus basically creating

a denial of service attack into the

network so it's not just a matter of

attacking layer 2 Network for

eavesdropping on traffic but it's about

attacking the network to make it stop

functioning properly now broadcast storm

control is just a matter of monitoring

the usage of all the ports for specific

thresholds now if you keep seeing the

same frames looping around around over

Network and we see huge traffic spikes

onto specific ports then we can simply

shut down that port or just block that

specific Mac address for M from ever

communicating onto the switch again now

what about actually filtering traffic at

layer 2. we know that at layer 3 we have

routers and firewalls and we can create

that control list so that's allow or

deny specific types of traffic based on

their IP addresses or subnets that they

belong to well we're about Layer Two

well at Layer Two we can only filter

based on Mac addresses of course which

means that of course certain layer 2

switches allow us to create something

called a Mac access list which is

basically just a list of Mac addresses

that are allowed to communicate through

a given Port now this is also sometimes

implemented in a in a global manner over

the entire switch and it's called MAC

address filtering it's just a matter of

defining a list of allowed Mac addresses

that are allowed to send traffic through

that switch of course we can even adopt

a block list approach to this uh to this

implementation and instead Define a list

of Mac addresses that are not allowed to

communicate over that Network which of

course is not really practical since Mac

address spoofing is painfully simple to

achieve so you're not really gaining

much security by trying to capture all

the malicious Mac addresses onto a

single list okay why this approach is

much better apart from the actual MAC

address filtering which you can probably

guess it's not going to be very

convenient and it's going to require a

lot of admin effort we could instead

Implement something called Port security

Now Cisco calls it poor security some

other vendors call it sport security as

well well basically it's just a way of

automatically manage the allowed Mac

addresses onto a switch how can you

automatically manage this well

unfortunately there aren't many methods

so apart from manually configuring Mac

addresses which we just said is not very

convenient we could do something a

little smarter that is once we power the

switch up and once the all the hosts

gonna connected to that switch start

sending traffic we tell the switch hey

look at the first Mac address that you

see on each and every port and store

that Mac address in your memory and also

make sure that no other Mac address is

going to be allowed on that Port from

now on so the first type of traffic that

the switch sees is considered to be

legitimate traffic ideally this is going

to happen in a controlled environments

right when you actually install the

switch hopefully the attacker is not

already in the network by then and then

the rest of the traffic is going to be

filtered based on that initial

information so everybody boots up

everybody comes into work Monday morning

they boot up their workstation the

switch remembers aha so these are my

legitimate destinations these are my

legitimate workstations I'm going to

store them in a permanent memory so

we're not talking about the cam table

here we're actually talking about

specific table that is designed to

ensure the support security

implementation now of course we could

increase this limit

that is we might be able to allow maybe

two or three Mac addresses onto every

port which is a very common scenario if

you have an IP phone and a desktop

workstation and perhaps a laptop on your

desk as well so you're gonna need 12 two

or three Mac addresses in order to

maintain connectivity but nevertheless

this implementation uh eases a lot of

the administrative burden of manually

configuring uh whitelisted Mac addresses

now some people call this a sticky Mac

address implementation that is because

the actual Cisco IOS command is Mac

address sticky so we call Sticky because

you know the first one that we see

kind of sticks right there on the board

and it becomes uh the only allowed Mac

address now as you can probably guess

we're doing this uh Mac address sticky

Port filtering uh business in order to

avoid situations where a attacker is

going to impersonate a legitimate user

so we're doing this against Mac address

spoofing now there's another problem

here which poor security doesn't fix and

that is our spoofing remember we said

that the r protocol is designed so that

even if a reply is received without any

request being sent that reply is still

going to be processed by each and every

host so unfortunately while poor

security doesn't help us with this we do

have problems of mitigating this type of

our spoofing as well and that relies on

a feature called DHCP snooping now the

HTTP host configuration protocol is a

protocol that you you're probably using

in your home network in your office

Network whenever you're connecting to

the network you're receiving an IP

address a DNS suffix a subnet mask uh

perhaps some additional information

automatically from the network so it's a

way for you to automatically configure

your network card the moment you connect

to the network all right now this DHCP

protocol again it's a type of request

response we send a request a podcast

this is unicast coming back here as a

response and after you've received the

valid IP address you know signing that

IP address to your network card you can

start communicating over that Network

segment and also with the default

gateway which is most likely an

information being received automatically

through the HTTP as well now this type

of traffic can be very useful in

identifying who is connected to which

port

unfortunately by default nobody is

looking at this information nobody's

looking at DHCP traffic but we can

configure our switch to inspect to Snoop

on the DHCP traffic in the network so

the switch is going to just look at the

DHCP traffic that that flows through it

let's see the request it's going to see

the replies and silently is going to

remember

which hosts which IP addresses and which

Mac addresses are located on which ports

so we're going to build a small database

of everybody who is connected uh to the

uh to the local switch

and then if at some point an admin

enables another feature called Dynamic

ARP inspection the switch is going to

start looking at ARP requests as well

why does it do this well in order to

identify our spoofing with our spoofing

eventually we're going to see an

attacker that announces themselves

with a different Mac address than the

one it was initially detected on that

port

and the switch knows about this because

the switch knows

the original Mac address due to the fact

that it was snooping on the DHCP traffic

from the very beginning so it knows

which host which IP addresses and which

which Mac addresses are connected on

which ports so if somebody starts

goofing around and starts announcing a

wrong or different Mac address the

switch is going to catch it immediately

and it's going to deny that traffic and

this combination of the HTTP snooping

with Dai Dynamic ARP inspection ensures

that a ARP spoofing man in the middle

attack suddenly stops being possible

within our Network segment and we don't

need any additional devices for this

this is just functionality built into

many not all of course layer 2 switches

nowadays going up in complexity as to

the security method that we can

Implement in the single Network segment

we suddenly reach the functionality

called network access control or neck or

network access protection or or pnac or

pnap any kind of combination nation of

acronyms here actually refers to the

same thing and because there's a lot of

confusion here we actually have a

standard behind it which is called 802.1

X network access control now this is a

type of protocol or security method that

can be implemented at switch Port level

again we're only talking about layer 2.

and we can configure that switch port

to make it mandatory for whoever

connects to that switchboard to present

some sort of authentication information

before being allowed to communicate

further through that switchboard if

we're talking about switch ports here it

doesn't mean it only applies to the

wired environment you can also apply

this in Wireless using access points

right but for the sake of the Simplicity

here because we also have a screenshot

here with the with the ethernet ports in

here we're just going to focus on the on

the wired equivalent now there are a

couple of protocols involved in this

communication some of them are under the

umbrella of EAP extensible

Authentication Protocol and the actual

protocol that is allowed between the

device that connects to the port and the

switch before they're even complicated

is called EAP over land that's the

protocol that can carry authentication

information that the device can present

before they're being given access to the

rest of the network now the other

authentication information can be as

simple as the username and the password

uh could be as complex as having

received a web portal where they could

authenticate perhaps to a third-party

device or a smart card or one time

password it could even be based on uh on

a certificate that is installed on that

device itself all right we can even

perform separate device authentication

and separate authentication for the user

of that device so there's a lot of

complexity built into this fortunately

you don't really need to know all this

for the exam but the important thing to

know here is that any switches that

support the type of authentication are

going to have to rely on an external

database as well in many situations that

external database is called the AAA

server that is an authentication

authorization and accounting server

which could be a radius server which

could be your your ldap server your your

active directory server perhaps in your

network it's it's going to be a

centralized database of whoever should

have access to the network so the

switches

receive those authentication requests

forward those authentication requests to

the AAA server they receive a yay or an

A a response from that server and then

in turn reconfigure dynamically

reconfigure the port that you're

attempting to connect to to either block

all access or allow access according to

your credentials and your identity now

optionally we can also augment this

authentication mechanism with something

even more complex that is called a

posture assessment so you're not just

looking at let me see if you have valid

credentials if you know the password

when whenever you're requesting access

to the network but instead I'm going to

try looking at your actual device let's

see are you running windows are you

running uh Apple iOS are you running

Linux Mac OS

do you have the latest updates what

versions are you running is it a

jailbroken iPhone or not do you have an

antivirus installed on your device is

the antivirus has been updated during

the last two weeks right so there's a

lot more complexity that we can add here

to the actual authentication process to

make sure that we're only allowing

legitimate devices and safe devices to

connect to our Network now as you can

probably guess this type of

implementation requires uh quite a bit

of admin effort but once it's being put

into place it's completely automated it

doesn't require any manual configuration

at the Port level any device that is

accepted in the network with a valid

username with a valid certificate all

right can connect to any port all over

the network can even connect over the

over Wireless can even authenticate over

VPN it doesn't matter where I'm

connecting from or uh to which

switchboard I'm connecting to the same

policies are going to be automatically

applied to me and installed onto that

specific port and of course if an

attacker comes in and tries to

impersonate me well they're going to be

denied access to the network and the

mention here about the agent on the

slide is that well of course if you if

you plan on uh looking at specific

details regarding the operating system

or the antivirus that's installed on the

host you're probably going to have to

communicate with a specific piece of

software that is installed on that post

which is also one more proof that the

the host belongs to us as a company that

is recognized by us if it has the valid

ad agent that is configured on it and

that agent is reporting the status of

the device to the switch and then the

switch to injects it back with the AAA

server well that's one more proof that

we are dealing with a legitimate device

finally a couple of words here to

mention about securing routing

information especially the information

that comes from routing protocols so

we're talking about layer 3 here and

routers all right and where do those

routers get their routing tables from

now first of all think about the fact

that routers are just all computers

they're running an operating system and

their operating system can have

vulnerabilities can have bugs that can

be exploited and any vulnerable database

at that point going to list some

vulnerabilities for networking devices

as well so don't think of network

switches and routers being impenetrable

devices you might have everything

secured in place but due to a bug or an

exploit at the operating system level

you might still be exposed right so

another thing to keep in mind when

updating your uh your devices all over

the network

uh also an authorized information

injection is another risk which means

that by default every routing protocol

out there is not going to enforce any

kind of authentication requirements so

basically uh whoever sends a rip update

or the hrp update on ospf update is

going to be accepted now unfortunately

these protocols do have authentication

mechanisms that require the standard of

the information to digitally sign the

information that they're communicating

now the signature is going to rely on

some sort of a password or or a secret

key so that only legitimate devices from

our Network those devices that know the

secret key can properly sign those

messages so we kind of minimize the risk

of accepting information spoofed

information from an attacker

uh routing up the sniffing means

intercepting routing updates because uh

as we mentioned before these protocols

basically transfer routing information

from one router to another uh in many

cases this information is sending clear

text so a successful man in the middle

attack can easily intercept this

information being sent between two

routers you might think well how is that

says deformation why is that so

important the the interception of of

routing traffic might not be the actual

purpose of the attack but knowing a lot

about the topology the routing topology

and the devices in your network is going

to help the attacker tremendously in

their reconnaissance phase understanding

more about your network and what can be

exploited finally uh last risk that's

worth mentioning here or maybe not even

worth mentioning actually is uh it's

Source routing no normally ivpects are

being routed by the destination because

they're supposed to reach a certain

destination so each and every router

along the path then look at the

destination IP address in order to

determine where to send it next there

are certain IP options this can be

enabled in the IP header that can enable

Source routing that is additional

information attached to the IP packet

that can tell a router over which hops

this packet is supposed to be sent to

right so it's instead of leaving the

router decide how to send the packet the

packet already comes pre-configured you

need to send this back to this router

and this router and this router and this

one up to the until the the Final

Destination now this is called Source

routing it's not enabled by default it

hasn't been enabled by default for quite

some time

it's quite unlikely that you will find

source routing enabled somewhere in the

network but if you do it's pretty

obvious that along with IP address

spoofing you can even spoof The Source

routing information and make your

packets uh Traverse whatever path you

want over the networking including a

path that goes through you the attacker

in case you want to perform some man in

the middle attack

okay so keep this in mind it's probably

not going to apply to you any real life

scenario that you might you might face

in the in the near future but keep this

in mind for the exam alright so thanks

for watching I hope I managed to present

this uh this information in a an easy to

understand matter because what's behind

it it's huge I mean we're probably going

to create a networking training at some

point uh CCN HTTP ccie level perhaps

even that's when we'll cover this in

more detail but fortunately for the

Security Plus exam you don't really need

to know all the nitty-gritty details of

what's Happening behind the scenes I

really hope I managed to present this in

an easy to understand matter if I did

like And subscribe support the channel

if you wish and if you can and see you

on the next video bye bye

[Music]



18 18


foreign

[Music]

welcome back and today we're going to

talk about wireless networks and

securing Wireless infrastructure of

course now whereas networks are pretty

much everywhere nowadays in your home

where you work where you play in public

areas

pretty much every company out there has

some sort of a wireless network and of

course having a wireless network creates

its own security implications now from

one perspective securing wireless

networks is going to sound easy at first

because we still have the same protocols

that we find in the wired networks as

well we still have ethernet we still

have mac addresses we can still kind of

perform MAC address filtering uh we're

still routing based on IP addresses

we're still running the exact same

applications that we're running on a

cable network but Simply Having a

wireless network that relies on wireless

signals sent over the air means that by

default in a wireless environment we

need to start with the expectation that

our traffic can be and will be

intercepted a potential traffic sniffer

a potential attacker doesn't really have

to do anything now in order to intercept

your wireless traffic they don't have to

actually perform some sort of a man in

the middle they don't have to get into

your server room and try hacking your

into your switches they simply have to

be located somewhere next to you right

they might be performing traffic

sniffing simply by sitting in the

parking lot or on the on the sidewalk

outside of your building so you need to

think about wireless security by

assuming that whatever we're sending

over Wireless Canon will be intercepted

so we start from there how can we still

secure data assuming that it will be

intercepted and before talking about the

actual protocols and security methods

involved in Wireless there's a first

step that has a lot of implications into

everything that we're trying to secure

later on when it comes to wireless and

that is how you design the actual

wireless network starting from the

grounds up as in uh how was how's the

the actual topology of the wireless

network design that is where the access

points located how are they oriented how

is the how are the antennas oriented and

what kind of coverage those access

points offer us are we simply designing

a wireless network that we don't care

about if somebody uh you know passing by

outside of our building can connect to

it or are we trying to properly secure

it and trying to make sure that there's

as little as possible signal leakage

outside of the area that actually

belongs to us or into our business

whereas Network design of course has

performance implications the further you

are from an access point the the weaker

the signal you're going to get and less

speed and more latency you'll you'll

experience uh the even the the materials

from which the walls are made of are

going to have security implications are

you going to be able to hear or

intercept the wireless signal from

behind the wall depending on well what

is that wall made of and finally since

we are all talking quote unquote over

the same medium over the same

environment there's going to be

interference because wireless networks

are not the only ones that are using uh

the wireless Spectrum the the same

frequencies we still have a wireless

peripheral devices like mice and

keyboards and wireless headsets

Bluetooth uses some of the same Wireless

frequencies as your Wi-Fi network and

microwave ovens as well unfortunately

and while microwave ovens aren't really

trying to communicate everything to us

over that wireless medium they will be

providing a whole lot of Wireless

interference which you have to take into

account

now the basic element in a wireless

network is called the access point that

is well pretty self-explanatory it's the

point that you're using to access the

wireless network it's the actual device

that you're connecting over Wireless in

order to gain access to the rest of the

network so from a very simplistic

perspective you could think of a

wireless access point as some sort of a

wireless switch that simply switches

your packets your frames based on Mac

addresses uh forwarding them to the rest

of your cable network and we have two

acronyms here that are worth mentioning

we have first the bssid basis service

set identifier which is nothing else

than the access points Mac address this

is how you identify the access point

this is how your device your mobile

device knows that it perhaps uh

connected in the past to the same access

point and is able to recognize it so

bssid nothing to do with the SSID but

it's actually the MAC address of that

access point now wireless communication

itself is basically just a bunch of

Standards which specify exactly what

frequencies you're allowed to use uh how

are the frames being sent over those

frequencies what type of security

methods are supported and so on so one

of the main differentiators of where the

standards are their frequencies and some

of these standard names are probably

familiar to you such as

802.11

BGN or ax these are the standards that

rely on the 2.4 gigahertz band similarly

we should be able to see the 5 gigahertz

band which is more typical to the a

standards and AC and ax standards so if

you just check the back of your wireless

router or your your mobile phone your

tablets your laptops there will be a

mention of these Wireless standards

being supported probably nowadays you're

gonna find at least a 802.11 AC if not a

X already being supported

now since Wireless Transmissions are

being performed over a shared medium and

we want to be able to not just allow as

many people to communicate at the same

time but we also want to be able to push

as much data as possible we're splitting

these uh frequency bands we're splitting

them into specific channels and we call

these Wireless channels right and of

course we have a different number and

size for these channels depending on the

wireless standard and frequency so for

example for the 2.4 gigahertz we can see

here we have a range from 2.412 up to

2.472 now in this range here or even

further just a bit in in this range

right here we can see that we have at

least in this screenshot here we have 13

channels now these channels as you can

see they take up

a certain chunk of this frequency range

which means that at any given point in

time for example in the 2.4 gigahertz

frequency we can only have at most three

non-overlapping channels such as number

one number six and number 11 in this

representation now it doesn't mean that

the rest of the channels are not usable

it just means that if two people two

devices are trying to send data over a

wireless medium over to adjacent

channels there's gonna be some sort of

interference there's going to be some

sort of signal degradation which brings

us to a mention of the types of

interference that we can find and first

of all we have code Channel interference

that is when two devices or two access

points are trying to communicate over

the same channel so they're basically

competing over the same

availability of that wireless wireless

medium that wireless Channel now of

course there are methods implemented at

layer 1 and layer 2 in these Wireless

protocols so that we can be sure that we

we don't get to that situation where

everybody is just talking at the same

time and we're jamming each other and

we're just uh creating a whole lot of

interference so that nothing coherent

can can come out of that communication

all right so even if two devices are

using the same channel there's there can

still be some sort of order within that

communication chaos now there's going to

be a lot of lost brains going to be a

lot of re-transmissions perhaps but

communication can still proceed now the

other type of interference is adjacent

Channel interference just like we saw in

the previous representation right here

even though they're not using the exact

same channel if they're using two

overlapping channels such as number one

and number three for example you see we

do have this section right here that is

um that is that creates potential for

interference so we're not going to have

so many errors or so much signal loss as

with code Channel interference but there

still is going to be a bit of a single

no degradation now the singular

degradation is not going to be reported

by your device any in any other way

other than simple low Wireless speed the

signal might be good you might be close

to the AP but due to the interference

around you you might not be able to

reach higher speeds in download or

upload and all this talk about

interference is not something that we

should just take as given I mean it's

not necessary to have this kind of

interference if you properly design your

wireless layout in your wireless network

and this is why a site survey is always

recommended before starting to install

your actual access points and giving

internet access to your clients a site

survey Maps the entire layout of the of

the floor of the building of the office

that you're trying to install your your

wireless solution in it takes into

account even the placement of the walls

the material of the walls themselves

because for example concrete walls are

going to degrade your signal much much

worse than than drywall for example and

this side survey is basically just a

process where a technician walks around

with a mobile phone or a wireless laptop

and simply tests how the signal strength

behaves depending on their position if

they're not satisfied with the coverage

we can move the access point we can

change the shape of the antenna perhaps

maybe reorient the antennas make sure

that we have proper coverage in the uh

the areas which with the largest amount

of people like hallways on or lobbies

and perhaps even ignore wireless access

altogether in the in the restroom

even though some people would say that

that would be a very bad idea right

in such a wireless survey software is

usually going to produce a heat map

that's just a visual representation

color for representation something very

similar to what you're seeing right here

this one was created with a software

solution from solarwinds which describes

how the wireless signal is supposed to

behave in different parts of the of the

office you can see there's a uh there's

an office building right here there's a

floor from an office building we have

three access points currently placed in

here and we have well areas with better

coverage in areas with very little or

even no coverage at all right so this

type of map is very useful when deciding

where the access points should be placed

and how they should be configured

another concept worth mentioning here is

the wireless LAN controller or the wlc

or the wireless controller actually well

the need for a controller comes from the

fact that if you only have a small

Network like just a couple of access

points you can probably think about well

why do I need some centralized

management for that I can just log into

each access point uh you know enable

some SIDS in there enable some

authentication methods uh do some

configuration limited configuration in

there and that would be more than enough

right but in larger companies

um companies that span tens of floors

hundreds of offices thousands of access

points perhaps well this type of manual

configuration is of course not going to

be feasible and it's going to be very

error prone so for larger deployments we

have another component in the wireless

solution quality wireless LAN controller

now this is this wlc is basically just

the brain of the entire Wireless

solution it's not just a brain as in it

controls tools and configures the access

point and allows you to create those

configuration policies centrally in one

single place and then they get pushed at

the same time to all the affected access

points which is great from a management

perspective right you only make a change

once you create an SSID once and then it

gets pushed to 5000 APS in a matter of

seconds that's great another role of the

wlc is the fact that in many cases the

actual design of the network assumes

that the traffic coming from the access

points

always goes through the wlc so it not

only becomes a centralized point for

management it also becomes a centralized

point for traffic uh filtering and

traffic policies now the wlc even though

the name says Wireless is basically a

very wired device it's going to be a

server it's going to be a virtual

machine perhaps running on a server that

or a dedicated appliance which at the

end of the day is still a server running

some some application basically which is

uh connected to the wired Network it's

always connected to wired Network and of

course the uh the connections to the

access points are also going to be wired

as well so it's wireless only because it

controls the wireless environment but

the controller itself is not a wireless

device

and since I'm talking here in a security

training we should mention that well if

access point security is pretty

important because you know the access

points basically see the wireless

traffic from all the clients and you

should secure them and should secure

access to those APS well I shouldn't

need to mention that you also should

secure access to the wireless LAN

controllers as well because that's where

all the traffic from the entire wireless

network comes in all right so anybody

who wants to intercept traffic perform a

man in the middle uh capture some uh

some Wireless logins perhaps well that

one is land controller is a pretty juicy

source of information so make sure you

properly secure it just like any other

networking equipment that helps you pass

traffic from one section of the network

to another just like uh router source

which is secure them in a in a data room

ensure physical security ensure

management security so that nobody from

the internal Network or from the guest

Network up for a bit can log into the

admin interface on those devices

and finally we need to talk about the

actual uh security protocols that we can

Implement in Wireless communication

because by definition wireless means

that anybody can intersect your traffic

I mean man in the middle performed in

Wireless is all almost no man in the

middle process at all you just listen to

the traffic that's it you don't need to

intercept anything you just listen and

the traffic comes to you if you are in

the range of the communication of course

so in wireless networks we should start

from the assumption that your traffic

can and will be intercepted so what can

you do now that you've assumed that a

potential attacker is going to get your

traffic how can you make sure that they

will not be able to understand it to

decode it and perhaps tamper with it so

along the timeline of Wireless Evolution

we've seen several standards uh being

introduced in the wireless environment

which ensure encryption Authentication

different methods for generating secret

Keys rotating keys and so on now some of

these standards have been deprecated

simply because some of them have become

obsolete so the computing power nowadays

is able to crack them without much

difficulty or some of them have become

obsolete simply because flaws have been

detected in these in these protocols in

this algorithms and they can be easily

cracked that way now unfortunately

upgrading your entire Wireless

environment from one standard to the

next going to less secure to more secure

is not always possible or it's not

always so easy because more often than

not these Protocols are Hardware coded

Hardware implemented right within the

chipsets of those devices themselves

which means if the device doesn't have a

chipset that knows a more secure version

of that algorithm you're pretty stuck

with what the device can do which can

open you up to a lot of security

vulnerabilities and this is this is one

of the major

problems with wireless security

worldwide the fact that people still use

old devices that are not able to upgrade

themselves to better and smarter

security methods and they become more

and more exposed as more and more

vulnerabilities are being discovered in

those older protocols and standards

now the first protocol ever invented

that ensured uh confidentiality so

encryption with wireless data was called

Web nowadays it's the weakest protocol

there is it's completely insecure if you

if you see it as an option in your

wireless router don't ever use it don't

ever select it now it's so weak that

your your wireless network can be broken

into in a matter of seconds maybe maybe

minutes so stay away from web and by the

way the joke here is that web initially

standed for Wired equivalent privacy

which was something like a very

optimistic name for the protocol that

ended up being the weakest one and the

most vulnerable one of all Wireless

standards now on newer devices nowadays

a web shouldn't even be an option but if

you're still using some older router

from your ISP perhaps it's probably

there and if it's enabled try try please

try disable it or just replace it with

something like WPA or WPA2 now things

aren't so simple so we have a couple of

versions with WPA as well this time we

did not say that we're so optimistic so

we just called it Wi-Fi projected access

and the first version still uses the rc4

still supports the rc4 encryption

protocol encryption algorithm and by the

way this was the same encryption

algorithm that was used by web but WPA

fixed a few flaws in the original web

while still maintaining the same

algorithm for encryption and decryption

this also helped by the way device

manufacturers to Simply upgrade the

firmware on their older devices that

were designed for web to be able to

support WPA because in in the back end

the algorithms were pretty much the same

now the performance dropped just a bit

of course because we had to calculate

some more and create some workarounds

and there but this was one of the only

situations where we were able to upgrade

to a newer version a better version of

the encryption scheme without changing

the actual Hardware on the devices

themselves now unfortunately this didn't

take too long until somebody managed to

break WPA as well so further

improvements were added such as tkip

temporal key Integrity protocol

which replaces rc4 with a better version

but still nowadays we're not considering

web nor WPA to be secure enough for any

kind of wireless communication right at

least not wpa1

so we ended up with WPA2 which

introduces the AES encryption algorithm

Advanced encryption standard which is

actually pretty good nowadays we're

still using it in pretty much any type

of transaction over the Internet we're

still using AES now originally on 128

bit one of the other improvements uh

introduced along with WPA2 was the ccmp

protocol and ccmp was designed to defeat

replay attacks that is when an attacker

simply intercepts an authentication

exchange some packets exchange between

the client and the access point and then

attempts to replay the same sequence of

packets in an attempt to authenticate

himself this is a potential

vulnerability that is often found in a

lot of protocols normally this shouldn't

be possible so a replay attack can be

dangerous so people should take care of

avoiding situations where replay attacks

can can function properly and the most

common method of avoiding these replay

attacks is to embed in the actual

exchange even though the exchange is

encrypted embedding the actual exchange

something that pertains to the timestamp

the current time of the exchange so that

later on the same sequence of packets is

not going to be accepted anymore or some

sort of a secret information like a

secret key a passphrase a password in

there now for the exam ccnp actually

stands for a counter mode with Cipher

block chaining message Authentication

code protocol

now you should remember this for the

exam if you did not just remember it

just remember ccmp and Google it later

on okay

now of course nothing lasts forever and

at some point somebody was able to prove

that even WPA2 is pretty vulnerable

though not so easily vulnerable like uh

wpa1 or web

still things had to change so we ended

up with wpa3

some of the improvements introduced with

wpa3 are SAE simultaneous authentication

of equals this is basically another type

of handshake which was replaced from

WPA2 because the handshake in WPA2 the

actual initial exchange of packets was

the one that ended up having a couple of

vulnerabilities so we place this with

SAE which is just the implementation of

the diffie-hellman protocol we also have

enhanced open and this is basically a

way to ensure encryption even for

clients and for wireless networks that

use open authentication up until now

whenever we had a wireless network that

was completely open authentication wise

the traffic wasn't encrypted so we we

couldn't have any kind of expectation

for privacy on that Network now wpa3

tries to ensure encryption even though

you're not asking for a password or any

kind of authentication credentials from

your clients we've upgraded the

encryption algorithms as well so AES had

some upgrades as a protocol itself and

also for the key length so we ended up

with up to 192 bits in key length from

the 128 bits that we had in WPA2 and we

also introduced mpf management

protection frames the management frames

are basically just a special type of

frames that were also the target of

attacks in older protocols now these

management frames are those frames that

are being communicated to announce

specific events in a wireless network

and we had for some time the danger of

these Wireless management frames being

sent completely unprotected

unauthenticated which correlated with

the fact that these are the frames that

ensure that a client can stay

authenticated or is the authenticated or

deauthorized from communicating over

wireless network creates a pretty big

loophole in there I mean because we we

were sent ending

management commands for the entire

wireless network in complete clear text

without no security whatsoever so if you

ever read about the authentication

attacks perhaps uh in WPA one or two

these are possible because the

management frames are not protected at

all the authentication attack means that

you can actually craft specific

management frames and send them to the

access point that you might not even be

connected to or authenticated to to

cause everybody else to become

disconnected

that's because the management frames are

not authenticated the access point has

no way of checking or making sure that

whatever they are receiving as

management frame is actually being sent

by a valid client so we've protected

these management frames now in wpa3 as

well

so how do we authenticate to a wireless

network well you might say well we need

the wireless password right and yeah you

would be right that's at least one of

the methods that you can use and the

first method is actually called

pre-shared key that's the wireless

password or psk pre-shared key now this

pre-share key means that like the name

says it has to be pre-shared among all

those who attempt to connect to the

network and

it has to be shared with the access

point as well because the access point

has to be able to check the key that is

correct right it's also known as group

authentication because everybody is

using the same key so they all become a

an authentication group basically

there's no

um identity information tied to that

wireless password that enables us or the

access point to identify well uh if the

client is showing me this password then

that client must be Andrew no there's no

such thing I can only know that somebody

from the entire group that knows that

she that share key has connected has

authenticated right now in WPA2 at least

the keys that need to be configured for

psk have to be at least eight character

ASCII character in length and at most 63

characters now like in many places in

computer security the actual encryption

key is not the one that you've provided

as a pre-shared key now your your key

your word your password is is taken and

then put through a process of hashes

that actually results in an age Mac of

256 bits in length and that's going to

be the actual encryption key because

otherwise Keys would be pretty easy to

crack right if we were to just use them

as the user entered them or as the admin

can figure them on the access point and

this process by the way is called key

stretching you take a smaller key you

run it through a number of computations

in there and you end up with a much

larger much longer seemingly random

string of bits key and that's the key

that you're using for the actual

encryption now what we're talking here

about is the so-called personal mode

that is the non-interest price networks

so we're not using a centralized server

for authentication we're just you know

configuring a simple wireless password

for a small office or home office that

is that relies on a shared password on a

pre-shared key now the same pre-shared

key authentication method is also

supported by wpa3 but wpa3 introduces

some small changes so the actual process

that wpa3 uses to generate those

encryption Keys is now called p-a-k-e

password authenticated key exchange

remember this for the exam we also

talked about SAE simultaneous

authentication of equals which we said

that is a process that replaces the

original handshake it actually was a

four-way handshake that we had in WPA2

which was proved to be vulnerable

the actual name of the handshake is

called the dragonfly algorithm which is

basically just a diffie-hellman

algorithm over elliptic curve

cryptography which is also combined with

a hash of the user's password another

authentication method for personal

networks was called WPS actually it's

still available nowadays but let me tell

you why you shouldn't use it WPS was

invented because for some people you

know configuring ssids and passwords and

choosing encryption algorithms is pretty

complicated especially for non-technical

people so vendors invented something as

simple as the push of a button you try

to connect to a wireless network and if

you have access to the router that hosts

that wireless network and you push the

WPS button on that router you are

instantly connected and authenticated

over WPA too pretty easy right

everything happens in the background you

don't really need to know anything about

how that wireless network is configured

you don't even really need to know the

password of that Network it's enough for

from a WPS perspective that you have

access to the wireless device itself

all good so far well yes and no

the problem is that what happens when

you push that WPS button is that the

authentication kind of shifts from the

traditional pre-shared key

authentication to a pin-based

authentication it's just an eight

character pin which is sometimes even

written on the actual device itself if

you flip the device around you're

probably going to see a WPS pin in there

which you can use as a password and the

problem with this eight digit PIN is

that it's extremely easy to Brute Force

this value not because it's just eight

digits right eight digits still means

like uh 99 million

uh combinations it could take a while

but unfortunately the way the the WPS

algorithm was designed was for the

client to First send the first four

digits of that PIN to the access point

and the access point would tell back to

the client are those four digits correct

or not

now if those four digits first four

digits were correct then the client

would send the other four digits to be

checked by the access point again so

basically just to crack half of the PIN

we only need four digits we only need 10

000 attempts which actually it's not

that much if you think about it right

where you're you're not trying them on

manually right you can write an

automated script that can Brute Force

through 10 000 values it's not that much

okay and the problem is that after you

you validate the first four digits

over a couple of tries in in brute force

uh the other four digits are actually

not even four they're just three digits

with one digit for parity checking so

you're basically have ten thousand

attempts to Brute Force from the first

four digits and then another thousand

attempts for the next three digits which

leads us to the tremendous number of 11

000 combinations to crack any wireless

network protected by WPS which is very

very low and very very easy to crack now

unfortunately WPS is also one of those

implementations that is Hardware

dependent so what vendors could do is to

just disable it from the firmware or

just instruct you not to use it I would

just instruct you to check your wireless

router at home if you do have WPS it's

probably available on the router but

make sure it's disabled because it opens

you up to a very very big security

vulnerability now w3a3 tried to address

this as well and of course we couldn't

just have WPS anymore so we replaced it

with something called Easy Connect very

easy to remember right well Easy Connect

is basically very similar to the method

that you're using when you're register

string iot devices in your home you know

you just if you bought a a smart light

bulb a a wall switch a window door

sensor or anything in most applications

you're just gonna have to scan a QR code

on the back of the device and then you

know perform some sort of a wireless

authentication of that device in order

to include it in the iot network and

that's pretty much it now something very

similar happens with Easy Connect as

well where using a smartphone or any

kind of smart device you can enroll

yourself or become authenticated

with the wireless access point uh just

by scanning a QR code or um or by

scanning an NFC or RFID tag and since we

did mention all the other encryption and

authentication methods we should mention

open authentication as well now open

authentication is basically when no

authentication is being performed uh you

know those wireless networks at

restaurants hotels perhaps any type of

public Wi-Fi is uh usually enabled with

an open authentication type of SSID now

this open authentication sometimes can

present you with a captive portal as

just a web page or a pop-up that shows

up whenever you connect to the network

uh making you I don't know accept some

terms and conditions maybe perhaps pay

for internet oh my God who does that

anymore or sometimes even uh you know

like the company on Facebook or connect

with them on Instagram on the LinkedIn

or something like that in order to gain

access today to the network one very

important thing here to remember up

until and including in WPA2 any type of

open authentication Network sends the

traffic completely unencrypted so you

don't have any type of confidentiality

in there it doesn't mean that all your

traffic is going to be intercepted if

you're still using something such as

https or SSH or any type of encrypted

application Level protocol your data is

still encrypted but keep in mind that

whatever you're sending unencrypted can

be easily sniffed and intercepted by

pretty much anyone and we did mention at

some point that this has been improved

in wpa3 as well because we've introduced

Wi-Fi enhanced open so it's one way of

ensuring that even though clients don't

provide a wireless password we're still

encrypting their traffic now we're

encrypting that traffic using some

dynamically generated keys since the

user doesn't provide a keyword we're

just you know mutually agreeing on some

sort of key that the client will use to

encrypt the traffic this ensures

confidentialities so we can defeat any

attempts to intercept the traffic but

still this doesn't provide any kind of

authentication for the access point so

if somebody poses as a wpa3 with Wi-Fi

enhanced open access point you're still

going to be connecting to it without

knowing that they are an actual attacker

because you have no way of validating

the identity of the access point

now as you can probably guess things

become more complicated when we go from

the personal error area to the

Enterprise area to the company area

because well we have a larger networks

we have more users more devices we have

more strict security policies and we

kind of like to migrate towards a

centralized point for managing all that

security business also uh here comes the

problem of who exactly is connecting to

the wireless network because well if in

a different McDonald's for example we

don't really care about the identity of

those connected to the wireless network

if we're inside of a company and that's

the production Network where all the

employees are connected well we probably

need to thoroughly validate the identity

of whoever connects to that Network

that's why in Enterprise networks we

cannot or should not rely on pre-shared

keys because we shouldn't share a key

among all the users in a network because

that key can become compromised and we

might end up one day with people

connected to our Network who have

nothing to do with our company and

that's bad so different implementations

of both WPA2 and 3 have been invented

and we call these Enterprise versions of

those authentication methods now since

we're talking about unique identities

and a lot of access points and a lot of

users we should centralize this in one

single place and that's why with

Enterprise implementations we are

relying on a central authentication

server we call this an AAA server AAA

server authentication authorization and

accounting server it can be a radio

server it can be a tech server but it's

just a database that holds all the user

identities and their credentials no

matter how those users decide to connect

to our network over wired connections

over wireless connections over vpns it

doesn't matter how their identities are

still going to be validated in the same

single place that's a triple a server

now of course the entire Wireless

infrastructure needs to be changed

because this time whenever a user

connects to an access point well the

access point is not going to Simply

check the pre-shared key of that user

but instead is going to contact the AAA

server on behalf of that user you know

grab its its credentials send those to

the AAA server and then wait for an

acknowledgment from AAA server saying

well is this user allowed to connect to

the network or not now this type of

Enterprise authentication method is

encompassed under the

802.1x protocol and that's the generic

name for pretty much everything that

we're going to be talking about in the

Enterprise world now as part of the

802.1x we have a suit of protocols a

series of protocols Under the Umbrella

of EAP extensible Authentication

Protocol which is basically just a

wrapper around a whole lot of other

methods for authentication I mean we

still can use share keys but in the

Enterprise Network you might want to use

digital certificates we might want to

use uh smart cards you might want to use

Biometrics we might want to use even SIM

cards in your mobile phone perhaps for

authentication and due to the multitude

of authentication methods we need a

wrapper around all of these and that

wrapper is called EAP extensible

Authentication Protocol it's basically a

way of saying anything goes in here as

long as it plays by the same rules as

the rest of the protocols the type of

traffic that is being allowed or a

wireless client before they are

authenticated in the Enterprise Network

is of type EAP over Wireless so EAP over

Wireless is the type of protocol that

allows a user even though they're not

yet authenticated with the access point

to still send their authentication

attempts before I become authenticated I

still need to be able to send my

username and password I still need to be

able to send my my digital certificate

to prove my identity and that's going to

happen over the EAP over Wireless

protocol and even more the AAP over

Wireless traffic is the only type of

traffic allowed for a user that is not

yet authenticated and if the user

doesn't manage to pass authentication if

the user is rejected by the AAA server

they are still going to be restricted

just to EAP over Wireless type of

traffic so they can retry authentication

again and again and again now the

official terminology here

and this might be useful for the exam as

well is the client that initiates the

authentication session that's the the

mobile phone the laptop the desktop that

tries to gain access to the network and

that's called the supplicant okay the

supplicant sends their own

authentication credentials now the

Authenticator

it's not the server it's actually the

access point or this or the switch in

the network so the authenticator becomes

the entity that relays the

authentication information from the

supplicant to the AAA server and then

back to the supplicant the response of

the AAA server right and finally we have

AAA server of course the radius or the

tax server that holds the database with

all the users and their credentials now

as we said before EAP is actually an

umbrella for a multitude of protocols

and there are a lot of them but a couple

of them you should recognize by the name

and you should be able to identify them

for the exam I can bet how many beers

you want that you will be asked at least

about one of these protocols on the exam

day so let's see what are the most

significant protocols under the EAP

umbrella starting with EAP TLS and

that's the exact same TLS that you've

heard about with web servers and https

right that's TLS transport layer

security with eaptls a TLS tunnel

encrypted tunnel is being created

between the supplicant and the

authentication server now the way TLS

goes is that you first need to present

the public key to be recognized or

validated by the other party now both of

them do this at the same time so both

the supplicant and the authentication

server which means that they're both

being authenticated to one another so

the client recognizes the server and the

server recognizes the client but also

requires that both the client and the

server have certificates installed onto

them which might become a bit more

difficult to implement in a large scale

environment a simplified version of

eaptls we call it peep p-e-a-p

protective extensible Authentication

Protocol which is basically just a

dumbed down version of the EAP TLS in

which only the server requires and

presents a digital certificate the

client doesn't need to present a digital

certificate anymore so this might be

easier to implement now the client of

course still needs to prove its identity

somehow so they can choose to use

passwords by having an inner

authentication method inside EAP such as

Ms chap for example Ms chap version 2

this is the challenge handshake

Authentication Protocol it's just a very

simple password-based authentication

mechanism or even digital tokens like

with EAP GDC finally another one is EAP

ttls that is tunnel TLS and you might

think here well wait a second wasn't TLS

or radio tunnel well yeah but we're just

abusing the language here just a bit now

ttls tele TLS is very similar to Pap

that is only the server requires a

certificate and the client can choose

whatever method they like the benefits

on top of peap is the fact that while

with peap the client could only use Ms

chat version 2 or EAP G EC now with

eaptls the client can use whatever they

want as long as it's supported by the

eaps team so including pep chap whatever

authentication method they want it's

truly true truly flexible so it's a type

of EAP implementation that allows the

client to use whatever authentication

method they can support and of course

whatever authentication method is

accepted by the Enterprise

last one here worth mentioning is EAP

fast very similar to Pap again but this

time it doesn't require a certificate

even on This Server so both a client and

a server can authenticate using

something called a pack a protected

access credential which is basically

just a key it's not exactly a pre-shared

key because otherwise we run into the

same problems of how do we share the

pre-shared key and how do we ensure

identity but it's usually a key that is

dynamically generated within the client

and the server using some sort of Divi

helmet implementation

the problem with this one is that again

like we mentioned a couple of minutes

ago there's no way to authenticate the

the server or the access point that

you're connecting to anybody could be uh

acting as a fake or Rogue access point

that is running or supporting EAP fast

and extract some valid credentials out

of you

now more on the physical side of

security when it comes to wireless

networks it's worth mentioning the term

of Rogue AP Rogue AP is basically any

access point that it's in your network

and you either don't know about it or

you don't want it to be there so it's

something that you've not authorized to

be in your network an access point that

doesn't belong to you it's usually a

rogue because it most likely belongs to

some uh to some attacker who has placed

that access point right there in your

network with the purpose of

impersonating your own SSID or company

SSID into tricking other clients to

connect to the attacker's access point

instead of the company's access point

why well because in this way they can

perform Man the middle attacks they can

perform uh I know malicious DNS red

malicious DNS redirects for example for

phishing attacks and such unfortunately

Rogue access points are pretty tough to

detect because they don't show up or

they just show up as another access

point that belongs to the same network

if this SSID is exactly the same as the

name is exactly the same then a mobile

client is not going to be able to

tell them apart now of course each

access point has its own BSS ID it has

its own Mac address but most users don't

don't check that don't even know that

that's a thing or something that needs

to be validated before connected to a

wireless network and even most mobile

phones actually don't even support this

function of validating the MAC address

of an access point so it's down to the

responsibility of the IIT department or

the security department to make sure

that they can detect these four in

access points now if you have a an

expensive and well maintained Wireless

management solution or an application in

your network that solution can probably

turn your network into a monitor mode

and simply monitor for interferences

start using all the access points as

sensors in order to detect potential

interferences now if your solution

supports something like this then it's

going to be extremely easy to detect a

an access point that it's still emitting

while the others are listening okay and

you detect it immediately you can even

pinpoints on a map and find exactly

where that X point is being hidden and

under whose desk perhaps in the or in

the in the conference room which leads

us of course to the second method of

discovery which is just physical

Discovery if you don't have a solution

that can automatically detect

interference sources it's up to you to

Simply look for those access points and

disconnect them from the network which

is pretty tough I know now since we

talked about Rogue APS there are a

couple of attacks in wireless networks

that you should know about starting with

the authentication attack now the

de-authentication attack basically

relies on sending a special type of

management frame for disconnecting or

de-authenticating actually a client from

an access point now an attacker could do

this in order to either force a

re-authentication of that client knowing

that intercepting the authentication a

sequence could help them you know break

the security of that of that wireless

network or in order to force that

specific client to stop talking to the

Enterprise access point and stopped

talking to the Rogue access point that

perhaps was just installed and of course

the reasons might not be so elevated

because a simple new authentication

attack can be used to perform a delay of

service simply you can keep sending the

authentication requests for all the

clients in the network and nobody's

going to have wireless access there you

go denial of service for the wireless

medium now a bit of a lighter version of

this attack is called the disassociation

attack now a disassociated host is not

completely disconnected but still cannot

send any traffic cannot communicate

unless they they associate back again so

using these management frames fake

spoofed management frames you could

perform disassociation attacks for

denial of service purposes and as you

probably remember from a couple of

minutes ago we said that these

management frames have been protected

now in wpa3 in order to block these

potential exploits for the

authentication and disassociation and we

call this now m f b management frame

protection

or sometimes you're going to see it as

manage mpf or management protection

frames both refer to the same thing and

of course we have pretty shared key

attacks those are the tags that are aim

to capture the the pressure key to crack

the wireless key of the of the network

basically now it's not exactly just a

matter of you know capturing the key

over the air as we said before we start

with the pre-shared key and we run it

through a key stretching process which

relies on a couple of hashes so what we

what we managed to capture in case we're

performing some sort of a traffic

sniffing for the authentication parts of

a device if we manage to intercept that

that key we're actually not intercepting

the key itself but we're intercepting

the hash of that key now if this is

successful half of the work is already

done but we still need to take that hash

and run it through a rainbow table or

run it through a an offline cracking

algorithm that is going to try to

determine the original key that was used

to generate that hash these attacks also

were called IV attacks initialization

Vector attacks in WEP because back then

the algorithm that was used to ensure

the uniqueness of the encrypted result

even given the same key relied on some

random numbers which was called which

were called the initialization vectors

and the way those IVs were generated was

pretty faulty which led to a fault or a

vulnerability in the entire web

algorithm itself the way this worked was

by forcing the access point to generate

a lot of traffic sometimes even by

sending the the authentication frames

right would you cause the the stations

to the clients to re-authenticate

themselves and to generate new IVs and

new IVs and new IVs and do that a couple

of times enough times and the access

point is going to run out of IVs and

it's going to start cycling them back

back through all of these IVs which is

going to reveal the hashed part of the

of the key so that the client the

attacker is going to know which part of

that bit stream is the IV and which part

of your bitstream is the actual

encrypted hash another type of attack uh

discovered or at least published in 2017

is called the crack attack this one uh

addresses both WPA and WPA2 it actually

has nothing to do with IV attacks

because their WPA2 for example is not

vulnerable to to ID attacks anymore but

the crack attack exploits the four-way

handshake in WPA2 that's why we say that

we've gotten rid of this this four-way

handshake in wpa3 replaced it with uh

simultaneous modification of equals so

that crack is not going to work anymore

it's not so easy to crack WPA2 as it

were to to craft web for example but it

still relies on Force the authentication

of the client

up to the point where the attacker can

actually determine some very important

information from that four-way handshake

where from a bunch of forward handshakes

that the client was forced to perform uh

in order to determine the uh the key the

pressure key of the network

finally the simplest type of Wireless

attack and probably as old as as the

radio uh is the jamming attack You're

simply jamming the wireless Spectrum so

it's sending noise sending gibberish so

that nobody can use the wireless

environment anymore right this can be

easily detected by both clients and

access points and can be easily

pinpointed exactly on the map if you

have some sort of a centralized Wireless

management solution that is able to

detect interference sources now if

you're thinking about using this because

it's the simplest attack to be conducted

keep in mind that in a lot of

territories around the world

jamming Wireless signals is illegal so

you've been warned all right so thanks

so much for watching I know there was a

lot of content in this chapter but trust

me this is gold for the exam so don't

glance over it try to understand how to

remember a couple of these

um protocols and algorithms because

they're going to come in handy in your

exam day all right so thanks so much for

watching uh like And subscribe comment

if you wish support this uh this channel

if you really liked it and see you on

the next video good luck in your studies

and bye bye

[Music]

thank you


19 19

foreign

[Music]

today we're going to talk about

connection balancing or load balancing

and that's basically going to be a

discussion about how to run your

applications in a distributed

environment that is you have an

application you have a web application

for example you want to run it on more

than just one single server because that

single server might fail or that single

server might just not be enough to be

able to support so many connections from

all your customers so you might want to

run that application into a so-called

server form that is multiple servers

configured almost identically that are

running the same application now since

you have multiple servers have multiple

endpoints that are able to serve your

application you also need some sort of a

device to put in front of those servers

that receives all the connections from

your clients for example the device that

responds to the DNS name of your website

and then in turn is going to take care

of Distributing those connections among

those multiple servers that you have in

your server Farm

that device is what we're calling a load

balancer and we're going to mention also

a couple of attacks designed to bring

down such an infrastructure especially

when it comes to web applications

so first of all let's try defining a

load balancer as we just said it's it's

a device it could be Hardware it can be

software device that receives all the

connections from your clients and then

decides to which server it's going to

redirect those connections

so here's a very small diagram here from

the nginx website we can see the clients

or the end users on the left hand side

connecting over the Internet reaching

out to a software load balancer or a

hardware load balancer basically it's

going to be pretty much the same

solution as in it's going to be some

sort of a software solution that

receives those connections and acts on

like some sort of a proxy it could be

just a software running on a virtual

machine it could be software running on

some infrastructure in some Cloud which

basically is still going to be a virtual

machine or it can be a dedicated box

physical box that's that's living

somewhere inside of your data center

right in front of your servers and of

course behind that box or behind that

software solution we're going to find

the application servers now of course

the load balancers need to be aware of

the servers uh behind them in order to

periodically check whether those servers

are still responding they're still able

to deliver the service that we're

announcing that's in our website or web

application but that's the business of

the load balancer all the clients need

to know is which internet address which

domain name which website address they

need to use in order to reach the

endpoint The Listener endpoint on this

load balancer the internet facing

endpoint of the load balancer a great

benefit of load balancers is the ability

to provide full tolerance so at some

point a server might fail once one of

those servers in that server Farm maybe

the power source failed maybe a hard

drive or an SSD fails well the load

balancer would better detect this before

the end customers would actually

continue attempting to connect to that

dead server so the load balancer should

perform some sort of a health check and

if that server is not responding anymore

it's going to temporarily remove it from

the server pool and stop directing

connections to it in an ideal scenario

your clients would not even feel the

fact that their their server that

they've been connecting to so far has

suddenly died and all their connections

are suddenly moved to a different server

in the same server pool next we could

have resilience against attacked and I

said we could have because the load

balancer in itself is not considered by

definition to be a security device it

can be in most load balancing Solutions

nowadays do have some security built in

but if you just think about the fact

that the load balancer is the single

point of connection through which all

the connections go in order to reach

your actual uh servers that are hosting

your applications well that would be a

great point in the network to perform

some sort of security filtering how

about we look at the traffic we look at

the requests coming in from from the

clients and see if something's fishy in

there let's see maybe we can detect uh

denial of service attacks maybe somebody

is trying to flood our website or even

even uh going higher up to layer 7 at

the application layer if we are able to

look at the actual HTTP requests coming

in we might be able to detect things

such as cross-site scripting or SQL

injection attacks but that depends on

how comp Flex the solution is the load

balancing solution how able it is and of

course how it was actually configured

just remember that by default the load

balancer is not a security solution in

itself even though even without any

security policy implemented in it it's

still one extra hop between a potential

attacker and the server the web server

to be compromised so you might ask how

there's a load balancer actually make

those decisions how does it decide where

to send those connections which server

to choose I have 10 servers in my server

problem there's a request coming in

where do I send it where there are a

number of algorithms that help them

decide which server to use but we also

have to start from what exactly is being

taken into consideration before making

that decision so what does the load

balancer look at and the simplest

implementation here would be for a load

balancer to Simply look at the layer 3

and layer 4 headers that is a source

destination IP address this destination

port and that's pretty much it alright

so we could be balancing connections

simply by looking at the fact that we

are receiving a an HTTP or an https

connection going to a specific

application and we know that we're

listening for that specific application

on the https port and if a connection

comes in then we can simply direct it to

one of the servers in the back end now

of course since we're talking about

layer 4 we should mention that we can

make decisions based on UDP Port as well

so if the UDP application is going to

receive udpa requests we're going to

treat them completely the same so if

it's a UDP application listening for a

request we could just direct those

requests based on

UDP destination port for example now if

we have a load balancer that is able to

look at layer 7 that means it has to

unwrap those requests coming in from the

clients and actually understand what the

client is trying to do so it can drill

down to some very specific and granular

piece of information such as the entire

URL being requested or the type of

traffic being requested that is let's

say for example we could direct those

connections in a different manner

depending on the actual URL or the

website or the application that the

client is requesting even though perhaps

the old servers in the back end are

running the same apps right but since we

don't want to overload the single server

we could just choose a couple of servers

that serve application a another couple

of servers that serve application B and

so on another method for balancing at

layer 7 is deciding what type of content

the client is requesting so we might

choose to direct those requests to a

regular server for I don't know maybe

HTML page request maybe CSS requests

maybe JavaScript requests things that

are let's say not so resource intensive

to be uh to be delivered but for example

if we see a request coming in that

requests a streaming video we might want

to direct that request to a server with

a lot more CPU processing power more RAM

and perhaps even more networking

bandwidth that is able to process to

keep processing that continuous stream

of video data and since we briefly

mentioned how does the load balancer

actually choose a server well it could

do it just randomly that's one of the

methods that can be used inside of a

load balancer but this is not going to

take into consideration the load of the

servers perhaps by just choosing a

server at random we might end up with

overloaded servers While others are

completely unused so a better solution

would be to take into consideration the

load of the servers themselves this

requires the load balancer to keep track

of how many requests have been sent to

each server and perhaps even query those

servers from time to time as to their

CPU usage how many active connections

they have and so on another method

another very simple to implement method

is called round robin that is just pick

one server at a time for each request

that comes in send the first request to

server one second one server two third

one server 3 and then come back again

and cycle through all those servers for

as many connections as we need to send

now this might sound like good load

balancing but you should remember that

not all requests are born equal that is

one request might take the server 10

milliseconds to process and to generate

a response for it another request might

take the server

10 or 20 seconds if it needs to access

some authentication third-party

authentication Services maybe it needs

to query a database made a database is

busy right maybe the response coming

from the database is to be processed by

the web application code and that takes

a lot more effort don't assume that

every request is going to be processed

in the same amount of time that's why a

a weighted distribution and especially a

distribution that takes into

consideration the load on each server is

the best distribution preferred in order

to achieve better resource utilization

in your server form and finally one

thing to mention here is session

persistence remember if you're

connecting to a return application to a

website right you're logging into your

email account let's say on a on a

browser then all subsequent requests are

going to suddenly become authenticated

that's because you have generated some

sort of a session information that is

being attached to all your subsequent

requests so all that session information

between you and the server is stored on

a single server on that backend behind

the load balancer so once you've

authenticated and you've generated that

that session information that session

information is going to be stored on a

single server which means that all your

subsequent requests should end up to the

same server because if they don't end up

to the same server another server is not

going to recognize you it's going to say

I don't know who you are you're not

authenticated

I'm not going to deliver that content to

you so the load balancer also needs to

be aware of the fact that some clients

when they initiate a session they have

to stick with it once they've chosen a

specific server in the back end to

initiate the session with

all the subsequent connections coming

from the same same client using the same

session information should end up

reaching that same server because that's

the only server that has that session

information and is able to further serve

those clients so session persistence

is something that has to be supported by

load balancer as well in most situations

this type of session persistence is

insured by using uh HTTP cookies in your

requests and of course the load balancer

has to look for those cookies and

identify them as valid active sessions

so in talking about attacks that are

aimed at denying the availability of a

specific resource with all these attacks

denial of service now the another

service attack is simple is is most

likely the simplest type of attack and

it's also a a very dangerous one its

only purpose is not to steal information

it's not to corrupt information it's not

to compromise data it's it's not aimed

for a data breach although it can be

used as a tool that leads to something

like this but its purpose is to Simply

deny access to some sort of a network

resource how do you do this well you

overwhelm that resource or any of the

devices that lead to it with so many

connections active connections uh or

you're trying to over saturate the link

bandwidth with so much bogus traffic

fake traffic or you're trying to consume

all the CPU power or all the memory or

any other resource involved in serving

those or ensuring access to those

resources so that the legitimate users

cannot reach them anymore so basically

we're creating so much noise so much

useless Network traffic

requests or CPU usage noise so that

regular users are denied access to those

resources

the bad news about a denial of service

attack is the fact that it is extremely

easy to conduct there are a lot of tools

out there rituals on on the internet

where you just have to enter an IP

address or web address and press a

button and it suddenly starts opening

tens of thousands hundreds of thousands

of connections to that single website in

an attempt to bring it down now in most

situations those connections actually

don't look like regular connections

initiated from a regular browser then

maybe half open connections that is

where initiating a connection and then

we're not fulfilling the entire

three-way handshake over TCP or we're

not responding with a valid HTTP code or

we're not continuing the communication

so that we can keep that connection open

on the server on the victim server and

thus by opening more and more

connections have open connections like

these we're going to exhaust its

resources and what's even worse is the

fact that a really efficient enough

service attack is launched from multiple

sources at the same time your computer

your laptop might not be enough to bring

down the server that is hosting an

application and was designed perhaps to

support let's say a thousand

simultaneous connections but what if you

have a thousand computers

well if you have thousand computers

under your control and you are the

attacker then that network of

compromised computers is called a botnet

and the reason for a botnet is that

whenever you're launching an application

especially denial a service application

from botnet your power is huge and if

the volume of traffic that you can

generate the amount of connections that

you can initiate every second are most

likely going to bring down any victim

that you choose over the Internet any

website hosted on any type of server and

whenever you hear of uh do not have

service attacks or flooding against

websites the most common type of

flooding is called a sin flood you know

the the three-way handshake in TCP you

send a sin you await for a sin act to

come back from the server and then you

respond with an ack those are the three

messages that make up the three-way

handshake well what if you ever send

this in the server replies back with a

sin hack but you don't reply with an act

back again well that's a connection that

is now half open

and in pretty much any situation every

resource on the search is going to be

limited and the capacity of a server to

maintain a number of half open

connection is also going to be limited

so at some point if you open just enough

a sufficient number of connections and

you leave them in this half open State

the server is going to fill up its state

table and it's not going to be able to

respond to valid requests coming in from

valid clients even more you can combine

this approach with a spoofed IP address

that is you're not only sending the sin

and you're not sending the the final

hack but you're even sending the sin

with a fake IP address so the server

response doesn't come back to you

because you don't want to flood yourself

right but the server response comes back

to some random IP address over the

Internet an address that has no

intention of completing that half open

connection of course also another

interesting approach in the service

attacks is an amplification attack it's

most likely also going to be distributed

as well so we're going to talk about

amplification DDOS attacks and an

amplification attack refers to the way

certain protocols were designed and

certain protocols which were designed so

that they act on a request reply pattern

which is completely typical but in some

situations those protocols have a

disproportionate ratio between the

request which can be very very small and

the reply which can be huge a couple of

Protocols are quote unquote vulnerable

because it's not exactly a vulnerability

it's more like a just a a design feature

of that protocol and among those two are

ntp and DNS for DNS you probably know

that a DNS request in itself is very

small but the response that you receive

from the server especially if the server

has a has a large database and it's able

to list a bunch of uh a records or name

name server records or Mail Exchange

records well the response can be much

much larger than a request similarly

with ntp you might not expect this but

ntp the network time protocol the

protocol that we're using to synchronize

time over the internet I can also uh you

can also support specific requests that

make the server reply with the list of

the last 600 IB addresses that the ntp

server has contacted again we're talking

about pretty old protocols designed in a

in an age where security wasn't the

first concern nowadays we can leverage

this Behavior to create distributed

Amplified denial of service attacks of

course by spoofing IP addresses and what

I mean by spoofing them is this time

we're not spoken the IP address with a

random address like we did with the syn

flood but now we're spoofing them with

their victim's address so we're

contacting a bunch of DNS or ntp servers

all over the Internet because they're

pretty much free right they don't have

any kind of security built in and then

we convince them all to reply at the

same time to a single IP address

overwhelming that IP address with a huge

amount of traffic and you don't even

need a botnet to do this you're

basically relying on the internet

infrastructure that's made up of ntp and

DNS servers out there free to use for

everyone but you start using them as

tools for your attack now that's kind of

scary right

now let's just talk for a minute how can

we possibly mitigate denials or

distributed now servers attack now we

could be doing it at our own load

balancing level inside of our load

balancer which perhaps is installed in a

clustered topology I'm going to talk

about this on the next slide a better

solution would have to be involved with

the ISP the internet service provider

and have them the ISP filter that bogus

traffic before it even reaches us and if

you think about it that's the best

solution because the isps network has a

lot more capacity than whatever network

capacity you might have in on your own

your own internet connection and

secondly the ISP is able to see that

traffic before it even reaches you

because if you're thinking about well

I'll just identify the traffic that

belongs to the live service and I'll

just simply drop it on my firewall or on

my router or on my load balancer yes you

might you might do this but well think

about it what if all the traffic that

reaches you is denial of service traffic

what if you're not even seeing you're

not even receiving any valid requests

because the amount of service has filled

up your entire bandwidth has consumed

your entire internet connection the

capacity of your connection and all

you're seeing is the null service

traffic you might drop that traffic but

you're left with nothing you're still

not receiving valid client connections

so a better solution would be to have

the ISP drop that traffic before it even

reaches you another

um a problem with doing your own

filtering inside of your your own

backyard is well what if that in our

service traffic is aimed at eating up

all your processing power or CPU

resources if your internet facing router

has its CPU at 100 it's probably not

even going to be able to respond to an

admin command when you're trying to

connect to it and you're trying to build

an access list perhaps and and match

that traffic in order to drop it your

router might be so overwhelmed that you

might not even be able to interact with

it

so another reason why ISP involvement is

a great solution here now of course this

is going to have a cost and it's going

to have a cost as in many isps allow you

to Simply buy the solution from

themselves

or you could have a solution where you

have a let's say a load balancer in your

own network

and you also have a piece of Hardware or

a virtual machine installed in the isps

network and the moment you identify

traffic coming in as being part of a

denial of service attack you you signal

your your device counterpart from the

isps network and that's when traffic

filtering starts to happen so you're

identifying the traffic and you're

communicating with another device that

belongs to you but it's hosted in the

isps network so you're basically

filtering your own traffic it's just

that you're doing before it reaches you

before it reaches your network now of

course this solution also has a pretty

big cost and finally the third method

here on the slide black hole and

sinkhole routing well black hole routing

is basically what we just said when

you're building an access list you're

matching that specific code you know

service traffic sometimes you're not

even being able to match it because it

uses spoofed IB addresses but let's

assume that you're able to map the

traffic and you simply redirect it to

null to the null zero interface to uh

Dev null to the bitbucket right you drop

the traffic so it doesn't reach any

other interface it's not being routed

it's not reaching your servers you're

just dropping the traffic now of course

the the problem that we mentioned uh

still stands what if your entire traffic

is you know servicing you're basically

dropping all the traffic and you're left

with nothing we're talking here about

let's say situations where uh denial

service traffic doesn't saturate your

your internet connection now single

routing is a type of traffic dropping

but with the ability to further analyze

it and many cyber security operation

centers it's not just enough to identify

an attack and drop it you want to have a

look at it you want to direct redirect

or save or make a copy of that traffic

in order to analyze it and understand

more about the attack and maybe create

some sort of security rule that avoids

and drops the traffic if it's identified

in the future again so that's one

solution to it black hole just drop

everything or sing sinkhole drop it but

also direct it or make a copy of it and

store it somewhere safe in order to

analyze it later on when the attack has

finished now another method for ensuring

connection load balancing and resiliency

is to have clustering enabled now with

traditional load balancing we're just

Distributing connections among multiple

servers well with clustering we have

multiple devices performing the exact

same role we keep them all completely in

sync with one another so that when one

of them fails the other one can

immediately take over and start

processing the client requests now you

might be thinking isn't that the same

thing that we've been doing with load

balancing well yes but with load

balancing all the connections had to go

through a load balancer well what if the

load balancer fails you might say all

right so we're going to get two load

balancers in there so if one of them

fails

well then what

your clients are supposed to connect to

the other load balancer but how do they

know about the other load balancer how

will they know to connect to a different

completely different device when the

main one on the on the first device

fails so this is what the problem of

clustering attempts to solve so

clustering if we were to redefine it is

a technology that allows us to

transparently present to our end users a

single IP address we call that a virtual

IP address even if on the on the

physical side that virtual IP address

might actually point to 1 2 3 or or more

identical devices

that all belong in a single cluster and

they're all synchronized with one

another

you might also find the term of floating

IP address and it would go with floating

IP address because at one point in time

that IP address might point to one

device later on when that device might

fail it might point to a different

device but this is completely

transparent to the users they all know

that the IP address that IP address is

the one that will answer their requests

they don't care which device is behind

it or if it's a different device even

now of course we're going to have some

protocols that take care of this type of

synchronization between those devices so

that we can configure them properly

enable to have one IP address that

points to multiple devices basically we

want to educate those devices to know

how to behave and how to answer to those

requests coming in from on that single

virtual IP well that synchronization

protocol is also going to take care of

who answers which requests because at

the end of the day even though you might

have two load balancers ready to process

your requests if a client sends a single

request well that single request is

going to each one of those two load

balancers it makes no sense to reach

them both alright so the redundancy

protocol also has to choose which one of

the devices in the cluster is the one

that is actively responding to those

requests which brings us to a situation

where we have to make a difference

between active passive clustering and

active active clustering well with

active passive we have one device that

answers all the requests and one or more

passive devices just waiting and

periodically checking through a

heartbeat whether that active device is

still up and running is able to to serve

those clients and the moment the active

device fails immediately another one of

those passive devices takes over the

active role so that's active passive now

on the other hand we'll could also have

active active clustering which is let's

say real load balancing or load sharing

and that is where both or all of the

members in the cluster are actively busy

serving requests that are coming in now

of course if one of them fails then the

remaining devices are going to take over

the tailed one's role and a couple of

the protocols worth mentioning here

would be carp that's the common address

redundancy protocol carp this is also

where you will find protocols especially

if you've been through some Cisco

courses uh protocols such as vrrp

Virtual Router redundancy protocol or

hsrp hot standby routing protocol or

even glbp Gateway load balancing

protocol there are many but they pretty

much work pretty similarly pretty much

they do the same thing as in they keep

in touch with one another they keep

track of the active cluster members and

they also talk to each other to decide

which one of us is going to respond to

ARP requests and out to the actual

application requests coming in onto that

virtual IP address because we only have

one virtual IP address but if you have

multiple members in the cluster here

that well we we have to talk to each

other and decide who is the the one

that's going to be responsible for

answering those requests so that's what

those Protocols are doing and there's

one more thing to mention here remember

when we said that there's a real problem

when it comes to active sessions that is

when a client authenticates themselves

and it creates a session cookie that it

needs to use on every subsequent request

so it makes sense for all those requests

to come back to the same server in the

back end well clustering attempts to

solve this issue as well clustering if

implemented at let's say firewall level

we have a cluster of firewalls or at

server level or even at database level

ensures that that session information is

also synced among the multiple members

of the cluster so that the moment one of

those members is unable to respond the

other 110 can take over immediately and

can even continue from where the other

left off because it knows about the same

session information now one last topic

here to cover as you probably know most

applications most networking device

devices are simply processing the

traffic that reaches them on a best

effort basis that is first come first

served if we have resources to process

this request type of traffic we're going

to process it if we don't well tough

luck we're simply going to drop it we're

simply going to ignore it we're going to

let it time out that's the default

Behavior if you don't have something

like quality of service implemented so

basically quality of service is a model

or a framework for prioritizing certain

types of traffic and when do you need to

prioritize traffic well when there's

congestion when there's more traffic

that you can handle or when there's more

requests than you can handle because if

you have enough capacity it makes no

sense to prioritize traffic because it's

going to reach its intended destination

in the same amount of time anyway so

quality of service kicks in the moment

when your resources are just not enough

and we have two types of traffic

prioritization first of all we either

might need to ensure a certain amount of

bandwidth or a specific application for

example if you have video streaming we

care about the video quality we want a

quality to be high we want to have good

sound good image so we need to ensure

that's what's for specific types of

traffic ideally the type of traffic that

we identified as belonging to video

streaming protocols we're going to

allocate a chunk of the bandwidth so

that the traffic quality the video

quality is not going to suffer on the

other hand another type of

prioritization that we might want to do

is latency well latency is the delay

between the packet is sent and the

packet is received of course that is

always going to be some type of delay at

least a couple of milliseconds between

any two points especially over the

internet

but certain applications are more

sensitive to delay than others for

example if you were to send an email and

the email arrives within let's say five

seconds you consider that email to be a

success right the connection is good

it's okay I mean five seconds for an

email is okay but if you're talking on

the phone and the other person hears

what you just said over five seconds

well that's not going to be an

acceptable type of conversation so as

you can probably guess uh the most

sensitive to latency are the

applications that rely on real-time

communication especially voice based

applications because the human ear is

much more sensitive to delay then the

eye is for a bit of delay in the image

or a couple of artifacts or image

degradation especially if it's just

temporarily so we need to do three

things in order to have quality of

service in order to be able to

prioritize the traffic

uh first of all we need to identify the

traffic we need to know what are the

rules that say well if you're seeing

this in the network then this belongs to

Netflix if you're seeing this then this

is a voice over IP call and if you're

seeing this oh this is BitTorrent we

don't care about that one okay so

identification of traffic is the first

step second we need marking of traffic

why do we need to put some sort of a

stamp onto that traffic once we've

identified well that's because we don't

have the two devices the the sender and

the receiver on the same network we have

a sender and receiver with the entire

internet in between or a VPN in between

or a bunch of devices in between and

those devices know nothing about the way

we've chosen to identify and to

prioritize that specific type of traffic

so if the network that's between the

sender and the receiver belongs to us

then in an ideal situation we could

configure those devices and tell them

watch for this type of traffic or watch

for a specific label or watch for a

specific stamp that's attached to that

traffic and if you're seeing this apply

a specific prioritization policy to it

so we're we're performing identification

and marking as close as possible to the

source of the traffic so that everybody

else who sees the traffic afterwards up

to its destination is going to be able

to know what type of traffic that is and

how they should handle it and of course

that traffic handling means applying a

specific QRS quality of service policy

to it that is reserving a chunk of

bandwidth maybe jumping the queue so

that we minimize the the latency

minimize the delay any type of of policy

that ensures that we're actually

reaching the level of service that we

intend to with this quality of service

implementation so first of all how to

identify traffic well we just match it

using access lists wow we could be

looking at layer 3 layer four sometimes

it could be looking at layer 7 but

that's the that's a special kind of

issue in there because sometimes looking

at layer 7 means assembling the entire

data stream

and looking in the entire that entire

payload in order to figure out what type

of traffic that is and that type of

queuing and traffic assembly and

decoding takes time and it might be too

late by the time you're done assembling

that traffic and figuring out what's

inside of it it might be too late for

that traffic to be prioritized it might

be already irreversibly delayed so in

many situations we prefer to identify

the traffic at layer 4 at most now

starting from layer 2 and especially

with frames that belong to a specific

VLAN and they are tagged with the

802.1q standard well the 802.1q tag

format includes information about the

VLAN and a couple more information here

including a three bit field which is

called priority code Point PCP this

field also

follows the specifications in the IEEE

802.1p also called class of service and

just like the name says these are just

three bits that when assigned to a

specific value they indicate a specific

type of traffic now you only have eight

values right ranging from zero through

seven since you only have three bits but

it might be enough at layer 2 to

identify a couple of important traffic

types as you can see here the standard

says that values uh 0 and 1 are part of

background traffic or best effort so

that's the lowest priority while values

such as 5 6 or 7 they belong to video

Voice network control internet control

so basically things that make the

network work or things that are

extremely sensitive to delay and Jitter

and by the way Jitter here is the

variation of delay or the variation of

latency so one thing to keep in mind

here it's not enough to just Mark those

frames with the these values in there in

order for them to be prioritized you

also need a specific qos policy that

takes that value into consideration and

applies a specific traffic policy to it

otherwise you could be marking packets

back and forth all over the Internet

nobody's going to care so that's what

happens at Layer Two remember 802.1p now

as layer 3 we had another implementation

called diff serve now the way the discs

server protocol is implemented is by

leveraging 8 Bits in the ipv4 header

these eight bits right here which

actually are called a DS differentiated

Services Bits And if you're looking at

some older documentation you might find

it listed as

let me see it right here you might find

the listed as TOS that's the type of

service field so they all refer to the

exact same thing there's eight bits in

uh in length in there and those eight

bits are divided among six bits that are

the dscp field that's the differentiated

Services code Point that's the field

that actually describes the

prioritization and two bits for explicit

contest and notification now these are

not really used anymore nowadays we're

going to focus on the dscp field now the

dscp field you might think oh so we have

three bits and in cos we have six bits

now in the escp more traffic classes

well yes more traffic classes but

unfortunately really complicated in the

way they were designed and the way the

sap was designed was to First Define a

type of traffic class and we have four

major traffic classes here default

forwarding like well the traffic that we

don't care about expedited forwarding

things that we need to prioritize

assured forwarding things that we really

need to prioritize and class a lecture

that's a simplified version of these

classes that are supposed to be

maintained backwards compatibility with

the IB presidents field or the 802.1p

field in in the actual frames where we

only had eight classes now among among

these uh this default forwarding classes

each and every one of them has multiple

subclasses and also different drop

probabilities we have low medium and

high drop probability so uh basically

for one single let's say a short forward

in class one we'll have a short

forwarding class 1 and draft probability

of low which means that it's going to be

pretty prioritized right if we if we

drop down as much as possible the

probability for that packet to be

dropped ranging through af103 right it's

still class one it's still a short

forwarding but now we have high drop

probabilities so back it marked with

af13 has a hard chance of being dropped

than a packet marked with af11 but of

course this has to be implemented in a

traffic policy as well class selector

classes as we said before there's this

simplified version of dscp and they also

enumerate eight types of classes here

ranging from zero to seven uh their

purpose is to map onto the older ones

that we saw in the layer 2 frame 802.1p

classes so pretty complicated here

actually we don't really need to go into

all that detail at least not for the

Security Plus or for the network plus if

you're going for ccnbcc IE well that's

going to be a different discussion but

for now just remember the dscp applies

to layer 3. it's a field of six bits

within the ipv4 header and that field

can be used for marking packets in order

for those packets to be prioritized

later on on the line uh until their

final destination speaking of

prioritization let's assume that your

traffic has been identified has been

marked and it has reached at some point

in the network a router or layer 3

device that sees those DHCP markings and

has to do something about it and decides

that well according to my traffic policy

I need to prioritize this type of

traffic how can I do this what does this

prioritization actually mean well it

could mean for example to implement a

specific queue of packets and I'm only

going to put that packets in that queue

if they belong to some high priority and

of course whenever I choose a package to

take from one of my cues and place it

onto the wire on on the interface I'm

going to make sure that I take packets

from the priority queue before I take

packets from other queues now that those

queues those packet cues is basically

are going to eat up memory so they're

going to be limited which means that you

can perform this type of queuing only up

to a point if you run out of memory to

cue those packets well killer is not

going to help you because you simply

cannot store nor send those packets

anymore you don't have enough resources

to do so so we have a number of

algorithms here that decide how to build

on how to take packets out of these dqs

we could rely on a single priority queue

we could rely on multiple cues according

to each traffic class we could rely to

some weighted distribution of traffic

classes uh or even weighted distribution

according to the amount of traffic that

an application is generating there are

even algorithms out there that tend to

prefer applications that send and fewer

traffics and prioritize those instead of

traffic that eat up a bunch of bandwidth

because it is assumed that if an

application generates a low amount of

traffic well that that traffic is

probably critical if you if you lose

that traffic you lose a bunch of the

functionality behind that application

while an application that generates a

lot of traffic well it might have some

built-in mechanisms to re-transmit those

packets so we might be safe

if we just drop some of that that huge

amount of traffic right I read this

comparison uh when when reading about

qos a couple of years ago in a Cisco

book that said if you're if you're in a

let's say in a meeting room and a lot of

people are talking and a few of the

people are just hogging the discussion

and the only only they're talking in

there nobody else has a chance to say

anything if one single person who has

never said anything before starts

speaking suddenly and only says like a

couple of words everybody's going to

listen to him right because that silent

person when they had something to say

it's probably important that's the same

behavior that is found inside kilos as

well we have a traffic that sends just a

couple of bytes every couple of minutes

well that traffic might be important

enough to prioritize it on top of an

application that generates 100 megabytes

per second all right so how do these

policy enforcements actually work well

we have your traffic identified you have

it marked and have it queued what do we

do now what do we do with that with that

huge traffic well if it's a priority

queue

obviously we're going to try to send it

as soon as possible if it's not a

priority queue what do we do with

traffic that is uh second class right

traffic that we we've chosen to

sacrifice in order to better serve the

priority applications well we have two

methods of dealing with traffic that is

low priority first of all we could be

doing shaping shaping means we're simply

going to queue up traffic and allow it

to leave the network interface up to a

specific speed

so we're let's say we're limiting

Netflix up to one megabit per second

if you're content with that if your

users can handle that image quality

fine by us we don't really care but

what's important to us is that whenever

there's congestion we don't want Netflix

to be the application that's eating up

all the network bandwidth so that's

shaping we're queuing up as many packets

as possible and then sending them at a

steady rate okay that's shaping well

queuing takes memory as I said and all

the resources in this world are limited

memory included so what happens when

even those packet queues get full well

there's only one thing to do you just

start dropping traffic call this traffic

policing so instead of just killing

traffic and nicely trying to shape the

traffic to match a specific flow

specific bandwidth we're just dropping

all the packets blindly dropping all the

packets that go above a certain

threshold so if we allow one megabit per

second for Netflix if somebody tries to

watch Netflix at 10 megabits per second

we're simply going to drop everything

above one megabit of course it's going

to be a lot of lost traffic in there TCP

is going to go crazy the sliding winners

are gonna have and there's a lot of

re-transmissions are going to happen but

most applications especially TCP

applications are going to start playing

nicely so they're going to level

themselves down they're are going to

level their sliding windows down to

match the available bandwidth so it's

kind of like the the police enforcing

order

so that people are kept in line so we're

dropping the traffic and we expect the

applications to figure out oh so that's

how much bandwidth am I allowed to use

let me just dial down the traffic just a

bit in order to avoid as much as

possible

too many lost packets and too many tree

Transmissions so it's long story short

shaping two packets and send them nicely

out at a steady rate releasing still

send packets at a stator rate but drop

everything in excess

and well since we're in a security

training what about attacks the target

aqis infrastructure well if you think

about it can somebody fake the markings

on your traffic and somebody introduce

fake DSC or 802.1p values in your in

your frames of course they can of course

they can and that's actually called a

fake urgency attack that is when you're

faking the fact that the traffic belongs

to a priority class there's not much

that you can do against this type of an

attack especially because it requires

the attacker to belong to your network

and be able to intercept the traffic now

fake urgency is a term that is coined in

the social engineering aspect of

security but we can apply this to qos as

well now there aren't really many ways

of protecting yourself against fake

urgency because once you're inside of

the perimeter of the network most

Security Solutions were considered that

type of traffic especially it has if it

has already gone through these security

devices through the firewalls it has

been identified and it has been marked

for a specific type of priority most

likely it was already deemed as valid

traffic and acceptable traffic and safe

traffic so if somebody manages to

intercept it and alter it even further

well this probably not much more than

you can do about it now the good news

about this is that well faking qos on on

packets isn't really that damaging to

your network apart from a situation

where it results in a dinner of service

attack as in the attacker prioritizes

their own fake traffic so that everybody

else is being denied access to network

resources but let's just hope that it's

too difficult to implement to ever find

yourself in this situation

now just for just for fun let me just

show you how easy it is to launch a

denial of service attack now what I'm

going to do here is I'm going to attack

this virtual machine that you're seeing

right here on the screen now it's a very

lightweight virtual machine only has one

single virtual CPU with four gigabytes

of RAM so it's not gonna take a lot to

bring it down but the tool I'm going to

use and by the way there are more tools

than you and I can count that you can

use to perform the service attack or syn

floods you can even use traditional

networking tools such as hping to do

this but what I'm going to show you here

is this kind of funny two little tool

right here called the low orbit ion

cannon like now unfortunately I cannot

increase the size of this window more

than it actually is I hope you can read

what's happening in here now but

nevertheless what's important is that

you can see it's a painfully simple

interface I'm only required to provide

the IP address of the victim that I'm

planning to attack and if I open a CMD a

promptering here and ipconfig is going

to tell me that my current ipv4 address

in this virtual machine is 10 10 10.134

so that's the exact IP address that I've

logged on to right here you can see this

big IP address in the middle of the

screen you can also choose a specific

method TCP UDP method based on HTTP you

can also set some program parameters in

here like the number of threads that

you'll be using uh on which Port is the

attack going to be conducted on how fast

it's supposed to go and so on and so

forth you can just leave them all at

their default

and what I'm going to do here I'm going

to click this big button right here that

says I sincerely hope you can guess what

this button does that's the that's the

hint that shows up here the button says

I'm charging the laser so I'll just

ignore how this this interface was

designed but let me show you this I'm

going to click on this button right here

you can see the number of requests

starts increasing here at the bottom

even if you cannot read this trust me

that's a huge number here it's always

already in the tens of Millions

it has already sent that many requests

so far

and it might be that the recording is

starting to suffer as well let me just

try to launch a task manager here to see

what's going on in the background

and we actually have to wait for the

task manager to load

apparently we've managed to bring down

this virtual machine with just a press

of a button so you can see the CPU is at

100 percent load

ethernet the network interface is

already almost 200 megabits per second

of flood traffic you see the CPU it's

stuck at 100 at right now there's not

much you can do with this virtual

machine if I were to launch just a

couple more threads or the same

application from a different computer

that like two sources that's it the

distributed denial service using this

just two sources that would probably

make this virtual machine completely

unusable it's that that easy all right

now I'm going to stop the uh I'm gonna

stop the flooding here and the virtual

machine is going to take a while to

recover as you can see it already

started dropping the uh the CPU load but

if you're looking here under the

processes it's still it still takes a

lot to process the request that it

already received in the queues that's

under system interrupts right here so

it's still gonna last for a while even

though I just chose to uh to stop the

flood right here where the uh where the

load dropped right so it's that easy

right to do to conduct a lot of service

attack

all right so that's it for today thanks

for watching and I know this has been a

pretty networking and intensive chapter

but I hope you found it interesting and

informative now if you like this you

know what to do like subscribe comment

support the channel if you wish I don't

need to tell you this every single time

right so thanks for watching and see you

on the next video bye

[Music]

foreign

[Music]


20 20

foreign

[Music]

we're going to talk about firewalls now

back to the basics back to the basic

security filtering that pretty much

everybody knows about and you might be

thinking wow this this must be the most

important chapter in this entire

training well yes but it's actually not

that complicated oh firewall is not that

of a complicated device it does sound

very simple things based on some

more or less simple rules but

nevertheless the the functionality of a

fireball whatever proxy actually it's

not that complicated it's the design of

those rules that make up those filtering

rules that's the complicated part and

that's going to be specific to your

environment your network your

requirements your apps but before we get

there let's just see what it's all about

so if you still don't believe me I will

I'm going to say it again the firewall

is a very simple device it's a

networking device it's just a device

that sits in the traffic path and

decides whether to allow the traffic to

pass or not in other words permit or

block that specific type of traffic just

like with pretty much any other security

device software solution or even Concept

in general if you want a security

solution to allow the traffic you'll

have to explicitly tell it to allow it

because by default a firewall is going

to block all the traffic effect that

attempts to go through it unless there

is a rule in place specifically telling

it please allow this type of traffic

this is also found sometimes implemented

as a concept called implicit deny that

is a device will implicitly deny all

traffic unless explicitly instructed to

allow it and not the other way around

the basic element for filtering traffic

in a firewall is a list of rules and we

call that an access control list or ACL

and it's exactly what the name says it's

a list that's controlled what type of

traffic is allowed in which type of

traffic is denied even if most traffic

is going to be implicitly denied right

just like we said now the access control

list is made up of rules and each rule

has to match a specific type of traffic

and also include a specific type of

action now the basic actions might be

drop or allow but we might have more

advanced actions such as simply log that

traffic right generating events

regarding the fact that that you've

detected that traffic it might be an

action that says further inspect the

traffic or try to decrypt it if it's

encrypted traffic scan it against

malware scan it against spam if it's

email traffic maybe create a packet

capture for further analysis so a more

advanced implementations of firewalls

could potentially have more advanced

actions that can be taken when a

specific type of traffic is matched but

just for the basics we're gonna have

allow or deny now we're allowing or deny

that traffic based on a specific match

so we're looking for information in that

traffic that is going to tell us or help

us identify what type of traffic it is

and thus which rules will apply to it so

we're going to be looking at things such

as source and destination IP addresses

of course I'm looking at sourcing

destination layer 4 Protocol port

numbers it might be TCP or UDP or any

other type of protocol we're going to be

looking at those board numbers as well

so we could have a very simple access

list made up of a couple of rules that

say available for specific destinations

or for four specific port numbers we're

going to allow or deny that's that type

of traffic depending on the actual

device itself we might see some layer 2

filtering as well well layer 2 filtering

cannot be based on too many parameters

in there because they changed on hop by

hop basis but we could for example allow

or deny specific types of traffic based

on the Mac addresses now careful with

these because Mac addresses can be

easily spoofed but we might be

required to fall back to layer 2

filtering especially if we have devices

that don't know how to communicate uh

let's say over IP or don't know how to

communicate over or outside of the local

network and don't forget that the rules

that we're creating as part of the

access control List have to be taken

into consideration according to the

direction of traffic so is the traffic

entering the firewall or an interface or

is the traffic leaving the firewall or

that specific interface so whenever

you're choosing to create an access list

of course you don't have have to design

the rules for it but you also have to

decide on which interface am I going to

apply that access list to and also in

which direction is the axis is going to

be considered or evaluated for traffic

right because we might have a set of

rules for whatever traffic is leaving

our Network okay but we might have a

different set of rules for whatever

traffic tries to come inside of our

Network to get into our Network

as an example you probably are going to

allow internet communication to pretty

much any destination as long as it's

originated from inside a local network

because you know we have employees

trying to navigate to over the internet

right we have to connect to outside

servers but probably if somebody tries

to connect from the outside from the

internet and to reach some resource

inside of your network well most often

than not you're not going to want to

allow that so what type of firewalls do

we have well starting with the most

basic type of firewall in fact it's so

basic that it's not even found in in the

real world anymore nowadays it's more

like a the original concept that sits

behind the development of firewall so

that one was called the stateless

firewall it's a firewall that has no

State information in other words it's a

fair it's a firewall that looks at each

and every packet in a completely

independent manner so it applies a set

of rules to one packet and then goes

ahead and looks to the next packet as if

it completely forgotten everything that

it saw up to this point so besides the

fact that it's not aware of any session

it's not aware of uh multiple packets

coming from the same Source going to the

same destination it's not able to

assemble those packets and look at any

other information apart from what's

obviously visible in the in the packet

the layers 3 and layer 4 headers it does

have other drawbacks for example it's

not able to detect attacks that ADD

stand multiple packets it's also not

able to handle applications that

dynamically negotiate the port that

they're about to communicating because

that's something that's embedded in the

actual payload of the packet and

stateless firewall cannot look inside of

the the payload of the packet now it's a

very simple implementation of the

firewall this is how original firewalls

was designed but this is not what we see

nowadays this is not what we have

nowadays what we do have nowadays is

called the state of firewalls it means

that the firewall has a specific area

inside of a memory where the state table

is stored that is it looks at the

traffic that goes through it and knows

that whenever the traffic is initiated

and allowed for example from the inside

of network to the outside of the network

well a reply has to come in

so the state of the connection is

maintained as long as the reply is still

pending in other words this is going to

help you tremendously when configuring a

firewall because you're only going to

have to create those rules in one

direction for example outbound rules we

just have gonna have to say instead of

that access list well members of the

private subnets in our Network can

access well let's say Google or Netflix

on the internet well you're not going to

have to create a separate rule saying

that reply is coming in from Google or

Netflix can go inside of the local

network because the firewall is

automatically going to open up the

return path and create a dynamic rule

that allows the return traffic the

moment it sees the request going out so

it's able to track that connection State

and it's also able to implement some

security filtering so for example if it

detects some half open connections that

haven't complete deleted they it might

decide that those connections need to be

taken down just to avoid a situation

that might lead to a denial of service

attack what we just talked about in a

previous video now in order to be able

to keep the state information it has to

track all the connections so it needs to

know who are the initiators of the

connection and who are the destinations

and what's the state of that connection

how many bytes was were sent was the

state of the three-way handshake and so

on now the three-way handshake applies

to TCP and that's pretty easy to track

but what about UDP well with UDP as you

know UDP is connectionless so we don't

have a request reply uh sort of

relationship we don't have a handshake

happening in there so how does that

firewall track a UDP connection well

based on some timeouts right so as long

as every 30 seconds or five minutes or

so we still see the same source and same

destination

conducting communication over the same

port so we're going to assume that the

connection is still up right it's it's

still it's still valid otherwise if no

traffic was was seen for a specific

amount of time we're going to tear it

down same goes for icmp or same goes for

any other protocol that doesn't have a

specific uh State tracking method such

as the three-way handshake with TCP now

since we're tracking these sessions

depending on the on how powerful the the

firewall is depending on how it was uh

configured and its features it might be

able to look at the application layer

information as well now keep in mind

that digging through uh application the

application layer in your packets

requires requires the firewall to

assemble multiple packets to try to

extract the application data from

multiple packets which is not only going

to introduce a bit of delay in the in

processing itself so the clients are

going to see the application responding

slower

but it's also going to put a pretty high

load on the processing power of the

firewall itself because the firearm was

going to be going to have to in real

time decode what's going on through and

what's what type of traffic is is going

through it but the benefit of this is

that if you have enough resources you

will be able to inspect things such as

URLs for example and in HTTP requests so

your access list rules might be elevated

up to the point where you're not just

matching on layer 3 or layer 4

information but you're matching on layer

7 information which makes it an

application layer firewall or a layer 7

firewall you can have a rule that says

allow traffic not just from this subnet

to this destination but allow traffic

from uh this internal subnet to Netflix

even more we could do things such as

malware scanning if we detect the fact

that the connections that were initiated

from within attempt to send or to

receive files we might be able to

assemble those files extract them from

the entire data stream save them locally

on the firewall and run some scanning

engine anti-virus scanning engine on

them in order to determine whether that

traffic is legitimate or not or if it's

allowed or not so again you might have a

layer 7 policy in your access list that

says allow from this source to this

destination as long as there's no

malware in it no that's a pretty complex

rule right for an access list and of

course as you probably know most

internet traffic is encrypted nowadays

though firewalls especially application

layer firewalls in order to be able to

do what we just what we just said as in

look inside the payload of the

application layer they have to be able

to decrypt somehow that encrypted

traffic so basically they're going to

prepare form some sort of a man in the

middle that attempts to decrypt the

traffic that is being generated by the

clients from within the network now this

can be easily done in networks that you

manage and where all the users belong to

the same let's say domain for example

same active directory domain not so easy

to perform whenever you're managing

let's say a public Wi-Fi Now regardless

of the type of the firewall we could

have implemented in one of two ways we

have routed and transparent methods now

routed acts like router in which each

and every interface on the firewall is

connected to a different subnet and the

firewall also has a routing table inside

of it which helps it decide to which

other interface it should be able to

Route any packets that it receives now

of course this routing happens at the

same time with security decisions so

we're only going to Route the traffic if

it passes

a rule if it matches a rule and allow

rule a permit rule inside of our X list

on the other hand we also have layer 2

firewalls or transparent firewalls or

bridged firewalls in which they're not

detected as a as a layer 3 device inside

of a network they probably only have one

single IP address and that is for the

management interface but what they're

doing is actually they're acting as a

switch so they're bridging to vlans or

or two separate networks into a single

one now the end result of this is that

the firewall is completely transparent

to the users they don't know even though

it's in there hence the name transparent

but also it allows the firewall to still

inspect all the traffic and perform

pretty much the same security procedures

whenever deciding whether to allow it or

not another implementation here right

here on the slide you can see it as

router firewall it's not exactly a

separate type of firewall it's more like

a firewall functionality built into a

router you're going to find this in SMB

devices and devices that you have in

your home that act as routers as Wi-Fi

access points as proxies or firewall say

they have all this functionality built

into one single device but usually we

see them implemented in low end devices

for home use or small offices other

types of firewalls or different

implementations you're going to find

them under the definition of host based

firewalls they're basically software

implementations of firewalls built into

the operating system or installed as a

separate application on your workstation

your laptop even your your mobile device

perhaps so Windows Firewall is one

example IEP tables is another type of

example if you're running on Linux they

still run based on the same principles

of rules that allow or deny traffic that

is still based on access lists with the

additional functionality of having rules

that can be enhanced by process

awareness that is if you look inside the

windows firmware going to see that not

only you can create rules that

specifically allow or deny traffic from

networks and ports and so on but you can

also say allow traffic from this

executable or from this application

towards the internet or deny it that's

type of an additional rule that can be

added because the host based firewall

has visibility over the process table of

the host that it's running on and we

also have application specific firewalls

and their code application specific

because they're designed to protect a

specific type of application we have two

let's say major types of applications

that usually benefit from having a

dedicated firewall first of all we have

web applications and because we have a

bunch of attacks that Target web

applications and also because web

applications are everywhere nowadays so

pretty much every website is a web

application or the back end that's being

accessed by your mobile device or a

mobile app on your mobile phone is also

a web application there's a lot of web

services out there there we have have

web applications that allow access to

Cloud infrastructure and so on so web

application for firewalls become an

important component especially because

they are specifically designed to detect

and stop attacks designed for web

applications so they're definitely going

to be layer 7 firewalls because you have

no chance of blocking a layer 7 attack

if you're not looking inside of the

layer 7 payload also on this topic we

also have database firewalls which are

specifically designed to detect SQL

injection attacks a remote procedure

calls onto databases the attempt to

execute complex queries that might cause

it enough service to database engine so

but they're basically specific

applications that know the language of

that database server the specific flavor

SQL perhaps and they know how to detect

any potential attacks that might Target

those Another one not a major topic here

it's called a network operating system

firewall I've honestly only heard about

this type of firewall and in

certification exams I've never even

heard somebody refer to them as a as a

network operating system firewall in

real life but let's go with that this

type of firewall is basically a type of

a dedicated server it might be Linux or

Windows that is running a firewall

software and that server acts as a

Gateway or as a proxy for the rest of

the network and since we are living in

the age of the cloud of course that we

have firewalls in a virtual flavor as

well starting with actual virtual

machines acting as firewalls uh they're

running on the on a hypervisor they're

running on a virtualized infrastructure

they're mostly going to be used to

protect the rest of the virtual

infrastructure so we have the the

firewall virtualized along with the rest

of the infrastructure or we could even

use that virtualized firewall to

airplane traffic for the rest of the

physical Network so you could still use

a virtual machine on a dedicated server

as your main firewall for the for the

entire network we can also have virtual

firewalls on a dedicated virtual

appliance that is a pre-configured

pre-packaged virtual machines that can

be deployed in just a couple of clicks

and most likely these are going to come

from recognized vendors such as uh you

know Cisco checkpoint Palo Alto 14 net

and so on the major firewall vendors or

security vendors out there and they can

also be deployed on your own virtualized

infrastructure or even in Cloud

environments if your entire

infrastructure inside of a cloud

everything is virtualized in there why

not pop a virtual machine in there that

acts as a virtual firewall especially if

you've gotten used to a specific vendor

and uh you're migrating let's say from

physical to Virtual or migrating towards

the cloud you don't want to use the the

cloud vendors firewall solution you want

to use the traditional Cloud solution

that you've had in your physical

environment just spin up a virtual

Appliance from your favorite vendor and

you're going to be able to configure it

and implement it just the way you did in

a physical data center another type of

firewall virtualization is when you are

actually partitioning or virtualizing

one firewall instance into multiple

instances it's very useful especially

when you're you're hosting let's say

multi-tenancy environments where

multiple let's say customers multiple

clients multiple departments perhaps are

using firework administering their own

rules onto the same formal box now you

can partition or virtualize that

firewall into multiple identities or

contexts or instances or virtual domains

depending on the on the vendor

terminology suffice to say that each and

every one of these instances act as a

completely independent firewall you

allocate a number of interfaces physical

or virtual to each one of those

instances they all have their separate

routing tables they all have their

separate access list their separate

users perhaps their separate management

interfaces so you're basically splitting

one larger firewall be it physical or

virtual into multiple smaller ones of

course the resources that you have

available the compute memory resources

disk resources those are going to be

partitioned as well and one more mention

here just because the exam wants you to

know about this we can classify

firewalls based on the fact that some of

them are open source like PF says right

you can freely download it install it as

virtual machine and even at home or

proprietary code those that run

proprietary code and those are you know

the firewalls that come from the major

commercial vendors out there now let's

talk about proxies and over time I've

seen uh in the last 20 years or so

there's a lot of gray area in people's

minds about what a proxy is and what it

does and most people think about proxies

as a dedicated device that only does a

single thing well nowadays the proxy is

more like a functionality built into

other devices such as firewalls or even

operating systems so a proxy we're going

to introduce it as a concept more than

as a as a dedicated device and we have

two types of proxies now we have forward

proxies and we can think about four

proxies as the traditional proxies that

we've gotten used to you know those that

you can configure inside of your browser

or inside of your operating system and

you're basically instructing the OS or

the browser whenever you try to reach a

specific destination sometimes even the

entire internet make sure you send your

your connection requests to this address

first right so this becomes your your

next hop for internet connectivity now

this type of for proxy is going to be

implemented especially for security

purposes yeah you're going to find it

implemented in networks where uh the

proxy is there to perform filtering or

URL filtering perhaps maybe deny access

to internal users to specific uh you

know gray areas of the internet right

maybe adult websites maybe gambling or

something like that it also can be used

for caching purposes if you know that a

lot of users inside of a company

frequently access the same resources you

might ask the proxy to Cache some of

those resources so what so that when a

different user requests that same

resource you're not going to have to

forward that request to the internet and

download that resource again you're

simply going to serve it from the

proxies cache for performance purposes

and these proxies can be implemented in

a non-transparent method that is the

method where you're actually configuring

the operating system or the browser with

the proxy information with the address

the port which type of Protocols are

going to be forwarded to it and such or

transparent where you're basically not

doing anything but the proxy sits in the

traffic path and automatically

intercepts uh the traffic that goes

through it allowing it or deny it

basically making it a transparent

firewall it kind of it's not the proxy

in itself because it is just a it's just

a point of quality enforcement and

that's it now the other type of proxies

and this is probably where most people

get confused are reverse proxies and the

reverse proxies I I always tell you say

this in in my trainings don't over

complicate the com concept of a reverse

proxy because what it is at the end of

the day is just a load balancer that's

reverse proxy so while the forward proxy

looks at connections initiated from the

inside going to the outside and decides

whether to allow them or not well a

reverse proxy guess what looks at the

connections coming from the outside

aiming to connect to resources inside of

our company and when do we have this

type of implementation when whenever

we're hosting let's say a website and we

have a load balancer inside of the data

center or inside of a in front of the uh

the server farm that hosts that website

or that web application well that load

balancer listens for connections from

the internet and forwards them to the

internal Network specifically to the

server Farm well that load balancer is a

reverse proxy now a reverse proxy or a

load balancer is going to have all the

benefits a couple of them we've already

mentioned in the previous video uh such

as you know balancing connections uh

maintaining session persistency

implementing security perhaps even right

uh maybe forcing the users to

authenticate first before allowing them

access to the rest of the the

infrastructure or even performing SSL

offloading as in terminating the SSL

tunnels or the TLs tunnels that are

initiated by the clients validating the

identity of the clients and then

forwarding that connection to a valid

server in the back end they might also

be performing health checks remember we

also talked about this on previous video

when the load balancer periodically

checks the servers that it has behind it

in order to make sure that the servers

are still up and running and they're

still able to to serve those requests

and by the way if you want to play with

a couple of firewalls you could just

open the management interface on your

home router there's gonna be a very

basic firewall functionality in there of

course you could also play with

something more complex such as pfSense

and by the way you can Google it and you

can download it for free run it as a

virtual machine and it's actually a very

powerful firewall engine completely open

source and free to use here's another

firewall example this one is from Cisco

Meraki that's a cloud-based managed

solution that is also designed for

security routing switching a lot of a

lot of other functionalities in here

that but just to give you a brief

overview here here's the here's the

layer 3 firewall rule here so we have

inbound rules and outbound rules so for

example I could add a new rule in here

and say that the policy is either delay

or allow we can add a description which

protocol I want to use uh what's the

source IP address or even the specific

vlans that I have in my network

destination destination application

destination port and so on right we have

inbound rules here we have outbound

rules as we said remember that we have

separate rules for for traffic entering

and leaving uh the the firewall the

environment we also have cellular

failover rules here's a different one

that's because this device has a

specific cellular failover interface

that can be used whenever the main link

fails uh and we also see some layer 7

rules in here so that's an application

layer firewall now it's not very complex

it's still just a home device here but

let me just select here add a new layer

7 firewall rules I could say which type

of application I want to identify now I

could also have a specific custom

application based on a specific traffic

matching here or I could just choose a

one of these categories so for example

if I want to deny let's say gaming but

what type of gaming you want to deny

Call of Duty do you want to deny I don't

know the Xbox network the Playstation

Networks team and so on I think

I think epic games is not in here

that's a that's a loophole right so

let's say for example I want to deny

Call of Duty that that's how easy it is

right that I now have a rule here that

denies a Call of Duty servers right

that's a layer 7 rules how cool is this

and for a more complex and complete

experience if you don't have a dedicated

Enterprise firewall to play with I would

advise you to head over to

floridagate.40demo.com and by the way

this domain might change in time uh but

just Google 40 gate demo right the four

gates are the uh the firewalls from

Fortinet major security vendor out there

and they allow you a read-only access to

a dedicated instance of a 40 gauge that

you can play with with you're not able

to change anything your you can only

look at the policies you can only see

what the capabilities of the firewalls

are but uh what you're seeing here is

the one of the dashboards right you can

see an overview of the entire security

posture of the network but if you scroll

down here on the left hand side you

should be able to see under uh policy

and objects there's firewall policy here

so these are the rules that make up the

access control list the layer 7 Access

Control list of this for the gate device

notice that what you're seeing here uh

every rule has a name it has a source it

has a destination uh sometimes the

source is a network sometimes it's just

a port a physical port on the device

same goes for the destinations it could

even be any any so we can have a rule

that says from any source to any

destination for example this is a rule

that allows DNS right we're accepting

all kind of DNS traffic it doesn't we're

not looking at it we're not

performing any additional uh inspection

to it all right now for the rules that

you can see it has some of them have

schedules right we can even enable some

rules on a specific uh time interval

during the day during work hours you can

even match the rule on a specific

service so there's this one right here

that's the uh Management on the virtual

IP address traffic which means that

we're only matching management traffic

such as HTTP https FTP SSH radius

traffic right and everything that's

related to aicmp because we're probably

using it for troubleshooting purposes

okay we also have an action here we can

accept or deny the traffic

we also have Naturals because some of

these perform Network address

translations some of them don't and we

also have security profiles uh probably

not be able to see this because of this

my face in front of it but it says

security profiles on the next on the on

the last column here on the right and

Siri profile basically means if you

choose to inspect this type of traffic

are you about to perform any additional

inspection to it so for example AV

anti-virus monitor that's a security

policy that performs layer 7 inspection

down to actual antivirus scanning for

any files detected within that layer 7

firewall so that's how complex a

firewall interface can be or just a rule

in the access control list now on the

left hand side you can see there's a lot

more to see in here I'll leave this to

you play with this one it's completely

free the login is com is already filled

in for you whenever you're you're

connecting to the to the demo website uh

have fun with it it's a nice experience

of what an Enterprise firewall already

configured Enterprise firewall actually

looks like

you can even drill down into one of

these specific rules and see what are

all the parameters that you can

configure under them so you start with

the incoming interface outgoing

interfaces you can see that we have we

can match based on a specific

destination or a specific protocol you

can set a schedule see when when the

rule is going to be enabled or when it's

not going to be enabled the service is

basically the applications the protocols

that the rule matches on you can also

enable Nat right Nat or even net between

ipv4 and IPv6 we can also enable

different security profiles just like we

said before so that's additional

inspection that we can perform we can

enable an antivirus engine here or

select a specific AV profile AV policy

web filtering URL filtering video DNS

application control that is identifying

a specific application especially for

web traffic

that kind of looks the same at layer 4

you have to look at layer 7 to determine

what type of application is in there uh

intrusion prevention can also be enabled

as a policy file filter can be enabled

as a pro as a policy especially in

scenarios where data loss prevention is

required that is we're looking at what

type of files are the users trying to

get out of a company or trying to stand

outside of the company are we going to

allow those files or not right voice

over IP policies web application

firewalls have a look at this one right

this one was supposed to be a dedicated

type of firewall but we have this

functionality built into the 40 gate in

this model at least an SSL inspection

right we do have methods for decoding

encrypted traffic because most web

traffic nowadays is encrypted and if we

don't have some way of looking inside

the SSL connections then we're missing

out on pretty much everything that is

application related

now another very important concept here

that comes into play whenever you talk

about routing towards the internet

firewalls and proxies the concept of

navs network address translation and

what do we translate from and to When

We're translating private IP addresses

to public IP addresses inside of a

network we're running on private IP

addresses specifically those that belong

to the ones described in RFC 1918 and

just a quick refresher if you just

Google for RSC 1918 are you gonna find

out the private IP address spaces that

we're currently using all over the world

are 10 zero zero zeros basically 10 8 we

have

172.16 12 and 192.168 is probably the

most common one that you surely

recognize from your home network which

is a slash 16 prefix now these addresses

are private as in they're not routable

over the Internet which also means that

you're free to use them however you want

inside of your own backyard sorry your

own network your own private Network and

since those private IP addresses are not

routable over the Internet that is you

cannot go out on the internet dressed

like that you cannot go out wearing a

source private IP address because the

traffic is not going to be able to reach

back to you that address is not routable

over the internet you'll have to

translate it to something that is

acceptable whenever you go out right on

the on the internet so you're gonna have

to translate the IP address on a private

range to a public IP address that is

routable over the internet and the way

we can perform these type of address

translations range from simple static

net that is just a one-to-one mapping

between a private IP address and a

public IP address not very often found

that is because well public IP addresses

are not so ubiquitous as they used to be

we don't really have that many of them

and most companies only have one or two

public IP addresses but thousands of

private private IP addresses so a

one-to-one mapping simply doesn't work

which means that we have to rely on a

different method of dynamic net that is

when we instead of having a single IP

address a public IP address that we're

using for outbound connections we have a

pool of IP addresses now don't think

that we have thousands of them we might

have two or three perhaps but we're

still using them together in order to

provide connectivity for as many hosts

on the inside as possible which brings

us to the actual real implementations

that we find nowadays which are called

port address translations or Pat or Nat

overload sometimes you're going to find

the overload terminology especially in

Cisco documentation that is a many two

one or many too few address mappings

between private and public IP addresses

in most situations this is going to be

implemented as a rule that says any

private IP address that comes from the

RFC 1980 range is going to be translated

to one public IP address that we're

going to be using to go out on the

internet and if you're thinking well how

do we actually keep track of all those

connections because well if 10 people at

the same time use the same IP address

when the replies come back in how does a

router know which reply belongs to which

user well that's simple basically we're

calling it port address translation

that's because we're multi-plexing so

we're combining multiple connections on

the same IP address on the same public

IP address but on different port numbers

right so each and every device behind

that Nat device is going to create a

connection with some Source port number

bhtcp or UDP well that Source port

number is going to be stored in a table

a translation table on the device that

performs snap or path and then when the

reply comes in on that specific Port

then the device is going to know to

forward it to the right client that

initiated the connection

so in a visual representation we could

have something like this we have

multiple clients on the left hand side

trying to access let's say Yahoo whoever

does that anymore uh we're gonna

initiate those connections and those

connections are going to be stored by

the center device here the route or net

device in a net translation table so for

the device that has a private IP address

of 192.168 100.3 well they might be

initiating that connection with a source

port number of 3855. now the router on

that device might overwrite the IP

address that's the basic Nat Network

address translation so it's going to

replace you with the public one that's

probably going to be the interface that

it has the IP address that it uses to

connect to the internet and perhaps even

replace the port number it doesn't even

have to maintain the same Source port

number right so it's going to create a

packet here it can create a request

going to Yahoo on Port A let's say but

sent with the public IP address and the

translated Port now whenever the reply

comes in back from Yahoo is going to

come for this IP address 145 12

3131.7 so that's going to be the public

IP address and for Port 6282 now

internally the translation table is

going to tell the router that whatever

connection comes in on Port 6282 it

belongs or it needs to be sent or

forwarded internally to this IP address

this private IP address the 103 IP

address on Port 3855 all right so as you

can imagine we can scale this a lot so

we can have hundreds of clients

thousands of clients in here each and

every one of them identified by a

different port number even though we're

only using one single IP address to

communicate over the internet

and finally one more topic here what we

just talked about Nets that's uh most

likely going to apply to the source net

and so the source address translation

that is we're trying to get rid of a

private Source IP address and replace it

with a public one but we can also

perform Nat in reverse that is

translation of the destination address

that's happening whenever we're

implementing port forwarding you

probably know about forwarding if you

try to make a service public in your

home network you have to configure on

the router a rule that said whenever

you're receiving connections on this

specific port on your internet interface

make sure you forward them to this

private IP address inside the network

and on this port so that's port

forwarding it's kind of a nap in reverse

that is worth listening for connections

coming from the outside and then we're

changing the destination IP address of

those connections to match a private

endpoint a private address within our

Network this is how we can expose

service is over the Internet even though

those services are running on private IP

addresses and we can allow people to

connect over the internet to those

internal services that we're hosting and

of course there's nothing stopping you

from performing poor translation in a

scenario as well now probably if you're

exposing a common application such as a

website you're probably going to be

exposing ports 80 or 443

and internally your application is most

likely going to be listening on ports 80

and 443 but your application can be

listening on any port as long as you

correctly configure the port forwarding

rule it doesn't even matter on which

what your application is listening on as

long as you properly instruct the router

to translate the connections coming on

ports 80 or 443 to be directed to be

forwarded to the right ports that your

application your internal application is

actually listening on

all right so that's it for today another

networking pretty heavy chapter in here

I hope you found this useful and

informative I hope you liked it and if

you did like subscribe leave a comment

to chat some more and hope to see you on

the next video good luck

[Music]


21 21 




foreign

[Music]

monitoring has been around for a lot of

time probably ever since the first

networks were invented just like with

any system just like with any electronic

device we tend to want to be able to

monitor if everything is going okay we

want to receive warnings we want to be

alerted when something goes wrong when

when something fails and this type of

monitoring is tremendously useful

especially in larger networks over time

this monitoring has extended to security

monitoring as well so we're not just

concerned about how is the network doing

if it's working well if you don't have

any failed devices but we're also

starting to look at the network traffic

how is the network utilized who uses it

who attempts to access it what type of

traffic are they generating and if we

try to gather all this type of

information we try to make sense of it

we try to correlate it with a smart

enough device we might be able to detect

attempts at intrusion or attacks that

are about to happen or that have

happened in the past or proves that

we've been compromised or somebody in

the network has been infected and all

that information is in there if you know

where to look for and also if you have

the right tools to look for it

in general the term internal detection

refers to a system that is able to

monitor whatever can be observed in a

network and in most cases we're talking

about two things that can be observed

first of all we have Network traffic

and then we have application events or

logs generated by the operating systems

by the applications running on those

os's and so on so coming back here to

our Network Focus we're talking about

intrusion detection at our Network level

we're going to call this one a network

based intrusion detection system or nids

and we have many commercial Solutions as

well as open source ones that are able

to perform this type of network-based

intrusion detection of course all the

major security vendors are doing it in

many examples you're going to see the

IDS functionality built into the

functionality of a larger firewall or a

larger UTM device especially for major

vendors out there but you also have

Solutions in the in the open source area

such as sort suricata or Zeke or bro

they're all available some of them also

have commercial versions as well but

they also provide you with three

versions that you can freely install and

try and run in your own environment now

the way these uh intrusion detection

systems work by definition is that they

rely on a database of signatures and

those signatures are basically just a

way to describe how a specific traffic

pattern is supposed to look like in

order to detect a specific type of

attack or attempt at an intrusion so we

might be looking at a sequence of

packets so that looks in a certain way

we might be looking at a specific type

of packet that doesn't play by the

normal protocol rules that it belongs to

or a specific type of payload or simply

just a a signature a byte sequence that

can be found in the in the packet

payload that indicates the fact that the

payload is malicious and this behavior

is very similar to what you're seeing in

antivirus scanning or anti-malware

scanning we're simply looking for a

sequence of bytes that indicates that

well if we find the sequence of bytes in

a specific executable file it means that

the file is infected with that specific

virus that the the sequence belongs to

now when intrusion detection again we

we're kind of doing the same thing right

we're looking for patterns but we're not

just scanning individual packets

sometimes we need to collect more

packets in a sequence in order to

determine if the behavior of the client

that is generating those packets is

abnormal and if it's abnormal what does

it indicate an attack pattern or not the

long story short intrusion detection

systems are strongly dependent on a

database of signatures now more advanced

nitrogen detection systems could also

correlate this network information with

log information so we're seeing

something fishy in the network by

looking at the network traffic let's

check the application logs that the

traffic is is going towards for example

let's see how that application reacts

and if we if we can see some abnormal

logs being generated by the app as well

now correlating that information the

traffic analogs might tell us more about

the actual attack or might increase the

confidence of the fact that we really

have identified a valid attack signature

not all solutions are able to do this of

course also a very important distinction

for intrusion detection system with an

emphasis on detection is the fact that

these systems are never able to block

the malicious traffic once they identify

it it's just like the name says just

detection it's not prevention all right

so we're not stopping the traffic we

might be able to see an attack signature

we might be able to raise some alerts

generate some syslogs but we're not

going to be able to block that specific

type of traffic one positive side for

this is that well if the device is not

inside of the traffic path then the

attacker might not even be able to

detect it

so most likely the the IDS is going to

work with a copy of the traffic just to

analyze it but it's not going to be able

to stop the malicious traffic and the

attacker is not going to be able to

detect the IDS device and might not even

be able to compromise it if if they

intend to in most situations the IDS

device doesn't even have a valid IP

address within the network that they're

monitoring so it cannot be addressed it

cannot be compromised by communicating

with it directly alright so since we

mentioned the fact that an IDs works

with just a copy of the traffic let's

see how can we generate that copy of

traffic right they're not within the

traffic path so we need to make a copy

of the traffic and just send it in a

separate channel on a separate channel

to the IDS device for analysis now my

way of doing this is by enabling Port

mirroring or span on in Cisco speak this

is switchboard analyzer just a

functionality on layer 2 or layer 3

switches that allow us to configure the

switch and we're basically telling it

well whatever traffic you're seeing on

ports let's say one two and three make a

copy of that traffic and forward it out

of port number eight and of course we're

assuming that on Board number eight

there's an IDs device connected right

there so we're basically telling the

switch to make a copy of all the

interesting traffic and send it towards

the IDS and of course you might be

thinking here well what if the switch is

overloaded what if there's more traffic

generated on those ports than the uh the

mirror report can actually support well

that's true it might happen so in in

cases when the switch is overloaded and

there's too much traffic in the network

packets might be dropped and also frames

with errors might not be forwarded to

the uh to the merits board either so we

might not be able to see 100 of all the

traffic but in most cases it's going to

be enough and it's also one of the

features that basically doesn't require

you to install anything else in the

network it's just a functionality just a

configuration effort just a couple of

commands on a switch another method for

duplicating traffic is by using a

passive order and active it's basically

layer 1 device called the tap a test

access port it's nothing else than a

kind of like a t connector where the

main cable goes from one end to the next

and there's a third cable that actually

receives a copy of the entire traffic

going through that that segment of cable

the device is not a smart one so it's

it's not like a switch it's not going to

look at the destination frames and

forward uh entire packets it's simply

going to duplicate the electrical or the

optical signals that it sees on the wire

and it's going to make a complete and

identical copy of those signals onto the

third connection which of course is uh

is ideally connected to the IDS device

now this type of approach is again

completely undetectable

span is not detectable either right and

also copies entire frames regardless if

those frames contain errors or not as we

said with Port mirroring while the

frames need to be correct in order to be

copied well with a tap the tap doesn't

care it's basically just a signal

repeater and we can do this for both

copper cables and so electrical signals

as well as fiber optic so Optical

signals the tap will not care we'll just

blindly copy all the signals that it

receives and finally the third method

for monitoring traffic is by having the

IDS device in the traffic path

but acting as a transparent device again

without an IP address or basically

becoming a layer 2 device that is part

of the same VLAN that they're they're

bridging but they cannot be addressed on

the network they cannot be detected on

the network and they if it's a true IDs

device then it's not going to be able to

block the actual traffic that goes

through it now having the device placed

inside of the traffic path opens us to

the possibility of actually blocking the

traffic and that's going to be a

different type of solution called

intrusion prevention system and we'll

get there in just a moment there's one

more type of intrusion detection device

or solution and that is a software

solution that can be installed directly

on the workstations so I'm not talking

about a box that listens to network

traffic on an entire segment but we're

talking here about a software solution

basically a program that runs on your

endpoint machine on your host machine be

it a laptop or a desktop now this one is

called host based instruction detection

because it runs on the host and it does

have pretty much the same benefit it's

or the same abilities as a network-based

internet detection so it's able to look

at the network traffic going in and out

of your network interface it's able to

look at the logs generated by the

applications on your system but since

they are running as an application on

your system they can become even smarter

because they might have access now to

the actual process table they might be

looking at the kernel you might be able

to look at the memory to see what

processes are running when did they

execute who executed them with what

privileges and they can also openly look

at encrypted traffic so if you are

communicating over SSL with a website

well a network-based internet connection

might not be able to understand anything

that's going back and forth because it's

encrypted but your host based intrusion

detection

is located at the end of that encrypted

tunnel so it is able to see that

unencrypted traffic before it even

enters the encrypted tunnel and right

after it leaves the encrypted tunnel so

it's able to actually watch the entire

traffic flow in an unencrypted form and

again since we have pretty much full

permissions on on the monitored host in

order to be able to properly monitor the

you know the process table and the

network connections and the network

traffic we could also have a look at the

files on the disk

why would you do that well that's

because monitoring the Integrity of the

files on the desk especially the

Integrity of the operating system files

and being able to detect when that

Integrity fails when a system file is

being replaced with a malicious one when

a system file is is becoming encrypted

or it is replaced with a completely

different version that might be an

indication of compromise that might be

an indication of the fact that you have

been infected with malware so Solutions

or functionality additional to host

based internet detection that monitor

files on your system especially

operating system files these are called

file Integrity Monitoring Solutions and

remember that we said that when we place

the intrusion detection device in the

traffic path

device actually becomes able to also

block the traffic that goes through it

which can make it an intrusion

prevention system right so detection

just alerts just generate alerts or

events intrusion prevention is about

actually actually taking action or

acting upon the detected intrusion so

what can a such a device actually do

whenever they're they're seeing

something fishy going on inside of the

network well they could do something as

simple as simply sending a TCP reset

packet to the originator of the

malicious connection they could also

have some more advanced functionality

especially if they if it's the same

device that acts as a firewall they

might be dynamically able to generate a

firewall rule to block similar traffic

like the one that was just detected as

being part of an attempt for for an

attack or for a compromise we could be

choosing if we're detecting something

that looks like a denial of service

attack we'd be choosing to limit the

amount of bandwidth that is allocated to

that specific type of traffic kind of

like policing that we're doing in into

our inequality of service in any case

any type of action that the IPS device

can take against the malicious traffic

we're going to call it active response

and depending on how complex the device

is and how powerful the device is you

might actually choose to look not just

at simple IPS or IDs signatures but also

look for malware signatures yeah that's

that's going to require you to you know

to decode encrypted traffic it's going

to require you to identify potential

protocols that might be carrying files

gather all those related packets that

belong to the same TCP Stream So the

same flow assemble them into an

executable file store that in memory or

attempt to scan it with an antivirus

engine and then determine if that flow

was actually malicious or not now this

requires a lot of processing power this

is going to create some sort of delay in

the networks of the users they're going

to see their their download uh unable to

finish or the application responding

slowly until the firewall the UTM device

or the nutrition prevention system is

actually able to scan those files

against malware signatures on a lighter

approach we could also just be looking

at URLs looking for malicious domains or

domains that show associated with

malware or with the command and control

servers we might be looking at URLs in

order to categorize those URLs and

figure out the reputation of that URL

and decide whether we want the

communication to that specific website

to proceed or not so regardless if the

device is an IPS or an IDs the detection

methods are pretty much the same now the

difference is just in what the device is

actually doing is it only alerting or is

it actually taking an active response

approach to the traffic but the

detection part is pretty much the same

right and when talking about detection

we are going to start with the basic

type of detection that is where we're

just looking for signatures in the

database which of course means that we

need to have an up-to-date database for

the device to be able to detect the

latest and the greatest attack now this

is basically one of the reasons why

people choose to pay for commercial

Solutions because databases maintained

by a dedicated software or security

vendor that deals with intrusion

prevention those databases are going to

be much more often updated and kept up

to date in order to mirror as best as

possible the database of all the known

attack patterns ever detected in the

world now with open source Solutions

you're gonna you're still going to have

a pretty good level of protection but

you might not be able to detect an

attack that was just identified

six hours ago nevertheless and

regardless how up-to-date your database

is you're still limited by the attack

patterns listed in that database if an

attack emerges and doesn't match

anything in your database it's still

going to go through

which leads us to a different approach

and that is a behavioral approach so

instead of looking at specific streams

of bytes specific headers specific

sequences of packets let's look at the

overall behavior of an application or of

a protocol

does it look like it's doing what's

supposed to do is it generating more

packets than we're used to seeing is it

uh generating more traffic is it

generating an abnormal amount of control

information as opposed to a real

transfer data and we call this

behavioral monitoring now in order for

Behavioral monitoring to work we need to

have something to compare that behavior

too and say well if it goes outside of

the known ranges

then it looks like something's fishy

well that known range is supposed to be

your Baseline so such a device or such a

system is supposed to be trained first

you're supposed to just leave it inside

of the network for let's say a week or

two just figure let it figure out how

does a normal Monday morning look like

in your network when everybody comes

into work and they start logging in and

start updating their their uh their

machines and perhaps even their mobile

phones only on the company Wi-Fi but

nevertheless you have to leave that

interim prevention solution learn what

does your normal traffic look like when

people start accessing internal

applications where people start

accessing internet destinations when

people start communicating sharing files

between each other when when backups

start to happen at midnight perhaps

right you have to let it learn so that

in a couple of weeks when something goes

outside of the known range where an

application behaves the way it did not

behave in the first training weeks then

it's going to be able to raise an alarm

and perhaps indicate the fact that the

application has been compromised or that

somebody is using it in order to elevate

their privileges or just compromise your

network and as you can probably guess

this is one area where machine learning

is going to provide you a lot of benefit

given that you take the time and efforts

to educate to teach the machine Learning

System what does your normal Baseline

look like now of course regardless how

complex or how well tuned Your solution

is going to be there will be false

positives and there will be false

negatives which is why I always tell

tell students there's a old saying that

I heard from someone in Cisco a long

long time ago and they said that IPS

Without Eyes

is useless so IPS without human eyes is

useless there there's always going to be

the need to have a human being right

there evaluating and analyzing whether

the alerts generated by the intrusion

prevention or detection system are valid

or not does it need more fine-tuning or

do we need to raise an alarm so what

devices can we actually find that

implement this type of advanced

functionality be it detection or

prevention well unfortunately this is

the uh the place where we're slowly

stepping into the marketing area that's

because the devices that we're going to

be listing here are not completely

different devices but over time

different naming conventions have

emerged different marketing names have

been invented to make them sound cool to

make them sound different from what the

other vendors were doing so we're going

to start with the next generation of

firewall and we will have this type of

Next Generation

for about 12 or 15 years already I've

been hearing the Next Generation term in

in uh in I.T security for so long that

I'm starting to wonder

are we still next generation are we have

we skipped the generation are we now in

the next next generation or where does

it stop where does it end where where

does the Next Generation begin right now

unfortunately marketing people don't

really ask themselves these questions so

we're kind of stuck with this

terminology for now and we're gonna keep

calling you next Generation until I

don't know when but regardless a Next

Generation firewall is basically just a

layer 7 firewall that's an application

layer firewall which is able to look at

the application layer payload so we're

actually seeing the data being sent

we're not just looking at the packet

headers and it also has some sort of

detection or prevention system built in

okay so we have an IPS or an IDs built

in which leads us back to the discussion

that we had before so we have an

application layer firewall which can be

enriched with additional functionality

now that we have access to the actual

application payload well why why not

look for intrusion signatures why not

look for malware signatures why not look

for spam signatures right so depending

on how complex the device is if it at

least has IPS functionality built in

we're going to call it the Next

Generation firewall and here's the funny

part if the Next Generation firewall has

a bunch of other additional features on

top of the IPS functionality such as

malware scanning antivirus scanning

perhaps looking at the files and being

able to implement some data loss

prevention policies uh it's able to look

at the URLs and categorize them and

analyze the reputation of the web pages

and pretty much everything that we could

possibly think of that we could be doing

just by looking at the application data

then we're going to call this a unified

threat management device a UTM device

again I don't think I need to repeat

this but the more complex the device

becomes the more stuff it needs to do in

order to decide weather to allow a

packet or not the more resources the

more CPU intensive is going to be the

more memory is going to require and the

more delay is going to introduce in the

network so keep this in mind even though

it kind of sounds cool right to have all

that security functionality in a single

box

which by the way you try to make sure

it's not a single box of failure single

point of failure all right

even though it sounds cool to have all

this functionality in one place

it's going to hit your performance

pretty badly right so keep this in mind

don't just enable everything blindly

because the end users the applications

and well God forbid the your your

customers you're paying customers

they're going to feel the the effects of

your of your awesome UTM device and

their application experience is going to

suffer now a special type of network

monitoring device can also be considered

a web application firewall we've briefly

mentioned about where allocations

firewalls in in a previous video and we

said that uh a web application firewall

is just a dedicated firewall that is

specifically trained and educated to

look at attack signatures aimed at web

applications so we're looking for things

such as cross-site scripting we're

looking for

um you know directory traversals we're

looking at SQL injection attacks we're

looking at pretty much anything that

could be performed by malicious user

that is trying to exploit a input

validation flaw in a web application so

it's still an application layer firewall

it still looks at the the application

layer payload it's just that it's a bit

more let's say picky about what type of

traffic is it going to analyze so it's

only going to look at web traffic and

it's only going to look for uh web

attacks web application attacks it's

mostly going to rely on signatures

that's because we cannot really do much

when it comes to requests coming in from

from our clients behavioral analysis

doesn't really play well here because

most attacks especially where vacation

attacks are just one single request one

single query with a malicious payload so

so in many situations it's gonna be

either black or white right we we're

detecting an attempt at an intrusion

we're detecting an attack in that

require West or not it's pretty much not

going to be much of a gray area with

verification firewalls and you could

deploy a WAFF as a separate device it

could be a physical box it could be a

virtual machine it could be a

functionality within a UTM device again

all in one wonders but it can also be a

part of the web server itself so we have

plugins that install alongside the

actual web server that is hosting the

web application such as plugins for the

Apache web server for the IIs web server

on on Windows server or for nginx so

we're installing these plugins right

there and their purpose is to scan the

traffic that's coming in from the

clients before allowing that request to

be processed by the web server having

something such as a plugin that runs

alongside the web server on the same

machine on the same box opens us to the

risk of either having that machine

compromised by an attacker who this time

doesn't Target the web application but

targets the scanning engine and can

intentionally cause for example a denial

of service give it so much traffic to

analyze that the web server running on

the same machine is unable to actually

respond to valid requests so there you

have it that's the now service attack

now when it comes to actually monitoring

the network traffic we said that a

solution would be to just simply mirror

all the traffic and then look for

specific deck patterns inside of that

traffic now that might not be always

feasible because the amount of traffic

entering a data center or the server

form that hosts an application might be

huge right so in some situations we

might not be able to analyze the exact

amount of traffic that goes in but we

might be able to generate a summary of

that traffic and then Analyze That

summary for intrusion attempts now this

traffic summary is sometimes found under

the terminology of netflow or S flow or

J flow which is basically just a

technology implemented by various

vendors out there in which instead of

creating an exact copy of the traffic

we're simply summarizing that traffic

and then reporting that summary back to

some analysis software so we're only

telling it what type of sources what

type of destinations have communicated

how many bytes were used what type of

protocols has been have been used uh

what type of flags have been set in that

specific type of traffic but we don't

put the burden of sending the entire

actual traffic in the entire payload to

that analysis software now this also

means that we're losing application

layer visibility all right since we're

just summarizing the type of traffic

we're only describing the metadata about

the traffic we're losing everything that

pertains to the application layer but

we're gaining a lot of performance and

we can also store this summary

information long term for further

analysis somewhere along the line in the

future sometimes looking at traffic it's

simply not feasible maybe we cannot grab

all the traffic that's running through

the network maybe we don't have network

devices smart enough to generate those

so those summaries those those flow

reports for us so another solution would

be to Simply have a software monitoring

service Ocean or so-called a network

performance monitor that queries

periodically your networking devices

queries your your routers your switches

uh your wireless LAN controllers your

firewalls perhaps about the status of

their physical resources status of their

interfaces how much traffic is going

through their interfaces I was the CPU

load what's the memory usage what's the

structure of the routing table how does

the r table look like how is the dhtp

traffic looking like right so any type

of monitoring information that can be

extracted out of these networking

devices which in turn can be correlated

in order to figure out if we can see

some anomalies in there one such

solution is for example solarwinds npm

Network performance monitor which is a

dedicated solution for monitoring not

just networking devices but also servers

and virtual machines about their their

their health right how are their network

interfaces looking like how much load is

there on their Hardware resource or

their Hardware components are they

generating any alerts do we have failed

interfaces do we have failed processes

we have something that's uh failed links

are we detecting errors or overloaded

devices stuff like that

now this type of performance monitoring

can be done over a variety of protocols

in most cases the SNMP protocol is going

to be used because it allows us to

report a lot of the hardware counters

and a lot of the interesting information

that we want to gather in store long

term also we might be using wmi such as

Windows management instrumentation and a

couple other protocols as well and of

course we could enrich this collection

by collecting logs from the monitored

devices and appliances as well and we

could be collecting those logs over

syslog so we need to configure the

device to actually send those syslogs

messages or at least a copy of them to

the monitoring device or we could rely

on an agent an additional piece of

software installed on the server on the

virtual machine that periodically

reports back to us everything of

interest regarding the that specific

host when talking about dedicated

software design specifically designed to

analyze a lot of information coming from

the network beat Network traffic Network

summaries such as netflow logs and any

kind of application data that solution

is most likely going to be called a seam

a security information and event

management now the keyword and a

definition of seam is correlation that

is it's not just a place where you just

dump all that information in a huge

database it's a place that as you dump

that information is going to look for

patterns inside of it it's going to try

to correlate Network traffic with logs

or application data with with netflow

data in order to figure out if some

anomalous behavior is detected in your

network so same solution and by the way

these are pretty expensive Solutions out

there are never designed to be just log

storage right they're engines smart

engines based on machine learning that

aim to detect patterns of intrusion by

analyzing and correlating information

found in multiple log files and what's

interesting about the implementation of

seams is that they're supposed to

collect logs from your network devices

from your security devices even from

your workstations and your mobile

devices perhaps and they're able to

understand and correlate all that

information and normalize all that

information even if it comes from tens

or hundreds of vendors or thousands of

devices

and they're able to normalize that

information and make it look the same so

that in the end

it can look for patterns inside of it

and it also allows you to perform

queries in a language quite similar to a

regular SQL language and query all that

information regardless of the fact that

it actually came from or tens of

hundreds of different vendors and since

a seam without machine learning

functionality is not a very useful theme

we could use that machine learning

features to look at user Behavior as

well because in the end we're trying not

to detect just you know attack patterns

we're also trying to identify who is

conducting them and a great risk comes

from Insider threats so if we are able

to monitor what our users are doing

we're not talking here about just

watching what websites they're they're

visiting or taking frequent screenshots

of their of their workstations now we're

not doing that but we're looking at the

behavior that they're exhibiting

whenever they are interacting with

specific applications and if the scene

has such an ability we call that ability

user and entity Behavior Analysis don't

think that we're only uh performing here

a Witch Hunt against uh Insider threats

think about the fact that we might be

able to detect abnormal behavior because

a user account has been compromised by a

hacker and that hacker is now acting on

behalf of that user the user might have

nothing to do with that abnormal

behavior might not even know about it

might not even be logged in at that

specific point in time but the attacker

might be acting on behalf of that user

if we're able to detect that abnormal

behavior we might be able to detect the

attack going on right then and stepping

just a bit into the realm of Science

Fiction here I know that some vendors

will say no this is not science fiction

where we're selling this we've had huge

success with this well yes and no I'm

gonna keep being a bit skeptical as to

how efficient this approach is what I'm

talking here about is sentiment analysis

or emotion AI that is analyzing user

behavior in what contents the user is

actually creating as in blog posts

social media posting

we're not talking here about actual you

know analyzing the contents of emails

and and chats because that might you

know step into the Privacy area which we

might not want to do that but by

analyzing publicly available information

generated by those users we might be

able to detect disgruntled employees we

might be able to detect uh unsatisfied

clients that might create some bad

reputation for the company perhaps even

before they become so upset as to take

action or malicious action against our

company again take this with a brain of

salt and don't just think that if it if

it sounds awesome on paper it has to be

awesome in real life if it sounds too

good to be true then it probably is too

good to be true

and finally the last term here that I

wanted you to know about is soar

security orchestration Automation and

response that's a mouthful I know it's

usually functionality built into SIM

Solutions or it can be just a standalone

solution but it basically uh it tries to

address is the problem of too much

information that is being overwhelmed by

too many alerts too many security events

too many security incidents too many

incidents that we need to determine if

there's security related or not

basically the hell of any I.T Department

that deals solely with monitoring the

network and the applications and the

idea behind this is that a solar

solution is supposed to use some machine

learning techniques in order to not just

to figure out which anomalous events are

occurring in the network but by

analyzing those anomalous events it is

able to take some action against them so

it could at the point uh determine if an

attack is going on even if it happened

in the middle of the night and take

action immediately by blocking some

ports by creating an access list by

disabling temporary disabling some user

accounts that might have been

compromised so that security

orchestration Automation and response

just be sure everybody is clear on this

especially for the exam where does the

theme get this information from where

first of all it's going to get it from

logs right syslogs that's going to be

the main source of information how do

you collect logs well you don't really

collect them you expect those devices to

send those to you so those devices need

to be configured uh be it networking

devices there might be servers there

might be virtual machines whatever type

of device you have just configure them

to send your logs to a secondary

destination if the seam is not the

primary one just make sure they send a

copy of those syslogs to the same device

as well next the scene can also collect

data by installing agents on specific

systems now of course we might not be

able to install agents on let's say

routers or switches apart from some

recent devices that are running Docker

containers perhaps but in most cases CM

agents are designed to be installed on

Windows and Linux systems then they're

running as background processes that

periodically scanned the system and

report back to the seam uh the logs

generated by the operating system the

running applications the long generated

by the applications actually running on

that host depending on how the agent is

configured the built-in listeners or

collectors that you're seeing here on

the slide refers to the fact that the

seam is pre-configured or has plugins

that allow it to understand what

different vendors are reporting back to

it so it's going to have different

plugins to understand Lots coming in

from you know Cisco devices HP devices

Dell VMware whatever vendor it is it

needs some sort of a plugin to

understand that specific log format and

more than one than that it needs to

understand the contents the payload of

what the log is saying SNMP traps again

most monitoring information is going to

come in through an SNMP query or as an

SNMP trap generated by the device back

to the seam and also netflow netflow or

different variants implemented by

different vendors are basically just

summaries of the traffic flows detected

over a certain period of time collected

and then sent over to the scene device

in order for that traffic summary to be

analyzed finally the scene can also

capture raw packet data if it has

dedicated sensors that are able to

generate a copy of the traffic and send

it back to the seam or we can even have

sensors installed inside of network that

are monitoring real traffic and they're

only telling back to the seam or

reporting back to the sim a summary of

that traffic this is very useful when

your devices don't have enough reporting

on monitoring capabilities to report

back to the Sim device instead you need

to install some specific sensors that

look at the traffic and then tell the

seam the necessary information that it

needs to perform those correlations

sometimes a sensor such as this one YB

and IPS or an IDs device even log

normalization is a feature built into

most Sim Solutions out there and

normalization is required and it's a

very important feature because the seam

is designed to collect information from

hundreds of vendors and thousands of

different appliances each of them

running different operating systems on

different versions and they're all

building syslogs and SNP traps in

different formats some some are

reporting them as a text some are

generating logs in binary format some

logs are in Json format some are in XML

format or or CSV format depending on how

the vendor actually designed its logging

and monitoring abilities we might even

find differences as to how the logs are

actually encoded some of them are might

be using UTF some of them might be using

some Regional encoding we might even run

into some issues due to the fact that

the new line character is represented

differently between Windows and Linux

systems and that also might be reflected

in the payload included in the logs that

we're receiving as as part of the

monitoring process not to mention the

fact that the SNMP mips basically the

the database schemas that each vendor is

using for their own software Solutions

or Hardware Appliances these are

completely different not just among

vendors but also among different

products from the same vendor so in

order to have all this bunch of

information collected in some

centralized location and to be able to

query all this information and to be

able to approach it in a in a consistent

manner we need normalization that is

taking all this information coming from

so many vendors in so many formats and

making that information look exactly the

same so that it can be stored in a

single database that can be queried at

once regardless of the source of that

information so what are we using to

normalize all this information coming

from all these vendors well you guessed

it we're gonna need some plugins some of

these plugins come from this Sim vendor

itself so they're going to be

pre-packaged with vendors vendor plugins

from for major vendors out there some of

these plugins are going to come from the

actual vendors so if a smaller vendor

create hate them let's say smaller

firewalls at some point and they want to

be able to integrate with the

large-scale seam Solutions they're going

to provide you with a plugin for their

own environment as well and another type

of normalization that is really really

important is timestamp normalization

don't forget that we're looking for

anomalies in a network traffic and in

network events and if we don't have

timestamp normalization if we don't make

sure that all the events that we're

looking at are actually stored with

their right timestamp at their right

moment in time when they actually

happened we have no chance of detecting

anomalies in the network so we might

have devices that are that have a badly

configured clock we might have devices

that have been configured for different

time zones we might have devices that

display time or or timestamp those time

values in the in their logs in in one

format versus another format some of

them might be using 24 hour some of them

might be using 12 hours some of them

might include the daylight savings time

some of them might be using a UTC or

Unix ebook time it's up to the vendor so

normalizing these timestamps is also a

very very important topic here that

needs to be taken care of by the same

solution before that event indicated by

that specific timestamp is stored in the

database alongside with the others now

the way a Sim solution can look for

anomalies in that huge database that we

just talked about well it could be done

in a number of ways we could just rely

on simple if then else matches so we're

looking for you know specific events

specific types of logs being generated

in a specific time range perhaps this

type of approach is the fastest one

because it it's basically boils down to

a simple query in that huge database

stored by the CM and Appliance

unfortunately if there are unknown

threats if there are attacks that we

know nothing about that we don't have a

signature for them we don't know what to

look for we're not going to be able to

detect them kind of makes sense right so

another approach would be heuristic rule

matching this is a type of rule matching

where we're not exactly looking for an

exact match

for the specific type of event but we're

looking for something that it's pretty

close to it all right so this type of

approach

relies on a more permissive set of rules

so if it doesn't 100 match or rule let's

say if we have some events that are

pretty close to it and match it like

let's say 80 or 90 percent

now this also requires you to fine-tune

your rule set so if at some point by

doing heuristic rule matching you're

detecting some anomalies but you don't

have a rule that matches that anomaly

100 well you'd better create it right

you'd better fine tune your rule set and

add some more rules or tweak the

existing ones to match that newly

detected anomaly and just to recap this

year in behavioral analysis implemented

in a CM relies on the fact that you need

to build a baseline you need to tell the

Sim how does your normal look like how

does your normal traffic look like how

does your normal logs generated by all

the devices and all the applications in

your network looks like so that in turn

can be used as a starting point in order

to detect potential well mismatches that

might indicate attacks or attempts at

compromising your network now of course

this is going to create a lot of false

positives so you might into a situation

where an alert is being raised because

in an application starts generating some

huge backups because some admin has

modified the backup policy now the same

device sees a lot of traffic in there

racism alert raises everyone from their

sleep at 3am in the morning and saying

that oh my God this looks like a data

exfiltration attempt somebody's is

dumping all the data from our database

and then an admin has to come in and

intervene and say my dear seem what's

happening in there what you're seeing is

just a full backup happening at 3am in

the morning it's okay right don't freak

out about it okay so it does require

human intervention for fine tuning these

rules

on the other hand we have anomaly

analysis and this is by definition a

type of analysis that is performed

whenever we're comparing observed

Behavior with known standard Behavior

especially when we're comparing what

we're seeing as part of a protocol's

behavior with what this theme device

knows that the protocol is supposed to

behave according to its RFC according to

its definition finally with Trend

analysis we're going to be looking at

historic data and try to extrapolate it

for example if we see that the backups

are increasing every single week because

more data and more data is generated the

same device might be able to generate a

pattern so that if we see five gigabytes

and backup this week and eight gigabytes

of backups next week when it is going to

see 12 gigabytes two weeks from now it's

not going to raise an alert because it

expected the backup volume to increase

by that amount but I don't need to tell

you that not everything can be safely

predicted this way finally after all

that advanced correlation and machine

learning and AI features the seams

actually can be used as a database for

event storage and they can be queried by

human users by admins if you know what

to look for perhaps you just need to

investigate some event perhaps you need

to perform some some forensic analysis

so those databases become available to

you to any admin basically simply by

creating specific rules in order to

match specific types of events stored in

there so you could create simple rules

that are they're matching based on

specific conditions look for one

specific IP address or look for a

specific time range look for one

specific string that might occur in all

those log payloads maybe look for a user

and see what are the events that are

that are generated by the user or that

implicate that you user and so on and so

forth so the seam appliances are going

to allow you to create some queries very

similar to what you might be already

used to if you ever used SQL in the past

because all that data is basically

stored in a relational database which

can be queried with an SQL like a

language and finally don't forget that

at the end of the day not everybody has

money to invest in a Sim solution so you

might end up having to analyze your logs

by yourself just navigating a bunch of

logs and this is where a bunch of text

matching utilities especially some

utilities that are built into most Linux

distributions are going to come in and

help you tremendously now this is not

Linux course and the exam is not going

to expect you to know everything about

all these command line commands but I

would say that knowing at least the

commands right here on the slide is

going to help you figure out a couple of

the outputs on the exam right so without

going into too much detail here let's

have a look in one of my folders here

that stores log files and a new Ubuntu

distribution this is running on WSL

right windows subsystem for Linux we

have a log file right here dpkg log

which is logged that's generated by the

package managers so this log is going to

tell me which package based operations

are have been conducted on this machine

from its big It's Beginning from its

installation right what did I install

what did I uninstall what did I upgrade

so it might be some useful information

in here so let's just see a couple of

these commands cat is the concatenate

command in Linux and can also be used to

list the contents of

text files so CAD dpk G log is going to

provide you a bunch of listing right

here trying to display all the contents

of the text file right at the console

now this file right here we can also

pipe it so resend the result of this cat

command to another command which could

be word count word count minus L this is

going to count the lines in its log file

so you can see it's over 9 000 lines

long pretty tough to search for some

information in a 9000 line log file so

what we can do right here is for example

limit the amount of information that

we're displaying on the screen this is

where the head or tail commands come in

the head command as you can probably

guess is going to provide you with a

listing of the first 10 lines in this

log file similarly the tail command is

going to provide you a listing of the

last 10 lines in a log file the tail

command is very useful for log files

that get appended frequently so you just

want to see the last modification

locations made in this file use the tail

command of course the number of lines is

configurable we're not going to go into

all these parameters right now if you're

interested in finding out more about any

Linux command any Linux utility just use

the Man pages man tail

and it's going to provide you with the

manual pages that are going to tell you

what are all the possible configuration

Flags or settings that can be added to

this command here's the dash n for

example number of lines I'll put the

last number of lines you can add it as a

minus n parameter or dash dash line

sequels how many lines you want to

display on the screen quit with the

letter Q now the graph utility is a

regular expression evaluator which can

be of course used to run some complex

regular Expressions which are going to

help you tremendously dig through a lot

of information extract what is actually

useful to you but you can also do some

very simple uh string matching using rep

for example if we are displaying the

dpkg log here and piping this to the uh

to the grep command and search for let's

say installation of a specific package

such as let me see ansible right I did

use this machine for ansible in the past

so there you go these are all the log

entries in here generated by the ansible

package notice that we've been through a

number of advancible versions in here

starting from version 2.8.1 we went

through 2.919 2.927 and so on we can

even see the evolution of this package

on this machine now this is just a very

very simple example here I just wanted

to let you know that you do have a lot

of utilities available at your disposal

for manual log searching if you don't

have a SIM solution available all right

now there's a lot more to talk about

this but since this is not a Linux

trading we're gonna stop right here

alright everyone thanks so much for

watching I know there's been a lot of

information in this video but I hope you

found this useful and informative and I

hope to see you on the next video as

well don't forget to leave a comment if

you like this support the channel if you

can if you wish if you find this useful

in your studies and see you in the next

video bye bye

[Music]

foreign

[Music]



22 22

[Music]

foreign

[Music]

we're going to talk about account

management in other words we're going to

talk about managing the digital

identities of your users starting from

gathering information that makes up that

user profile how to store that

information what type of information is

relevant how do you deal with users that

change departments and change their jobs

change their roles gain more Privileges

and such so there's a lot of a lot of

stuff going on here which is closely

related to daily maintenance operations

when it comes to maintaining an identity

and access management system so let's

see where does it all begin

and surprisingly enough because this is

still a security training the role of HR

here is vital in account management and

identity management because that's when

the actual digital identity is created

within a company when that person joins

the company and HR provides the

necessary information for their own

account and they associate the

Privileges and permissions that come

with it and the very first type of

identity or profile that sometimes gets

created inside of a company is the one

created by HR even before the hiring

process finishes and that is the profile

that is used to conduct the background

checks your previous employers your

previous activity basically what HR is

doing at this point is very similar to

open source intelligence reconnaissance

phase at the very beginning of an attack

so it uses whatever information has

available publicly over the internet in

order to determine more about your

actual identity after the hiring process

finishes while the HR is going to take

care of providing you with the set of

credentials that you will be using from

now on to interact with other services

inside of a company now this might be

just a simple account creation a digital

account or it might require you to get a

hold of some some smart cards maybe some

USB keys that you'll be using all over

the all over the company assets such as

mobile devices laptops any kind of

devices that you might need to use for

your job role also need to be

provisioned and then given to you with

the necessary accounts and permissions

already configured within them and of

course as part of your induction process

probably you're gonna have to go through

some security trainings that make sure

that you are security aware at least as

far as your job role is concerned so

that you're not going to increase the

attack surface in your company you will

not present an additional risk to the

entire security of the company HR old

doesn't end here it also works as a

centralized point for disseminating any

kind of policy update security policy

updates that might be implemented in the

future their role is to make all the

employees aware of any changes that

might have been introduced in the

meantime

and of course the role of HR ends with

the termination of the employee I know

it sounds drastical but you know when a

person leaves the company it's still

called termination even if we don't

actually terminate that that employee

but again the role of HR is going to be

to handle the management of those

credentials such as making sure that the

IIT Department disables their user

account maybe the IG Department should

store in some backup any keys or

encrypted information that was generated

by that user account so that in the

future if a forensic investigation

perhaps needs to be performed they will

have something to work with and those

the files created by that user are not

lost forever along with their

credentials that's why in most companies

user identities use digital identities

are never completely deleted they're

just disabled when that user leaves the

company and also don't forget about

retrieving any devices that the user

might have received from the company uh

because the device belongs to the

company of course but also because the

information the data stored on those

devices is probably confidential and

protected by ndas and is in some way or

another some sort of intellectual

property that needs to be protected

alright next up we have Personnel

security which means the involvement of

the employees within the company's

security policy and in order to gain

something like this there has to be some

sort of a friendship being kindled

between HR and the IIT Department which

is not always the easiest thing to do

and the purpose behind these policies

involving employees is to avoid

situations where one employee might

abuse their privileges in order to

perform

unauthorized actions or to gain some

personal Advantage by using company

resources and we have a couple of

policies here starting with separation

of Duties exactly what the name says

it's sharing responsibility among

multiple people so that no single

individual can abuse the power that it

has been given to them as you can see

this is a method of trying at least to

avoid the potential risk of Insider

threats implementing this requires each

and every individual to know exactly

what their job role is and how they

should be performing that job role

normally this type of description is

written in a document called SLP or

standard operating procedure and as long

as nobody derails from that sop

everything should be fine I mean

everybody should be doing their own job

and no individual user should have

authority in excess another technique

that can be implemented right here is an

approval process one person initiates an

action wants to do something and then

that action first needs to be approved

by somebody higher in the hierarchy or

sometimes even by equal peers in the

same team least privilege is a very

well-known principle in security and it

doesn't just apply to people and

Personnel it also applies to program

Services applications running over the

network pieces of code that get executed

and what it says is that at least when

it comes to personnel and people doing

their job each and every individual

should have sufficient rights and

permissions to do their own job but no

more than that this is

avoid on one hand privilege abuse and on

the other to avoid situations when an

account gets compromised by an attacker

and that attacker might gain

surprisingly High privileges simply by

compromising that account

least privilege should also be managed

inside of the company's security policy

whenever people change roles or change

jobs because it it happens more often

than not that a a person who switches

departments gains the permissions and

the Privileges associated with the new

department but still retains all those

permissions from the old Department

because nobody is concerned anymore

about those historical privileges and

policy assignments that's why in many

companies people who have been in there

for 10 15 years or so have switched a

lot of departments they're kind of like

super users in there many gods if you

wish

they have access to so many resources

they can do so much stuff in that

Network simply because they have

retained all the Privileges and all the

access that they have gained over the

years so this privilege helps us avoid

the situation called by the way

privilege creep job rotation again

against Insider threats and collusion

and abuse of privilege means that one

person should not hold the same job for

an unlimited amount of time one

advantage of doing this is that

knowledge isn't now constrained to a

single individual to just a bunch of

people can be freely shared among a team

and also lowers the chances that a

certain individual is going to abuse

their privileges in a certain position

maybe they've discovered some back doors

maybe they've discovered some methods to

bypass company policy and they're never

going to be caught because nobody else

ever looks over their shoulder and

nobody else ever takes over their job

and that's also one of the reasons be

behind mandatory vacation go step away

from your from your office for for two

weeks or so so that somebody else can

step in do your job because this also

makes it that much harder for the

original person to hide any malicious

activity that they might have been

running around in that unsupervised job

and also from a management perspective

you know having somebody else step in

and take over another employee's job

might also reveal some inconsistencies

or even the fact that God forbid that

original person wasn't doing their job

properly

well all good things come to an end or

in the case of resignations perhaps not

all good things but also bad things come

to an end

s that we're also going to have an

off-boarding policy so what happens when

an employee leaves a company from a

security perspective first off we need

to take care of the accounts that the

user has been using uh even including

shared accounts those are a bit

difficult because if you can simply

disable a user account if there's an

account that was shared among multiple

team members for example you cannot just

disable that account right because

everybody else loses access so what do

you do if uh if one of the team members

suddenly leaves

well do you change the password and let

everybody know or how about not using

shared accounts in the first place

carefully with user encrypted data as we

said before users have the ability to

request certificates to use those

certificates to encrypt files on the

disk if an entire disk drives using

BitLocker for example well what do you

do if sometime in the future you need to

perform an investigation or you discover

some malicious activity that the user

was involved in and you have no way of

accessing that encrypted data there are

situations where this can be mitigated

such as keeping the private Keys

generated for that user in key escrow

like a backup database of private Keys

just in case sometime in the future you

will need to access the data owned by

the user who has long left the company

luckily Windows domain controllers also

have the ability of automatically

storing these keys in key Escrow in a

key backup database specifically for

that reason and also don't forget about

the actual physical assets laptops

mobile phones tablets any kind of

electronic devices that can store data

or that can be used to gain access into

the company or into the company's

Network make sure you get a hold of them

and ideally those devices should not be

clonable you should be pretty sure that

the user doesn't have a backup copy of

the data that can still offer them

access to confidential information in

your company

now don't forget that even though you

might be following all these procedures

closely and checking every requirement

in here there is still a potential risk

because a person who's leaving the

company might have had deep detailed

knowledge of the security systems in

that company of how the network works of

how the what applications they're

running in there how old they are what

vulnerabilities they have so there's

never a zero risk from somebody who's

leaving a company especially if they had

privileged access

so what are the types of accounts that

we can find in an Enterprise environment

or an Enterprise Network we're going to

start with generic users just like you

and me right they're not able to change

any security policy right they are just

meant to obey those security policies to

play by the rules and of course this is

one place where we should definitely

always apply the principle of least

privilege of course according to each

user's own job role and requirements we

also have guest accounts ah pretty

Dangerous Ones these are the accounts

that anybody can use even without a

password or with a default shared

password they do come with a lot of

security risks because there's no way to

track down the activity to a specific

user to know exactly who did what

this is also one of the reasons why this

is one of the places where definitely

you should apply the principle of least

Privileges and probably the Privileges

that a guest account has they have to be

even lower than the Privileges that a

normal user has

almost Next To None the policy is

probably going to be just it provides

internet access or filtered regulated

internet access for guest users but

that's it no other type of access to any

other VLAN or any other network

resources in your in your network and

actually think about if you really need

guest accounts because you do have

methods even for wireless just access

for providing users with temporary

credentials or by using any other type

of authentication mechanism that avoids

the use of shared or guest accounts so

consider if it's not better if you just

disable them all together

the administrator or the root accounts

well these are dangerous because these

are the first Target of an attack always

so when an attacker attempts to

penetrate a network to escalate their

privileges to gain more access they will

be targeting these administrator

accounts because these allow them

unrestricted access all over the network

so make sure that the password policy

the security policies that apply to

these accounts are bulletproof

and their target not just because they

allow attackers or potential attackers

to gain access everywhere over the

network but they also have the ability

to change security policies so if an

attacker gets their hands on an admin

account they might even be clever enough

not to use that admin account to perform

their malicious activities but to lower

the security policies or to create

additional users perhaps in order for

them to interact with the network

completely undetected or even to erase

their tracks after their malicious

activities have been conducted

next up we have shared accounts and

these are the worst shared accounts are

any accounts who's logging credentials

are known to a group of people not just

to any individual and everybody uses the

same account which means that we also

lose track of who is doing what there's

no identity information tied to that

shared account we don't know which of

the 10 team members has performed an

action because everybody uses the same

account to log in we also don't have no

repudiation there's no such thing right

nor repudiation relies on some

cryptographic knowledge that can

uniquely identify a single person we

don't have this with shared accounts and

don't just think that shared accounts

are you know Joe from ite creates uh

creates an account for him and then

shares that account with somebody else

no shared accounts can also be those

default admin accounts that most

appliances network devices applications

come pre-configured such as the login

with the user admin and password

admin123 right that's also a shared

account and in many situations many

companies people don't even change those

default accounting they don't even think

about well let's create individual

Accounts at least so we have some

traceability in there we can perform

some sort of accounting as to who did

what action and there's one more problem

with shared accounts if a group of

people know the same login credentials

then you have to find a way to securely

distribute that login information to

multiple people at the same time now

distribute a certificate or a password

which is not an easy thing to do and the

more people know that secret information

the less secure that information

actually is

and speaking of those generic admin

accounts they are worth a separate

category in here actually during admin

accounts pre-configured accounts that

you can find in most network devices

applications appliances that you install

in your network they're also a large

Target for attackers simply because a

lot of companies a lot of it departments

forget about them or even even worse

they start using them from the very

beginning and they and they stick with

them simply because they don't really

care about creating additional users and

all the hassle that comes with

additional identities and

synchronization with an identity

provider and creating security policies

for each user yeah what the heck just

give the admin account to everyone and

that's it including the attacker

now on the topic of assigning

permissions or privileges this is

basically the policy that says what type

of resources does a specific user have

access to what servers can it connect to

what type of URLs can they access what

type of applications can they log into

what type of file servers can they

access and do they have read or write

permissions in there so all these

policies are basically the authorization

part what privileges you have after you

have authenticated in a network system

so we have two ways of assigning these

privileges first of all we can assign

them per user so when a new user comes

into the company perhaps HR discusses

with the uh the manager of the users

department and they decide together well

these are the resources that this user

should have access to let's give them

access to this app and this app and this

file server and if they need access to

something else something more they're

probably just create a ticket or a

request when they actually need it so

that's not very efficient especially in

large company is and also it's a

security risk because this entire

process has to be recreated every single

time a new user comes into the company

not to mention when the user changes

roles or when the user leaves the

company so a better solution to this

is to rely on group based policies so

instead of signing these permissions to

users at a user level we create groups

or roles that closely match the actual

job roles from real life or inside the

company so let's say for example that we

have developers we have database admins

we have uh I don't know security testers

penetration testers different teams

different roles we create specific

groups for them and then we assign all

the Privileges to that group now

whenever a new employee comes in the

company and the new employee needs to be

assigned to the development team for

example we simply add that user that

digital identity to the development

group and they automatically inherit all

the permissions from that group

this makes user management much easier

and also makes permissions management

much easier because we avoid a situation

where a new user comes in and we forget

to provide them with the necessary

credentials or we even give them too

many permissions simply because we don't

know exactly what they should have

access to moving a user between

departments also is made much easier and

also when a user leaves the company it's

just a matter of removing that user from

all the groups and then disabling that

digital identity

and by the way there's no reason why a

user cannot be a member of multiple

groups so if we need for that user to

inherit permissions from multiple

departments or for from multiple let's

say security levels we can just as

easily make it a member of multiple

groups and all the permissions are going

to be inherited and compiled into one

single set of permissions that apply to

that user specifically and to give you a

place to start most operating systems do

you have some default security groups

such as the group called users and

windows as opposed to the group called

administrators and windows you probably

can guess what the difference between

the permissions assigned to these two

groups are in Linux well pretty much

everybody is the same type of user but

we have group membership in Linux as

well except for the part where the

privilege escalation or the execution of

privileged

operations on a Linux machine can be

done using pseudo privileges super user

do so that's going to require in a Linux

machine to add that user to the sudoers

list or the sudoers file which in many

distributions is located in a simple

file just like everything else in Linux

and slash Etsy sudos

if your user ID or username is in there

then you are allowed to perform

privileged operations

speaking of operating systems we also

have different types of accounts

depending on the operating system

starting with Windows on Windows we also

have the notion of a service account or

a so-called or how I like to call them

machine accounts these are accounts that

are used by applications or by processes

by Services running in the background on

Windows and they cannot be used directly

by a human user they don't allow direct

user interaction within with them but

instead we use them for example for a

web server to be able to authenticate

itself and to gain access to a backend

database that they need in order to

serve some website content some of these

default service accounts start with

system this is the supreme ultimate

account in Windows so it has the most

privileges and it can launch processes

even before the user logs in again a big

Target for attackers secondly we have

local service which is very similar to a

regular user account except except for

the fact that it is being used by

internal processes inside windows so

it's a machine account but they can only

access local resources or network

resources but without any kind of

authentication so they don't have a

network identity that's why we also have

the network service which again does

inherit pretty much the same privileges

as the normal user account but it is

able to present itself using

authentication credentials as an account

that can authenticate itself to Services

over the network on Linux things are a

bit simpler due to the fact that every

user in Linux looks pretty much the same

so user accounts and machine accounts or

accounts used by demons ordered by

background Services they look exactly

the same with a single difference that

in general any type of service account

in Linux will not allow an interactive

shell from a user so you're not able to

log in as that user if that user is

supposed to be used by some internal

application in Linux in most cases these

use users are created automatically as

part of the package installation process

so whenever you install I don't know

Apache for example as a web server

you're going to find that a new user

called Apache or

www.data is being created in your user

list but you're not able to log in as

that user

another important set of credentials

especially in the Linux world are SSH

Keys SSH stands for secure shell and as

you probably know already SSH is a

powerful protocol that can be used for a

number of things most likely you've

heard of SSH as a method for securely

connecting remotely connecting to a

resource over an unsecure Network such

as the internet and because it provides

you with CLI access in a secure manner

we can also use SSH for performing file

transfers in that case you're probably

using a utility called SCP that secured

copy that uses the same methods behind

the scene just as SSH but instead of

transferring CLI text commands and

outputs it's going to transfer binary

data and since we have the ability of

transferring binary data that kind of

means that we can also extend the SSH

protocol to allow us to Tunnel encrypted

traffic from one point to the next

from one SSH client to an SSH server so

we can use SSH as a tunneling protocol

now the SSH authentication method in

itself relies on two key Pairs and those

in most cases are RSA public private key

pairs first of all we have the server

key pair also known as the host key now

the server whenever a client

authenticates to it the server is going

to present its public key to that client

and it is assumed that the client needs

to evaluate that public key validated

and decide whether to accept it or not

if the client accepts that public key

then that public key is going to be used

to encrypt any information that we need

to send back to that server now what we

just described is basically the server's

authentication process this is where the

server presents itself to the client and

tries to prove its identity we also need

to present the user to the server as

well because well that's pretty much the

authentication part that concerns the

user when connecting over an SSH

connection so if a user needs to

authenticate himself to an SSH server

then they need to First upload their

public key into the SSH servers database

there's a local database of public keys

in there and that database works as a

way for the SSH server to know which

connection requests to accept so if a

connection request if some encrypted

traffic comes in from a private key that

corresponds to one of those public keys

that are already in the SSH server's

cache then that connection is going to

be allowed

also on the topic of more exotic

credentials that we need to manage there

are also credentials generated by online

services such as API keys or API tokens

or remote access Keys depending on the

terminology like for example the keys

that you're generating into a cloud

console that allow you access to Cloud

resources if you want to interact with

the cloud environment using an API or

using an automation tool such as ansible

or terraform you will need to generate a

set of API keys and then sign or send

those keys along with each and every

request that you are sending to the API

endpoint of that cloud providers which

basically means that those keys become

kind of like the the keys to the kingdom

especially if there's a large

infrastructure or many critical

resources behind that API endpoint that

your company uses on a daily basis so

make sure that the keys that allow you

access to all the infrastructure that is

hosted in some Cloud environment are

thoroughly kept secure and you have a

strong security policy and you have user

traceability and have a strict access

control method so that those keys are

not going to become public knowledge

now an account policy is the actual

policy document that describes what a

user can or cannot do and the digital

identity to which an account policy is

usually attached to is a set of digital

information that makes up a user profile

and user profile is made up of a number

of attributes such as the full name the

department their email address maybe a

unique identifier within the system like

a numerical ID all that stuff makes up a

user profile then the access policy is

the actual set or access list of

resources that the user has access to

now these permissions can directly be

assigned to the user or they can be

inherited from any group memberships

that user might be a member of in

Windows this type of privilege

assignment is being performed through a

group policy object or GPO gpos can be

used to configure privileges for both

users and groups in a Windows Active

Directory system many account policies

also include a password policy as well

such as the minimum requirements for the

password length the complexity of the

password how often it should be changed

if ever and perhaps if the user is

allowed to reuse any of the previous

passwords whenever they change their

password additional security controls

can be implemented by enriching these

access policies using location

information such as where is the user

connecting from are they inside of the

company premises in the main building

are they within a branch are they

located Somewhere over the Internet

connecting over the VPN connection

perhaps

or we can even correlate the IP address

information from which the the user is

connecting from to a geographic IP

database in order to determine which

region the user is physically located in

or in more cases than not the actual

country the user is located in and since

we can have location policies we can

also have time-based policies such as

the time of the day or the day of the

week when the user is allowed to access

specific resources or even down to how

long a specific connection event is

supposed to last now as you can guess

all this privileged assignment business

is not an easy one because you can

easily make mistakes in here you can

either assign too many privileges to a

user or to a group which defeats the

principle of least privilege or you can

assign too little privileges in an

attempt to thoroughly secure your user

access which in turn is going to create

frustration and a large amount of

support tickets

so ideally in an Enterprise environment

you should have an auditing process for

those security policies so that

periodically you can validate from top

to bottom ideally in an automated manner

if all the policy assignments and the

privileged assignments follow the best

practices and the internal security

policies of your company

this process is called privilege review

and it should be run from time to time

to better detect and potentially improve

your security posture

another type of Audi that can be

performed is the auditing of user

activity now as you can guess this

information can help us a lot when we're

investigating a security breach or an

abnormal behavior or a Potential Threat

to our network but there's also a

downside to this because you might be

tempted to log as much information as

possible which in turn is going to

create so many events so much

information that it's going to be

impossible to search or to store or to

properly make sense of it

so be careful here it's sometimes a form

of an art to decide what is the exact

sweet spot of what's useful for you to

know to record to log and what should be

ignored

generally or as a best practice you

should probably log in at least every

connection attempt so every time a user

attempts to connect to your system you

should generate an event for this even

failed attempts because those might

indicate potential attacks that are

trying to break into your network of

course you should think about which

resource access logs you're going to are

going to keep you probably don't want to

record any type of file access that your

users access all over the network but

you're probably going to want to record

the access to privileged files on

specific file servers or in specific

Network locations also if you have the

resources for processing this type of

information and you have the ability to

to monitor the process creation on each

and every machine in your network this

might also prove useful whenever you're

trying to investigate where did the

breach come from and where did a

specific piece of malware entered our

Network and who executed it first

of course any changes to policies and

settings local to the machine or Global

for the entire network of course those

should be logged as well because

normally only admins should have access

to uh to those policies and only admins

should have the ability to change them

well if at some point you figure out

that somebody has tampered with those

security policies you should have a log

a a proof of what happened when it

happened and who was the author and of

course any privilege escalation and I'm

not talking about privilege escalation

in a in a hacking way but in uh in any

type of request for additional

privileges such as executing something

as administrator on a Windows server or

executing something with pseudo

privileges on a Linux machine

and of course as part of the identity

management policy you should have

methods for managing when and how and

under which circumstances you will

disable either temporarily or

permanently your user accounts we should

have a policy in place to disable

accounts that we suspect for malicious

activity definitely have a policy in

place for disabling accounts for people

who are no longer working for our

company account expiration might be

useful for contract work for temporary

access for a partner maybe another

company that needs temporary access to

some specific resources and account

lockout should be part of an automated

reaction or response in your security

policy so that after a number of failed

attempts for example after a number of

failed passwords a user is going to be

locked out

for a limited number of time or until

the admin intervenes and unlocks that

user account in order to avoid Brute

Force attacks and any other type of

password attacks that might try to break

into your your user accounts so thanks

for watching a lot of information in

this chapter if you like this if you

want to discuss some more leave a

comment in the comment section and if

you thought this was useful then like

and subscribe good luck in your studies

and see you on the next video bye bye

[Music]

please

[Music]



23 23 


foreign

[Music]

and securing data this is going to be a

sequence of videos where we're going to

be focusing more on policies and

procedures and before you roll your eyes

keep in mind that these are still as

impo as important as technical controls

whenever you need to to prove compliance

and whenever you need to cooperate and

to work with external parties with

business partners even with so it might

not be the most spectacular Topic in

this training but I'll try to make it

sweet and easy to follow and a bit fun

now and then now when talking about

Security in general we've covered this

in the First videos and we introduced

the concept of the CIA Triad

confidentiality integrity and

availability and we understood that we

need to ensure that we protect all these

three in order to have a coherent

implementation of security now we also

have to take into consideration

situations where not all of these

pillars apply to any type of data so for

example if you're thinking about some

data that is supposed to be publicly

available on a website that should be

publicly accessible by your your clients

your customer or by anyone for that

matter then confidentiality of that data

is something that doesn't warrant any

concerns and while everybody can agree

that security is important privacy is

also important as well or privacy if you

wish I'm going to keep it I'm going to

leave it as privacy privacy is a

governance requirement especially when

processing personal data or personally

identifiable data data that can be used

in some way to uniquely identify a

person their attributes their financial

information maybe their their health

status and all that information and the

way it is processed the way it is stored

who has access to it when should it be

uh disseminated for how long should it

be stored all these factors are going to

be accumulated in something called a

privacy policy so while security is

about you know confidentiality integrity

and availability privacy is more about

the regulations that apply to the proper

use of that specific type of data and

since we're going into the Regulatory

and legal realm here as usual there's

going to be a lot of blame to go around

so let's see exactly who it is to blame

for which task when involved in

protecting data

and we're going to start with the data

owner the data owner is the sole

responsible for ensuring the

confidentiality the integrity and the

availability of that data it might be

the person who actually created the data

or it might be the person that

introduced the data in your company or

in your system nevertheless they are

responsible for securing that data

they're also responsible for classifying

it that is if you are the first person

who ever introduced that piece of data

it doesn't matter if you created it or

not but you are the first responsible

for letting everyone else know what that

data is about and how sensitive it is

what type of information is in there and

then according to that classification

everybody else is going to know how to

treat that data how long to store it

where to store it and how to secure it

better as part of the labeling process

the owner also gets to decide who should

have access to the data from the very

beginning and we're not just talking

here about individual people but of

course an organization can be the owner

of that data especially with

intellectual property that's when an

organization holds the intellectual

property rights of any data that is

generated within its perimeter now a

data owner usually chooses some

additional minions or acolytes to help

them in managing that data and those are

data stewards and data custodians by

definition the steward is the person

responsible with the data quality that

is making sure that the data is properly

labeled handled and is stored and

represented in a in a manner adequate to

the contents of that specific data the

custodian on the other hand is a more of

a technical person especially with you

know Digital Data and that person is

responsible for ensuring the well-being

of the system that hosts that data that

is the storage Appliance making sure

that the data is properly encrypted

making sure that the backups are being

performed regularly and also that the

backups are secured as well as the

original data and it also manages any

type of Access Control that might be

implemented in order to provide or to

deny access to that data the privacy

officer is the person that is more on

the legal side that has some sort of a

high level overview in which they are

able to determine whether the specific

type of data that we're processing that

we're storing complies with the local

and Global regulations

the data controller a lot of job roles

in here right data controller is the

person responsible for making sure that

the data is not used outside of its

intended purpose and is also not used

outside of the allowed regulations so in

other words if we're collecting the

client email addresses make sure that

those email addresses are only used as

let's say unique identifiers or as a

correspondence address whenever we need

to reach that customer not for sending

spam or for sending them to the highest

bidder and finally we have a data

processor and that is the person or the

entity that takes care from a technical

perspective and makes sure that the data

is properly collected stored and

processed internally

data classification is a very important

process so that everybody knows what to

do with the data and how to process it

and how much care it should be applied

to that data most classification methods

are going to rely on some sort of

confidentiality requirement they're

going to see classifications such as you

know public confidential or critical

which might be mapped to something such

as unclassified or secret or top secret

depending on which spy movies you're

watching

and usually these categories are pretty

self-explanatory with the confidential

or secret category usually being a a

situation in which the data can be

accessed by only those who are approved

to do so and that is uh people who have

signed an NDA maybe business partners

somebody has to give them access in

order to access that data at the other

two ends we have the public information

which normally doesn't have any kind of

confidentiality requirements it'll have

critical or top secret requirements

which means that it's on a on a need to

know basis and very very few people have

access to that data in order to keep a

tight control over the potential risk of

data exposure we can also classify data

by its actual type so for example if the

data contains some sort of proprietary

information that is intellectual

property for example then the data

belongs to that company only of course

this could be a target for data breaches

competitors or somebody who doesn't

agree with the business practices

oh a specific company might Target this

data and try to make it public in order

to hurt the Public Image and perhaps

even the entire business you can also

have private or personal information

that uniquely identifies a person of

course this can also be the target of a

data breach because information

that pertains to individuals can be used

in identity theft and in general

sensitive information is information

about a person that is not necessarily

used to uniquely identify that person

but if that information is is disclosed

becomes public knowledge that person is

not going to be happy about it so it

could hurt that person because it might

be about their political affiliation

religious sexual orientation maybe their

their financial habits or their income

or their health status an official

classification of data types starts with

data that usually has the most concerns

attached to it whenever we need to

process it and store it and that is

personally identifiable information pii

that's information that can uniquely

identify a person this also has to be

taken into a specific context so for

example if something such as a

government assigned identity number or a

social security number can definitely be

a personally identifiable information

other things such as the IP address that

the user is using to browse the internet

in specific contexts can also be used to

identify that person this information is

sensitive because it first can be used

in identity theft and also sometimes

knowing enough about a specific person

is enough for you to bypass their let's

say password reset mechanisms if they

have a password reset a mechanism that

relies on security questions that only

they should know well if you know that

information if you know about that

person if you know enough about that

person then you might be able to bypass

those security questions customer data

in the context of a company it might be

about sales data it might be about there

the a customer's profile their previous

purchases their business agreements that

we might have with them in general it's

not considered as sensitive as other

types of information but especially in a

business environment we usually provide

access to this type of information only

after we signed an NGA that's a

non-disclosure agreement document Health

Data health information pertains to the

health status of a person it might be

their health history it might be

whatever they suffering from whatever

treatment they might be on that's

information that shouldn't become public

knowledge it can be used in blackmail

scenarios to create some serious damage

to a person's reputation in finance

related data this one covers data that

pertains to how much money you have what

income sources you might have of course

you probably don't want everybody else

to know this but it also covers uh

credit card information as well now we

also have extenders that take care of

the way credit card information is

processed it's stored how transactions

are conducted and that standard is

called PCI DSS which stands for payment

card industry data security standard

other Concepts here related to data that

you should know about are purpose

limitation this is the purpose for which

the data is collected and used for and

you have to make sure that the data is

not going to be abused it's not

collected for other purposes and it's

not stored more than required an impact

assessment is also connected to

sensitive data because especially for

companies that process a large volume or

personally identified information health

information financial data they need to

periodically perform this type of an

assessment in order to mitigate any

potential risk for data breaches that

could affect those sensitive sets of

data data retention is strictly related

to compliance because in many cases in

many countries according to the local

legislation you might be required to

store a specific type of data for either

a minimal amount of time or for a

maximum amount of time especially if

that data is really sensitive don't

forget from a technical perspective that

this long-term retention should also be

performed on storage equipment and with

storage solutions that are just as

secure as the data that you're using on

a daily basis data sovereignty is an

issue that comes into play whenever

you're thinking where should we store

our data and who has jurisdiction over

that data this is extremely relevant

especially when you choose to store that

data in a cloud environment and it's not

just your your day-to-day data you might

be choosing to use a a third-party

backup provider for example well that

data still falls under the same

jurisdiction and has to comply with the

same regulations as your normal data and

since we talked about where we're

storing that data it's actually a

problem that can be approached from 2

different angles first of all where do

you store your data so choose the

appropriate data centers to the

appropriate Cloud regions and also think

about where are your users located

because if your users are accessing that

data from outside a An approved

jurisdiction or legal area then you're

going to have a problem in there hence

all the web services that you might

encounter over time that say that this

service is not yet available in your

region even though the data is there but

you are not located in a country or in a

location where you can access that

service now this probably doesn't come

as a surprise to anyone but the

downsides of a data breach are actually

are actually many so in case your your

confidential data your sensitive data

becomes public knowledge that's what we

call a data breach and the effects of

this are going to be felt first and

foremost on your reputation because if

you're a company that was supposed to

process confidential data that you had

some customers that they trusted you

with their data and you had a data

breach that's obviously going to be a

really bad mark on your scorecard for

any future business that you might be

willing to do people need to trust you

in order to provide you with their data

with their money with their their secret

information with their files with the

whatever you're choosing to to offer

them other than that of course the

actual data loss that's happening could

also be uh damaging for your business

and of course your reputation especially

if you're a software company that

develops a proprietary product if your

source code gets stolen well of course

that's going to be very bad news for any

future business that you might be

willing to do identity fraud can also be

encountered especially uh as part of a

data breach that targets personally

identifiable information and in some

countries and in some regions of the

world the simple Act of suffering a

breach which after an investigation is

determined that you did not take a

minimum amount of measures to prevent it

you didn't perform any due diligence

tasks in order to minimize as much as

possible the risk of a data breach can

also attract some huge fines a gdpr in

Europe is one of these examples where

you might be fine for not doing your

homework now everybody can can suffer a

data breach so don't get me wrong you're

not being punished for having a data

breach you're punished for not doing the

minimum efforts in order to prevent it

if you don't lock your door when you go

out then the insurance company is

probably not going to be willing to pay

in case you you have a home invasion

also in some regions depending on the

local legislation some companies have to

notice their customers whenever they

detect a data breach sometimes as soon

as a couple of hours or one or two days

at most so that their customers can also

take the necessary measures in

protecting whatever information might

have been disclosed about them data can

be shared and keep in mind that when you

choose to give your data to somebody

else for storage for processing for a

business relationship if they have a

data breach then you're going to have a

data reach right the ultimate

accountability even though they should

be protecting their data the alternator

Fallout of that data breach is still

going to affect you now with that being

said we still have some legal agreements

here that can make life a bit easier

whenever we need to share data among

multiple companies starting with SLA

service level agreement which is the

most common document that outlines how a

specific service should be delivered if

the metrics are defined in there then

any potential fines or any potential

penalties for not complying with those

metrics should also be written in the

SLA interconnecting security Agreements

are relevant for federal governments and

whoever chooses that federal government

to work with so so if there's a

relationship between a federal entity

and some commercial entity out there

then an interconnection security

agreement is going to be signed a

non-disclosure agreement an NDA is a

document that helps protect sensitive

information whenever we're sharing that

information with someone if they sign an

NDA then they're not authorized to

further disseminate it we are legally

protected finally we also have other

types of agreements in general these are

agreements that are strictly connected

to a specific field such as medical

Finance or in general some agreements

that pertain to a personally

identifiable information so gdpr HIPAA

they all have such agreements in which

once you sign them you you basically

promise to comply with the with the

regulations that those standards entail

from a technical perspective protection

of data can happen at three levels first

of all we have data at rest that is when

data is stored and this is where we

apply techniques for protect acting data

such as encryption and don't forget

about access control who has access to

the place where the data is stored data

in transit is about means for protecting

data as it is being communicated from

one system to another we can enable link

encryption we can enable encrypted

tunnels and here it doesn't matter if

it's ipsec or TLS or whatever tunnel you

might have in there just make sure that

the medium that we're using to transport

that data cannot be sniffed intercepted

or altered in any way and finally we

have data in use that is when data is

actually loaded in a computer's memory

whenever you have to use that data

regardless of how sensitive it is or how

well you've chosen to protect it at rest

or in transit whenever that data reaches

the memory of your computer and needs to

be usable that's when the data is

visible it's in clear text it's

unencrypted it because that's the only

way in which that data can actually be

made useful

which opens up to theoretical risks of

malware infecting the computer that is

processing sensitive data which might

lead to the disclosure of that data and

over times many solutions have been

introduced especially by Hardware

vendors to help mitigate these risks one

of them is called Intel software guard

extensions which allow you to actually

work with encrypted data in memory for

companies or systems that process

sensitive data data exfiltration or

protecting against data acceleration

becomes a very important topic data

exfiltration is any unauthorized copy or

unauthorized transfer of that

information outside of its approved

environment so outside of of the company

for example

systems that protect us against data

Explorations are called dlps Data loss

prevention or sometimes called Data leak

preventions now these are pretty

complicated systems they are first and

foremost reliant on data classification

so you need to have a very thorough

understanding and classification in each

and every file that lives inside of your

company so that the DLP solution can

know whenever they detect that file

being attached to an email being sent

over instant messaging being sent over

an encrypted child perhaps they would be

able to apply a specific policy

according to the contents of that file

in general DLP Solutions can apply a

multitude of actions whenever they

detect a specific type of information in

an exponentration attempt in those

actions range from a simple alert that

is generated to reach the admins

workstation we can also block the access

to that file for that specific user that

attempted the exfiltration could also

quarantine the file that is whenever we

sense that somebody has tried to

exfiltrate that data we are basically

isolating that data for everybody else

so that nobody else is going to attempt

uh the same action now this of course

warrants some investigation an

intervention from the admin side and

finally Tombstone means replacing that

file with a simple notice or a or a

generic file that says that this

attachment here was removed because it

violated the company DLP policy finally

the last topic that we're going to be

discussing today is a topic about the

Technologies involved in ensuring or

enhancing the privacy of our data and it

all starts with the way you choose to

collect that data and how much of it

you're collecting it for how long are

you storing it and this is called data

minimization that is don't collect more

data than it's actually required for the

intended purpose and don't store it for

longer than it would be required for

that purpose also if you did collect

more data that intended make sure that

you sanitize it first before you store

it long term so you remove all the

personally identified information from

it or you remove any fields that could

potentially attempt an attacker in a

data breach an example of minimization

is also called de-identification that is

removing all these sensitive information

from that data especially once that

information is no longer needed for

long-term storage so as an example here

you might be obtaining a customer's

credit card in order to perform a

transaction but are you going to store

that credit card information long term

no in most cases you're only going to

store the last four digits so that the

customer is going to be able to see

which card they used on an invoice

perhaps that they might be generating a

month from now that's a type of

de-identification it's also useful

whenever you're communicating a

sensitive information between companies

in between business partners

anonymization is a process where you're

simply removing all the identifiable

information so that nothing can be used

or extracted from that data set in order

to identify a person

pseudo-anonymization is some sort of a

gray area where we're still removing

that identifiable information but then

we're storing it someplace else so with

sufficient permissions and sufficient

correlation effort we could combine

those two data sources and obtain the

original data source and while

pseudo-anonymization is reversible data

masking is probably the simplest method

out there which is completely

irreversible so we're simply replacing

characters and data sets and data

structures from that sensitive set of

information with the generic characters

such as I know stars and hash signs you

probably saw this whenever you're

looking at a previous transaction and

you're looking at those credit card

numbers that were used to perform it

strictly for database storage this

applies to data masking as well we have

tokenization tokenization is about

replacing the sensitive field with a

token it's a random token now that token

becomes some sort of a key or a password

that can be correlated with the original

data set that now is stored on a

separate database now we might provide

access or more generic access to the

tokenized database but we're not going

to provide access except for after a

very thorough authentication to the

actual database of tokens so whoever

needs access just to the summary of the

information or just to the an overview

of that data we can provide them with a

view of the database that only displays

those random tokens but in case we need

to actually rebuild the original data

perhaps for a forensic investigation

let's say in some sometimes the future

we can also unlock that token database

and then correlate it back with the

original database in order to build the

original data set aggregation or banding

it's another practice that can be used

for statistical information so let's say

you don't want to store the exact age of

a person in a database but you would

store it as a range so that person is

somewhere in between 20 and 30 years or

30 and 40 years that information can

still be used to perform some

statistical analysis sometimes in the

future but it stops being personally

identifiable caching and salting are

other methods for hiding information a

hash it's a one-way function that can

generate a fixed length string unique

string out of any data input that is

being provided now the only thing you

can do with a hash since it's

irreversible you cannot get the original

data out of it is to figure out if two

data sets produce the same hash so you

could potentially still hide that

information but be able to identify if

two people have the same age or they

live at the same address without

actually viewing that information or

having access to that information this

is also used with passwords whenever we

have to store passwords we should never

ever store them in clear text but we are

storing is actually a hash of that

password so that when we're checking for

the username and the password of a user

that tries to log in we are hashing the

password that the user sends us and then

we're comparing those two hashes this is

very useful because in case of a data

breach the attacker is only going to

obtain the hashes and in general it's

not going to be possible to extract the

original passwords out of those hashes

this is where the process of salting

actually improves this inability of the

attacker to to crack those passwords

sorting makes passport cracking a lot

more difficult next to Impossible

whenever those passwords are word as

hashes basically the salting process

means making each hash unique thus

making the use of pre-computed table

hashes also known as the rainbow tables

from being used in order for an attacker

to be able to determine which original

string was used to generate that

specific hash finally the

de-identification attacks are more of a

theoretical concept but whenever you're

choosing different methods for hiding

that data or for splitting that it and

store it in separate places you have to

assume at least the risk of some smart

attacker being able to correlate that

partial information and take it from

multiple sources perhaps even combine it

with publicly available open source

intelligence over the Internet and try

to determine some some things that were

meant to be hidden so this is called the

de-identification attack and an attempt

to correlate seeming incomplete data

sets in order to determine something

more about that data that normally it

would not be public knowledge

so I hope you had fun with data as much

fun as you as someone could have with

data of course but uh hopefully this was

uh interesting and informative and if it

was like And subscribe share comment

with me support the channel if you can

and see you on the next video

[Music]


24 24 


foreign

[Music]

so here we are seconds from disaster

that dreaded moment when we realized

that a security incident has already

happened and the problem now is what do

we do who does what and how do we react

in the best way possible so that we can

also stop the attack from continuing we

can also isolate the affected systems

and then we can also learn something

from what just happened in order to

avoid it in the future

now the size of plus exam doesn't really

require you to go too much in depth in

these incident response procedures this

is more likely uh adequate to the slicer

plus certification and exam but on a

high level note need to understand what

is going on what are the necessary roles

what are the necessary actions and steps

to be taken whenever a security incident

happens

so incident response has a process it's

actually a procedure that needs to be

followed whenever a bad thing happens

whenever a security incident happens and

just like with any procedure that needs

to be followed in moments of high level

of stress and critical moments it does

need some really clear instructions and

really clear steps to be taken so that

everybody knows exactly what they need

to do what are we doing right now and

what's the end game what's the target

what are we after and one of these

structured documents has been published

for a while by nist the National

Institute of Standards and technology

and it can be found for free on the

internet as special publication

800-61. officially this one is called

computer security incident handling

guide and this document does outline

some major steps when dealing with

incident response starting with

preparation which is not actually part

of the instant response itself because

this is something that it should happen

long before the security incident has

happened so preparation means making

sure that your networks your systems

even your people are secure so you're

taking all the necessary steps in order

to increase your security posture so

that when an incident hits its impact is

going to be as as low as possible it

also implies that you need to train your

users so that everybody knows what to do

you also need to train your users in

order to avoid potential security

incidents and also testing of existing

security response and incident response

procedures is part of the preparation

phase so it's not just enough to have

them in place you have to make sure that

everybody is aware of them and that they

are up to date

next in line comes the identification of

the incident because a security incident

is only a security incident if it

affects in some way the security posture

of a system or of your company as a

whole

there are a lot of incidents out there

which are not secured incidents so it

all starts with a report it starts with

a complaint perhaps reported to the IG

Department by a regular user it can

start by identifying alerts generated by

one of your your devices and this is

where everything starts this is a sort

of a triage phase where we analyze what

happened and then we decide is this a

security incident or not and if it is

then we're going to start notifying the

right people and taking the right steps

like for example taking steps to contain

that security incident make sure it

doesn't affect more than it already has

so if you're facing a malware that is

spreading over the network make sure

that you you isolate somehow the uh the

affected workstations you could do this

at layer 2 using vlans you could do this

at layer 3 using routing you could do

this simply by disconnecting network

cables

sometimes disconnecting it with network

cables even though it's extremely

efficient it might not be the best idea

whenever an attack is ongoing because if

it's an ongoing attack then it means

that there is a live connection between

some compromised host in your in your

network and an attacker's workstation

somewhere outside or even inside a

company you should be able to identify

this connection and to be able to figure

out who is at the end of it and perhaps

what are their intentions if you just

start disconnecting everything and

unplugging all the network and perhaps

even the power cables you're pretty much

left in the dark you don't know what

happened and there's no way for you to

find out how to protect against that

incident in the future once containment

has been successfully implemented of

course eradication has to take place

that is eliminating the malicious

effects of that data breach of that

attack of that secured incident from

your network part of the elimination

process might be required to re-image

reinstall operating systems or

reconfigure devices that have been

affected and of course this

reconfiguration and reinstallation

should be augmented by an update your

security policies an update of the

affected software so make sure you're

patching everything perhaps you've just

ignored for some time some security

updates and that's exactly what exposed

you to a potential attack and erasing

all the traces of malware might prove

difficult sometimes this is why you

might have to rely on some processes

such as security arrays where you simply

completely erase anything that can store

data inside of a system including disks

and ssds and in caches and everything

else that can store data or disk

sanitization in the recovery phase we're

trying to come back to the functional

state that we had before the attack

happened that is we're trying to bring

back the affected systems into

production

now if we had to clean up after the

actual attack then those systems might

require a restore from a backup or a

rebuild of their functionality or a

reconfiguration of their functionality

and finally lessons learned it's very

important to understand what happened to

document what happened so that somebody

else along the line in the future is

going to be able to avoid the same type

of incident it also pays to understand

where were the flaws that actually allow

this incident to happen and it's not

just a a game of pointing fingers here

and throwing blame it's about figuring

out where your weaknesses are in order

to fix them as soon as possible as part

of the response coordination a lot of

departments are going to be involved in

a security incident especially because

most departments are going to be

affected by that security incident but

there are different levels at which each

and every one of them becomes involved

in this process starting with senior

leadership even though they might not

understand exactly what happen at a

technical level and why that security

incident got to happen in the first

place they are still the number one

decision point so whenever we need to

make a big decision such as I don't know

disconnect all the entire data center

from the Internet or isolate the

affected systems or notify the affected

parties that have been affected by the

the data breach that we we just faced

everything that requires high-level

decisions needs to involve senior

leadership

legal team can also have a have

something to say here because more often

than not these data breaches especially

if they are accompanied by the loss of

confidential information personally

identifiable information Financial

Health Information

there are going to be legal consequences

following that's data breach also

depending on local legislation you might

have to notify affected parties as soon

as possible about your data breach so

don't keep it Hush Hush don't keep it

under the rug uh because at some point

everybody is going to know about it and

the sooner the better the it and

networking teams are definitely going to

be involved because those are going to

be the ones that actually Implement

those decisions taken by senior

leadership now these are the people that

are going to first of all try to contain

the incident then they're the ones that

eradicate any traces of the uh of the

malware or the or any artifacts left

over by the security incident and

they're also the one ones that are going

to have to put those affected system

back into production

also HR is going to be involved whenever

the author of The attacker of the data

breach is proven to be an Insider threat

so it's one of your colleagues tough

luck

and marketing or public relations this

department is going to have a pretty bad

day when tasked with informing the

affected clients the public the the

markets the news websites they're going

to take care of publishing an official

message about what happened and they'd

better do it before the Press finds out

about the fact that you've just gotten

breached also if a data breach affects

in some way the uh trustworthiness of

your company your reputation again

marketing and PR are going to have a lot

of work to do in taking care of your

reputation in front of your customers

as far as communication goes during an

incident response situation that's going

to be critical communication is key in

many places in life but also especially

in in a during an incident response

phase so communication is going to start

with the computer security incident

Response Team those are the the people

especially trained to know exactly what

to do in case of a security incident is

going to happen so they are going to be

the ones that actually work as a single

point of contact so whoever needs to

interact with the team that takes care

of the internet response it's going to

actually interact with the csirt now

there are also going to be the ones that

report back to Scenery management and to

affected parties what is the current

status and how bad the data breach

actually was

as far as communication goes internally

between internal teams out of bad

communication is recommended that is

because when you don't know exactly the

extent of a security breach or of a

security incident perhaps the internal

communication channels that you are

normally using are like email like

instant messaging like some some

collaboration software that might have

in your company those might be

compromised and for once it means that

those me those communication methods

might not be trustworthy anymore and

second if the attacker has managed to

compromise those communication channels

then you might be informing the attacker

by using them you might be informing the

attacker as to what is the development

of the incident response process and you

don't want to give away your defenses

you don't want to tell the attacker what

you're about to do before you're

actually doing it especially if the

attack is still ongoing another reason

why your normal communication channels

might be compromised is because you

don't know exactly if the threat if the

attacker that is the author of the of

the data breach is an outsider or an

Insider if it's an Insider then the risk

is much higher for that person to have

compromised some internal communication

application that you're using in your

company what I mean by out of Van

communication here could be anything I

mean you could just fall back to instant

messaging link over your mobile phones

like WhatsApp or or telegram or iMessage

or whatever you have at your disposal

that is not part of the Network that has

just been breached and stakeholder

involvement of course this is also part

of a communication plan just like we

said a couple of minutes ago you need to

notify all the affected parties you know

your business partners your your

customers other branches perhaps might

have been affected they need to know

about this as soon as possible and also

you need to control how this

communication is going to flow you don't

want people to find out about your

breach before you get a chance to

actually communicate what happened in an

informed and coherent manner so

officially you should have something

called an instant response plan now this

could be a document or multiple

documents developed by the team dealing

with security incidents and it might

also be custom tailored depending on the

type of incident so you might have a

specific instant response plan for a

data breach you might have one for

enough service attack you might have one

for a natural disaster perhaps so you

might have different response plans

according to the type of incident that

you are facing the actual list of steps

to be taken has the name of a standard

operating procedure an sop sometimes

it's called A A playbook sometimes it's

called a running book it's just a list

of steps to be taken so that when

everybody is so stressed and people are

running around

aimlessly not knowing what to do there

is a a document somewhere hopefully you

know what it is that's going to help you

identify what exactly are the next steps

and who is responsible for what

and this is the response plan not only

includes the necessary steps to be taken

it also mentions the people responsible

for taking those steps and it also

mentions any available resources that

you might have at your disposal not

Financial Resources necessarily but I.T

resources perhaps and selecting those

resources or allocating those resources

in an efficient manner depending on the

type of incident requires you to First

classify the incident

and the incident is most likely going to

be as bad as the value of the resources

affected by it

so we can assess the affected Resources

by a number of factors for example by

the value of the data being held by

those systems or by the value of the

data that was just part of a data breach

another prioritization Factor might be

if the affected systems imply some sort

of downtime so is the attack going to

affect the availability of our systems

or is it just going to affect the the

performance of some systems or is it

going to Simply put down the entire

business another decision factor is how

visible is this incident going to be

from the outside in other words the

Optics of the incident that publicity

right so how is this going to be

received by the media by the by the

customers by our clients how bad is this

going to affect our reputation the scope

generally means the number of affected

systems how large of a data breach are

we talking about how many systems have

been affected because depending on the

number of the systems and the types of

the systems it's going to require are

more or less effort for recovery

and to bring them back into a working

state

time to detection this is an interesting

one what exactly do we mean by this well

the idea here is that in many cases real

successful data breaches and real

successful attacks on on companies that

are aimed to steal some data to

introduce some backdoors or some

vulnerabilities in some code

those attacks sometimes go unnoticed and

I don't mean go unnoticed until the next

business day they might go unnoticed for

months

so you might be

in a security incident without even

knowing about it you might Discover at

some point a back door in one of your

servers that has been there for a year

if you discover something like this it's

obviously going to become sky high

priority to fix that one in front of any

other security breach that you might be

detecting at the same time

recovery time is also an important

factor when deciding where to allocate

resources you might have some systems

that you can easily just replace or

bring back into into working States or

we might have some some systems that are

going to take days or weeks before they

become usable again and of course during

that time ask yourself is the business

going to be able to function without

those systems or am I going to be facing

even more attacks or even I'm going to

expose myself with even more

vulnerabilities due to the fact that I'm

unable to use those systems that perhaps

were even involved in the protection of

our Network

now over time there have been introduced

many methods for describing the stages

of an attack these these descriptive

stages have been introduced in order to

better try to understand at which stage

we currently are in an attack what we

can do at that stage or what is the end

purpose of an attack that has just been

detected and many people have tried to

abstract the these in in some papers in

some Frameworks in order to create some

sort of a theoretical model that should

match pretty much all attacks out there

now the degree to which they managed to

create a valid model is up for

discussion of course but we do have a

couple of models that are worth

mentioning because they're pretty close

to to real life for example Lockheed

modern Corporation you find something

called the Cyber kill chain or the

intrusion kill chain in this white paper

right here now this skill chain defines

the phases for common attacks but

applies mainly to those conducted by ABT

groups advanced persistent and threats

now the same document also talks in

details about iocs indicators of

compromised methods to mitigate those

attacks uh reconstructing attacks after

they already happened and some details

about campaign analysis that is to

determine whether the attack is part of

a larger campaign that targets multiple

individuals or multiple companies or is

it something that is strongly focused on

your single company so it's a very

targeted type of an attack and the best

way to view this in a graphical manner

no less is by visiting the actual

website of Lockheed Martin that's a

little cyber kill chain right here you

can see it's focused on APD threats a

stands for advanced means targeted

coordinated purposeful persistent

this type of an attack that can last for

weeks for months so it's a type of

attack that opens up a Communication

channel for long-term interaction

between the attacker and the victim and

a threat which is the actual person or

the entity that has intent opportunity

and the capability to conduct this

attack the phases defined by Lockheed

Martin start with reconnaissance with

reconnaissance we're talking about an

attacker who is trying to gather as much

information as possible of other

potential victims it might be using open

source intelligence it might be using

active reconnaissance tools like active

scanning trying to hit the firewalls

trying to hit the email service trying

to hit any publicly available Services

just to see if there are any weaknesses

in there and try to discover as much as

possible about the internal structure

internal design of that of that Network

next comes the weaponization phase and

with the weaponization we are coupling

or connecting a specific exploit with a

specific vulnerability so once we have

found a vulnerability that can exploit

we are choosing an exploit for it and we

are building we're wrapping it up and

ready to be delivered to the victim

system which actually happens in the

delivery phase with delivery phase we

are tricking the victim into either

sticking a USB stick into their their

computer clicking a link downloading

some piece of malware installing some

sort of a back door we could be using

social engineering here we could be

using other Advanced Tools in order to

get and gain a foothold and to deliver

that malicious payload to the victim's

computer

finally we've got exploitation so

assuming that the victim has managed to

introduce that

malware into the network and or into the

system uh that's when the malware starts

exploiting a specific vulnerability by

installing a back door by propagating to

different systems or by simply acting on

objectives as in trying to steal the

data that we were after or trying to

perform a denial of service attack

installation of malware is a phase that

is relevant whenever the attack requires

to be persistent so we need to make sure

as an attacker we need to make sure that

we can connect to that compromised

workstation anytime we want in the

future so we can send it commands and

make it do our bidding command and

control phase that's basically the

control Channel between the compromised

host and the attacker's workstation this

is the channel through which the

attacker is going to keep providing

commands and querying that compromise

toast as to its Health in order to make

it do whatever the attacker intends to

do in other words manipulation of the

victim and finally actions and

objectives that is whatever the attacker

intended to do in the first place didn't

want to steal some data did we want to

compromise some data Maybe perform it in

a lot of service attack or maybe just

maybe the initial purpose was to gain

access to gain control of as many

systems as possible so that in the

future those compromised toast might be

used in a coordinated attack so remember

this one remember these phases more than

likely you're going to be asked on the

exam day about the Cyber kill chain

another way to describe attacks and this

one I actually prefer this one

personally is from miter and it's called

the attack framework and yes it is

written ATT Ampersand CK it's the attack

framework in which it's actually not

just a theoretical model but it's

actually a kind of a database it's an

attack Matrix for Enterprise you can see

it right here it's kind of a database of

observed and known and documented

attacks

let me show you how this works this

right here is the monitor attack

framework as you can see it is divided

in a couple of columns in here and all

of these basically describe different

types of attacks now the entire list

here is actually much larger

I just couldn't fit it on on a single

screen here so you can see we have

different uh example of attack methods

regarding gaining initial access or

privilege escalation or credential

access or lateral movement command and

Control Data exfiltration and so on and

so forth and all of these underneath

each of each one of these are going to

find a lot of examples documented from

Real World situations so for example

under credential access I'm going to

find here Brute Force right along with

forged web credentials uh authentication

process modification intercepting

multi-factor authentication or pretty

much anything that was ever hacked in

the world belongs to some sort of a

category in this minor attack framework

let's just see a couple of examples here

in the Brute Force section so if you

click on Brute Force first of all we're

going to see a couple of sub techniques

in here there you go password guessing

cracking spraying and stuffing

and finally we're going to see a couple

of examples here so under procedure

examples and you'll find some ideas in

here with some names these are the

actual name of the malware or if the APT

group that was identified as an author

that performs brute force in an

organized manner in order to gain access

to credentials there you go so many

examples so many examples in here

observed over time on major malware out

there that was specifically designed to

Brute Force authentication credentials

you can also see a couple of mitigation

techniques so this also works as a

database of what to be on the lookout

for and how to protect yourself right

much better than that simple cyber kill

chain this one is actually useful

and methods for detection how do you

detect Brute Force so I will let you

play with this one for just a bit it's

available at

attack.myiter.org it's freely available

and it's a Priceless source of

information regarding everything that is

hackable in this world

so don't ignore this don't ignore this

for the exam and don't ignore it for

your general knowledge I would strongly

recommend to have a look over this stack

framework uh download it by heart of

course but try to understand different

types of techniques presented here it's

probably the single most comprehensive

collection of information about cyber

attacks and it's a great learning tool

for discovering and understanding how

cyber attacks look nowadays and this

entire database is based on real

observations so everything that you see

in here is not just Theory but has been

observed has been documented and used as

an attack technique at least once in

real life next up we have the diamond

model of intrusion analysis now

personally this is not one of my

favorites because it can prove to be a

bit hard to follow and also because it's

a bit limited I know it focuses on on a

single intrusion event now what we see

here in this diamond model is actually

an intrusion event described by the

relationships between four core features

of that event we have the adversary we

have the capabilities of the adversary

we have a victim and we have the

infrastructure that makes the attack

possible and the lines in this model are

the relationships between these Concepts

and they tell us that it's possible for

an analyst to reach the other connected

points given enough information so for

example if we analyze a victim we can

see the capabilities used by the

attacker against that victim so we can

see how the victim was attacked if we

have infrastructure visibility of the

network or of the logs for example then

we draw in more conclusions about how

the capability used in the

infrastructure to compromise the victim

so as an example here we could say that

a connection between the victim and an

attacker's capability is the fact that

the victim was able to discover a piece

of malware on the system now that

malware used the infrastructure because

it actually pointed to a malicious

domain it might have been a malware that

tried to contact a command and control

entity on the internet all right so

that's a that's a connection between the

capability being the malware and the

infrastructure that is available to it

that's the internet and the local

network next up we have the domain part

of the infrastructure that points to an

IP address so we as a security analyst

now we can identify specific IP address

pointing to that source of malware by

looking at the network logs that is the

connection between the infrastructure

and the victim we could potentially

identify multiple victims in the same

network we could potentially identify

multiple workstations that are now part

of a botnet that have been infected by

the same malware simply by looking at

the logs and the affected workstations

that's a connection between the

infrastructure and the victims

and finally by analyzing the IP address

pointing the commander control we are

able to pinpoint the location of the

adversary now we might not know exactly

their name and date of birth but we know

that the IP address that we detected is

the root of all evil so that's one

domain that should be probably

blacklisted and all traffic should be

filtered whenever other workstations

perhaps infected workstations will

attempt to communicate over that command

control Channel and well after

discussing the Cyber kill chain after

discussing the miter attack framework

this kind of sounds very oversimplified

right kind of like too easy to be true

too easy to be to be useful it actually

does include a bit more information that

information is considered a meta feature

of the diamond model I know all this

terminology here kind of doesn't help it

looks like it attempts to to over

complicate things I've already said that

I don't like this model but bear with me

here for one more minute now as part of

these meta features we could add another

set of details of this event such as for

example an event timestamp when did the

event happen in security event happened

in which phase was the event in was it

during reconnaissance was it doing

weaponization and so on a result was the

event successful or not did it

compromise any part of confidentiality

integrity and availability was it just a

failed attempt a direction was it

initiated by the victim so somebody

tricked the victim into installing

malware by themselves or it came from

the outside or was it somehow

bi-directional a method what exactly was

the attack was phishing was it an

exploit was it a malicious link was it a

cross-site scripting was it a denial of

service attack depending on the type of

the attack and finally the resources

required to complete the event like

reconnaissance information that might

have been required password hashes that

the attacker might have gained in the

meantime the presence of a vulnerability

that's high on the list probably

anything that the attacker needs to

assume or gather before conducting the

attack and all these features then are

being assigned a confidence level which

of course is based on a assumption well

incident response planning looks good on

paper but you have to make sure

periodically that the people can

actually put it into practice that they

can apply it whenever hits the fan

so testing your incident response plan

requires you to perform a set of

exercises now these exercises depending

on how much money and time you have at

your disposal might range from something

as simple as a tabletop exercise which

is kind of similar to a board game just

by using a couple flashcards just by

using a theoretical scenario people just

gather together and discuss so if this

happens this is what I would do this is

what you would do this is what we all do

and we all laugh and then go to lunch

not very efficient but it's better than

nothing next up we would have a walk

through now I walk through it very

similar to a tabletop exercise but it

requires the participants to actually

demonstrate their skills like performing

a scan you know analyzing a piece of

malware playing with some isolated

environments uh that would simulate

somehow the environment that has been

breached in general all these

environments are just sandboxes or just

virtual machines that are there for

testing purposes so it's kind of a

tabletop exercise but with a bit more

Hands-On practice

finally we have simulations now with the

simulation this is this requires a lot

of time a lot of money a lot of

involvement in uh in a simulation we

actually divide people into two teams we

have the red team that simulates the

attack we have the blue team that

simulates the defense team right and we

also have a white team that works as

some sort of a control or Arbiter of the

entire game right uh we are simulating a

real Attack perhaps on a on a limited

set of resources perhaps on a on a test

environment but we are actually

attacking those resources right so uh

Blue Team and Red Team of course they're

both part of the same company but uh

they have to learn to play together and

to learn from this exercise how to

better protect against somebody who

doesn't do this for fun

now you shouldn't confuse incident

response with the generic term of

business continuity the incident

response is just focused on a security

incident now on the other hand we also

have a couple of different approaches

two different types of incidents that

might happen to our building to our

business to our systems IIT systems so

for example we have a disaster recovery

plan which can be considered a special

type of incident where the entire

business is affected it might be a

natural disaster it might be due to a

war a to a civil unrest regardless of

the reason usually a disaster recovery

plan is going to include all the

necessary resources and instructions for

relocating the entire business to some

other secondary site business continuity

planning on the other hand is a document

or a procedure that instructs how to be

able to keep the business going even in

a situation where the the entire

business affected by a disaster or by a

security incident so for example if a if

a server or an ID resource is made

unusable due to one of these incidents

above then the business continuity to

plan should provide some sort of an

alternative or methods for providing

some sort of a failover onto a secondary

system that can still keep the business

going and finally continuity of

operations plan this is a type of plan

that is mostly associated with

government facilities and by its

definition it refers to a situation in

which the entire organization needs a

backup plan to work without any kind of

I.T support so that's continuity of

operations plan also also written in a

shorthand notation as Coop so those are

the phases of incident response in a

very very high level overview of the

people and the resources and the steps

involved in dealing with a security

incident now I hope you found this

informative and you useful like And

subscribe if you enjoyed this and see

you on the next video

[Music]



25 25


foreign

[Music]

nice and easy chapter here about log

analysis and CM appliances because these

are really relevant whenever you're

preparing yourself to have something to

analyze just had have something to

investigate during incident response

performing incident analysis and mapping

that analysis with one of these attack

patterns or attack Frameworks is made a

lot easier by the presence of a seam

Appliance in your network so a seam tool

is a security information and event

management tool that collects

information from Network traffic and

from device and application logs in

order to be able to generate some smart

insights into all that data we call this

correlation that is taking seemingly

disparate and completely independent

events and trying to make sense into

understanding what exactly is happening

in there potentially identifying a

security incident so a Sim device can be

used for log storage even though it's

not exactly designed for log archival

because we need the same Appliance to be

able to quickly respond to correlated

events if you have a huge database of

all the logs generated in the past five

years obviously we're not going to be

able to react exactly the same moment

when the security incident happens so we

can you use the seam as a temporary log

storage solution but not as a log

archival solution but we are going to be

using it to analyze those logs I'm going

to use it to learn to create some

patterns machine learning is a is a

great feature combined with the

abilities of a scene because it is able

to update and continuously monitor the

Baseline that it builds internally for

all the monitored environments of all

the devices and all the servers that are

generating those events that end up in

the scene Trend analysis is another very

useful feature present in a lot of the

scenes out there and it's about looking

at patterns seeing patterns in past data

in order to be able to anticipate or to

predict how the data will evolve over

time Trend analysis is the main

technique involved in building this

Baseline that the seam tries to

continuously monitor in order to

identify outliers and events that don't

match whatever was observed in the past

regarding a specific type of application

or a protocol or a server or any type of

device in your network

for Trend analysis we'll be looking at a

number of factors for example the

frequency of events now a single error

or just a couple of errors in a small

time frame it might not alert any

investigation but an increase in the

frequency of let's say application

errors DNS errors routing errors perhaps

even it might indicate a fact that

somebody is trying to tamper with your

Network volume analysis could be looking

at how much of something you're

currently using how many logs are being

generated how much storage is being used

how many disk input and output

operations are we seeing right how much

CPU is being used at a specific point in

time if monitoring these show us that we

are looking at an increasing Trend that

Trend might indicate an on Earth saying

that if you keep doing this if this this

trend keeps going in one week or so you

will end up with no resources and your

your infrastructure will become unusable

and finally Trend analysis helps us I

identify those outliers those points

that don't map the Baseline that

presents statistical deviations from the

Baseline

it could be about specific events it

could be about resource usage a network

traffic usage and so on

logs are generated by pretty much

anything on your network devices

workstations servers operating systems

applications and those generated by

operating systems are somewhat of a

special category because they can meet a

number of formats it might be difficult

to unify them into a single environment

to normalize them inside of a seam

Appliance and they also belong to

multiple categories for example on

Windows systems Windows operating

systems we're going to find a couple of

categories in which the logs are being

generated by default we have application

logs generated by the actual

applications on the systems and by

System services this is where you'll

find alerts regarding a service that

cannot start for example we also have

security logs these are considered to be

audit events as in we're checking to see

if something still complies with our

security policy a failed login for

example or an attempt to execute

something that a user doesn't have

enough privileges to execute that's

going to be shown here in the security

log uh system logs are going to be

generated by the operating system and

the service regarding the functionality

of the operating system itself so uh not

having access to the network not having

access to storage not being able to

perform some sort of an operation that

is required by the operating system

these errors are going to be found here

in the system log setup logs are being

generated by the installation of

programs Windows updates and basically

anything that can change the

configuration of the system and its

applications and finally forwarded logs

these are logs that don't belong to our

own host but have been taken from other

hosts so they have been forwarded to us

from other workstations

now Windows logs are by tradition binary

files that's why you don't you need a

specialized application even viewer for

that matter in order to be able to read

the contents of those logs on the other

hand also traditionally

on the other hand in the Linux World

we've grown used to see Linux as the

environment that generates logs and text

formats which are easily parsed and read

by pretty much anyone and anything now

funny enough in recent days we kind of

we were kind of witnessing a paradigm

shift here where Linux logs are slowly

becoming binary especially with more

recent distributions and the binary

format of those logs needs to be

accessed using a specialized utility

called Journal CTL while at the same

time Windows is slowly moving towards

text file logs so there we go pix can

fly

Mac OS with it being a specialized

distribution that is based on FreeBSD so

it does have the Unix philosophy at its

core still generates uh text log files

it does have a specialized utility to

access access them even though you can

gain access to them directly from the

command line just as with any regular

text file and that utility is called the

console app a bit of a bad naming

convention I would say since whenever we

say console we definitely think about

something else other than the utility to

access log files right

among other logging sources that you can

find uh they're going to be network

devices especially network devices these

are probably the number one source of

all the logs that deal with the

well-being of your network so router

switches firewalls load balancers

proxies anything you have in your

network can generate log alerts

informing you when something has

happened it's pretty useful to have this

type of information not just for the

health of the devices themselves but

also because those devices can alert you

about intrusion events or about a field

authentication or about a device that is

attempting to perform IPS spooling or

Max spoofing on your network logs

generated by authentication systems are

again very useful now we're talking here

about AAA servers we're talking here

about active directory domain

controllers anything that has to do with

managing user identities and allowing or

denying access obviously you will want

to log any kind of failed login attempt

but also you might want to gather it as

a statistic for statistic purposes the

successful logins as well vulnerability

scan results generated by the

vulnerability scanning software well

usually these results are going to be

presented as a report that has to be

interpreted by the Admin but in some

situations where this vulnerability

scanning solution is running unattended

for example every day at night or every

number of days perhaps uh you know the

admin is not going to be looking over

each and every report that is generated

that's why it might be useful to have

that scanning solution generate a log as

an alert whenever one of those reports

even though nobody looks at them happens

to to contain one or more

vulnerabilities

web servers can generate a lot of useful

information in their in their generated

logs not just about errors even though

errors are really useful as a source of

information you're going to be looking

at 400 errors which are client errors

you're going to have to analyze any 500

errors that might occur because those

indicate a problem with the server

itself but you might also want to find

within those logs an indication of a

malform request that happens to hit your

web server perhaps HTTP headers that

don't really play by the HTTP standard

or connection attempts that were never

finished or any type of input that is

coming from your users that has

generated some sort of an error or an

abnormal response in your web server

those are all potential indicators of

compromise not to mention that a web

server can also identify who is

accessing it now how many users have

been accessing a specific resources or

what type of browsers were those users

using

or where are they coming from are your

clients located in a single country or

across the ocean or from within the

company

DNS logs just like with web server logs

can offer you a lot of information about

successful name resolutions so for

example you could glean from the DNS

logs what are the destinations that your

users are constantly accessing you can

also get a lot of information from the

errors why do we get resolution errors

is it really someone who isn't unable to

correctly type a domain name in inside

of our company or is it a faulty malware

that is attempting to connect to a

non-existing domain perhaps the memory

dump is another Priceless source of

information memory dock is created on

the disk as an image of the memory of

that system whenever something goes

wrong whenever the system crashes when

an application crashes and it's really

useful to be able to analyze the

contents of a memory dump in order to

identify what exactly led to that

application crash was it an attempt to

exploit the vulnerability was it just a

programming error was it something that

was due to a denial of service attack

you really need to understand what

exactly happened in there now A Memory

dump is not exactly part of the logging

sources of information and cannot

exactly Implement those memory Doms and

inject them into a seam Appliance but

they will be an important information

Source whenever you start investigating

mobile devices don't exactly generate

logs by themselves or at least not logs

that end up in your company or your

steam Appliance but by analyzing those

devices you're going to uncover a whole

Treasure of historical information like

the call history of that device or what

type of Internet destination has it

accessed what type of History does it

have in its browser what type of

information that is currently have

cached or even malware that might still

reside on it now the actual call history

the actual coil records that is

something that you will have to get from

the mobile operator not from the mobile

phone itself finally additional sources

of information also called metadata in

other words data about data can be Glee

and can be extracted from files on the

file system last time when a file was

accessed or by whom that's something

that might be attached to that file

itself depending on what file system the

file is stored on metadata about web

requests and replies these might be

logged into your actual web servers or

within any other intermediary devices

such as your firewalls or IPS or ids's

and finally on email messages metadata

found in the headers of email messages

can provide you with a lot of

information about the path that the

email message has taken and the servers

through which it had to pass and the

security checks it was subjected to in

order to reach you and you should know

that the main protocol in use nowadays

as it has been for many many years

already for generating and transmitting

logs over the network is called syslog

it's a very old protocol it's running

over UDP Port 514 it has absolutely no

built-in security so everything is in

clear text but we don't really expect to

send very sensitive information as a

syslog especially since those logs

should only be present or transmitted

within our internal Network and perhaps

even over a management Network now there

are newer versions that Implement some

security hinge assist log but of course

they're going to be running on different

ports like 1468 as for the structure it

has been the same ever since the

Inception of the syslog protocol as a

structure we have a header that looks

pretty much the same on every syslog

message we have a timestamp that

uniquely indicates when that message was

generated which means that it's very

important to have your time in sync on

all your devices that generate syslog

the IP address that was used to generate

and to send that syslog message over the

network a facility is some sort of a

subsystem that actually generated that

syslog so you might have a an entire UTM

device or entire firewall but you might

be interested in only checking those

logs generated by the uh let's say the

authentication subsystem or the

antivirus subsystem or only the

intrusion prevention subsystem okay the

severity of the log is just a numerical

identifier that indicates how critical

that log is it might be just a simple

debug message this might be just an

informational message or it might be a

message that is saying with its last

breath that the router has failed that's

going to be a critical one and finally

the message itself that's the payload of

the log message and unfortunately

there's no there's no standardized model

for describing the contents of a syslog

basically every the application and

every vendor and every device out there

can write whatever they want in that

message body more often than not it's

actually just a description of something

happening with that description being

designed to be read by human eye so it

actually tells you a story this and this

happened when this was happening as well

so unfortunately this is also one of the

difficulties in normalizing and parsing

syslog messages from many vendors and

this is one of the uh tasks that the

seam Appliance is is required to do

normalization of all the information in

these syslog messages even if they might

be coming from tens and hundreds of

vendors and thousands of different

applications and operating systems and

network appliances and apart from the

header the facility and the severity

they are all going to look completely

different

finally the last source of information

that can be correlated with syslogs and

with any other source of logs on a CM

Appliance is Network traffic information

now nettle traffic can be captured in a

number of ways the first and the most

obvious method is to perform a simple

package capture that is actually

capturing all the packets that are

traversing over the wire or over

Wireless and then sending that packet

down to the seam to be analyzed now this

is not always feasible for one reason

you might not have just a single point

of traffic collection in your network

where all the interesting traffic can be

found so you might have to gather that

traffic from a number of different

points which already creates a lot of

administrative burden secondly the

amount of traffic that you might need to

capture could be huge I mean you could

have gigabit links all over the place

especially between virtual machines and

servers in a data center if you try to

capture all that traffic and send it to

a Sim you will overwhelm that same image

a matter of minutes so that is not

always feasible that's why we have

additional solutions that instead of

capturing the entire packet content they

are only capturing a description or a

statistical view of the traffic that has

passed through a link or between two

destinations we call these traffic

summaries generically we call them

netflow now netflow in itself is a

protocol that was invented by Cisco but

the technology behind it this

summarizing technology of just looking

at the traffic and then generating a

report of top talkers how much traffic

was transferred how many connections

were were generated who were the uh the

endpoints between those connections how

long did those connections last and so

on basically everything about that

traffic except for the actual traffic

content that technology has been

implemented several times by multiple

vendors out there so you're going to

find it as s flow you're gonna find it

as jflow you're gonna find it as ipfix

unfortunately shortly even though the

original net flow was a proprietary

protocol from Cisco the newer ones have

become much more open unfortunately also

much more capable so nowadays we even

find Cisco equipment that can support it

fix for example which has become the de

facto standard for a gathering this type

of network statistics as a flow

information so instead of sending the

actual packet captures to your sim

you're now sending netflow statistics

and those natural statistics can be

easily assembled and prepared and sent

by the networking devices themselves so

you don't really need any intermediary

device to collect that netflow data and

then send it back to the CM you can also

perform protocol analysis with or

without netflow the scene Appliance can

also perform some sort of protocol

analysis that is generating statistical

information simply by looking at the

protocol headers that are generated

either by the events and syslog messages

or by the events captured from netflow

traffic or pure package capture so Aseem

would be able to generate a high level

overview of who is talking to who in

your in your network how much traffic

they're generating which applications

have been detected over the network and

so on finally monitoring the bandwidth

usage is very important because

bandwidth spikes an abnormal bandwidth

usage can often be an indicator of

compromise now monitoring bandwidth can

be done in a number of ways we could

even get this information out of netflow

Statistics so netflow could report to us

that in a specific time frame that was a

huge bandwidth Spike between this and

that destination but often bad with

monitoring is performed using dedicated

Solutions we have Network performance

Monitoring Solutions out there that are

designed to monitor the performance of

an entire network Apple level of each

and every interface so we have

collectors all over the network we might

have plugins or we might even rely on

SNMP traps and queries to gather this

information directly from within our our

networking devices usually these

Solutions were monitoring the bandwidth

and the health of networking devices

they are running a standalone software

on some server or some virtual machine

and then they constantly query or wait

for those devices to report back to them

their health they are periodically

checking them pinging them to see if

they're still responding and they're

querying all the SNMP oids regarding

their resource usage their bandwidth

usage their interface status any errors

that might have been generated and so on

so it doesn't really matter how you get

this information regarding your

bandwidth usage the important part is to

have this information injected into the

seam so that when a certain event

happens in a network that event could be

correlated with a bandwidth usage event

and that might indicate to you in a

matter of seconds perhaps that a denial

service is happening or that a DJ

exhiltration attempt is currently going

on so I promise you an easy chapter and

hopefully I did hold my promise so I

hope you found this informative and

useful I know this wasn't really the

most complicated chapter out there but I

hope I managed to present it in an easy

to understand and easy to follow way

this should be more than enough for the

Security Plus exam so good luck in your

studies uh like subscribe comment

support whatever you want to do but

whatever you do make sure you don't miss

the next episode thank you

foreign

foreign

[Music]


26 26


foreign

[Music]

another very short and easy chapter here

small discussion about our last attempt

at managing security incidents and that

is how to mitigate security incidents so

how can you make sure that they don't

happen again the first approach to an

incident is going to be how to contain

it before we can do anything else let's

limit the damage as much as possible now

in order to do this first of all we need

to analyze what exactly was affected so

how much did we lose or how much do we

risk losing if we don't act now also we

need to be aware of the resources that

we have at our disposal how can we act

and what resources we can use in order

to respond to a specific type of

incident of course there's no cookie

cutter method here that is going to

apply to pretty much any type of

incident out there or any type of

security Incident That's why planning

for incident response is usually going

to be continuous process that keeps

updating and updating according to the

threats that we keep identifying in the

world and in other companies such as

ours or even in past security events

when thinking about counter measures we

need to know what exactly do we have at

our disposal and also what's the cost

because we might be able to quickly

Implement an additional security

solution but that one might be too

costly or the additional security

solution might take too long to be

implemented or it might actually hinder

the business operation so we might not

be able to continue doing our business

simply because we are trained in a some

sort of a lockdown due to the evolution

of the attack

finally how can we act not just

according to the incident response

procedure but also we need to think

about how can we Act without alerting

the attacker what we do is going to be

sensed by the attacker as well is going

to be received by the attacker as well

if we're planning on learning something

from that incident perhaps what we are

doing should be designed not to alert

the attacker as to what our intentions

are and coming here back to the previous

example here if you just pull the plug

on everything

it's going to stop the attack but you

will never understand what happened and

how can you prevent it in the future so

an isolation type of containment is a

method by which we are removing or

isolating the affected systems from the

rest of the network it could be done in

a logical manner so we can just enable

some access lists or some filters so

that those effective systems are not

able to communicate outside of the

affected Network segment or it could be

a just a physical disconnection from the

network or a physical Port shutdown on

the switch that is connecting those

affected devices also this isolation

could refer to disabling some logical

entity such as a user account that was

used to conduct the attack simply

temporarily disabling that user account

from performing any other actions on the

on the domain and network is going to

stop the attack but it's also going to

allow you to further investigate by

looking at the generated logs and events

what exactly happened and how did that

user end up being compromised

additionally a different type of

isolation is called segmentation

segmentation containment is the type of

isolation that is performed using

networking functions that is a layer 3

or layer 4 access lists or Mac access

lists that are applied directly on the

affected interfaces another type of

segmentation containment is to contain

the traffic flow using a specific

routing policy what do you mean by that

well let's assume that there is a

constant flow you're able to identify

the attack traffic coming in it might be

command and control traffic it might be

a denial of service traffic it might be

some sort of a continuous traffic flow

that is attempting to exploit the

vulnerability well that traffic flow

once identified you could just drop it

of course or you could redirect it to

some sort of a sinkhole or a or a honey

net or a Honeypot in which that traffic

is now captured and further analyzed in

order to determine the nature of the

attack and perhaps even the identity of

the attacker and part of the

segmentation containments especially in

malware-based attacks is to identify the

piece of malware involved in the attack

and then run it in an isolated

environment it might be a Sandbox it

might be just a virtual machine that is

completely disconnected from the rest of

the network that allows you to analyze

what that malware does and how you're

supposed to detect it a second time in

the future and if you remember from our

previous discussion about incident

response phases you probably remember

one phase that was about recovering the

systems or rebuilding the affected

systems now rebuilding an affected

system might range from a simple malware

scan and a disinfection down to an

actual destruction of the entire data

set that is stored on that system and

they're rebuilt from scratch that is a

complete reinstall of the operating

system all of the applications a

reconfiguration rejoining that system to

The Domain Network and perhaps even

updating or patching any potential

vulnerabilities in the software that is

running in there security policies and

security controls also need to be

checked as part of the recovery

procedure because

nobody can deny the fact that the

incident was able to happen because it

was allowed to happen so at some point

there is a device in your network that

actually permitted that malware traffic

to go through that schematic control

traffic to go through so there is

definitely some point of security

enforcement in your network that needs

to be updated in order to catch future

attempts at similar types of

exploitations

also on the networking Parts especially

for firewalling Solutions every UTM or

next Generation firewall Solutions

there's probably going to be a bit of an

administrative effort involved here and

updating the access list and the

security policies built into these

devices you will have to check using the

logs using the events generated by those

devices when did the attack happen and

how it could have been prevented what

type of traffic was allowed where it was

initiated from why was it allowed all

right and how did that compromise the

workstation end up being compromised in

the first place because there had to be

some sort of a delivery Vector that

workstation had to be involved in some

sort of a phishing attempt by clicking a

link by downloading an executable file

while installing a backdriver that it

knew nothing about so something happened

at some point that allowed the attack to

go through you need to identify what was

that exact event and how could that

event being prevented or to action at

least by your security devices mainly

your firewalls once you identify the

malicious destinations involved in the

attack which shouldn't be really hard if

you have a proper logging procedure in

place you will have to identify those

bad reputation destinations and of

course add them to a block list on all

your networking devices don't allow any

further Communications with something

that has already proven to be harmful in

the past also review the security

posture and security policies for your

users do they really need access to any

destination on the internet maybe we

should perhaps Implement some sort of

URL filtering based on categories don't

allow your users to visit just any

website out there especially if it has

nothing to do with work productivity and

perhaps even if it doesn't have to do

with their job well at least allow them

access to social media perhaps but don't

allow them access to just any website

out there with no reputation information

or websites that have appeared in the

last 12 hours or so those are definitely

bad news update your content filters

that is if you are performing layer 7

inspection you're looking at malware

you're looking at spam you're looking at

abnormal protocol usage scanning for

injection attacks and weird payloads if

you're doing any of that those are going

to be some signatures in there that need

to be constantly updated make sure that

your device does this automatically most

of them can do this automatically so

it's not going to be a full-time job

that's taking care of updating

everything all over the place and

reviewer DLP policies if necessary and

if you have a DLP policy of course it

might not be strictly related to your

attack or is it a security incident that

you just faced but even if nobody

attempted to exfiltrate information from

your network and it was a completely

different type of an attack you don't

know what lurks behind the corner what's

going to happen the next time you are

subjected to a data breach because in

many situations an attack is conducted

with the purpose of stealing information

and if you're not able to stop the

attack from happening perhaps you would

be able to stop that data from leaving

your company at least so that's going to

be a well-formed and well-implemented

DLP policy as part of the lessons

learned and as part of the remediation

phase after an incident you also have to

review your endpoints your workstations

because most likely those are going to

be the first point of contact then the

first uh point of compromise for the

attack that's just happened in many

cases a workstation a simple laptop or a

simple mobile device is the patient zero

when whenever a data breach happens all

right so there's a just a regular user

who is strict into clicking a link or

downloading some piece of malware and

everything starts all the disaster

starts from one single workstation so

make sure you have some sort of

vulnerability scanning process in place

if you didn't have one maybe it's time

to think about one there are three

solutions open source Solutions out

there green bone or open vas and one of

them now of course if you're willing to

pay for commercial solutions that offer

vulnerability scanning you're going to

get much better results in hands and

update your security controls maybe you

don't have antivirus and anti-malware

installed in your host maybe you don't

have an endpoint protection suit

evaluate some of these options make sure

you choose one that is financially

feasible and actually improves your

security posture review these standard

configurations of your host maybe you

don't even need an additional security

solution maybe you only need to update

some group policy objects that are being

pushed to your workstations and that

might be enough to just increase the

security policy get better security

Harden your hosts review everything

that's open and that might invite an

attacker from the outside open

interfaces open ports applications that

are nobody uses services that have been

enabled ever since the installation of

the operating system and again nobody

uses them but they still pose the risk

of increasing your attack surface so

host hardening that's a process that

should be reviewed from time to time and

don't forget about users as well because

those are always going to be the weakest

link try to educate them try to make

them understand the risks of what

they're doing the implications of

clicking a link of down loading a file

of trusting somebody who impersonates a

figure of Authority or somebody from

tech support without checking their

credentials and their their identity

make them understand that they could be

responsible for a disaster and that

should be enough to scare them at least

enough to make them attend the mandatory

training on social engineering

it implements configuration updates

under the uh form of a an allow list or

a block list you decide which approach

you're going to take it might be about

application execution and which you are

defining which applications you are

allowed to install and to execute on our

workstations that might be a whitelist

approach or a lawless approach but also

have a block list approach in which you

are denying access to specific website

categories for example so depending on

where you're implementing this type of

policy and what type of security control

technical security control is being

affected you might need to find a

balance between you know whitelist

approaches and block list approaches

that's up to you normally if your

mitigation attempts are not successful

if you're not 100 sure that it was

successful you might be better off just

withholding the affected systems in an

isolated environment such as a

quarantine VLAN or just a small isolated

Network for future analysis and perhaps

even forensic investigations you don't

really have to determine everything

under the pressure of time at the moment

when when the event is happening it's

enough to know that the the attack has

been contained and that you have taken

some measures and then later on as part

of the Lessons Learned process you could

go back and analyze those systems and

find out more about what actually

happened who was the attacker and what

type of attack was conducted and what

type of attack methodology was used as a

concept soar or security orchestration

Automation in response is an automated

approach to incident response and as

good as it sounds is as difficult it is

to implement in real life the soar is

designed to be a type of dedicated

solution that attempts to solve the

problem of overwhelming alerts of the

security team not able to process that

many alerts that many events and not

being able to investigate so many things

happening at the same time in a network

especially during an incident at its

core is a system that can correlate

multiple sources of information so

sometimes the sewer functionality

becomes an additional functionality on a

Next Generation CM device it could be a

dedicated device or a standalone device

in itself but more often than not it is

going to use the intelligence from the

CM Appliance it might also complement it

with some machine learning abilities and

perhaps even some additional external

knowledge and as part of the response

phase a well-behaved and well-trained

main soar system could potentially

dynamically create access list entries

filter different types of traffic

reconfigure the network especially if

it's an sdn based Network create disable

removed user accounts temporarily

disable applications or block specific

ports anything that normally would take

a lot longer to identify and to

implement for a manual intervention team

and the good news is that it's not just

the type of tool that shows its benefits

during an incident response phase but

it's actually a tool that can be used

during threat hunting as well now thread

hunting is something that you do

when you've got nothing else to do as a

security analyst it's basically a

process in which you decide periodically

to look for indicators of compromise for

those types of persistent threats that

are really hard and tough to identify so

threat hunting happens when everything

is good everything is green but you just

think that it might warrant some

investigation just in case we're missing

something which is staring us right in

the eye right here

and remember the terminology that we

introduced along with the incident

response phases and along with the

automation techniques that we mentioned

a couple of videos ago so whenever we're

talking about orchestration because

basically this is orchestration of

security incidents right we're

automating the response to security

incidents and the lists of tasks that

need to be executed whenever this

automation kicks in now these are called

run books or playbooks one last topic

here to mention which is more on the

realm of sci-fi for now is the

adversarial machine learning or

adversarial AI approach from an attacker

what exactly is this well in order to

understand this let's try to remember

when we talked about machine learning or

artificial intelligence and we said that

these approaches are extremely

beneficial for all these systems that

analyze the behavior of users of

workstations of applications and then

try to build a baseline of their

functionality they're trying to identify

how is that user normally behaving how

is that application normally behaving

thus building a machine learning model

then on top of that machine learning

model we can then identify any outliers

any events that don't match what we've

seen before now the same thing can

happen in order to detect malware so we

could be analyzing samples of code of

behavior in our applications perhaps

even send them to do some Cloud

environment to Some Cloud analytics

service in which that behavior is

analyzed and further stored in order to

build a baseline for what that

application or that user is supposed to

function in its good days now

adversarial Ai and try to keep an open

mind about this is the involvement of

the attacker and these centralized

machine learning environments in which

the attacker using its own machine

learning or AI able tools and the

attacker is generating their own samples

fake samples in order to be injected in

this analytics engine

by slowly educating that machine

learning engine into believing that

whatever

Behavior the attacker is about to

exhibit when they launch their attack is

supposed to be considered normal I don't

know if you ever if you ever did a an

allergy treatment where you are slowly

and steadily exposed to the allergen in

order to educate your immune system to

learn about it and to understand that it

doesn't pose a threat this is probably

the closest example I can give you which

looks like adversarial AI in which the

attacker starts slowly training the

actual security solution that was

designed to catch abnormal behavior into

making it believe that whatever attack

the attacker is about to conduct is

normal is part of an educated and

modeled as machine learning goes a

modeled Baseline so it's smart it's uh

it's a bit cheesy it's still in the in

the Sci-Fi realm for now because there

aren't really documented situations in

which this has actually happened but it

is possible and it might have happened

without us knowing about it another

approach to this would be for an

attacker to submit fake samples or fake

hashes of uh of files that are supposed

to be malicious and when submitting them

they're also reporting them as being

safe to online scanning services such as

virustotal or other antivirus

anti-malware proprietary Solutions such

as Cisco towels and then of course when

the actual malware is detected in the

network your security equipments are

going to scan that file is going to

generate a hash of that file and they're

going to upload it to Some Cloud

environment which is going to send and

back a verdict about the file saying

I've seen this file before and I have

been told it is not malicious so to go

ahead allow it to run and that file is

actually malware fun stuff right

especially fun when the videos aren't

that long and fortunately you know the

end of this training is made up of small

and interesting tidbits of information

like this video right here so thank you

so much for watching like subscribe

support do whatever you normally do

after watching a video that you enjoy

and don't forget to watch the next video

as well thank you so much and see you

next time

[Music]

foreign

[Music]



27 27


foreign

[Music]

forensics now digital forensics might

sound like a pretty weird chapter to

include in a Security Plus training but

even though you might not be the actual

person responsible for performing a

forensic investigation you might have

not have any legal training perhaps you

still might be part of the technical

team security team that can help those

investigators gather information making

sure that the method used to gather the

the data that might incriminate someone

is collected in a consistent Manner and

it is stored in such a way so that it is

admissible later on in court so you need

to understand a couple of the legalese

terms in this chapter and also we're

going to talk about a couple of the

technical methods for actual collecting

data in order for it to be admissible in

court which I believe is going to much

more interesting topic now one thing to

mention here before we begin is that

digital forensics is often a process

that is conducted against someone who

has been identified as an internal

threat or an Insider threat that's

simply because it's much easier to uh

you know to investigate a person that

you can reach and the equipment that was

used to conduct an attack perhaps if

that equipment belongs to a certain

company especially if it's your company

because in other situations where the

attacker is located perhaps in

completely other country in another

continent you don't really get a chance

or at least not in your jurisdiction you

don't really get a chance to investigate

into gather all this information from

the attackers equipment and from the the

data used by the attacker to conduct

your attack so most investigations are

going to be performed under your own

roof and the key word in a any kind of

Investigation is evidence you need

evidence in order to prove that some

something has happened in order to

prosecute a specific person in order to

prove guilt or even innocence and

evidence in the computer worlds is

called latent that is it's not the type

of evidence that it's so obvious like

like a murder weapon it's a type of

evidence especially when it when it

comes to data it's a type of evidence

that you need to interpret it using a

specialized system a computer all right

you can you cannot just simply you know

display a hard drive in a court of law

and just say well this hard drive

includes all the necessary evidence to

prosecute a person and that person it

simply cannot work like that so as part

of the evidence collection process you

need to make sure that whenever you're

collecting that evidence because

collecting that evidence is also going

to be performed using an external system

another computer right you need to make

sure that the process of collection is

conducted in a legal Manner and it also

is admissible in court also you might

have to worry about how do we store that

type of evidence long term so that let's

say two months from now or one year from

now whenever that piece of evidence is

actually going to be presented in a

court of law that evidence is still

going to be considered valid because we

all know that data can be volatile right

you can lose you can delete data you can

alter it somebody might come in and make

some changes into the actual evidence

that incriminates them so the entire

process of managing and collecting

evidence is a lot more complicated than

with actual evidence that you could

normally you know touch and collect and

put into into a zip tie bag and then

present in front of a judge and the

concept of due process in many areas of

the world means that everybody has the

right to a to a fair trial now that

fairness in Fair trial actually includes

fairness and in the evidence as well

that's why you are the one involved in

this process of evidence Gathering and

digital forensics as a security person

as an I.T technician perhaps you're

going to be involved because you have to

be part of the team that helps the

actual investigators gather the

necessary evidence in order to ensure

that fair trial because whenever you're

Gathering evidence

well if you're planning on tampering

with it you might have a chance to do so

and you must be a trustworthy person you

might be part of a of a team that knows

how to act in a legitimate Manner and in

an ethical manner so that trial fairness

is still going to be preserved and it's

not just a matter of Ethics here I

believe you've seen enough you know

lawyer movies and TV series and forensic

investigations TV series like CSI and

such you know that every single time

when something is interpretable whenever

something doesn't really hold water so

to say whenever the type of evidence

might be interpreted in a different way

it is going to be attacked in a court of

law by the other party so you have to

make sure that all your evidence and all

your steps taken to collect that

evidence are flawless because otherwise

any flaw any mistake in this process of

collection of storage of presenting

evidence is going to make your evidence

is completely useless legal hold is

another important concept it's actually

a very simple one it means that whenever

a piece of software or a specific system

needs to be investigated needs to be

held in order to be evaluated as part of

a trial it can always be taken as

evidence without any prior notice this

means that if you are subjected to a

forensic investigation or if you're part

of a trial you might end up one day with

a team of investigators at your doorstep

that are about to Simply leave with a

couple of your servers in your data

century and of course this is going to

cause you downtime it's going to affect

your business it might even launch your

disaster recovery process in order to

recover from the absence of the

investigated systems so again legal hold

is something that you have to be aware

of because it might hit you when you

least expect it another well-known term

here with the investigations is called

chain of custody you might have heard

about it from TV shows at least

achieving custody is a process that

ensures that any evidence that gets

collected stored and then presented in a

court of law has been subjected to a a

clear process that can be traced back to

each and every person or each and every

entity that has ever touched that piece

of evidence and also it can prove that

the evidence hasn't been tampered with

so it's a process that ensures that

whatever was collected from the very

beginning when the investigation started

is actually the same piece of evidence

that gets presented in a court of law

but before we actually get to produce

that piece of evidence that is about to

be presented later on in a court of law

well there has to be some sort of an

involvement of the actual person who

investigates that case and the person

that investigates the data stored on a

specific system and well before the

evidence is actually produced there's

going to be some sort of a perforensics

report that is a report that lists all

the findings of that person related to

the case or that might be related to the

case that is currently being

investigated so you're starting with a

bunch of computers that you might have a

legal hold on or a bunch of hard drives

but you have to allocate some people

some resources in there to find that

needle in that Haystack in order to

identify which exactly is going to be

that piece of evidence that is going to

help our case now this report is going

to touch upon that ethical discussion

again because you obviously have to use

a person to perform that investigation

and generate that report a person that

has no bias

and nothing to gain from the current

investigation because if they are biased

then their findings are going to be

insincere to say the least another

important factor here is that any

methods that are being used to generate

that type of data generate that report

or to extract any piece of evidence out

of a a hard drive or of a larger system

needs to be repeatable methods so you

cannot just come up with something

that's I I managed to get my hands on

this file right here but I cannot tell

you how or the like accidentally I've

destroyed the storage device that's held

the original file but here it is now

trust me that this is the this is the

original file that doesn't work like

that right so we need to have a

repeatable and predictable method of

extracting that information that is if

if another investigator doesn't trust

your process they can simply repeat

their process on their own and get to

the same result and of course and

obviously the data that you're Gathering

that you're collecting must not be

tampered with ideally not even the

original source of the data shouldn't be

tampered with that's why in many cases

we're actually working with copies we're

first performing copies of disks and

ssds before we're actually trying to dig

in after some more detailed information

and to find some more obvious pieces of

evidence in there e-discovery is another

important term here and it actually

implies a very simple thing that is

digging through all the data available

on a disk on a drive it might be a flash

drive might be an internal hard drive or

an SSD or any type of storage device and

then filtering out all the noise or the

unnecessary information so that whatever

is identified as potentially being

relevant to the to the case that we're

investigating gets added to a database

in such a way in such a form and its

Integrity is insured so that later on it

can be presented in a court of law so

e-discovery means digging through data

basically now whenever we're performing

e-discovery it's not just about looking

at the actual files on a disk it's also

about trying to recover deleted files so

we're going to be analyzing the free

space on that disk as well part of the

e-discovery process is going to be

filtering out operating system files for

example or files that have nothing to do

with the case that we're investigating

also since we are collecting a lot of

data and we're storing it in a database

for later analysis we should be able to

structure that data in such a way so

that it becomes searchable we could be

doing a simple semantic search as in

we're just collecting all the email data

or all the

keystrokes let's say all the web history

on a on a computer and of course that's

going to be text content which is easily

searchable but in some situations

especially for binary data in order to

make it searchable you need to attach

some sort of tags to it so we have to

tag the data that we're collecting so

that around we can easily identify it

and perhaps even place it on a timeline

to understand what actually happened

sometimes in the past when the security

incident began and don't forget that

following a knee Discovery process

whatever findings are being produced

they need to be shared with both parties

both the defendant and plaintiff so

everybody needs to know what you found

in there first of all because you as a

as an investigator as a security analyst

shouldn't be biased so you shouldn't be

providing evidence to just one of the

parties and secondly because that's how

fair trial is supposed to look like

right everybody should have access to

the same evidence and it's about

interpreting that evidence in order to

determine who is guilty and who is is

not and the first step whenever an

investigation begins is to document a

scene document the current state of the

scene making sure that you have not

missed any potential source of

information so for example CCTV cameras

or any type of recording devices that

might have been recording while the

events happened also as part of the

scene preparation and documentation it

interviews can be conducted as well if

other people were present in there you

could conduct audio video interviews

which are extremely useful especially

because you know getting that

information when it while it's still

fresh might be very useful down the line

Because the actual trial might take

place in a couple of months or years and

people might not remember what exactly

happened uh two years from now so

documentation of the scene and

interviews are still tasks that are

going to be performed by forensic

investigators before we even get to the

technical part and determining all these

events as a result of interviews or as a

result of the actual data that is

gathered from the from the live systems

or from any system found at a crime

scene in order to make some sense out of

it you need to assemble something called

a timeline now fortunately most forensic

investigation tools out there are going

to try to build this timeline

automatically as in whenever you're

scanning some disks and and looking for

email messages and you identify some

email messages of Interest then those

timestamps extracted from those email

messages are going to be placed neatly

on some timeline so you can understand

that just by looking at the Timeline

what happened what type of events

happened at which point in time now

things are aren't really that easy in

real life because sorting events by the

time they took place at it might be more

difficult than you think especially

because not all computers might have

synchronized clocks right not

everybody's using ntp some computers

might be on different time zones

especially if you're looking at

communication over the Internet between

uh between client and server perhaps you

know there might be completely different

time zones there might be Daylight

Savings Time involved in there also some

computers internally notably uh file

systems and some databases they use

internally the UTC time Universal

Coordinated Time which might not be the

actual time zone that you're currently

in so you might have to perform some

sort of a Time shift on those events if

you're Gathering them directly from the

disk for example from the file system in

order to make them match the actual

timeline of the place where the event

took place where the security incident

took place and before beginning to talk

about capturing evidence from actual

systems and computers don't forget that

you can also sometimes you can also

capture evidence directly from the

networks or from the event logs

generated by the computers on that

Network now unfortunately the data

captured in this way is pretty tough to

make it admissible in court that is

because for example for logs and events

well you might have captured the set of

logs that was currently available on

that system but if that system is left

in production well those logs are

definitely not going to be available a

year from now when the actual trial is

going to take place so you're going to

have a tough time proving that the log

that you've collected or actually the

the real logs initially present one year

ago on that same machine Network traffic

is even tougher to to identify because

once you've captured that Network

traffic just in case you might have a

packet captured device in there well

that traffic is gone so how do you prove

that what you captured was actually what

happened to you to pass through that

wire sometimes in the past that's going

to be an issue and sometimes companies

do invest in more expensive solutions

that allow them to gather Network

statistics and store them long term

sometimes even uh Gathering the actual

traffic traffic captures in order to be

analyzed later on

sometimes these tools allow you to

perform something called a retrospective

traffic analysis RNA that is some sort

of a again some sort of a timeline of

whatever happened in your network or in

your data center so you could just

simply you know slide a a scroll head

down to the timeline and figure out what

type of traffic was going through that

Network maybe a couple of weeks ago or

who communicated with whom and what type

of backups were were being conducted

what protocols were identified that were

second and so on now chances are you're

not going to be facing a company that

has this type of resources and if it

does getting a little hold on that data

might take so long that the RNA tool is

actually not going to provide you with

enough data retention in order for you

to be able to extract that data and then

present it later in a court of law and

finally two additional keywords here and

I promise you we're done with the

terminology with this slide we have two

purposes behind forensic investigations

first of all we need to think about

forensic investigation as something that

can be either used to determine who is

guilty of a certain security incident

but also a forensic investigation can be

conducted in order to better secure

ourselves and to you know increase our

security posture by doing a proactive

approach to security so basically what

we're doing is we're launching a type of

forensic investigation even though

nothing happened in order to better

protect us against future attempts

attacking or their protectors against

the risk of Insider threats and so this

is where we find these two terms first

of all we have strategic intelligence

and this is the type of research that is

supposed to produce some sort of

actionable insight that is preparing you

and your your risk processes your risk

analysis and to understanding where your

flaws are located it which in turn of

course is going to be extremely useful

in developing your security capabilities

the second one is counterintelligence

and Counter Intelligence is about

capturing information about the actual

attacks going on in a situation where

the uh you're you're doing this in a

proactive manner so when an attack

hasn't occurred you it means that you're

preparing your systems you're preparing

your network so that whenever an attack

happens you get a chance to gather as

much information about it as possible so

it facilitates your future forensic

investigation process for example this

would be about preparing continents and

honeypots or DNS sinkholes any type of

device or system that is designed to

collect information about an attack and

not disrupt the attack in order to help

you understand how the attack is being

conducted understand the the ttps behind

that attack the tactics techniques and

procedures involved in there in order to

better understand what's going on and

how your your security incident response

team is supposed to react so coming back

here and talking about the technical

side of forensic investigation a very

big chapter from a technical focus is

called data acquisition now acquisition

basically means extracting some data

that later it can be analyzed and

presented as evidence and in a digital

crime scene it it's always much more

difficult to extract this information

rather than you know just collecting

objects and collecting fingerprints that

is because the data that you're

collecting might be available only as

long as the computer that it's holding

it is running so for example you might

only be able to extract the contents of

the RAM memory only as long as that

computer is on on the other hand you

might be able to extract data from disks

at any point in time but again when you

shut down the computer you might either

trigger some protection mechanism

anti-forensic mechanism or you might

even lose the opportunity to extract

other things such as Network packets or

caches that might be hidden in raid

controllers or in graphics cards so

there are a lot of places where you can

collect this data but it's not that easy

it's not just sitting there waiting for

you to to take it home and present it in

a in a court of law so we have a

specific order here which is called the

data acquisition order which takes into

consideration the order of volatility of

that data that is how probably is for

that piece of data to become unavailable

if you don't collect it right now

starting with the most volatile of all

memory types such as CPU Registries and

caches in this controllers in graphics

cards and even caches created by the

applications or the operating system

that is currently running then we're

looking at the memory we're trying to

perform a dump of the contents of the

entire memory of a system it's very

useful because everything that a

computer does can be seen in memory all

the files it loads all the previous

conversations that were conducted you

know email messages uh applications

currently running everything is there

inside of that random access memory and

the memory is also the place where you

can identify things such as the current

routing table of the system the current

process table the current ARP cache so

for example who are the most recent

destinations in the network that the

computer has accessed or tried to

contact and so on now after we're done

with the memory then we can start

focusing on persistent mass storage that

is disks so hard drives ssds flash

memory nvme drives whatever is directly

attached to the computer and can be

safely copied or extracted don't forget

that free space is also a point of

Interest here because from that free

space and or deallocated space on any

disk you can always carve out old files

you can try to recover deleted files or

files that have been partially

overwritten perhaps and that might be a

a great wealth of information then if

the system allows you to and there is

such a thing you might be looking at

remote logging systems so centralized

logging locations that gather logs from

all over the network if you have access

to those then again that's going to be a

great source of information and any

other monitoring tools or Monitoring

Solutions that might be running in there

the physical system configuration that's

just for you to to document it and the

network topology in case it's a more

complex Network figuring out how

everything is set up in there and how is

the network actually designed finally

we'll be looking at archival media this

is the last point of interest because

archival media is it's there to store

data long term we're talking about tape

uh maybe external hard drives removable

drive USB sticks things that if you

don't touch them they'll still be there

waiting for you to to investigate them

so that's the data acquisition order in

the order of volatility

now collecting data from memory sounds

like a you know the first thing you

should be doing right but it's also one

of the most difficult tasks out there

that is because first of all memory is a

constantly changing space

there's no such thing as you know we're

just looking at how memory looks like

and you start extracting information

from it and you can nicely pinpoint to

specific events that are happening in

there no things are changing thousands

or billions of times every second inside

that computer's memory which makes live

acquisition that is trying to extract

information from a computer's memory

that is currently up and running a bit

more difficult and it's also a bit more

difficult to prove that whatever you've

just extracted from that memory is also

true because at one point in time the

data might be there and in a couple of

seconds it might be gone right so it's

you might have a difficult time proving

in a court of law that whatever you

captured from memory contents is

actually the the real stuff in there

that there are also other places that

are strictly connected to the random

access memory that can also provide some

useful information such as crash term

files now crash dump files are generated

whenever or something fails an

application or the entire operating

system fails as a last resort the

application or the OS is going to try to

create an image of the memory or at

least of the area of the memory where

the segmentation fault the error has

occurred and try to dump it on the disk

so that later on you can actually

analyze what happened in there now the

crash dump itself of course is not just

going to contain the error details but

it's also going to contain whatever

happened to be in the memory at the time

of that crash so that might be a good

source of information in case you find

these crash down files lying around on

your system a hibernation file is

basically an image of the memory

whenever a computer hibernates it

basically takes the entire contents of

the memory and then writes them onto the

disk so that later on if you want to

come back out of hibernation you just

load the contents from that file on the

disk you just replace the memory content

and you can simply resume where you left

off down to the actual process list and

the position of the mouse cursor in the

actual next CPU instruction that was

about to be executed of course if you

manage to find a hibernation file

depending on when exactly it was created

it might present you a lot of useful

information because that's already an

image of the memory and it's already

waiting for you right there on the disk

page file is an extension of the memory

it might be difficult to extract some

useful information from the page file

because usually the page file starts to

be used the moment when the memory is it

becomes insufficient and certain pages

especially older pages that haven't been

asked for some while those are the pages

that become exiled in the in that page

file so you're going to find some bits

and pieces maybe some strings in there

but you're not going to be able to find

entire running processes and coherent

sets of data in that page file combined

with the contents of the memory yes

that's going to be a really good source

of information but the page file in

itself might not be exactly what you

expect it to and unfortunately there's

another downside to live memory

acquisition think about it how do you

reading higher contents of the memory

well you execute some sort of command

you load some sort of a program in

memory memory okay to read the rest of

the contents of that memory and then

dump it back into a file on the disk

so just by having to load a a driver or

a kernel module or just a simple small

application or just a command that is

about to be executed by the operating

system you're already changing the

contents of the memory that you're about

to dump which is going to be a big

problem if you're trying to present

those contents in a court of law now

when it comes to extracting information

from disks and when we say disks you're

actually referring to any kind of drive

so it might be flash it might be an SSG

and vme physical Spinning Disk it

doesn't really matter which type of disk

extracting information from these drives

can be performed on a bit by bit basis

and it's normally recommended that you

extract that information bit by bit

because that way you're also extracting

the free space and again as we just said

free space can be used to reconstruct to

extract to rebuild a deleted files now

here comes the question how exactly do

you read that information from the disk

do you remove the disk and then connect

it back to your machine do you try to

access the disks through the system the

computer that's already up and running

and using that disk how do you do it

well we actually have three ways of

accessing information from a disk first

of all we have live acquisition just

like with memory but again it runs the

risk of changing data on the disk

normally we do have some tools that

allow us to read information from a disk

without making any accidental changes to

that disk these are called Write

blockers now write blocker is nothing

more than a small piece of Hardware or

sometimes even a piece of software that

simply filters out any attempt from your

computer your investigator's computer to

the disk that you're analyzing any

attempt that might change the uh the

information on that test so any right

attempts are being denied but you are

allowed to read from that disk so this

is a type of tool that you'll be using

whenever you're acquiring data from a

disk for performing six purposes so as

we said live acquisition runs the risk

of having the content of that disks

being changed right as you are trying to

extract the data from it on the other

hand we might perform a static

acquisition that is let's try to access

that disk while it is not running or at

least the parent system is not running

this probably requires disconnecting

that disk and then reconnecting you to

your own machine

and here comes another problem uh we

actually have two types of static

acquisition one of them relies on simply

shutting down the system elegantly and

then disconnecting the disk in order to

avoid any Corruption of data

but what if the system has an

anti-forensic measures in there what if

the system detects a shutdown that

wasn't planned that or wasn't performed

the way it shouldn't been performed and

that's a warning sign that somebody is

trying to use that computer that isn't

authorized to do so so the attacker

might have installed some sort of

anti-forensic mechanism such as this in

order to delete all the data on the disk

whenever a

non-approved shutdown is being detected

it's not really sci-fi this stuff I mean

it can be easily done

so sometimes a better solution would be

to perform static acquisition by pulling

the plug actually the physically

disconnecting

the entire machine from power or

disconnecting the disk allowance is

still running now you might be running

the risk of course of corrupting a bit

of one or two files on that disk but

it's probably worth it just in case you

are you're suspecting that

anti-forensics measures might be in

place

now assuming that you've decided onto

the best method for extracting

information from a disk what you'll be

using is called an Imaging utility

that's basically a software that is

designed to extract information from

these disks for forensics purposes so

again these are the types of software

that sometimes Implement a right blocker

as part of their functionality they know

how to read pretty much all the file

systems out there and they're able to

create a bit by bit copy of an entire

disk and then dump it onto one of your

local disks now of course in order to

ensure integrity and to be able to prove

Integrity later on the image that it's

being extracted is gonna have to go

through a hashing process now hashing

process as you know creates a unique

fingerprint for that data set so that

later on in court of law whenever we are

trying to demonstrate that this disk

collected maybe six months ago contain

this type of sensitive information which

we plan on using as evidence then you

can also demonstrate that by calculating

the original hash of that disk and still

going to match the hash presented in

court of law so the contents haven't

changed in the meantime now other

sources for accessing data might range

from snapshots and virtual machines so

for example if you're planning on

extracting data from a virtualized

server fortunately this is this is much

easier than with a a normal bare metal

machine because a virtual machine

already has its disks in a in an image

format stored in the in the data store

of whatever virtualization solution you

are you're using so the machine is

already there basically you only need to

copy one single file and that's going to

be the disk or the disks of that virtual

machine a snapshot can also be useful as

a snapshot with a snapshot you can

basically make a point in time image of

a virtual machine so that any later

changes performed on that virtual

machine are going to be saved in a

separate file called a Delta so we're

only storing the changes that were

performed since the last snapshot if

necessary you can at any time come back

to their previous snapshot and basically

you're going back in time with that

virtual machine now this is great for

administrative purposes but it's also

great for forensic investigations

because a snapshot basically stores the

current state of original machine so

it's kind of like you know already

preparing a virtual machine for data

acquisition it's just there waiting for

you firmware can also include some

interesting data although sometimes

you're not going to have direct access

to the firmware and you will need some

specialized Hardware to read it it is

not normally available to the operating

system itself

and the real problem comes in whenever

the actual systems that need to be

investigated are virtual machines in

some Cloud out there especially public

clouds and it's because you don't really

have access to the underlying Hardware

you cannot really disconnect some disks

and then create with uh and create an

image using an Imaging utility out of

those disks you don't have access to the

underlying hardware and the legal

implications of investigating something

in the cloud are going to create some

issues especially if you consider that

pretty much all the servers that you're

using in some Cloud are shared among

multiple users multiple customers

multiple clients so you're probably not

going to be allowed to perform the same

type of forensic investigation due to

privacy concerns of other people's data

that's already on the same Hardware now

you could contact the cloud provider and

ask them for some for some snapshots for

some logging data for any type of events

monitoring that might help you out in

conducting your investigation and think

about chain of custody then how can you

ensure chain of custody

before some data that's coming in from a

data center thousands of kilometers away

or even on another continent how can you

ensure that chain of custody isn't

broken when the data and the hardware

that you're investigating is so so far

away and completely out of your

jurisdiction so that's it about forensic

investigations now I hope this was at

least interesting and fun because this

is not a really deep Topic in Security

Plus but you do need to understand the

high level overview of what's going on

during a forensic investigation in order

for you to be able to do your security

Analyst job in the best possible way

alright so thank you so much for

watching like and comment subscribe

support whatever you want to do but make

sure you're not missing the next episode

thank you

[Music]

oh



28 28


thank you

[Music]

all right here we are risk management it

makes a lot of sense to talk about risk

management in the context of a

Enterprise security it's just that sweet

Security Plus and the exam and the

training for it it doesn't really ask

you to go into too much depth in this

topic because the topic itself is huge I

mean there are entire certifications

focused on evaluating risks on on

building risk reports on on managing in

general risk in a large organization but

for now we're only going to have just a

couple of cute little slides in here in

a short little episode so here it goes

so in general long story short risk

management is a process that is supposed

to help us identify any risks that are

threatening our business and also to

find some ways to mitigate those risks

and over time of course there have been

many representations of how this risk

management business should be approached

or how this process should actually look

like or what are the necessary steps to

be taken and in general what we can find

nowadays in pretty much any approach out

there are some generic steps the first

one is identification of mission

essential functions those are those

functions those abilities of your

business that if somehow disrupted the

entire business is going to suffer so

obviously this is going to be the first

place where we start looking for risks

and vulnerabilities because those are

the resources the processes the services

the I.T equipment perhaps that is going

to hurt us the most if something goes

bad in there next up once we've

identified those critical systems we're

going to start looking for

vulnerabilities yes from technical

perspective we're actually going to be

looking at whatever could possibly be

exploited and how that could could

happen in order to better focus our

remediation efforts

now don't just think about

vulnerabilities from a software and

Hardware perspective a vulnerability

might be also the fact that you don't

have a proper physical security in place

like you don't have any cameras or CCTV

like you don't have any alarm system

you're building that's also a potential

vulnerability next up we have to

identify the threats that might attack

those vulnerabilities so what exactly

would be a Potential Threat coming in

from the inside or from the outside how

would it look like in case that

vulnerability gets discovered and

somebody decides to exploit it how would

they go about that next we will be

looking at the business impact as in if

that vulnerability is discovered and

somebody exploits it how much are we

going to suffer how is the business

going to be impacted and how badly are

we going to have to work in order to

recover from that security incident now

once we have this entire picture built

where we know exactly where our

weaknesses lie and what are the

potential risks and what threats we

might be facing that is going to be the

best moment to decide how are we going

to act upon that information what are

risk response going to be how do we

invest in additional security measures

how do we reconfigure existing security

measures in order to better increase our

security posture and minimize the

overall risk and we keep talking about

risk and I'm pretty sure that everybody

has some sort of a picture in their

minds about what risk actually is now on

a more uh programmatic approach we would

calculate risk of course it starts with

assumptions it's going to be a lot of

assumptions in this video when we

recalculate risk we're basically

thinking at multiplying two values the

first one being the chance for the

probability of a bad event happening

now we have the probability and we have

to multiply that probability by the

impact that the event would have in the

potential case that the event actually

gets to materialize gets to happen so on

one hand we think how often would that

happen

and secondly how bad would it affect us

now these two basically are both

directly proportional with the amount of

risk now an event that's going to happen

often it's still going to affect us even

though it's individual impact might be

low on the other hand even if on an

event might only happen once every 5 or

10 years

but when it happens it brings down the

entire business then it's also going to

be considered a high risk event so we

have risk as the product between

probability and impact and as far as

categorizing types of risks well risks

can come from pretty much anywhere they

can come from the outside it might be an

external attacker it might be just a

natural disaster it might be the

covid-19 pandemic it might be the

Ukraine war it might be something that's

completely out of your control it does

still have a probability of happening

low or high doesn't matter it's out of

your control but it's still something

that can affect you can affect your

business and it has to be taken into

consideration internal risks are going

to be a bit less visible perhaps because

you honestly don't really think every

single day that the greatest risks

should come from within your company now

most people think about risks as being

an external threat but risks can come

from within your company and even more

than that it might be about Insider

threat it might be somebody from your

company that suddenly decides to cause

some harm but it might also be an

accidental type of risk it might be that

somebody has forgotten their their

laptop their credentials in some public

place maybe somebody has accidentally

deleted some sensitive files or has

mistakenly configured the access list so

that those files have become public

knowledge now not everything bad that

happens comes with a with a malicious

intent sometimes it's just accidental

now you also have to plan for those

accidents as well of course you cannot

predict those how fun would that be but

you can take into consideration the fact

that if human error is the major factor

if human error is the weakest link at

least make sure that you have a couple

of additional technical measures in

place that might have the ability to

keep under control such a such a human

error in case it happens we have risks

related to intellectual property those

are basically the uh the types of data

that you're producing as a company and

the data that you're relying on in order

to conduct your business that's

something that you created now if that

something becomes public knowledge as

part of data breach or of an accidental

breach perhaps your reputation is going

to suffer perhaps your market share is

going to suffer perhaps your your

customers are going to abandon you so

those again are risks that need to be

evaluated along with the actual security

incident that led to that risk being

materialized so in calculating risk the

impact is not just the fact that you had

a data breach the impact is that it's

going to take you perhaps years to

recover from the data breach and re-earn

the trust of those affected by it you

might open up yourself to risks due to

misuse of software licenses maybe it's

some security audit or some vendors

audit you find out that you been using

more licenses that you were entitled to

or that some Shadow I.T licenses have

been installed somewhere in the IT

department that you know nothing about

there's always this type of risk most of

them can be mitigated by careful

evaluation with a well-trained I.T staff

and also by defining a clear and easy to

understand internal security policy so

that everybody is going to know that

they're not allowed to install pirated

software on a company computer and that

they're not allowed to bring a switch or

a Wi-Fi router from home simply because

they want to connect more devices at

their desk so there's a lot of potential

risky behavior that can happen from an

I.T perspective in a large company it's

really tough to keep a tight control

over everything everything nasty that

your employees could be thinking about

doing but at a minimum make sure that

your company internal security policy

tries to cover as much as possible these

exceptional situations because if they

are discovered too late especially if

they're discovered after the security

incident has happened and a further

investigation proves that it happened

because some Shadow I.T component in

there actually increased our risk and

our exposure then there's definitely a

lot to do from a policy standpoint in

that company it should have been avoided

from the very beginning it's one thing

to identify a vulnerability that was

just discovered maybe two days ago and

everybody is vulnerable to it and you

just happen to have a data breach

because of it it's a completely other

thing to realize that you've been

running some insecure software

unlicensed software on some publicly

facing servers that nobody cared about

nobody bothered to include them in a

security assessment and honestly you

were you were asking for it right you

were asking for that before that bridge

to happen and just as a last example

here because as you can probably guessed

this list can go on and on and on for

days risks associated with Legacy

hardware and software products that are

no longer supported that don't receive

any more security updates but you keep

using them because you know people have

gotten used to them maybe because

there's going to be a lot of uh

Financial efforts involved in order to

replace one product with uh with a

completely brand new one or simply

because you know if it works don't touch

it

that approach is okay from an

availability perspective from a

usability perspective it's not so okay

from a security perspective you really

do have to touch it from time to time

from a security perspective and I know

how that sounds yeah

foreign

now we're going to have to introduce a

couple of formulas here which are

relevant whenever you're performing a

quantitative risk assessment that is

assessing the risk but also by assigning

some numerical values to what you're

assessing

let me show you exactly what this is all

about and also let me tell you that you

should really remember these formulas I

can bet whatever you want that you will

receive at least a couple of questions

on the exam about these formulas so

whenever we're trying to assign some

numerical values to whatever assets we

have and assets that need to be included

in a risk assessment we're going to

start with something that is pretty

obvious that is the asset value how much

is the asset going to cost us assuming

that we're going to have to replace it

we might have to replace it because it

was compromised because it was part of a

data breach maybe because it was

actually stolen right but in any way

that's the value either the value that

we spent to obtain that asset in the

first place to buy that server for

example or the value that we would be

required now to spend in order to

replace it so AV is going to be the

answer to the value then we're going to

have to evaluate something called an

exposure Factor now exposure factor is

going to be a percentage of that asset

value and it's a way of saying in case a

security incident happens a specific

security instance of course we cannot

generalize this but in case of specific

security incident happens to affect that

asset how much of that asset are we

going to lose

and you might be thinking here well

isn't this always 100 isn't this always

a unitary multiplication here not

necessarily yeah perhaps if you're just

evaluating a hard drive let's say or an

SSD well you either lose or don't lose

that SSD right if it's an a server and

the risk that you're evaluating is the

risk of array power surge perhaps that

is going to damage your psus or your uh

your power supplies then those power

supplies are going to be just a

percentage of the value of the entire

server so you're not going to lose the

entire server you're going to lose

something that is let's say 10 20 of the

cost of that server similarly if you

think about physical assets such as a

building right you have a building uh

with three or four floors let's say and

you're in a uh an area that is really

often subject to to floods right a flood

might happen once every a number of

years well if a flood happens

are you going to lose the entire

building it's probably not going to be a

tsunami right that's going to wipe away

all four floors but it's probably going

to be just a ground floor that is going

to be affected so again that might be

something like 25 an exposure factor of

your building in case a flood happens

now if your data center it's at the

first floor

that's going to be 100 right especially

if we just consider the data center

equipment but that's the exposure Factor

EF

so finally if we combine these two

values we can calculate something called

the single loss expectancy that is how

much can we expect to lose on a single

occurrence of a nasty event

in other words single lost expectancy is

the absolute value multiplied by the

exposure Factor so how much monetary

value do we expect to lose if that asset

is being affected and we know that it is

exposed with a certain Factor so this

single loss expectancy pretty easy so

far

we have to introduce another variable

here called Aro this is the annual rate

of occurrence so once we have thought

about the asset value and once we have

thought about the exposure factor and we

know that all these apply to a single

event to a single security incident but

what if that security incident has a

chance of happening multiple times a

year or once every number of years so

any rate of occurrence is how often that

event actually can happen

and it's going to be relevant if we

combine it with the annual loss

expectancy how much do we expect to lose

in a monetary value of our assets during

the course of an entire year

and these two as you can probably guess

are going to be combined like this so

the annual loss expectancy how much we

expect to lose over a year is going to

be obtained by multiplying the single

loss expectancy so how much do we lose

once multiplied by how often do we

expect this to happen during a year it

kind of makes sense right if we you know

we expect to lose one hard drive every

month then of course we're going to have

an annual loss expectancy of the cost of

one hard drive multiplied by 12 months

12 times a year right so that's going to

be how much you expect to lose on that

specific type of asset during the course

of entire year so remember these

formulas are not really complicated

they're pretty self-explanatory but make

sure you understand what's going on in

here because again I can bet whatever

you want that you will be asked on the

exam about these two formulas what else

is missing here

well a crystal ball perhaps

you might be saying oh where's the

crystal ball that's going to tell me how

often am I going to see an earthquake

this year or how often am I gonna be

subjected to a data breach well of

course there's no such thing as a

crystal ball to help you evaluate this

type of risk so quantitative risk

assessment even though it kind of looks

like I don't know if there's a lot of

math in there there's numerical value so

easy to graph easy to plot easy to

prioritize yeah but it's still a lot a

lot of guesswork now that guesswork can

be more or less educated so we could be

looking at similar companies in our you

know same field as us we could be

looking at our historical events

um even though we should have learned

from those historical events and if we

did get a data breach like three times

last year you probably shouldn't get the

same amount of data breach this year

right otherwise we didn't learn anything

right so yeah you you could learn this

you could educate this from from the

market from other vendors from whatever

threats are emerging out there but it's

still going to be a lot a lot of

guesswork

so let's try doing this some other way

yeah it's nice to have some numbers in

there but sometimes those numbers mean

nothing if they don't come from a

reliable source and unfortunately

there's no reliable source for the

quantitative risk assessment that's why

we have a quality of risk assessment

which is based on interviews now we're

just asking people about their opinions

we're asking the people responsible for

the servers for the apps for security

for the building management and we're

basically asking them to evaluate a

specific type of risk and let us know do

you think that this is a high risk

medium risk low risk Red Green

yellow how how much risk do you do you

see in this event actually materializing

and you might think that again this is

also very subjective but you might be

surprised that this type of response can

actually prove to be much closer to

reality especially if you ask the right

people because if you have some you know

you know the I.T bill that are dealing

with the data center infrastructure

they're probably going to know better

than anyone else how often something

breaks in there or how often a Cyber

attack might happen a deny of service

any type of threat out there might

happen of course they might not be able

to predict when an earthquake or a flood

would happen but who can actually right

so it's better than nothing and in some

cases it might be better than the

quantitative risk assessment because

it's it's easier to understand and it

doesn't really require you to invent

numbers just provide an opinion and the

reports generated by such a risk

assessment is also called a traffic

lights report because we have a red

yellow and a green colored in there in

order to better represent or visualize

how the risk is distributed and which

areas actually warrants more security

Investments right so what you're going

to do with all that risk well first of

all before you do anything what you have

is inherent risk so there's the risk

that's lurking in there unless you

actually plan on doing something about

it uh let's say that you perform the

secret assessment your foreign risk

assessment you've prioritized the

necessary assets you know exactly where

your highest impact is going to be what

type of risk is most likely to happen

and you now know exactly where you need

to focus where you need to invest what

you need to do in order to minimize that

risk now once you've taken all these

measures

you are always going to be left with

something called residual risk that is

because you're always trying to minimize

risk you will never try or succeed for

that matter in completely eliminating

risk the only way you can completely

eliminate a type of risk is to stop

doing the risky action

so if you have a web facing server that

is hosting a website if you know that

you're always going to be exposed to the

risk of uh web-based attacks like SQL

injection and cross-site scripting or

denial of service

the only real method for you to avoid

all the possible risks out there even

though unknown ones is to stop running

your website it's to shut down that

server and start publishing your website

which is probably not what you intend to

do so in pretty much any situation you

will have to keep going you'll have to

keep doing the risky action but you will

try to minimize the risk as much as

possible and then you'll have to decide

what are you going to do with that

residual risk

now there are a couple of things you can

do with that residual risk first of all

you could continue mitigating it trying

to lower it even more that's risk

mitigation at some point you're going to

have to stop because at some point the

improvements that any type of cost or

any type of money that you decide to

throw at that risk are not going to be

worth it in any type of investment

especially security Investments you're

never going to have to invest more money

than the value of the asset that you're

trying to protect it doesn't make sense

right it doesn't make sense to pay more

than it would cost you if that asset

would be lost or if that asset would be

breached

so you're going to have to mitigate up

to some point where the investment

simply stops being feasible you can also

completely avoid that residual risk risk

avoidance that's exactly what we said

before stop doing your Risky Business it

might be something minor it might be

something that's not critical for your

business and you might decide at some

point well you know what we're going to

stop that web service we're going to

stop that API which nobody uses anymore

we're going to stop that Legacy

application I'm going to stop something

that exposes us but isn't really

critical to the business

so that's risk avoidance we can also

transfer that risk to somebody else well

that's basically what you're doing when

you're buying insurance right well think

about it even if you're transferring the

risk which means that the financial

impact is not going to hit you the

reputation impact is still going to hit

you so you're not going to be able to

transfer the reputational impact to

somebody else even though you're paying

somebody else to take care of your your

residual risk take care of your data for

example even if they have a date breach

well it's going to be your customers in

their data breach that are going to be

affected so you are going to be the one

to suffer the consequences

and finally last Last Resort what do you

do with that residual risk well you just

learn to live with it you just accept it

that's risk acceptance life is life so

life goes on even with a bit of rest

every single day and finally the last

line here on the slide risk awareness

this is sometimes the biggest issue when

performing risk assessments that is

making sure that everybody understands

the types of risks that you might be

exposed to if you're talking to

executive level uh people key

stakeholders right in the company

they're probably not going to understand

what a cross-site scripting attack is no

matter how much you're going to try to

explain it they might be able to

understand a denial of service they

might not be able to understand a data

exfiltration an apt type of an attack so

any type of risk report has to be

enhanced and Rewritten in the language

of those involved in making the actual

decisions

in order to convince them to understand

the value of an investment that's going

to minimize the risk in most cases the

easiest approach here is going to be to

try and generate a quantitative risk

assessment approach in which you can

actually put a dollar value to a

specific type of security incident so

you can demonstrate to a to a c-level

person that this is how often this type

of event happens in our Market this is

the average loss that the companies have

to have to suffer whenever that event

happens and this is how little we need

to invest in order to lower our security

exposure by this much never lie to them

never tell them that you will definitely

eliminate risk because they might

believe you

and when that Dreadful day comes where

the data breach is going to demonstrate

that the risk actually wasn't zero

you're going to be responsible for

promising something that you weren't

able to deliver so I hope you enjoyed

this this fun discussion about risk

awareness risk assessment risk

evaluation there are all of them they're

they're pretty logical Concepts I would

say that if you apply common sense to it

you shouldn't have any problems on the

exam day but make sure you you remember

a couple of key terms make sure you

remember the formulas that we introduced

and that should be more than enough at

least for the Security Plus exam so

thank you so much for watching see you

on the next video and until next time

you know what to do right like subscribe

comment you know you know that already

see you on the next video bye

[Music]

foreign

[Music]



29 29 


foreign

[Music]

everyone one last topic one last chapter

one last push in this training and if

you manage to get up to this point then

this is probably going to be a piece of

cake for you and it actually is the

physical security is not exactly the

most the the simplest topic out there

but it's a lot of common sense in it

because we can all understand why

physical security is of parallel

importance it doesn't matter if it's

about your home your car your data

center even the place that actually

stores your data there are a lot of

situations in which physical equipment

can be hijacked can be compromised

simply by being in the vicinity of it by

having access to the actual disks the

actual power supplies having access to a

password recovery procedure that can

only be performed if you're right next

to that device and maybe put some

buttons on it a physical security can

also impact data confidentiality I mean

regardless of how much security you

might have in place for Access Control

for for validating your users for

enforcing a lot of authentication

methods if somebody can actually remove

your hard drives and go home with them

that's probably going to be a big big

impact onto the confidentiality and

integrity of that data so physical

security I hope you'll find that this is

a chapter filled with common sense and

for any questions related to physical

security try to focus on them for a

couple of seconds on your own just think

about them because anybody can

understand physical security you don't

really have to learn it by heart or you

don't even need me to teach you this

actually and ensuring the security of

physical assets is at the end of the day

an approach that is very similar to what

we've been doing so far about stickering

data so we're still ensuring

confidentiality we still need to make

sure that access to a specific area or a

physical area can guarantee a certain

level of Integrity so that whatever we

store in there can have its Integrity

guaranteed as well and also availability

is involved as well on on two sides

actually first of all if anybody has

access to your data center then your

availability might be impaired because

anybody can can mess around in there and

secondly the moment you're implementing

a physical access system you are also

tasked with maintaining the availability

of that system because otherwise if you

end up being locked out out of your own

building out your own data center due to

a badly configured physical security

policy you're gonna have bad time right

that's not yet what you intended so in

most cases focusing on physical security

is going to be about determining where

to invest into dedicated Security

Solutions that can protect actual

physical assets or physical areas and

this decision is also included in some

sort of a risk assessment because you

don't want install a redness can onto

every door all over your building right

you don't want to annoy your users you

don't want to to implement so much

security that it becomes unusable and it

also might become cost prohibitive so

you're gonna have to identify and design

the the actual layout physical layout of

the building and of the areas of

interest and where are the peoples

flowing from and uh which are the common

areas which are the areas that hold

sensitive data and try to abstract them

in a design that should be as simple as

possible but a design that allows you to

implement physical security only at key

locations

so let's see a couple of methods by

which we can Implement physical security

controls starting with something very

basic such as simple warnings and

signage that is displayed on a door on a

certain area explaining to somebody

who's about to enter that they will be

subjected to video recording perhaps or

that they shouldn't be there if they're

not authorized to do so or that they

they need a special type of credential

in order to access that area and at the

very least this fight discourage a

couple of well not so determined

attackers or Intruders

and this is also going to help you from

a legal standpoint because you've just

warned potential Intruders about the

potential consequences that they might

face in case they choose to ignore that

warning

secondly once you've identified the

zones that fold sensitive data or

sensitive equipment or areas that are

simply not for Public Access then you

have to install some sort of a entry

point Security in that area so make sure

that you identify all the entry points

of course and then make sure you have

some sort of an authentication mechanism

that is able to check the identity of

the person that is about to enter it

could be completely automated it might

be based on a on a key card might be

based on a fingerprint it might be based

on a person put in there in order to

check your ID and allow you or deny your

access now in general this type of

secure entry point should also be

recorded using video and audio so that

you'll always know exactly and you'll

have a recorded proof of what happened

and who managed to gain access in that

secure area from a design standpoint

never use a secure area as a Transit

area in other words try to minimize the

traffic between security zones as in you

you have a security The Zone and you

just have to decide who gets to enter it

and who gets to leave it that's it it's

never going to be used as Transit

between other two areas ensuring

visibility for certain areas might seem

counter-intuitive but it's actually

recommended to ensure as much visibility

as possible especially for public areas

or for high traffic areas because a high

level of visibility

discourages a lot of the people who

would normally try to install some Rogue

devices maybe perform some surveillance

maybe perform some reconnaissance

actions in there if they know that

they're in plain sight and there's no

place to hide they're probably going to

look for some other way to get that

information and for direct access

between a public area and a secure area

try to install something such as a a DMZ

so that there is never going to be a

direct access to just one single door or

one single barrier between a high

traffic area and a highly secure area

always have some sort of buffer offer

and in that case try to avoid any

visibility onto the secure area so that

people who are just passing by are not

going to be able to just speak inside of

your data center

sometimes this type of buffer can also

be considered an air-gapped Zone it's

like having a completely empty zone

between a a high traffic and public area

and a high security area this allows you

to observe any traffic that might pass

between those two zones it allows you to

implement authentication and access

control mechanisms between those two

areas and physical security can also

help you secure actual data such as

using the traditional saves and volts to

protect highly sensitive pieces of data

or unsensitive assets for example the

root server of a CA might be stored in

such a vault of course it's going to be

air gaps it's going to be completely

disconnected from the rest of the

network but we're trying to implement

the best level of physical security that

we can afford in order to make sure that

nobody is going to get their hands onto

your private key and yes we're not just

talking about Digital Data here paper

data and printed data can also be stored

in such a safe or revolt Faraday cages

can also be used for highly sensitive

electronic equipment a faraday cage is

designed so that no electromagnetic

signals can enter or leave that

enclosure this might protect against

eavesdropping might protect against

attacks targeted at the electromagnetic

emissions of a specific device there's

actually a specific standard defined by

the Department of Defense the usdod

called The Tempest standard in which the

devices are certified up to a certain

level that they are not emitting or they

cannot be intercepted by their

electromagnetic emissions

and yet there are solutions for

protecting not just the actual equipment

but also the the cable runs that reach

those equipments or the cable runs that

go through a public area and because of

that they might be exposed to either a

denial of service somebody is simply

reaching that cable and cutting the

cable and secondly if somebody has

access to the cable then they could

potentially install a tap onto it and

then Sniff and listen to the data that

is passing through it that's why we also

have solutions for protecting data which

are kind of obvious right uh we're

simply installing those data into a

shielded and actually impenetrable metal

conduits so that if somebody attempts to

actually reach the cable within that

that tube they're either going to create

a lot of noise they're going to create a

lot of disturbance and they're most

likely not going to go unnoticed and

finally back to the basics don't forget

that especially for publicly facing

areas you could channel the traffic flow

and we're talking here about I don't

want to say human trafficking but and

we're talking here about the flow of

people uh two specific areas by

installing barricades and fences also

don't forget about lighting a well-lit

areas are by default already protected

against up to a certain level of course

already protected against potential

Intruders because if everything is in

plain sight and extremely visible you're

probably going to discourage a lot of

potential Intruders

from trying to do something nasty such

as jump defense or pick a lock or break

some windows if that area is extremely

well lit and they are perfectly visible

door locks as simple as they might seem

there's still one of the most efficient

methods of securing access to specific

areas just for the exam remember that we

have three types of door locks we have

physical mechanical door locks we also

might have electronic door locks which

might be controlled by a keypad or by

access through an RFID Card we also have

biometric locks which obviously are

going to can some some physical

characteristic of whoever tries to to

pass through like the fingerprints or

the retina man traps are the next

Evolution after locks and as funny as it

might sound a man trap is exactly what

the name says it's it's basically a

isolated area in which the person that

is attempting to go from one area to

another is going to be temporarily

trapped or subjected to a second

authentication mechanism in order to

proceed so you're basically going to

have to go through two doors or two

barriers two authentication mechanisms

one wants to enter demand trap and then

to exit the Man Trap this allows much

better monitoring and much better

accounting of whoever went from one

security Zone to another and it also

avoids a lot of those situations in

which one person holds the door odor for

somebody else or when somebody manages

to catch a closing door before it

actually gets to close and then succeeds

on sneaking in after an authorized

person so we're gonna avoid these

situations using man traps now of course

they're going to be costly sometimes man

traps are even augmented using dedicated

Personnel that is while you're in a man

trap there's somebody looking at you

validating your ID in order to allow you

to pass through the second door but this

depends on the security level of the

company and in in general their security

budget of course

securing physical access to devices

might be performed using cable locks you

might have heard of a Kensington lock it

actually can serve two purposes the

first one it's kind of obvious right you

you connect the the device like the

laptop with the Kensington lock so that

nobody's going to be able to just lift

it and leave with it secondly you can

also have a Kensington lock that stops

any attempt at dismantling the device

like opening the case of a computer

alarms are designed as a backup system

whenever the main security systems

happen to be bypassed so whenever we're

detecting the presence of an

unauthorized person whenever you detect

movement or when the person has

reception detects that something fishy

is about to happen like a break-in they

could sound an alarm we actually have

multiple types of alarms here we could

have open circuit or closed circuit

alarms which means that the alarm is

going to sound either when the circuit

is closed or when it is opened for

example you might have a closed circuit

alarm that's going to sound whenever it

detects an open window

now an open circuit alarm is going to

sound whenever it detects a contact

being made as a small note to make here

a open circuit alarm is considered to be

less secure because they are designed to

be by default monitoring an open circuit

that is they're going to sell whenever

the circuit closes so if they're

designed to be okay with an open circuit

then just by cutting that circuit

maliciously cutting that circuit you're

basically going to bypass that alarm you

can also have motion detection uh based

alarms that is the alarm system is

connected to some sort of a passive

infrared sensor like those that you hang

over the walls or in the corners of the

rooms that detect movement whenever the

security system is armed we could also

have alarms that are triggered by noise

or by proximity that is whenever we need

to track the movement of specific tagged

objects or assets like assets with RFID

tags remember we sense the fact that the

RFID tag is passing through a Gateway

device then we're going to to sell the

alarm now pretty much what you can find

on the RFID tags attached to to clothes

and uh and pretty much any shop in the

mall and finally we can Implement duress

alarms these are alarms that are

manually triggered by the security

Personnel by the people sitting at a

reception by whoever happens to detect

something fishy and they decide that an

alarm needs to be sound it might be a

silent alarm it simply notifies the team

to intervene or it might be just a noisy

alarm to scare everybody else duress can

also be implemented as a simple

application on a phone or it can even be

a type of authentication code which has

a special value that triggers the duress

alarm so if normally you would have I

don't know code one two three four in a

in a keypad to access a secure area if

somebody's holding a gun to your into

your head uh just by entering four three

two one you might also open the security

area but it will also trigger a silent

alarm

guards and dogs

are also a type of I like to call it

observable physical security because one

of the reasons why we Implement people

equipped with a uniform and perhaps a

gun in order to check your ID and allow

you access it's not because we couldn't

replace those with something like a

simple barrier that reads an RFID Card

but because the actual presence of a

real person that is supposed to check

your ID and determine if something looks

fishy or you're not being sincere or try

to impersonate somebody else is already

deterrent in itself so in many

situations you might be wondering why do

we see Security in a in a mall or in a

pizza restaurant or anywhere where you

wouldn't really expect so many bad

things to happen that you would need

security to intervene the idea here is

that having the security person employed

in there invisible at all times

that simple fact is going to discourage

most attempts at disturbances dogs are

very efficient because dog cannot be

bribed and perhaps cannot be even fooled

as long as you you match whatever they

are trained to detect cameras uh they

might be analog they might be digital

doesn't really matter in general the

system is called closed circuit

television or CCTV so any type of video

surveillance is great of course video

surveillance should be augmented by

somebody who actually watches the video

field or at least by a recording feature

like a DVR or any VR that is going to

store that data for not necessary very

long time but for a sufficient period of

time to allow you to investigate

whenever you detect that something fishy

has happened you can also rely on some

smart features of recent cameras such as

Dynamic identification of faces or car

license plates or at the very least the

ability of of a camera to react the

moment it detects motion or a specific

type of motion such as the motion

generated by a person not the motion

generated by a dog or rustling leaves

and by the way Spar detection is already

available in a lot of cameras out there

you don't really have to buy an

Enterprise great solution to to benefit

from uh from this ability to

automatically recognize objects and

people by using your your IP cameras so

this right here an example from the from

the back of my house and please ignore

the Christmas lights which are still

hanging in there I can enable vehicle

detection for example right you can see

it right here and at the bottom I can

even set a blockness or a loud list of

car license plates that I know I should

be seeing in there perhaps because it

might be my car or my neighbor's car

passing through but I could also make

that camera alert me whatever a foreign

license plate is detected this is part

of the vehicle detection feature if I go

over here under the smart event

area or even basic events starting with

basic event I can enable motion

detection here right and I can also

detect some smart events including phase

detection right or even Line crossing

detection so for example I can draw a

theoretical

barrier over my my graphical

representation from the camera and

whenever I detect a person passing

behind that virtual barrier then I'm

going to generate an alert so again this

is not exactly a very sci-fi not exactly

very expensive you can implement this on

a lot of Hardware out there even for

your own personal use

and of course reception security as in

employing actual people to check the IDS

of whoever's entering your building your

data center any secure area is going to

be is one of the most traditional

methods of securing access and it's also

very efficient now of course you're

relying on the Integrity of the people

that you're employing but this method

can also help you in documenting the IDS

of all the people that are entering your

your building especially for visitors

and people who don't belong to your to

your business so that whenever a

security incident happens and uh an

outsider for example might be

responsible you can also backtrack that

event down to the actual moment when

that person signed in and try to

determine uh their identity where they

came from and how to make them

responsible of course for insiders for

internal users you should rely on some

company managed set of ID so usually

your employees really have some sort of

a badge or RFID or or at least some sort

of code that they need to present in

order to uniquely identify them HVAC

security that is a heating ventilation

and air conditioning is especially

important all over the building but even

more important whenever uh the protected

area is the data center because in a

data center you're gonna have to have an

extremely high level of control over the

temperature and the humidity in there

and always be sure that whatever you're

monitoring and whatever changes you're

making to the environmental factors are

going to be strictly controlled that is

important because especially in rooms

with a lot of equipment having a too

high temperature of course might cause

the the equipment to shut down to become

overheated to low temperature again

might not cause them to even boot up too

much humidity might cause corrosion and

might damage the electrical circuits and

to little humidity might come cause

static electricity which is going to

damage everything also on the data

center it's important to design data

center in such a way so that you're

going to alternate hot and cold aisles

that is You're simply going to think

about the data centers as rows and rows

of racks and servers and between those

rows you're going to have some empty

space right air now those are called

aisles and you should have a cold aisle

alternated with a hot aisle the cold

aisle is the aisle from which all the

equipment on the left hand side and on

the right hand side they all draw air

from so that's the air that everybody is

using to cool down the equipment right

so they all have fans and the fan is

going to move the air from one end of

the device to the other end of the

device so you're going to have to

position those devices in in your racks

so that all of them are going to draw

air cool air from the cold aisle and

dump or exhaust the hot air onto the hot

iron now of course the air conditioning

in your data Center should also be

designed in such a way so that it's

going to blow cold air into the cold

aisle and it's going to try to take out

as much of the hot air from the hot

aisle as possible in order to keep a

steady temperature in that room fire

detection and suppression is really

important because fire can damage

everything starting from the equipment

down to the actual building not to

mention a risk to human lives so for as

far as suppression and or methods that

help you eliminate a fire once it was

detected we have a couple of them that

you should remember for the exam just to

mention a few of them dry pipe dry pipe

is used especially when the pipes go

through the exterior of the building

where there is a risk of freezing so a

dry pipe is not going to hold anything

in it not going to hold water unless it

is actually required to start a

sprinkler system that is because if you

constantly have water in those in those

pipes and they're exposed to Sub-Zero

temperatures they they might freeze and

your fire suppression system might not

work a pre-action is kind of like dry

pipe except that whenever the alarm is

triggered on a certain level of or

threshold of temperature or smoke

detection is reached then those pipes

are going to be automatically filled and

only when the actual flame is detected

and the sprinklers are going to be

activated Halon was used for some time

because it was based on gas and it did

not damage electrical systems but it has

been removed by many countries because

it attacks the ozone layer so what we're

using nowadays is called clean agent or

sometimes called inergen and it's a type

of gas that attempts to deplete the

amount of oxygen in that room so that

the fire is not going to have any more

fuel to maintain itself surprisingly

enough physical security is not just

about securing access to data usable

data but also about denying accessor

making sure that nobody else is ever

going to have access to a specific piece

of data that we're planning on deleting

or planning on destroying this is where

we find methods for secure array secure

deletion of data or even media

destruction so in general the concept of

securely erasing the contents of data

from a storage medium is called Data

standardization that is not just simple

erasing that data or formatting the disk

but making sure that the actual medium

cannot be used in a data recovery

process and nobody's ever going to be

able to reconstruct the data that used

to be stored on that device among these

methods you can probably guess that

burning is going to be a very efficient

method of destroying pretty much

anything anything we also have shredding

especially for paper we have different

types of shredders actually some

shredders are able to destroy even more

than papers such as CDs or DVDs some

shredders can even destroy actual hard

drives well probably you're not going to

buy one of those but nevertheless you've

probably seen a paper shredder before

pulping is another method that can be

combined with shredding that is

combining the uh the shredded results

with water or with some other agent

design at disintegrating the actual

pieces of paper that end up after the

shredding process

pulverizing actually means breaking

physically breaking a harder device

you've seen this in movies performed

with a hammer or with the sole of your

shoe that's probably not the most

efficient method even though many times

it's actually going to work Industrial

Level pulverizers actually do a lot more

damage and finally we have glossing this

applies to Magnetic media that is hard

drives right in uh degaussing we're

hitting the uh storage medium with a

very powerful electromagnetic field so

that it's going to completely damage all

the storage cells on that Medium so that

they're never going to allow anybody to

recover what was stored on them and even

more than that the the hard drive itself

is probably not going to be usable again

for storing any type of data so it's

kind of a lobotomy that you're doing to

the hard drive and remember that

degaussian only applies to Magnetic

media so ssds and flash drives they

aren't going to give a damn about the

gossip now talking about sanitization

tools that don't involve Hammers and

fire and chemicals we do have the option

of performing a secure erase on storage

medium for both hard drives and ssds one

method would be to Simply write zeros on

top of the entire disk including the

pre-space of course but in most cases

this is not going to be enough now there

are specific industrial recovery methods

that even after a zero erase data still

can be recovered alternate methods

include writing random patterns of data

random patterns of bytes or even

performing multiple passes like three

pass seven passes 11 passes over the

same disc in order to make sure that all

the previous remnants are completely

gone in general especially for SSD

drives this is not always very possible

because an SSD has kind of a mind of its

own due to the fact that most ssds try

to monitor the usage of their storage

cells so that they are going to try to

distribute data as much as possible onto

the available cells and try to always

write data into the least used cell up

to that point in order to preserve the

endurance of the entire drive you cannot

really rely on having an SSD the ability

to write a piece of data exactly where

you want it to write it so that's why

most secure erase methods actually need

to be developed by the actual

manufacturer of the SSD itself and most

vendors out there do allow you to

download some dedicated tools from their

websites which allow you to perform this

type of security arrays because

otherwise if you're relying on the ssds

controller you're not going to be able

to overwrite all the areas of that SSD

just by using normal operating system

calls now the software provided by The

Venture knows how to interact with the

firmware of the device especially for

this type of security erase intervention

or self-encrypting drives the method

employed is very similar to what we

talked about when we mentioned a remote

wife that can be performed on the mobile

devices that is once you have the entire

device encrypted with an encryption key

you really don't need to waste time

rewriting each and every piece of data

every sector in Block on that disk with

random data or zeros you need only to

remove the encryption key so the only

secure erase process that you need to

perform is a secure erase process onto a

very small piece of data which is the

actual data encryption key throw away

the key and the remaining data encrypted

data becomes

unusable congratulations you've reached

the end of this training I really hope

you you found it interesting uh useful

fun enjoyable or any other positive

adjective that you can think about uh

because I've tried to make it as well as

possible in order to provide you with

free training in order to provide you

with something really useful in order to

help you become a better professional

and perhaps even a better person

so with that being said just leave me a

comment let me know what you thought

about this training uh hit me with any

positive or negative feedback I can take

them both good luck on the exam don't

forget to get some Hands-On practice

with a couple of the tools mentioned in

trading and if you think I deserve one

buy me a coffee why not so thank you so

much for watching and I really hope you

will enjoy your future career in I.T

security

goodbye and see you next time

foreign

[Music]



30 30 


[Music]

all right hi everyone

um my name is rob lee as uh lee just

mentioned um i'm the uh head of faculty

and the curriculum director at the sans

institute

um that's a lot of words for uh i kind

of help the instructors out and

help develop content of what's going to

show up in our courses

i really want to i think sam's uh the

presenters

uh from yesterday and today and the

organizers of this and of course lee

whitfield uh whose crazy idea

this past summer offhand on a i think a

slack message back then

uh said hey you know we'd like to do

this uh

cyber camp for teens and uh they say

yeah let's do it it's gonna be great

and then they were of course they were

asking me on uh you know to attend

both of these and both of these ended up

landing right in the middle when i was

on

a vacation i'm actually on my vacation

uh today and uh but i i still signed up

to want to give a uh

this um uh presentation for everyone

because i think it's super important to

have a chat with

uh all the parents and all the uh teens

and kids

that are interested in the uh cyber

security

and cyber career fields that are out

there because it is

an amazing time uh to be in this field

if you haven't noticed everything that's

going on

uh in the press and the world these days

i want to

give you a quick overview what i'm going

to talk about today you know number one

i kind of want to give you a brief

overview of the what people

think uh cyber security is you know when

you kind of hear about it from your

neighbors and so forth

number two uh i'm going to talk

generically about

what it takes in terms of personality

traits

uh that someone really who's good

at this in any of the variety cyber

paths that you might end up on

what what is the best type of individual

and what kind of things would you want

to have to work on you know personality

wise

to really grow in this field and then

finally i'm going to start diving into

you know if cyber security is something

that you're really interested in

i really want to take you down some of

the niche areas

that exist in cyber security you know of

course we always

have the pop movies and everything else

that you know people watch

you know which you kind of give a hint

but you know in terms of what actually

people

do um in their career paths you know

kind of

give a broad overview of each one of

these as you go through it and then of

course at the end we'll

open up for uh some questions hopefully

um

that if we have any time so i want to

start off with

a brief history of hacking um you know

most people who are aware of

what cyber security is is probably first

introduced to it

through television and movies

um for there's always that uh

group of individuals that always have

the you know someone sitting

in the bat cave somewhere with a headset

you know tippity-tappity onto the

keyboard anytime that they need to

hack into the feed to be able to watch

the video cameras

or anything this is interesting as a

concept and you see it in

almost every single television show now

i have nine year old twins

and even on things like paw patrol you

see

them watching some sort of little dog

hacker

that is like all of a sudden breaking

into something uh

in the television show i'm sitting there

like my mind is blown

that almost every single one of these

all the way down to the early early kids

television shows has some sort of

individual that is technically astute

that likes computers

that is a key part of the team

ironically they're not far off from the

truth is that

in today's society when we end up taking

a look at this

every group of individuals organization

that's out there

including your families you could

probably point to the one

or two individuals that is the tech

support

so think about that for a second when

you think of your own family and you

think about wow when the wi-fi goes down

who is the person that everyone turns to

and says hey

uh is the wi-fi out or are you doing

something with wi-fi i always get blamed

every time i come and visit home that as

soon as i leave as soon as the wi-fi is

out i get a call from my mom

saying hey um did you mess with the

wi-fi

and i said no i didn't do anything this

time but i have been

blamed for it in the past but you know

the key concept here

is that there's always in every

organization

in every group someone that is tuned

into being the

the techno file the person who loves the

computers

who will say hey no problem i'll get the

tv functioning i'll log into the thing

i'll get it going if that's kind of your

personality if you are the person

in the family right now that everyone

already turns to

and is saying hey tech support can you

help me and you take their phones and

you go tipity tappity okay i have it all

set up for you here you go

you're key for cyber uh security career

field

because you already like uh the the

technology and i just realized

i have a major misspelling here uh in

the middle of this i'm very embarrassed

it shows i should probably actually look

at my screens here before i actually do

that

um all right so

i was more focusing on the memes i was

putting in here versus when i was typing

this on the plane

all right so the one thing the meme

that's in here on the left-hand side is

the hackers after typing two letters and

movies

always say i'm in that is really not the

reality of what happens behind the

scenes when you're talking about

um cyber security uh in in reality

people who learn these skills and want

to be the best

individual there is it takes years uh in

years and years and years

of you know education and training and

it never honestly ends

the interesting thing when we start

talking about

um cyber security as a field to get into

is that unlike other sciences unlike

other fields of study um there

is no hard science of truth

when it comes to computers meaning that

the

field is still moving forward in what

was

truth a year ago may no longer be its

truth today you know take for example

physics

when you drop an item at a certain

height you know

exactly how to calculate the

acceleration it is going to

travel before it hits the earth if that

is a constant there are certain

constants that exist

in other fields but in cyber security

that may not be the case um in cyber

security

in general you end up having new

capabilities

new inventions new things that are con

consistently bombarded uh the field with

and you

always have to be learning new um you

know

it would help to potentially back up a

little bit and talk about my

my background to really explain how this

is this is kind of true

when i was in college you know of course

everyone in high school and i actually

frown on on a lot of

um guidance counselors and you know

people

who are telling you know someone who's

16 17 years old

what do you want to be when you grow up

and they're looking at this thing and i

say i don't know

when i was 16 or 17 um what i was going

into i was going to go be a part of nasa

i wanted to be a part of

the space field i really wanted you know

anything all things space related i

loved it

um when i ended up going to the uh air

force academy the surface academy

um i majored in that field um the space

operations and astronomical engineering

uh was

my background and that's what i focused

on all four years that i was there

and during that time frame there were

also

you know a lot of computers that were

thrown at me uh we had to do programming

languages and a bunch of stuff behind

the scenes but

what ended up happening during that time

frame is that uh

apparently you needed good color vision

it was the same reason i couldn't go

become a pilot out of the air force

academy is that i have a slight red

green

uh color um vision issue and so i wasn't

pilot qualified but apparently

in order to go into the space operations

field you still needed the same

qualification so i was like huh what am

i gonna do

um it was around this time that the

career field and it really was this

brand new thing at that point

um in cyber they called it at that point

information warfare

um kind of came up and i was interested

in it started attending seminars and

met some of the people at that point and

you know

they were looking to recruit people and

because i was

kind of without a job and i liked

computers i was good at them

i got picked up into this brand new

experimental unit

um down in south carolina called the

609th information warfare squadron

now the reason i mentioned this here's

like what does this have to do about me

what's your point rob

um i didn't know anything at that point

i was trained to learn how to put a

satellite

into orbit and i was able to do things

on computers that others couldn't do

but in terms of having people look at me

and rely on me to actually know what i'm

doing

on a computer system in order to defend

it from attack

i was clueless i had no idea and of

course what the secret was at this point

no one

knew what they were doing no one had

that

kind of mindset but i was worried behind

the scenes that people would think of me

as a fraud that somehow is given this

job

that i really didn't know what i was

doing you know because that's

this is true through today we actually

there's a

term in the industry that is called the

imposter syndrome

that you know people look to you like

you actually know what you're doing but

deep down inside you think oh

i actually don't know if i'm actually

qualified for this

and so you're worried someone's going to

call you out on your expertise

and call you out and saying you actually

really don't know what you're talking

about

you know you should not be talking right

now and so everyone is kind of

constantly has this weighing on them the

challenge here though

is that everyone feels this in this

field including

the best experts all the way down to

those who are new

and if you're new you actually kind of

have an excuse uh to start out in the

fields like well i don't know what i'm

doing and so i'm gonna learn

but as you progress later people are

gonna still look to you it's like well

you

that individual knows a little bit more

and so ask them in question hopefully

they'll know the answer

and then the imposter syndrome sets in

you get worried that someone's gonna

not know that you actually don't know

everything uh in this field

and so the first thing you have to

wrestle with which is number one

if you like technology understand you're

gonna be constantly learning it

from that point forward and i didn't

realize this at the time i was you know

22 years old in my first job in south

carolina

and i was like pulling out books and

just reading books and how to do it

and how to figure it out and having

mentors who were able to be very patient

with me

sitting down saying oh you're doing it

wrong the command is you know grep

uh and then you have to use this other

command called awk and i'm like i've

never heard of this it sounds like

you're throwing up

and you know it's like oh that's funny

you know but the real thing that

it was really struggling for me was i

felt like i should know it i felt like i

didn't give myself a break

on how much i really thought

i was supposed to have mastered at that

point but

you know and that's the thing i'll tell

you if you're new to this field

give yourself a break there's no ring

that once you cross

that line all of a sudden you are now

considered

done done is an a word that does

not exist in the learning aspect in

cyber security because

the science is still progressing they

just launched 5g networks today that's

going to change

everything when it comes to the amount

of internet connected devices

that will exist and that we're going to

have to secure

that no one knows how the communication

protocols exist between these devices

and it also opens up new doors for

attack and vulnerabilities because

the consumer products that are out there

are developed

for the individual consumer in mind it's

not ever a security first perspective

and so there's always going to be

something that someone overlooked

and didn't realize existed and there's

always going to be something else for

someone to learn

um as a part about uh as a part of this

so

you know as i move through my career

i'll i'll touch base on some other

things here

i finally became comfortable with myself

and saying

i'm just always going to be learning and

it's not one of those things you say

well if i don't know it i'll look it up

some of these things you can't look up

there is no thing to look up

there's you ran into the end of the road

you're looking at this you know abyss

and saying i can't find the answer i

don't even understand this

and that's where it comes into like

level two of like your knowledge is

well i guess i have to go figure it out

myself and that's

really where that hacking mentality

comes into play so this is where i'm

going to talk about the personalities

in order for you to be extremely good at

this career field

if you decide to go into it if this is

something that you want and you say i'm

going to be good at this

is that there are three things and i

look for these three things and

a big hat tip to one of my initial

mentors

in the field individual named paul

myrick and i worked with me and when i

was in the government

um doing a lot of you know cool stuff

at that point but you know he basically

said and it was a mantra of his which i

picked up on

and the three areas that he said that

will make someone success regardless of

the career field even if you don't

choose

cyber security this is true if you're

gonna become a doctor

an engineer an architect if you're going

to be the best

artist out there you need to have these

free trades otherwise you'll probably

will fail

the first is you have to be passionate

about your chosen

career field you have to love it you you

know you get to the point where

people are paying you to do the thing

that you

love um when i'm at home and i'm my

laptop open and i'm watching something

on the tv and it's 9 pm at night

um you know i have my kids and you know

anyone else is in the room with my wife

saying are you working or are you

playing and i look at them

and i actually don't know how to answer

that question because the answer is

yes to both because you have a passion

for the career field

everything that's about it including the

things that you're researching playing

is like

well this is actually not work to me i

don't feel like i'm working i feel like

i'm learning so there's this constant

passion that you have

about it that you just love it so much

that you wake up you know every single

thing you're absorbing

anything is anyone's throwing you you're

gathering mentors you're asking people

questions

consistently the second one is your

desire to be an expert

is that you don't want to just learn

enough

you want to truly understand

the topic it's it annoys you

when you're you know someone throws it

you know a question you know you have an

an idea for a question and then the

person that answers it you don't need to

worry about that he says well

explain that to me a little bit more i'd

really like to understand

why this one-off area even exists

you know new technologies are released

and you want to understand

how are they able to do that

how are the capabilities in that

thing that now exists exist how does

streaming work

versus something that is on disney plus

is it really the same thing you know is

it using the same backbone

all these different things that exist

out there you're constantly trying to

figure out how to

how it works and if you that annoys you

you start looking at how websites are

developed you're looking at how

protocols are

you're looking at how different you know

you definitely know you're in there if

you're playing video games

and you're thinking about i wonder if i

could cheat on this video game

by hacking a little bit um again

all fits in that desire to be an expert

um as a part of this you know i go

always go back to people that i was

interviewing in my

previous jobs that when we

always found a candidate that was really

good i was always able to find and even

if they're brand new to the field it's

like you know nothing about cyber

security

you want this first job it's an

internship or something like that

and i'm asking all these questions they

said i really like it i'd like it might

be given a chance

i have no experience though so i'm not

an expert so what i end up doing is i

peel back

the onion a little bit and say well tell

me about something that you took on

that you know you drove past

that which got the time of the third one

here that point in which

others say oh this is hard i give up i'm

done

i'm out the door this is you know

difficult and usually i'll be able to

tap into the individual

you know by saying well i took up golf

last summer

and you know my dad played golf i never

really played golf before and i really

wanted to join him

uh playing golf and the individuals say

you know why i didn't know how to play

golf so i just stuck at it you know i'm

not a great golfer but at least i'm you

know double bogey triple bogey at this

point

you know at least i'm out there with my

dad and that's all i care about the fact

that they were able to

get through hey i became good enough

to be able to hang with my dad at that

point

was phenomenal or you potentially say

someone learned a foreign language

because

you know there was an exchange student

who spoke at foreign language

and they were trying to have dialogue

with them and so a lot of people say

well learn a language

they get through a couple days of it and

saying oh that actually learning

languages is hard

they're like nope i want to be able to

at least order food

with the individual or say please and

thank you and make that effort

those are the types of things that

you're saying you know you don't need to

be 100

need uh knee-deep into the i'm a full

expert side but just the facts

that exist that you are willing to get

through

the point in which everyone else quits

and that's the last one is you need to

be willing to

fail and be okay with it if you are

working through anything it says wow

this is hard i'm stuck

um you know can't figure out how to

solve this complex problem

and you know in some cases that means

that you're turning in assignments that

you know have it in

correct answer on it you know it's like

well i couldn't figure it out you know i

tried to get help on it

and i'm i'm done but again it when you

get to that point

even though you already have your grade

but you're still working through the

well exactly what was my approach what

did i get

wrong in that and then you're willing to

fail to

learn and that's really where

the key aspect of all these things above

kind of fall into is that

people who are good at this field or any

field that's out there

have to accept that it's going to get

hard and difficult at some point

and you will not master it immediately

you actually have to be willing to hey

i'm i'm going to be horrible at this and

even make fun of yourself for it hey i'm

the horrible individual

don't ask me how to do it but i'm here

i'm present i'm willing to learn

uh but probably if you want me to

actually get it right and probably it's

not going to happen the first

time you just you can't even make a joke

of it initially but then

you know after about two to three years

of this people say hey you actually know

something now

and then that impostor syndrome syndrome

comes in you have to constantly weigh

that down on both sides of you

uh when you're working through uh these

uh particular issues

when it comes to it so um moving forward

is like what types of cyber security

areas exist which ones would you be kind

of interested in moving into

and you know when you hear cyber

security they just you know typically

think of you know that's the hacker

that's you know

the person back in the uh the bat cave

with the headset

but in reality um cyber security and i t

in general

are closely related we have a lot of

people who start an i.t and move over

into information security and vice versa

um it's mostly because it's like hey

that's interesting i'd like to do that

you know of course everyone says well

what am i going to get paid how am i

going to be able to you know

will i be able to afford an apartment um

i'll tell you

you know i don't know how the field is

going to change over the next you know

five to ten years

um you know i personally know that

there's a lot of 20 year olds are doing

very well for themselves

who've taken on cyber security as a

career field will continue to be that

way

i don't know uh will you definitively be

able to make a career out of this

yes more so now than ever because of the

things i mentioned earlier

so if this is a career field that you're

interested in you know the first one i

i always tell you to take a look at is

just being a generic cyber security

blue team defender um that is

charged with defending a network

defending devices defending

you know making sure that the access of

these networks

uh is controlled and is a part of that

is not just the architecture

and the design of it to make sure that

we don't have

a bunch of holes that someone can

exploit um you know we go into

the example that just happened with

solar winds um this is a big oops moment

um you know again there's a lot of oops

moments in here

but the fact that you have not only your

own stuff in your network that you have

to have

third-party devices you know you have uh

you know all these different

capabilities that you're bringing in

into your own organization

you have to trust that those

organizations are doing their jobs too

to make sure that they're not inserting

their own back doors into it and that's

where

solarwinds kind of happen is that as a

result of an update

um or maybe the code wasn't checked

correctly

the fact that it got uploaded and

distributed to so many organizations

is you know how do we defend against

that and this is where a lot of

folks who are working through the cyber

security engineering side right now

are scratching their heads and saying

what do we do how do we defend this

and how do we detect it once someone's

inside

and you know so as a part of the blue

team side you know and you know mention

this it ties into the next field and

instant response in digital forensics

which is

once you are compromised to go

investigate it but you

have this front and side which is how do

we know we are even compromised

it's not like what you think in the

movies in which you have two

teams red versus blue pounding against

each other like in some sort of cyber

paintball war that's not what's going on

the key here if you're working in the

defense side

is that your aggressors those that are

trying to break into your organization

are trying to do so without alerting the

fact that they're there without alerting

their presence and so it's a game of

stealth it's a game of spy versus spy

and you are in charge just like in you

know i almost

hate to say you know airport security

you're responsible for making sure

nothing bad ever happens and that's a

huge task

you know but it's also one of the more

interesting ones because it's a

consistent problem to solve

and every organization has to deal with

it including

the organization of the family at home

is that you have to make sure you're

protecting

your own number of devices and that's a

question you have you know go look in

your own wi-fi router

or whatever is assigning your ip

addresses in at home how many devices

does your household have at this point

and i guarantee the numbers much larger

than most people realize

how do we make sure each one of those

devices isn't allowing

something in that we didn't know about

at that point

so the overall cyber security engineer

is basically

those who are in charge of defense and

detection of looking for

anything that's bad but also securing it

to the point where it reduces the chance

of bad

ever happening and that last piece there

is really key is that you know

a lot of movies and everything else that

you hear about making it a defensible

network that no one can ever penetrate

into

those things don't exist it's it's you

know the unicorns don't exist this

doesn't exist either

the if you are targeted by an extremely

thoughtful and well-funded adversary

they will eventually be able to break in

the question is can you detect them soon

enough

so they don't achieve their objectives

you know which is what it is that

they're potentially after

my first job um at the 609th was i was

defending ninth air force

um bases from internet attack it was

during the time

and again this is like shows how ancient

i am there was another solar

event that happened back in 1997

an event was called solar sunrise at

that point it was

uh thought to be iraq who was attacking

the pentagon

but ended up being some teenagers in

california

and being mentored by another hacker in

israel

but again at that point everyone was

worried that it was

some major cyber onslaught that was

going to occur at that point

um and i give a lot of credit to

all the rest of the things i did in my

career is

having the defensive background set

first

and really understanding how things work

now the skills i had back then are not

applicable today because the fields

changed

what we were defending back then were

simple things like ftp

and telnet which people don't worry

about near as much anymore they

completely block those but at that point

it was a brand new thing you know

so i cannot use the skills i learned

over 20 years ago

to become a decent cyber defender today

your skills have progressed

all the technology and ways to do that

have also progressed

all right the second one i'll talk about

is digital forensics

when i left uh the 609th down in south

carolina i was pulled into the air force

offices special investigations it was a

unit i was in charge of

called the technical monitoring team so

in this case my job

was to work with agents who were

investigating incidents that happened in

the air force

when um an intruder an intrusion if it

happened

meaning that a hacker broke into an air

force network they would call us in we

would be the tech people just like you

see on the tv in this case

sit at the desk but it's much less sexy

than what you believe

is that we had to figure out how they

broke in and we had to do it through

both setting up uh wiretaps and

monitoring the network looking for where

the attacker was

but also starting to do digital

forensics on the affected devices

and this is you know way before there

was anything any software that was out

there

uh on learning how to do and track

adversary activity

inside the network um and the thing

about digital forensics is it's

really when bad things happen

these individuals are called to come in

and respond to it

investigate it and make recommendations

as to how to prevent the attack in the

future

and then that is potentially then

attributed over back to the blue team

defenders

to say well how do we potentially

prevent that based on what they found

so digital forensics is a blue team

field but it's mostly when bad things

happen this is the team that comes in

and does the response

um and this is where i spent a large

portion of my career

honing my skills initially was on

network forensics

then unix forensics then windows

forensics but

just like if someone asks you well how

good are you at smartphone forensics

i'll say i've no idea what i'm doing i

mean i understand the concepts behind i

understand what's possibly there

but i've never done a smartphone in my

life i rely on others

to who are experts in smartphone

forensics to be able to do that

smartphone analysis

so even within these subfields there's

there are niches that you potentially

get

into and each one of them has as much

knowledge as you would find if you're

becoming a doctor and then taking a

niche field saying i'm gonna become

a podiatrist or i'm gonna become uh you

know a neurosurgeon

is that you end up having to say okay

here's my understand the basics of being

a doctor then i'm going to take the

field a step further

and so each one of these has as much

knowledge out there as possible

when you're potentially approaching this

um i found a lot of fun for hunting

the bad guys in these networks and we

started calling hunting back then too

the first major incident that was in um

was

again over 20 years ago in 1998

um it was a nation-stated attacker it

was one of the first times uh that it

really became public that we had a

nation state attacker

uh hitting uh research installations and

you know across the united states at

that point it was the russians

um and the russians were uh

hacking multiple locations and we were

basically using

our knowledge of their tools techniques

and procedures

how they're working

um this one's really interesting because

people say you cannot make a career

out of being an attacker that is

patently incorrect um today especially

more so than ever

a lot of organizations are very

interested in seeing how

attackers think operate and might be

able to break in their own networks

this is the like you saw the movies that

are out there one of the best movies

you could probably go watch to really

kind of understand what the concept here

is

is a movie called sneakers i know it's

old has robert redford and a bunch of

other folks in and you're like wow i

think that guy's like

really old yeah they're really old but

they have this concept of how do you

break in an organization

to be able to see where they're

vulnerable

um and it encompasses not only

human interaction we try to exploit the

human but also network

and host-based exploitation to be able

to see how someone breaks into a network

to be able to do that today we use this

across the board

for being able to examine whether

applications are vulnerable

how attackers might be able to break in

we even have a lot of organizations

usually the larger ones

will actually pay groups to emulate

specific type of nation-state

adversaries and they call that threat

emulation

there's also an aspect of this that blue

team defenders

become better blue team defenders if

they learn how to be a red team

an attacker using offensive skills how

to break in the network

because once they learn how to break

into something they actually learn how

to defend it better

this is called purple teaming uh because

it has the red and blue together

and they really have this you know

sharing of knowledge back and forth that

says in order for me to

defend something i need to know how an

attacker thinks in order to break in

and that's where this amalgamation of

both sides ends up really crossing over

um and it's one of the things when i was

in the field and i

i worked in offensive operations for

some point but my digital forensics

background really helped out inform the

offensive side of what i was learning at

that point

and vice versa and now after i worked in

the offensive side for a while

my digital forensic score skills

actually exploded because i

realized what i didn't know at that

point again in that consistent

learning umbrella environment that you

find yourself in

and so the offensive operations you know

it's you know you also have you know the

military the cyber warfare stuff that

exists in there

um and those fields definitely exist

across the planet too

um you know again the way i try to

categorize it you try to hack for the

good guys

but you know the major employment factor

here for offensive operations

is like i was saying is that you're

teaching organizations how to defend

against a really well-skilled attacker

um and it also helps inform the defense

here a lot so

a lot of people see that this is hacking

this is the way to go forward

i have found that people ask me should i

go directly into offense i would

actually tell them no

i would say start with uh start with

defense initially and then move into

offense there's a lot of

you know a lot of people say i'd like to

do both that's fine too

but i've actually seen people succeed a

little bit better by moving from defense

to offense

as a part of their you know if i'm going

to make the wrongs of learning where

would i go

part of the reason why is that offensive

stuff tends to age out

more quickly than the defensive stuff

what worked yesterday is not going to

work today as soon as it's patched

so there's certain truths to it but it's

such a consistently evolving field that

it's a week-to-week

update basis that you have to be on

versus

uh some of the ones on defense where you

have to say okay we're

practicing good hygiene making sure

people are not um

you know getting uh hit with um phishing

attacks and so forth

but the concept of the offensive

operation exists the same

the last one i'll mention to you here

and this is kind of an amalgamation

between several of the fields and blue

team and everything else

which is talking about ics security um

in ics security really is dealing with

those

parts of society um and you know i know

robert emily talked about this a lot

yesterday too

but when you're starting to talk about

infrastructure security

um where the electrical grid where you

end up being able to have the stop

lights outside

everything in what you see outside is

now connected to

a network somehow and you know going

back to the standard double lead classes

some of those things are programmed on

these devices

that are really old that basically it's

a turn switch left turn switch right

and basically you know to stop light at

that point says either go

not go but there's something that's

controlling that on the back inside that

is then connected to a network

and then attackers will try to reach in

to get to these devices

to do whatever i mean and this is where

you know you're you know the movies have

done

a very fantastic job of trying to

explain this but it's also a very

fascinating field that i

really recommend folks look into you

after you initially progress

uh through the blue team uh side so to

close out this presentation

um a lot of people say well where do i

start what do i where do i begin

is that there are many ways into cyber

security but don't forget about the

personality traits that i told you just

it doesn't matter if you get a cert

first or if you get a formal education

if you're willing to just learn on any

technology basis in front of you

the cyberstart program the ctf sign up

for every single thing that's free

buy free get free books there's a ton of

them use google there's

magazines that back in the late 90s

early 2000s we read consistently called

frack

i mean there's so many resources out

there you don't have to spend any money

on

and still get going and then look for

opportunities even if you're working at

best buy in the geek squad as an

intern anything that is consistently

exposing you to technology

is going to be another point forward in

your path

to becoming an expert just as long as

you have this passionate desire to be an

expert and willingness to fail

i also recommend do not specialize too

soon um

be open to many different ideas of what

cybersecurity

could do the third one a lot of people

will take me to task on this one

but no you do not need to code first

coding is something that i'd recommend

that you learn along the way or at least

be familiar with

master one language a bit but are you

are you coding on a daily basis

you ask anyone cyber security the answer

is no but the coding fundamentals that

it exposes you to

in terms of the computer science things

that are important

that is going to be fundamental you know

the how those things work behind the

scenes

is going to translate perfectly into the

cyber security career field

do you need to code on a daily basis no

it's more

just like everyone in school eventually

has to take a foreign language class

yes just like that take a language class

at some point

become familiar with it even though i

don't code on a daily basis anymore

those coding fundamentals that i end up

having are

still educating me on a day-to-day basis

as i said before take part in all the

online programs competitions that you

could get a hand of

uh james lyons ctf with lauren's

cyberstart program

um understand what you're uh getting

yourself into there but it's fun

and then finally uh the last few aspects

of this is number

i'll start with the last one never stop

learning always understand that

no one is an expert challenge those who

are affirmative

the two words i always like to uh throw

people who are saying oh this is exactly

what's happening

cool show me especially when you're new

those two words are very powerful can

you show me how that works

and some cases like well you know you

know you get this you know

hand wavy thing that sometimes occurs

just understand that they may be

uh bluffing there too they actually may

not know what they're talking about

but and that's where you start to

realize wow no one actually knows

everything

once you get there you know you're in

the right spot and then finally this was

a very

very very important one the more you

learn

the more you have to understand with

great power comes great responsibility

you will be able to do things with your

newfound superpowers

others cannot do you have to realize

that you cannot cross the line

of when you're looking at how you're

employing these skills

in your day-to-day life you can find

yourself in trouble

just experimenting and just understand

if you have questions on that get a

mentor you know this is why a lot of

people set up their own home networks to

be able to do things on their

own stuff just you know understand if

you don't personally own it

you need to get permission to talk to

someone about using your newfound

superpower skills

against that the online programs

competition really good thing in there

but even those

you have to sign up you have to accept

you uh all those things that are

involved there

understand that as you're learning

you're gonna learn things no one else

has a capability of understanding

but just with great power comes great

responsibility

uh and with that i'm gonna open it up to

any questions that folks have i really

appreciate being invited to give this

talk

and i hope you have a couple takeaways

that come from it

thank you

you

